{"title": "Findings of the Association for Computational Linguistics: ACL 2022", "url": "https://aclanthology.org/2022.findings-acl.0/", "abstract": "findings-2022-findings", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関するACL 2022の研究成果についての要約です。", "jabstract": "1. Natural language processing (NLP) is a field of study that focuses on the interaction between human language and computers.\n自然言語処理（NLP）は、人間の言語とコンピュータの相互作用に焦点を当てた研究分野です。\n\n2. NLP has become increasingly important in recent years due to the growth of digital data and the need to extract meaningful information from it.\nデジタルデータの増加と、その中から意味のある情報を抽出する必要性の高まりにより、NLPは近年ますます重要になっています。\n\n3. NLP techniques are used in a variety of applications, including machine translation, sentiment analysis, and speech recognition.\n機械翻訳、感情分析、音声認識など、NLP技術はさまざまなアプリケーションで使用されています。\n\n4. Despite significant progress in NLP, there are still many challenges to be addressed, such as understanding the nuances of human language and developing more accurate models.\nNLPにおける重要な進展があるにもかかわらず、人間の言語の微妙なニュアンスを理解することや、より正確なモデルを開発することなど、解決すべき課題はまだ多くあります。"}
{"title": "“Is Whole Word Masking Always Better for Chinese BERT?”: Probing on Chinese Grammatical Error Correction", "url": "https://aclanthology.org/2022.findings-acl.1/", "abstract": "Whole word masking (WWM), which masks all subwords corresponding to a word at once, makes a better English BERT model. For the Chinese language, however, there is no subword because each token is an atomic character. The meaning of a word in Chinese is different in that a word is a compositional unit consisting of multiple characters. Such difference motivates us to investigate whether WWM leads to better context understanding ability for Chinese BERT. To achieve this, we introduce two probing tasks related to grammatical error correction and ask pretrained models to revise or insert tokens in a masked language modeling manner. We construct a dataset including labels for 19,075 tokens in 10,448 sentences. We train three Chinese BERT models with standard character-level masking (CLM), WWM, and a combination of CLM and WWM, respectively. Our major findings are as follows: First, when one character needs to be inserted or replaced, the model trained with CLM performs the best. Second, when more than one character needs to be handled, WWM is the key to better performance. Finally, when being fine-tuned on sentence-level downstream tasks, models trained with different masking strategies perform comparably.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「全単語マスキングは常に中国語BERTにとって良いのか？」：中国語文法エラー修正における探査", "jabstract": "全単語マスキング（WWM）は、一度に単語に対応するすべてのサブワードをマスクするため、英語のBERTモデルをより良くします。しかし、中国語では、各トークンが原子文字であるため、サブワードは存在しません。中国語における単語の意味は、複数の文字から構成される合成単位である点が異なります。このような違いから、WWMが中国語BERTの文脈理解能力を向上させるかどうかを調査することにしました。このために、文法エラー修正に関連する2つのプロービングタスクを導入し、事前学習モデルにマスクされた言語モデリングの方法でトークンを修正または挿入するように求めます。19,075トークンのラベルを含む10,448の文を含むデータセットを構築します。標準的な文字レベルマスキング（CLM）、WWM、およびCLMとWWMの組み合わせの3つの中国語BERTモデルをトレーニングします。主な発見は次のとおりです。まず、1つの文字を挿入または置換する必要がある場合、CLMでトレーニングされたモデルが最も優れています。第二に、複数の文字を処理する必要がある場合、WWMがより良いパフォーマンスの鍵です。最後に、文レベルのダウンストリームタスクで微調整される場合、異なるマスキング戦略でトレーニングされたモデルのパフォーマンスは同等です。"}
{"title": "Compilable Neural Code Generation with Compiler Feedback", "url": "https://aclanthology.org/2022.findings-acl.2/", "abstract": "Automatically generating compilable programs with (or without) natural language descriptions has always been a touchstone problem for computational linguistics and automated software engineering. Existing deep-learning approaches model code generation as text generation, either constrained by grammar structures in decoder, or driven by pre-trained language models on large-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of them account for compilability of the generated programs. To improve compilability of the generated programs, this paper proposes COMPCODER, a three-stage pipeline utilizing compiler feedback for compilable code generation, including language model fine-tuning, compilability reinforcement, and compilability discrimination. Comprehensive experiments on two code generation tasks demonstrate the effectiveness of our proposed approach, improving the success rate of compilation from 44.18 to 89.18 in code completion on average and from 70.3 to 96.2 in text-to-code generation, respectively, when comparing with the state-of-the-art CodeGPT.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "コンパイラフィードバックを用いたコンパイル可能なニューラルコード生成", "jabstract": "自然言語記述を用いたコンパイル可能なプログラムの自動生成は、計算言語学と自動ソフトウェアエンジニアリングにおける基準的な問題である。既存の深層学習アプローチは、コード生成をテキスト生成としてモデル化し、デコーダー内の文法構造によって制約されるか、大規模なコードコーパス（CodeGPT、PLBART、CodeT5など）の事前学習言語モデルによって駆動される。しかし、これらのアプローチのほとんどは、生成されたプログラムのコンパイル可能性を考慮していない。本論文では、生成されたプログラムのコンパイル可能性を向上させるために、コンパイラのフィードバックを利用した3段階のパイプラインであるCOMPCODERを提案する。このパイプラインは、言語モデルの微調整、コンパイル可能性の強化、およびコンパイル可能性の識別を含む。2つのコード生成タスクに対する包括的な実験は、提案手法の効果を示し、CodeGPTと比較して、コード補完におけるコンパイル成功率を平均で44.18から89.18に、テキストからコード生成においては70.3から96.2に向上させた。"}
{"title": "Towards Unifying the Label Space for Aspect- and Sentence-based Sentiment Analysis", "url": "https://aclanthology.org/2022.findings-acl.3/", "abstract": "The aspect-based sentiment analysis (ABSA) is a fine-grained task that aims to determine the sentiment polarity towards targeted aspect terms occurring in the sentence. The development of the ABSA task is very much hindered by the lack of annotated data. To tackle this, the prior works have studied the possibility of utilizing the sentiment analysis (SA) datasets to assist in training the ABSA model, primarily via pretraining or multi-task learning. In this article, we follow this line, and for the first time, we manage to apply the Pseudo-Label (PL) method to merge the two homogeneous tasks. While it seems straightforward to use generated pseudo labels to handle this case of label granularity unification for two highly related tasks, we identify its major challenge in this paper and propose a novel framework, dubbed as Dual-granularity Pseudo Labeling (DPL). Further, similar to PL, we regard the DPL as a general framework capable of combining other prior methods in the literature. Through extensive experiments, DPL has achieved state-of-the-art performance on standard benchmarks surpassing the prior work significantly.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「アスペクトおよび文ベースの感情分析のためのラベル空間の統一に向けて」", "jabstract": "アスペクトベースの感情分析（ABSA）は、文中に出現する対象アスペクト用語に対する感情極性を決定する微細なタスクです。ABSAタスクの開発は、注釈付きデータの不足によって非常に妨げられています。これを解決するために、以前の研究では、主に事前学習またはマルチタスク学習を介して、感情分析（SA）データセットをABSAモデルのトレーニングに利用する可能性を研究してきました。本稿では、このラインに従い、初めて擬似ラベル（PL）法を適用して、2つの同質なタスクを統合することに成功しました。2つの高度に関連するタスクのこのラベルの粒度の統一の場合に生成された擬似ラベルを使用することは簡単に思えますが、本稿ではその主要な課題を特定し、デュアル粒度擬似ラベリング（DPL）と呼ばれる新しいフレームワークを提案します。さらに、PLと同様に、DPLを文献中の他の先行方法を組み合わせることができる一般的なフレームワークと見なしています。広範な実験により、DPLは、先行研究を大幅に上回る標準ベンチマークで最先端のパフォーマンスを達成しました。"}
{"title": "Input-specific Attention Subnetworks for Adversarial Detection", "url": "https://aclanthology.org/2022.findings-acl.4/", "abstract": "Self-attention heads are characteristic of Transformer models and have been well studied for interpretability and pruning. In this work, we demonstrate an altogether different utility of attention heads, namely for adversarial detection. Specifically, we propose a method to construct input-specific attention subnetworks (IAS) from which we extract three features to discriminate between authentic and adversarial inputs. The resultant detector significantly improves (by over 7.5%) the state-of-the-art adversarial detection accuracy for the BERT encoder on 10 NLU datasets with 11 different adversarial attack types. We also demonstrate that our method (a) is more accurate for larger models which are likely to have more spurious correlations and thus vulnerable to adversarial attack, and (b) performs well even with modest training sets of adversarial examples.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "入力特異的な注意サブネットワークによる敵対的検出", "jabstract": "セルフアテンションヘッドはTransformerモデルの特徴であり、解釈性と剪定についてよく研究されています。本研究では、アテンションヘッドの全く異なる用途、すなわち敵対的検出について示します。具体的には、入力固有のアテンションサブネットワーク(IAS)を構築する方法を提案し、真正と敵対的な入力を区別するために3つの特徴を抽出します。その結果、BERTエンコーダーに対する10のNLUデータセットと11種類の敵対的攻撃タイプに対する最新の敵対的検出精度を7.5％以上改善する検出器が得られました。また、本手法が(a)より大きなモデルに対してより正確であり、偽の相関がより多く存在し、敵対的攻撃に対して脆弱である可能性があること、および(b)敵対的な例のわずかなトレーニングセットでも良好な性能を発揮することを示しました。"}
{"title": "RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction", "url": "https://aclanthology.org/2022.findings-acl.5/", "abstract": "Despite the importance of relation extraction in building and representing knowledge, less research is focused on generalizing to unseen relations types. We introduce the task setting of Zero-Shot Relation Triplet Extraction (ZeroRTE) to encourage further research in low-resource relation extraction methods. Given an input sentence, each extracted triplet consists of the head entity, relation label, and tail entity where the relation label is not seen at the training stage. To solve ZeroRTE, we propose to synthesize relation examples by prompting language models to generate structured texts. Concretely, we unify language model prompts and structured text approaches to design a structured prompt template for generating synthetic relation samples when conditioning on relation label prompts (RelationPrompt). To overcome the limitation for extracting multiple relation triplets in a sentence, we design a novel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL datasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot relation classification. Our code and data are available at github.com/declare-lab/RelationPrompt.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "RelationPrompt：プロンプトを活用して、ゼロショット関係トリプレット抽出のための合成データを生成する", "jabstract": "関係抽出は知識の構築と表現において重要であるにもかかわらず、未知の関係タイプに一般化する研究は少ない。我々は、低リソースの関係抽出手法に関するさらなる研究を促進するために、Zero-Shot Relation Triplet Extraction (ZeroRTE)のタスク設定を紹介する。入力文が与えられた場合、各抽出されたトリプレットは、ヘッドエンティティ、関係ラベル、およびテールエンティティから構成され、関係ラベルはトレーニング段階で見られない。ZeroRTEを解決するために、言語モデルをプロンプトして構造化されたテキストを生成することにより、関係例を合成することを提案する。具体的には、言語モデルのプロンプトと構造化されたテキストのアプローチを統一して、構造化されたプロンプトテンプレートを設計し、関係ラベルプロンプトに条件付けるときに合成関係サンプルを生成する（RelationPrompt）。文中の複数の関係トリプレットを抽出する制限を克服するために、新しいTriplet Search Decoding方法を設計する。FewRelとWiki-ZSLデータセットでの実験は、RelationPromptがZeroRTEタスクとゼロショット関係分類において有効であることを示している。我々のコードとデータはgithub.com/declare-lab/RelationPromptで利用可能である。"}
{"title": "Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?", "url": "https://aclanthology.org/2022.findings-acl.6/", "abstract": "What can pre-trained multilingual sequence-to-sequence models like mBART contribute to translating low-resource languages? We conduct a thorough empirical experiment in 10 languages to ascertain this, considering five factors: (1) the amount of fine-tuning data, (2) the noise in the fine-tuning data, (3) the amount of pre-training data in the model, (4) the impact of domain mismatch, and (5) language typology. In addition to yielding several heuristics, the experiments form a framework for evaluating the data sensitivities of machine translation systems. While mBART is robust to domain differences, its translations for unseen and typologically distant languages remain below 3.0 BLEU. In answer to our title’s question, mBART is not a low-resource panacea; we therefore encourage shifting the emphasis from new models to new data.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習された多言語シーケンス・ツー・シーケンスモデル：低資源言語翻訳の希望か？", "jabstract": "mBARTのような事前学習済みの多言語シーケンス・ツー・シーケンスモデルは、低リソース言語の翻訳にどのような貢献をすることができるのか？我々は、10の言語で5つの要因を考慮して、徹底的な実験を行い、そのことを確認する。それらの要因は、(1)ファインチューニングデータの量、(2)ファインチューニングデータのノイズ、(3)モデルの事前学習データの量、(4)ドメインの不一致の影響、および(5)言語のタイポロジーである。実験は、いくつかのヒューリスティックを生み出すだけでなく、機械翻訳システムのデータ感度を評価するためのフレームワークを形成する。mBARTはドメインの違いに対して堅牢であるが、未知の言語やタイポロジー的に遠い言語の翻訳は3.0 BLEU以下にとどまる。我々のタイトルの質問に答えると、mBARTは低リソースの万能薬ではないため、新しいモデルよりも新しいデータに重点を置くことを推奨する。"}
{"title": "Multi-Scale Distribution Deep Variational Autoencoder for Explanation Generation", "url": "https://aclanthology.org/2022.findings-acl.7/", "abstract": "Generating explanations for recommender systems is essential for improving their transparency, as users often wish to understand the reason for receiving a specified recommendation. Previous methods mainly focus on improving the generation quality, but often produce generic explanations that fail to incorporate user and item specific details. To resolve this problem, we present Multi-Scale Distribution Deep Variational Autoencoders (MVAE).These are deep hierarchical VAEs with a prior network that eliminates noise while retaining meaningful signals in the input, coupled with a recognition network serving as the source of information to guide the learning of the prior network. Further, the Multi-scale distribution Learning Framework (MLF) along with a Target Tracking Kullback-Leibler divergence (TKL) mechanism are proposed to employ multi KL divergences at different scales for more effective learning. Extensive empirical experiments demonstrate that our methods can generate explanations with concrete input-specific contents.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "説明生成のためのマルチスケール分布深層変分オートエンコーダー", "jabstract": "推薦システムの説明を生成することは、特定の推薦を受け取った理由を理解したいというユーザーの要望に応えるために、透明性を向上させるために不可欠である。従来の方法は主に生成品質の向上に焦点を当てていたが、ユーザーとアイテムの特定の詳細を組み込まない一般的な説明を生成することが多かった。この問題を解決するために、私たちはMulti-Scale Distribution Deep Variational Autoencoders（MVAE）を提案する。これらは、入力の意味のある信号を保持しながらノイズを除去する事前ネットワークを持つ深層階層VAEであり、事前ネットワークの学習をガイドする情報源として機能する認識ネットワークが組み合わされている。さらに、マルチスケール分布学習フレームワーク（MLF）とターゲットトラッキングクルバック・ライブラー分散（TKL）メカニズムを提案し、より効果的な学習のために異なるスケールで複数のKL分散を使用する。広範な実験により、私たちの方法が具体的な入力固有の内容を持つ説明を生成できることが示された。"}
{"title": "Dual Context-Guided Continuous Prompt Tuning for Few-Shot Learning", "url": "https://aclanthology.org/2022.findings-acl.8/", "abstract": "Prompt-based paradigm has shown its competitive performance in many NLP tasks. However, its success heavily depends on prompt design, and the effectiveness varies upon the model and training data. In this paper, we propose a novel dual context-guided continuous prompt (DCCP) tuning method. To explore the rich contextual information in language structure and close the gap between discrete prompt tuning and continuous prompt tuning, DCCP introduces two auxiliary training objectives and constructs input in a pair-wise fashion.Experimental results demonstrate that our method is applicable to many NLP tasks, and can often outperform existing prompt tuning methods by a large margin in the few-shot setting.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「デュアルコンテキストガイドの継続的なプロンプト調整によるフューショット学習」は、自然言語処理に関する論文の要約です。", "jabstract": "プロンプトベースのパラダイムは、多くのNLPタスクで競争力のあるパフォーマンスを示しています。しかし、その成功はプロンプトの設計に大きく依存し、効果はモデルとトレーニングデータによって異なります。本論文では、新しいデュアルコンテキストガイドの連続プロンプト（DCCP）チューニング方法を提案します。言語構造の豊富な文脈情報を探索し、離散的なプロンプトチューニングと連続的なプロンプトチューニングのギャップを埋めるために、DCCPは2つの補助トレーニング目的を導入し、入力をペアワイズで構築します。実験結果は、当社の方法が多くのNLPタスクに適用可能であり、フューショット設定では既存のプロンプトチューニング方法を大幅に上回ることがよく示されています。"}
{"title": "Extract-Select: A Span Selection Framework for Nested Named Entity Recognition with Generative Adversarial Training", "url": "https://aclanthology.org/2022.findings-acl.9/", "abstract": "Nested named entity recognition (NER) is a task in which named entities may overlap with each other. Span-based approaches regard nested NER as a two-stage span enumeration and classification task, thus having the innate ability to handle this task. However, they face the problems of error propagation, ignorance of span boundary, difficulty in long entity recognition and requirement on large-scale annotated data. In this paper, we propose Extract-Select, a span selection framework for nested NER, to tackle these problems. Firstly, we introduce a span selection framework in which nested entities with different input categories would be separately extracted by the extractor, thus naturally avoiding error propagation in two-stage span-based approaches. In the inference phase, the trained extractor selects final results specific to the given entity category. Secondly, we propose a hybrid selection strategy in the extractor, which not only makes full use of span boundary but also improves the ability of long entity recognition. Thirdly, we design a discriminator to evaluate the extraction result, and train both extractor and discriminator with generative adversarial training (GAT). The use of GAT greatly alleviates the stress on the dataset size. Experimental results on four benchmark datasets demonstrate that Extract-Select outperforms competitive nested NER models, obtaining state-of-the-art results. The proposed model also performs well when less labeled data are given, proving the effectiveness of GAT.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Extract-Select：生成的対抗トレーニングを用いたネストされた固有表現認識のためのスパン選択フレームワーク」についての論文の要約です。", "jabstract": "ネストされた固有表現認識（NER）は、固有表現が互いに重複する可能性があるタスクです。スパンベースのアプローチは、ネストされたNERを2段階のスパン列挙と分類タスクとして扱うため、このタスクを処理するための本来の能力を持っています。しかし、エラー伝播、スパン境界の無視、長いエンティティ認識の困難さ、大規模な注釈付きデータの要件などの問題に直面しています。本論文では、これらの問題に対処するために、ネストされたNERのスパン選択フレームワークであるExtract-Selectを提案します。まず、入力カテゴリが異なるネストされたエンティティが抽出器によって別々に抽出されるスパン選択フレームワークを導入し、2段階のスパンベースのアプローチにおけるエラー伝播を自然に回避します。推論フェーズでは、トレーニングされた抽出器が、与えられたエンティティカテゴリに特化した最終結果を選択します。次に、スパン境界を最大限に活用するだけでなく、長いエンティティ認識の能力を向上させるハイブリッド選択戦略を抽出器に提案します。第三に、抽出結果を評価するディスクリミネータを設計し、生成的対抗トレーニング（GAT）で抽出器とディスクリミネータの両方をトレーニングします。GATの使用により、データセットサイズに対するストレスが大幅に軽減されます。4つのベンチマークデータセットでの実験結果は、Extract-Selectが競合するネストされたNERモデルを上回り、最先端の結果を得ることを示しています。提案されたモデルは、ラベル付きデータが少ない場合でも良好なパフォーマンスを発揮し、GATの有効性を証明しています。"}
{"title": "Controlled Text Generation Using Dictionary Prior in Variational Autoencoders", "url": "https://aclanthology.org/2022.findings-acl.10/", "abstract": "While variational autoencoders (VAEs) have been widely applied in text generation tasks, they are troubled by two challenges: insufficient representation capacity and poor controllability. The former results from the posterior collapse and restrictive assumption, which impede better representation learning. The latter arises as continuous latent variables in traditional formulations hinder VAEs from interpretability and controllability. In this paper, we propose Dictionary Prior (DPrior), a new data-driven prior that enjoys the merits of expressivity and controllability. To facilitate controlled text generation with DPrior, we propose to employ contrastive learning to separate the latent space into several parts. Extensive experiments on both language modeling and controlled text generation demonstrate the effectiveness of the proposed approach.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "辞書事前情報を用いた変分オートエンコーダーによる制御されたテキスト生成", "jabstract": "変分オートエンコーダー（VAE）は、テキスト生成タスクで広く使用されていますが、不十分な表現能力と制御性の低さという2つの課題に直面しています。前者は事後崩壊と制限的な仮定によるもので、より良い表現学習を妨げます。後者は、従来の定式化における連続的な潜在変数がVAEの解釈性と制御性を妨げるために発生します。本論文では、表現力と制御性の利点を持つ新しいデータ駆動型の事前分布であるDictionary Prior（DPrior）を提案します。DPriorを使用した制御されたテキスト生成を容易にするために、潜在空間をいくつかの部分に分割するために対比学習を使用することを提案します。言語モデリングと制御されたテキスト生成の両方における広範な実験は、提案手法の有効性を示しています。"}
{"title": "Challenges to Open-Domain Constituency Parsing", "url": "https://aclanthology.org/2022.findings-acl.11/", "abstract": "Neural constituency parsers have reached practical performance on news-domain benchmarks. However, their generalization ability to other domains remains weak. Existing findings on cross-domain constituency parsing are only made on a limited number of domains. Tracking this, we manually annotate a high-quality constituency treebank containing five domains. We analyze challenges to open-domain constituency parsing using a set of linguistic features on various strong constituency parsers. Primarily, we find that 1) BERT significantly increases parsers’ cross-domain performance by reducing their sensitivity on the domain-variant features.2) Compared with single metrics such as unigram distribution and OOV rate, challenges to open-domain constituency parsing arise from complex features, including cross-domain lexical and constituent structure variations.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "オープンドメイン構成解析への課題", "jabstract": "ニュースドメインのベンチマークにおいて、ニューラル構成解析器は実用的な性能を達成しています。しかし、他のドメインへの一般化能力は弱いままです。クロスドメイン構成解析に関する既存の研究結果は、限られた数のドメインにしか適用されていません。この問題に対処するため、私たちは5つのドメインを含む高品質の構成木バンクを手動で注釈しました。私たちは、さまざまな強力な構成解析器に対して、言語的特徴のセットを用いて、オープンドメインの構成解析に対する課題を分析しました。主に、私たちは以下のことを発見しました。1）BERTは、ドメイン固有の特徴に対する解析器の感度を低下させることにより、解析器のクロスドメイン性能を大幅に向上させます。2）単語分布やOOV率などの単一のメトリックと比較して、オープンドメインの構成解析に対する課題は、クロスドメインの語彙や構成要素の変化などの複雑な特徴から生じます。"}
{"title": "Going “Deeper”: Structured Sememe Prediction via Transformer with Tree Attention", "url": "https://aclanthology.org/2022.findings-acl.12/", "abstract": "Sememe knowledge bases (SKBs), which annotate words with the smallest semantic units (i.e., sememes), have proven beneficial to many NLP tasks. Building an SKB is very time-consuming and labor-intensive. Therefore, some studies have tried to automate the building process by predicting sememes for the unannotated words. However, all existing sememe prediction studies ignore the hierarchical structures of sememes, which are important in the sememe-based semantic description system. In this work, we tackle the structured sememe prediction problem for the first time, which is aimed at predicting a sememe tree with hierarchical structures rather than a set of sememes. We design a sememe tree generation model based on Transformer with adjusted attention mechanism, which shows its superiority over the baselines in experiments. We also conduct a series of quantitative and qualitative analyses of the effectiveness of our model. All the code and data of this paper are available at https://github.com/thunlp/STG.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「より深く」進む：木構造アテンションを用いたTransformerによる構造化された意味素予測", "jabstract": "セメム知識ベース（SKB）は、単語に最小の意味単位（すなわちセメム）を注釈付けすることで、多くのNLPタスクに有益であることが証明されています。SKBの構築は非常に時間がかかり、労力が必要です。そのため、いくつかの研究では、注釈のない単語のセメムを予測することによって、構築プロセスを自動化しようと試みています。しかし、すべての既存のセメム予測研究は、セメムの階層構造を無視しています。この階層構造は、セメムベースの意味記述システムにおいて重要です。本研究では、階層構造を持つセメムツリーを予測することを目的とした、構造化されたセメム予測問題に初めて取り組みます。私たちは、調整されたアテンションメカニズムを持つTransformerに基づくセメムツリー生成モデルを設計し、実験でベースラインよりも優れた性能を示しました。また、モデルの有効性に関する一連の定量的および定性的分析を行いました。本論文のすべてのコードとデータは、https://github.com/thunlp/STGで入手可能です。"}
{"title": "Table-based Fact Verification with Self-adaptive Mixture of Experts", "url": "https://aclanthology.org/2022.findings-acl.13/", "abstract": "The table-based fact verification task has recently gained widespread attention and yet remains to be a very challenging problem. It inherently requires informative reasoning over natural language together with different numerical and logical reasoning on tables (e.g., count, superlative, comparative). Considering that, we exploit mixture-of-experts and present in this paper a new method: Self-adaptive Mixture-of-Experts Network (SaMoE). Specifically, we have developed a mixture-of-experts neural network to recognize and execute different types of reasoning—the network is composed of multiple experts, each handling a specific part of the semantics for reasoning, whereas a management module is applied to decide the contribution of each expert network to the verification result. A self-adaptive method is developed to teach the management module combining results of different experts more efficiently without external knowledge. The experimental results illustrate that our framework achieves 85.1% accuracy on the benchmark dataset TabFact, comparable with the previous state-of-the-art models. We hope our framework can serve as a new baseline for table-based verification. Our code is available at https://github.com/THUMLP/SaMoE.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自己適応混合専門家を用いた表ベースの事実検証", "jabstract": "表ベースの事実検証タスクは最近広く注目されており、非常に困難な問題であることがまだ残っています。それは、自然言語に関する情報的推論と、表上の異なる数値的および論理的推論（例：数え上げ、最上級、比較）を組み合わせた推論が本質的に必要です。そのような状況を考慮して、我々は専門家の混合を利用し、新しい手法である自己適応型専門家混合ネットワーク（SaMoE）を提案します。具体的には、専門家の複数のネットワークから構成される混合専門家ニューラルネットワークを開発し、推論のための意味の特定の部分を処理する各専門家があり、管理モジュールが各専門家ネットワークの貢献を決定するように適用されます。外部の知識なしに、異なる専門家の結果をより効率的に組み合わせるための自己適応型方法が開発されています。実験結果は、当社のフレームワークがベンチマークデータセットTabFactで85.1％の精度を達成し、以前の最先端モデルと比較可能であることを示しています。当社のフレームワークが表ベースの検証の新しいベースラインとして機能することを望みます。当社のコードはhttps://github.com/THUMLP/SaMoEで利用可能です。"}
{"title": "Investigating Data Variance in Evaluations of Automatic Machine Translation Metrics", "url": "https://aclanthology.org/2022.findings-acl.14/", "abstract": "Current practices in metric evaluation focus on one single dataset, e.g., Newstest dataset in each year’s WMT Metrics Shared Task. However, in this paper, we qualitatively and quantitatively show that the performances of metrics are sensitive to data. The ranking of metrics varies when the evaluation is conducted on different datasets. Then this paper further investigates two potential hypotheses, i.e., insignificant data points and the deviation of i.i.d assumption, which may take responsibility for the issue of data variance. In conclusion, our findings suggest that when evaluating automatic translation metrics, researchers should take data variance into account and be cautious to report the results on unreliable datasets, because it may leads to inconsistent results with most of the other datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自動機械翻訳メトリックの評価におけるデータの分散を調査する。", "jabstract": "現在のメトリック評価の実践は、例えばWMT Metrics Shared Taskの毎年のNewstestデータセットなど、1つのデータセットに焦点を当てています。しかし、本論文では、メトリックのパフォーマンスがデータに敏感であることを定性的・定量的に示しました。評価が異なるデータセットで実施されると、メトリックのランキングが変化します。その後、本論文では、データの分散の問題に責任を負う可能性がある、つまり無視できないデータポイントとi.i.d仮定の偏差を調査しました。結論として、自動翻訳メトリックを評価する際には、研究者はデータの分散を考慮し、信頼性の低いデータセットでの結果を報告する際には注意が必要です。そうしないと、他のほとんどのデータセットと一致しない不一致な結果につながる可能性があります。"}
{"title": "Sememe Prediction for BabelNet Synsets using Multilingual and Multimodal Information", "url": "https://aclanthology.org/2022.findings-acl.15/", "abstract": "In linguistics, a sememe is defined as the minimum semantic unit of languages. Sememe knowledge bases (KBs), which are built by manually annotating words with sememes, have been successfully applied to various NLP tasks. However, existing sememe KBs only cover a few languages, which hinders the wide utilization of sememes. To address this issue, the task of sememe prediction for BabelNet synsets (SPBS) is presented, aiming to build a multilingual sememe KB based on BabelNet, a multilingual encyclopedia dictionary. By automatically predicting sememes for a BabelNet synset, the words in many languages in the synset would obtain sememe annotations simultaneously. However, previous SPBS methods have not taken full advantage of the abundant information in BabelNet. In this paper, we utilize the multilingual synonyms, multilingual glosses and images in BabelNet for SPBS. We design a multimodal information fusion model to encode and combine this information for sememe prediction. Experimental results show the substantial outperformance of our model over previous methods (about 10 MAP and F1 scores). All the code and data of this paper can be obtained at https://github.com/thunlp/MSGI.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語および多モーダル情報を用いたBabelNet SynsetsのSememe予測についての論文の要旨です。", "jabstract": "言語学において、セメムは言語の最小意味単位と定義されています。セメム知識ベース（KB）は、セメムを手動で注釈付けすることによって構築され、さまざまなNLPタスクに成功裏に適用されています。しかし、既存のセメムKBはわずかな言語しかカバーしておらず、セメムの広範な利用を妨げています。この問題に対処するために、BabelNetシンセットのセメム予測タスク（SPBS）が提示され、多言語百科事典辞書であるBabelNetに基づく多言語セメムKBの構築を目指しています。BabelNetシンセットの自動的なセメム予測により、シンセット内の多言語の単語が同時にセメム注釈を取得することができます。しかし、以前のSPBS方法は、BabelNetの豊富な情報を十分に活用していませんでした。本論文では、BabelNetの多言語シノニム、多言語グロス、および画像をSPBSに利用します。我々は、多モーダル情報融合モデルを設計して、この情報をセメム予測のためにエンコードおよび結合します。実験結果は、我々のモデルが以前の方法に比べて大幅に優れていることを示しています（約10 MAPおよびF1スコア）。本論文のすべてのコードとデータは、https://github.com/thunlp/MSGIから入手できます。"}
{"title": "Query and Extract: Refining Event Extraction as Type-oriented Binary Decoding", "url": "https://aclanthology.org/2022.findings-acl.16/", "abstract": "Event extraction is typically modeled as a multi-class classification problem where event types and argument roles are treated as atomic symbols. These approaches are usually limited to a set of pre-defined types. We propose a novel event extraction framework that uses event types and argument roles as natural language queries to extract candidate triggers and arguments from the input text. With the rich semantics in the queries, our framework benefits from the attention mechanisms to better capture the semantic correlation between the event types or argument roles and the input text. Furthermore, the query-and-extract formulation allows our approach to leverage all available event annotations from various ontologies as a unified model. Experiments on ACE and ERE demonstrate that our approach achieves state-of-the-art performance on each dataset and significantly outperforms existing methods on zero-shot event extraction.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "クエリと抽出：タイプ指向のバイナリデコーディングとしてイベント抽出を洗練する", "jabstract": "イベント抽出は、イベントタイプと引数ロールを原子的なシンボルとして扱い、多クラス分類問題としてモデル化されることが一般的である。これらのアプローチは通常、事前定義されたタイプのセットに限定されている。我々は、イベントタイプと引数ロールを自然言語クエリとして使用し、入力テキストから候補トリガーと引数を抽出する新しいイベント抽出フレームワークを提案する。クエリの豊富な意味により、我々のフレームワークは、イベントタイプまたは引数ロールと入力テキストの間の意味的相関をよりよく捉えるための注意機構の恩恵を受ける。さらに、クエリと抽出の形式により、我々のアプローチは、さまざまなオントロジーから利用可能なすべてのイベント注釈を統一モデルとして活用することができる。ACEおよびEREの実験により、我々のアプローチは、各データセットで最先端の性能を発揮し、ゼロショットイベント抽出において既存の手法を大幅に上回ることが示された。"}
{"title": "LEVEN: A Large-Scale Chinese Legal Event Detection Dataset", "url": "https://aclanthology.org/2022.findings-acl.17/", "abstract": "Recognizing facts is the most fundamental step in making judgments, hence detecting events in the legal documents is important to legal case analysis tasks. However, existing Legal Event Detection (LED) datasets only concern incomprehensive event types and have limited annotated data, which restricts the development of LED methods and their downstream applications. To alleviate these issues, we present LEVEN a large-scale Chinese LEgal eVENt detection dataset, with 8,116 legal documents and 150,977 human-annotated event mentions in 108 event types. Not only charge-related events, LEVEN also covers general events, which are critical for legal case understanding but neglected in existing LED datasets. To our knowledge, LEVEN is the largest LED dataset and has dozens of times the data scale of others, which shall significantly promote the training and evaluation of LED methods. The results of extensive experiments indicate that LED is challenging and needs further effort. Moreover, we simply utilize legal events as side information to promote downstream applications. The method achieves improvements of average 2.2 points precision in low-resource judgment prediction, and 1.5 points mean average precision in unsupervised case retrieval, which suggests the fundamentality of LED. The source code and dataset can be obtained from https://github.com/thunlp/LEVEN.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "LEVEN：大規模な中国法的イベント検出データセット", "jabstract": "事実を認識することは、判断を下す上で最も基本的なステップであり、法的ケース分析タスクにおいては、法的文書内のイベントを検出することが重要です。しかし、既存の法的イベント検出（LED）データセットは、不十分なイベントタイプに関するものであり、注釈付きデータが限られているため、LED方法およびその下流アプリケーションの開発を制限しています。これらの問題を緩和するために、私たちはLEVENを提案します。これは、8,116の法的文書と108のイベントタイプにおいて150,977の人間による注釈付きイベントメンションを持つ、大規模な中国の法的イベント検出データセットです。LEVENは、充電関連のイベントだけでなく、法的ケース理解に重要であるが既存のLEDデータセットで無視されている一般的なイベントもカバーしています。私たちの知る限り、LEVENは最大のLEDデータセットであり、他のデータスケールの数十倍を持っており、LED方法のトレーニングと評価を大幅に促進することができます。広範な実験の結果、LEDは困難であり、さらなる努力が必要であることが示されました。さらに、私たちは法的イベントを副次的な情報として利用して、下流アプリケーションを促進しました。この方法により、低リソース判断予測において平均2.2ポイントの精度向上、および非監視型ケース検索において平均1.5ポイントの平均精度向上が達成され、LEDの基本性が示されました。ソースコードとデータセットは、https://github.com/thunlp/LEVENから入手できます。"}
{"title": "Analyzing Dynamic Adversarial Training Data in the Limit", "url": "https://aclanthology.org/2022.findings-acl.18/", "abstract": "To create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Models trained on DADC examples make 26% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「限界における動的敵対的トレーニングデータの分析」", "jabstract": "広範なテスト入力に対して堅牢なモデルを作成するためには、トレーニングデータセットには多様な現象をカバーする例が含まれる必要があります。動的な敵対的データ収集（DADC）は、改善し続けるモデルに挑戦する例を作成するアプローチとして、多様なトレーニングセットを生成するための有望な方法です。以前の研究では、1〜3ラウンドのDADCを実行することで、モデルが一部のエラータイプを修正するのに役立つことが示されていますが、敵対的なテストデータを超えたより良い一般化を必ずしももたらすわけではありません。私たちは、DADCを多数のラウンドで実行することで、タスクに関連する多くの現象をカバーできるため、トレーニング時間の利点を最大化すると主張しています。私たちは、敵対的および非敵対的なアプローチの両方で、一連の前提段落のNLI例を20ラウンド収集する長期的なDADCの最初の研究を発表します。DADCの例でトレーニングされたモデルは、非敵対的なデータでトレーニングされたモデルに比べて、専門家が作成したテストセットで26％少ないエラーを生成します。私たちの分析は、DADCが非敵対的な例に比べて、より困難で、より語彙的および構文的に多様で、注釈のアーティファクトが少ない例を生成することを示しています。"}
{"title": "AbductionRules: Training Transformers to Explain Unexpected Inputs", "url": "https://aclanthology.org/2022.findings-acl.19/", "abstract": "Transformers have recently been shown to be capable of reliably performing logical reasoning over facts and rules expressed in natural language, but abductive reasoning - inference to the best explanation of an unexpected observation - has been underexplored despite significant applications to scientific discovery, common-sense reasoning, and model interpretability.This paper presents AbductionRules, a group of natural language datasets designed to train and test generalisable abduction over natural-language knowledge bases.We use these datasets to finetune pretrained Transformers and discuss their performance, finding that our models learned generalisable abductive techniques but also learned to exploit the structure of our data.Finally, we discuss the viability of this approach to abductive reasoning and ways in which it may be improved in future work.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "AbductionRules：予期しない入力を説明するためにTransformersをトレーニングする", "jabstract": "トランスフォーマーは、最近、自然言語で表現された事実やルールに対して論理的推論を信頼性高く実行できることが示されていますが、予期しない観察の最良の説明に対する推論である帰納的推論は、科学的発見、常識的推論、モデルの解釈可能性に重要な応用があるにもかかわらず、未だに十分に探究されていません。本論文では、自然言語の知識ベース上で一般化可能な帰納的推論を訓練およびテストするために設計されたAbductionRulesというグループのデータセットを提供します。これらのデータセットを使用して、事前学習されたトランスフォーマーを微調整し、その性能について議論し、モデルが一般化可能な帰納的技術を学習したこと、また、データの構造を利用することも学習したことを発見しました。最後に、この帰納的推論のアプローチの実現可能性と、今後の改善方法について議論します。"}
{"title": "On the Importance of Data Size in Probing Fine-tuned Models", "url": "https://aclanthology.org/2022.findings-acl.20/", "abstract": "Several studies have investigated the reasons behind the effectiveness of fine-tuning, usually through the lens of probing. However, these studies often neglect the role of the size of the dataset on which the model is fine-tuned. In this paper, we highlight the importance of this factor and its undeniable role in probing performance. We show that the extent of encoded linguistic knowledge depends on the number of fine-tuning samples. The analysis also reveals that larger training data mainly affects higher layers, and that the extent of this change is a factor of the number of iterations updating the model during fine-tuning rather than the diversity of the training samples. Finally, we show through a set of experiments that fine-tuning data size affects the recoverability of the changes made to the model’s linguistic knowledge.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要旨の以下の文を日本語に翻訳してください：\n\n微調整されたモデルの探査におけるデータサイズの重要性について", "jabstract": "いくつかの研究は、通常プロービングのレンズを通して、ファインチューニングの効果的な理由を調査してきた。しかし、これらの研究はしばしば、モデルがファインチューニングされるデータセットのサイズの役割を無視しています。本論文では、この要因の重要性と、プロービングのパフォーマンスにおけるその否定できない役割を強調します。我々は、エンコードされた言語知識の範囲がファインチューニングサンプルの数に依存することを示します。分析はまた、より大きなトレーニングデータが主に上位層に影響を与え、この変化の程度がトレーニングサンプルの多様性ではなく、ファインチューニング中にモデルを更新する反復回数の要因であることを明らかにします。最後に、一連の実験を通じて、ファインチューニングデータサイズがモデルの言語知識に対する変更の回復性に影響を与えることを示します。"}
{"title": "RuCCoN: Clinical Concept Normalization in Russian", "url": "https://aclanthology.org/2022.findings-acl.21/", "abstract": "We present RuCCoN, a new dataset for clinical concept normalization in Russian manually annotated by medical professionals. It contains over 16,028 entity mentions manually linked to over 2,409 unique concepts from the Russian language part of the UMLS ontology. We provide train/test splits for different settings (stratified, zero-shot, and CUI-less) and present strong baselines obtained with state-of-the-art models such as SapBERT. At present, Russian medical NLP is lacking in both datasets and trained models, and we view this work as an important step towards filling this gap. Our dataset and annotation guidelines are available at https://github.com/sberbank-ai-lab/RuCCoN.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "RuCCoN：ロシア語における臨床概念の正規化", "jabstract": "私たちは、医療専門家によって手動で注釈付けされたロシア語の臨床概念正規化のための新しいデータセットであるRuCCoNを提供します。それには、UMLSオントロジーのロシア語部分から2,409のユニークな概念に手動でリンクされた16,028以上のエンティティメンションが含まれています。我々は、異なる設定（層別、ゼロショット、およびCUIレス）のトレイン/テスト分割を提供し、SapBERTなどの最新のモデルで得られた強力なベースラインを示します。現在、ロシアの医療NLPは、データセットとトレーニングされたモデルの両方が不足しており、この作業をこのギャップを埋めるための重要な一歩と見なしています。私たちのデータセットと注釈ガイドラインは、https://github.com/sberbank-ai-lab/RuCCoNで利用可能です。"}
{"title": "A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings", "url": "https://aclanthology.org/2022.findings-acl.22/", "abstract": "Contrastive learning has shown great potential in unsupervised sentence embedding tasks, e.g., SimCSE (CITATION).However, these existing solutions are heavily affected by superficial features like the length of sentences or syntactic structures. In this paper, we propose a semantic-aware contrastive learning framework for sentence embeddings, termed Pseudo-Token BERT (PT-BERT), which is able to explore the pseudo-token space (i.e., latent semantic space) representation of a sentence while eliminating the impact of superficial features such as sentence length and syntax. Specifically, we introduce an additional pseudo token embedding layer independent of the BERT encoder to map each sentence into a sequence of pseudo tokens in a fixed length. Leveraging these pseudo sequences, we are able to construct same-length positive and negative pairs based on the attention mechanism to perform contrastive learning. In addition, we utilize both the gradient-updating and momentum-updating encoders to encode instances while dynamically maintaining an additional queue to store the representation of sentence embeddings, enhancing the encoder’s learning performance for negative examples. Experiments show that our model outperforms the state-of-the-art baselines on six standard semantic textual similarity (STS) tasks. Furthermore, experiments on alignments and uniformity losses, as well as hard examples with different sentence lengths and syntax, consistently verify the effectiveness of our method.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「文は128個の疑似トークンに値する：文の埋め込みのための意味認識対比学習フレームワーク」は、自然言語処理に関する論文の要約です。", "jabstract": "対照学習は、SimCSE（引用）などの教師なしの文埋め込みタスクで大きな可能性を示しています。しかし、これらの既存の解決策は、文の長さや構文構造などの表面的な特徴に強く影響を受けます。本論文では、文の長さや構文などの表面的な特徴の影響を排除しながら、文の擬似トークン空間（つまり、潜在的な意味空間）表現を探索することができる、文埋め込みのための意味に敏感な対照学習フレームワークであるPseudo-Token BERT（PT-BERT）を提案します。具体的には、BERTエンコーダーとは独立した追加の擬似トークン埋め込み層を導入して、各文を固定長の擬似トークンのシーケンスにマップします。これらの擬似シーケンスを活用して、注意機構に基づいて同じ長さの正例と負例のペアを構築し、対照学習を実行します。さらに、勾配更新エンコーダーとモーメンタム更新エンコーダーの両方を活用して、インスタンスをエンコードしながら、文埋め込みの表現を格納する追加のキューを動的に維持することで、エンコーダーの負例の学習性能を向上させます。実験の結果、本モデルは、6つの標準的な意味的テキスト類似性（STS）タスクで最先端のベースラインを上回ることが示されました。さらに、アラインメントと均一性の損失、および異なる文の長さと構文を持つハードな例に対する実験は、本手法の有効性を一貫して検証しています。"}
{"title": "Eider: Empowering Document-level Relation Extraction with Efficient Evidence Extraction and Inference-stage Fusion", "url": "https://aclanthology.org/2022.findings-acl.23/", "abstract": "Document-level relation extraction (DocRE) aims to extract semantic relations among entity pairs in a document. Typical DocRE methods blindly take the full document as input, while a subset of the sentences in the document, noted as the evidence, are often sufficient for humans to predict the relation of an entity pair. In this paper, we propose an evidence-enhanced framework, Eider, that empowers DocRE by efficiently extracting evidence and effectively fusing the extracted evidence in inference. We first jointly train an RE model with a lightweight evidence extraction model, which is efficient in both memory and runtime. Empirically, even training the evidence model on silver labels constructed by our heuristic rules can lead to better RE performance. We further design a simple yet effective inference process that makes RE predictions on both extracted evidence and the full document, then fuses the predictions through a blending layer. This allows Eider to focus on important sentences while still having access to the complete information in the document. Extensive experiments show that Eider outperforms state-of-the-art methods on three benchmark datasets (e.g., by 1.37/1.26 Ign F1/F1 on DocRED).", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Eider：効率的な証拠抽出と推論段階の融合による文書レベルの関係抽出の強化」は、自然言語処理に関する論文の要約である。", "jabstract": "ドキュメントレベルの関係抽出（DocRE）は、ドキュメント内のエンティティペア間の意味的な関係を抽出することを目的としています。典型的なDocRE方法は、ドキュメント全体を入力として取りますが、証拠として注目されるドキュメント内の一部の文は、人間がエンティティペアの関係を予測するのに十分であることがよくあります。本論文では、証拠を効率的に抽出し、推論で抽出された証拠を効果的に融合することによって、DocREを強化するEiderというフレームワークを提案します。まず、軽量な証拠抽出モデルとREモデルを共同でトレーニングし、メモリとランタイムの両方で効率的な証拠モデルを作成します。実験的には、ヒューリスティックルールによって構築されたシルバーラベルで証拠モデルをトレーニングしても、REパフォーマンスが向上することがあります。さらに、抽出された証拠とドキュメント全体の両方でRE予測を行い、ブレンドレイヤーを介して予測を融合するシンプルで効果的な推論プロセスを設計します。これにより、Eiderは重要な文に焦点を当てながら、ドキュメントの完全な情報にアクセスできるようになります。広範な実験により、Eiderが3つのベンチマークデータセット（例えば、DocREDのIgn F1 / F1で1.37 / 1.26）で最先端の方法を上回ることが示されました。"}
{"title": "Meta-XNLG: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation", "url": "https://aclanthology.org/2022.findings-acl.24/", "abstract": "Recently, the NLP community has witnessed a rapid advancement in multilingual and cross-lingual transfer research where the supervision is transferred from high-resource languages (HRLs) to low-resource languages (LRLs). However, the cross-lingual transfer is not uniform across languages, particularly in the zero-shot setting. Towards this goal, one promising research direction is to learn shareable structures across multiple tasks with limited annotated data. The downstream multilingual applications may benefit from such a learning setup as most of the languages across the globe are low-resource and share some structures with other languages. In this paper, we propose a novel meta-learning framework (called Meta-XNLG) to learn shareable structures from typologically diverse languages based on meta-learning and language clustering. This is a step towards uniform cross-lingual transfer for unseen languages. We first cluster the languages based on language representations and identify the centroid language of each cluster. Then, a meta-learning algorithm is trained with all centroid languages and evaluated on the other languages in the zero-shot setting. We demonstrate the effectiveness of this modeling on two NLG tasks (Abstractive Text Summarization and Question Generation), 5 popular datasets and 30 typologically diverse languages. Consistent improvements over strong baselines demonstrate the efficacy of the proposed framework. The careful design of the model makes this end-to-end NLG setup less vulnerable to the accidental translation problem, which is a prominent concern in zero-shot cross-lingual NLG tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Meta-XNLG：言語クラスタリングに基づくメタ学習アプローチによるゼロショットクロスリンガル転移と生成", "jabstract": "最近、NLPコミュニティでは、高リソース言語（HRL）から低リソース言語（LRL）への監視の転送が行われる多言語およびクロスリンガル転送研究において急速な進歩が見られています。しかし、クロスリンガル転送は、特にゼロショット設定において、言語によって一様ではありません。この目標に向けて、限られた注釈付きデータを用いて複数のタスク間で共有可能な構造を学習することが有望な研究方向の1つです。多言語アプリケーションは、世界中のほとんどの言語が低リソースであり、他の言語といくつかの構造を共有しているため、このような学習セットアップから利益を得ることができます。本論文では、メタ学習と言語クラスタリングに基づく多様な言語から共有可能な構造を学習するための新しいメタ学習フレームワーク（Meta-XNLG）を提案します。これは、未知の言語に対する一様なクロスリンガル転送に向けた一歩です。まず、言語表現に基づいて言語をクラスタリングし、各クラスターの重心言語を特定します。次に、メタ学習アルゴリズムをすべての重心言語でトレーニングし、ゼロショット設定で他の言語で評価します。本研究では、2つのNLGタスク（抽象的テキスト要約と質問生成）、5つの人気のあるデータセット、30の多様な言語でこのモデリングの効果を実証します。強力なベースラインに対する一貫した改善は、提案されたフレームワークの有効性を示しています。モデルの慎重な設計により、ゼロショットクロスリンガルNLGタスクで顕著な問題である偶発的な翻訳問題に対して、このエンドツーエンドのNLGセットアップはより脆弱ではありません。"}
{"title": "MR-P: A Parallel Decoding Algorithm for Iterative Refinement Non-Autoregressive Translation", "url": "https://aclanthology.org/2022.findings-acl.25/", "abstract": "Non-autoregressive translation (NAT) predicts all the target tokens in parallel and significantly speeds up the inference process. The Conditional Masked Language Model (CMLM) is a strong baseline of NAT. It decodes with the Mask-Predict algorithm which iteratively refines the output. Most works about CMLM focus on the model structure and the training objective. However, the decoding algorithm is equally important. We propose a simple, effective, and easy-to-implement decoding algorithm that we call MaskRepeat-Predict (MR-P). The MR-P algorithm gives higher priority to consecutive repeated tokens when selecting tokens to mask for the next iteration and stops the iteration after target tokens converge. We conduct extensive experiments on six translation directions with varying data sizes. The results show that MR-P significantly improves the performance with the same model parameters. Specifically, we achieve a BLEU increase of 1.39 points in the WMT’14 En-De translation task.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MR-P：反復改良非自己回帰翻訳の並列デコーディングアルゴリズム", "jabstract": "非自己回帰翻訳（NAT）は、すべての目標トークンを並列に予測し、推論プロセスを大幅に高速化します。条件付きマスク言語モデル（CMLM）は、NATの強力なベースラインです。CMLMは、マスク-予測アルゴリズムでデコードされ、出力を反復的に洗練します。CMLMに関する多くの研究は、モデル構造とトレーニング目的に焦点を当てています。しかし、デコードアルゴリズムも同様に重要です。私たちは、MaskRepeat-Predict（MR-P）と呼ぶ、シンプルで効果的で実装が容易なデコードアルゴリズムを提案します。MR-Pアルゴリズムは、次の反復のためにマスクするトークンを選択する際に、連続した繰り返しトークンに優先度を与え、目標トークンが収束した後に反復を停止します。私たちは、データサイズを変えた6つの翻訳方向で広範な実験を行いました。その結果、MR-Pは同じモデルパラメータで性能を大幅に向上させることが示されました。特に、WMT'14 En-De翻訳タスクでBLEUスコアが1.39ポイント向上しました。"}
{"title": "Open Relation Modeling: Learning to Define Relations between Entities", "url": "https://aclanthology.org/2022.findings-acl.26/", "abstract": "Relations between entities can be represented by different instances, e.g., a sentence containing both entities or a fact in a Knowledge Graph (KG). However, these instances may not well capture the general relations between entities, may be difficult to understand by humans, even may not be found due to the incompleteness of the knowledge source. In this paper, we introduce the Open Relation Modeling problem - given two entities, generate a coherent sentence describing the relation between them. To solve this problem, we propose to teach machines to generate definition-like relation descriptions by letting them learn from defining entities. Specifically, we fine-tune Pre-trained Language Models (PLMs) to produce definitions conditioned on extracted entity pairs. To help PLMs reason between entities and provide additional relational knowledge to PLMs for open relation modeling, we incorporate reasoning paths in KGs and include a reasoning path selection mechanism. Experimental results show that our model can generate concise but informative relation descriptions that capture the representative characteristics of entities.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nオープンリレーションモデリング：エンティティ間の関係を定義する学習", "jabstract": "エンティティ間の関係は、例えば両方のエンティティを含む文や知識グラフ（KG）の事実など、異なるインスタンスによって表現されることがあります。しかし、これらのインスタンスは、エンティティ間の一般的な関係をうまく捉えることができない場合があり、人間には理解しにくい場合があり、知識源の不完全性のために見つからない場合があります。本論文では、2つのエンティティが与えられた場合、それらの間の関係を説明する一貫した文を生成するOpen Relation Modeling問題を紹介します。この問題を解決するために、我々は機械に定義的な関係記述を生成することを教えることを提案します。具体的には、抽出されたエンティティペアに条件付けられた定義を生成するために、事前学習済み言語モデル（PLMs）を微調整することを提案します。PLMsがエンティティ間を推論し、Open Relation Modelingのための追加の関係知識を提供するために、KG内の推論パスを組み込み、推論パス選択メカニズムを含めます。実験結果は、我々のモデルが、エンティティの代表的な特徴を捉えた簡潔で情報量の多い関係記述を生成できることを示しています。"}
{"title": "A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots", "url": "https://aclanthology.org/2022.findings-acl.27/", "abstract": "A slot value might be provided segment by segment over multiple-turn interactions in a dialog, especially for some important information such as phone numbers and names. It is a common phenomenon in daily life, but little attention has been paid to it in previous work. To fill the gap, this paper defines a new task named Sub-Slot based Task-Oriented Dialog (SSTOD) and builds a Chinese dialog dataset SSD for boosting research on SSTOD. The dataset includes a total of 40K dialogs and 500K utterances from four different domains: Chinese names, phone numbers, ID numbers and license plate numbers. The data is well annotated with sub-slot values, slot values, dialog states and actions. We find some new linguistic phenomena and interactive manners in SSTOD which raise critical challenges of building dialog agents for the task. We test three state-of-the-art dialog models on SSTOD and find they cannot handle the task well on any of the four domains. We also investigate an improved model by involving slot knowledge in a plug-in manner. More work should be done to meet the new challenges raised from SSTOD which widely exists in real-life applications. The dataset and code are publicly available via https://github.com/shunjiu/SSTOD.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "スロットは一つの発話で構築されない：サブスロットを持つ話し言葉の対話\n\nNote: As an AI language model, I cannot determine the context and the appropriate translation for certain terms without further information. Please take this translation with caution and consult a professional translator for accuracy.", "jabstract": "スロット値は、特に電話番号や名前などの重要な情報について、複数のターンの対話でセグメントごとに提供されることがあります。これは日常生活でよくある現象ですが、以前の研究ではあまり注目されていませんでした。この論文では、Sub-Slot based Task-Oriented Dialog（SSTOD）という新しいタスクを定義し、SSTODの研究を促進するために中国語の対話データセットSSDを構築します。データセットには、中国語の名前、電話番号、ID番号、ナンバープレート番号の4つの異なるドメインから合計40Kの対話と500Kの発話が含まれています。データは、サブスロット値、スロット値、対話状態、アクションでよく注釈が付けられています。SSTODで新しい言語現象や対話方法が見つかり、タスクのための対話エージェントの構築に重要な課題が生じています。SSTODで3つの最新の対話モデルをテストし、4つのドメインのいずれでもタスクをうまく処理できないことがわかりました。また、プラグイン方式でスロット知識を組み込んだ改良モデルを調査しました。現実のアプリケーションで広く存在するSSTODから生じる新しい課題に対応するために、さらなる研究が必要です。データセットとコードは、https://github.com/shunjiu/SSTODを通じて公開されています。"}
{"title": "Towards Transparent Interactive Semantic Parsing via Step-by-Step Correction", "url": "https://aclanthology.org/2022.findings-acl.28/", "abstract": "Existing studies on semantic parsing focus on mapping a natural-language utterance to a logical form (LF) in one turn. However, because natural language may contain ambiguity and variability, this is a difficult challenge. In this work, we investigate an interactive semantic parsing framework that explains the predicted LF step by step in natural language and enables the user to make corrections through natural-language feedback for individual steps. We focus on question answering over knowledge bases (KBQA) as an instantiation of our framework, aiming to increase the transparency of the parsing process and help the user trust the final answer. We construct INSPIRED, a crowdsourced dialogue dataset derived from the ComplexWebQuestions dataset. Our experiments show that this framework has the potential to greatly improve overall parse accuracy. Furthermore, we develop a pipeline for dialogue simulation to evaluate our framework w.r.t. a variety of state-of-the-art KBQA models without further crowdsourcing effort. The results demonstrate that our framework promises to be effective across such models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ステップバイステップの修正を通じた透明なインタラクティブな意味解析への取り組み", "jabstract": "従来の意味解析に関する研究は、自然言語の発話を1回のターンで論理形式（LF）にマッピングすることに焦点を当てています。しかし、自然言語には曖昧さや変動性が含まれるため、これは困難な課題です。本研究では、予測されたLFを自然言語でステップバイステップで説明し、ユーザーが個々のステップに対して自然言語のフィードバックを通じて修正できる対話型意味解析フレームワークを調査します。我々は、知識ベース上の質問応答（KBQA）をフレームワークの具体例として重視し、解析プロセスの透明性を高め、ユーザーが最終的な回答を信頼できるようにすることを目的としています。我々は、ComplexWebQuestionsデータセットから派生したクラウドソーシング対話データセットINSPIREDを構築します。実験の結果、このフレームワークは全体的な解析精度を大幅に向上させる可能性があることが示されました。さらに、クラウドソーシングの努力をさらに必要とせずに、最新のKBQAモデルのさまざまな観点からフレームワークを評価するための対話シミュレーションパイプラインを開発しました。その結果、我々のフレームワークは、そのようなモデル全般にわたって効果的であることが示されました。"}
{"title": "MINER: Multi-Interest Matching Network for News Recommendation", "url": "https://aclanthology.org/2022.findings-acl.29/", "abstract": "Personalized news recommendation is an essential technique to help users find interested news. Accurately matching user’s interests and candidate news is the key to news recommendation. Most existing methods learn a single user embedding from user’s historical behaviors to represent the reading interest. However, user interest is usually diverse and may not be adequately modeled by a single user embedding. In this paper, we propose a poly attention scheme to learn multiple interest vectors for each user, which encodes the different aspects of user interest. We further propose a disagreement regularization to make the learned interests vectors more diverse. Moreover, we design a category-aware attention weighting strategy that incorporates the news category information as explicit interest signals into the attention mechanism. Extensive experiments on the MIND news recommendation benchmark demonstrate that our approach significantly outperforms existing state-of-the-art methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MINER：ニュース推薦のためのマルチインタレストマッチングネットワーク", "jabstract": "個人化されたニュース推薦は、ユーザーが興味を持つニュースを見つけるのを支援するための重要な技術です。ユーザーの興味と候補ニュースを正確にマッチングすることがニュース推薦の鍵です。既存の多くの方法は、ユーザーの過去の行動から単一のユーザー埋め込みを学習して、読書の興味を表現します。しかし、ユーザーの興味は通常多様であり、単一のユーザー埋め込みで十分にモデル化されない場合があります。本論文では、ポリアテンションスキームを提案し、各ユーザーに複数の興味ベクトルを学習させ、ユーザーの異なる興味の側面をエンコードします。さらに、学習された興味ベクトルをより多様にするための不一致正則化を提案します。さらに、ニュースカテゴリ情報を明示的な興味信号としてアテンションメカニズムに組み込むカテゴリ意識のアテンション重み付け戦略を設計します。MINDニュース推薦ベンチマークでの広範な実験により、当社のアプローチが既存の最先端の方法を大幅に上回ることが示されました。"}
{"title": "KSAM: Infusing Multi-Source Knowledge into Dialogue Generation via Knowledge Source Aware Multi-Head Decoding", "url": "https://aclanthology.org/2022.findings-acl.30/", "abstract": "Knowledge-enhanced methods have bridged the gap between human beings and machines in generating dialogue responses. However, most previous works solely seek knowledge from a single source, and thus they often fail to obtain available knowledge because of the insufficient coverage of a single knowledge source. To this end, infusing knowledge from multiple sources becomes a trend. This paper proposes a novel approach Knowledge Source Aware Multi-Head Decoding, KSAM, to infuse multi-source knowledge into dialogue generation more efficiently. Rather than following the traditional single decoder paradigm, KSAM uses multiple independent source-aware decoder heads to alleviate three challenging problems in infusing multi-source knowledge, namely, the diversity among different knowledge sources, the indefinite knowledge alignment issue, and the insufficient flexibility/scalability in knowledge usage. Experiments on a Chinese multi-source knowledge-aligned dataset demonstrate the superior performance of KSAM against various competitive approaches.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "KSAM：知識ソースに注意したマルチヘッドデコーディングを介した対話生成に複数ソースの知識を注入する", "jabstract": "知識強化手法は、対話応答の生成において人間と機械の間のギャップを埋める役割を果たしています。しかし、以前の研究では、ほとんどの場合、単一の情報源からの知識のみを求めており、そのため、単一の情報源のカバー範囲が不十分であるために利用可能な知識を得ることができないことがしばしばありました。このため、複数の情報源からの知識を注入することがトレンドとなっています。本論文では、複数の情報源からの知識をより効率的に対話生成に注入するための新しいアプローチであるKnowledge Source Aware Multi-Head Decoding（KSAM）を提案しています。KSAMは、従来の単一のデコーダーパラダイムに従うのではなく、複数の独立した情報源に対応したデコーダーヘッドを使用して、複数の情報源からの知識を注入する際に生じる3つの課題、すなわち、異なる知識源の多様性、不確定な知識の整列問題、そして知識の使用における十分な柔軟性/スケーラビリティの欠如を緩和します。中国語の複数の情報源に整列したデータセットでの実験により、KSAMがさまざまな競合手法に優れた性能を発揮することが示されました。"}
{"title": "Towards Responsible Natural Language Annotation for the Varieties of Arabic", "url": "https://aclanthology.org/2022.findings-acl.31/", "abstract": "When building NLP models, there is a tendency to aim for broader coverage, often overlooking cultural and (socio)linguistic nuance. In this position paper, we make the case for care and attention to such nuances, particularly in dataset annotation, as well as the inclusion of cultural and linguistic expertise in the process. We present a playbook for responsible dataset creation for polyglossic, multidialectal languages. This work is informed by a study on Arabic annotation of social media content.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "アラビア語の多様性に対する責任ある自然言語注釈に向けて", "jabstract": "NLPモデルを構築する際、文化的および（社会）言語的ニュアンスを見落とし、より広範なカバレッジを目指す傾向がある。本論文では、特にデータセット注釈における文化的および言語的ニュアンスへの注意と、プロセスに文化的および言語的専門知識を含めることの重要性を主張する。また、多言語、多方言の言語に対する責任あるデータセット作成のためのプレイブックを提供する。この研究は、ソーシャルメディアコンテンツのアラビア語注釈に関する研究に基づいている。"}
{"title": "Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection", "url": "https://aclanthology.org/2022.findings-acl.32/", "abstract": "Hate speech classifiers exhibit substantial performance degradation when evaluated on datasets different from the source. This is due to learning spurious correlations between words that are not necessarily relevant to hateful language, and hate speech labels from the training corpus. Previous work has attempted to mitigate this problem by regularizing specific terms from pre-defined static dictionaries. While this has been demonstrated to improve the generalizability of classifiers, the coverage of such methods is limited and the dictionaries require regular manual updates from human experts. In this paper, we propose to automatically identify and reduce spurious correlations using attribution methods with dynamic refinement of the list of terms that need to be regularized during training. Our approach is flexible and improves the cross-corpora performance over previous work independently and in combination with pre-defined dictionaries.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nクロスコーパスのヘイトスピーチ検出を改善するための動的に調整された正則化", "jabstract": "ヘイトスピーチ分類器は、ソースと異なるデータセットで評価されると、大幅な性能低下を示す。これは、訓練コーパスからのヘイトスピーチラベルと必ずしも関連しない単語間の虚偽の相関関係を学習するためである。これまでの研究では、事前定義された静的辞書から特定の用語を正則化することで、この問題を緩和しようとしてきた。これにより、分類器の汎用性が向上することが示されているが、その方法のカバレッジは限られており、辞書は人間の専門家による定期的な更新が必要である。本論文では、動的な用語リストの精緻化による帰属方法を使用して、虚偽の相関関係を自動的に特定し、正則化することを提案する。我々のアプローチは柔軟であり、事前定義された辞書と独立または組み合わせて、クロスコーポラのパフォーマンスを改善する。"}
{"title": "Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue Systems", "url": "https://aclanthology.org/2022.findings-acl.33/", "abstract": "Users interacting with voice assistants today need to phrase their requests in a very specific manner to elicit an appropriate response. This limits the user experience, and is partly due to the lack of reasoning capabilities of dialogue platforms and the hand-crafted rules that require extensive labor. One possible solution to improve user experience and relieve the manual efforts of designers is to build an end-to-end dialogue system that can do reasoning itself while perceiving user’s utterances. In this work, we propose a novel method to incorporate the knowledge reasoning capability into dialog systems in a more scalable and generalizable manner. Our proposed method allows a single transformer model to directly walk on a large-scale knowledge graph to generate responses. To the best of our knowledge, this is the first work to have transformer models generate responses by reasoning over differentiable knowledge graphs. We investigate the reasoning abilities of the proposed method on both task-oriented and domain-specific chit-chat dialogues. Empirical results show that this method can effectively and efficiently incorporate a knowledge graph into a dialogue system with fully-interpretable reasoning paths.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "対話システムのための大規模で解釈可能な知識グラフ推論に向けて", "jabstract": "現在、音声アシスタントとのやり取りをするユーザーは、適切な応答を引き出すために非常に特定の方法でリクエストを表現する必要があります。これはユーザー体験を制限し、対話プラットフォームの推論能力の欠如と、広範な手作業が必要な手作りのルールの一部によるものです。デザイナーの手作業を軽減し、ユーザー体験を改善するための1つの可能な解決策は、ユーザーの発話を知覚しながら推論を行うことができるエンドツーエンドの対話システムを構築することです。本研究では、知識推論能力を対話システムによりスケーラブルかつ汎用的に組み込むための新しい手法を提案します。提案された手法により、単一のトランスフォーマーモデルが大規模な知識グラフを直接歩くことで応答を生成できます。私たちの知る限り、これはトランスフォーマーモデルが微分可能な知識グラフを推論して応答を生成する最初の研究です。提案された手法の推論能力を、タスク指向型およびドメイン固有の雑談対話の両方で調査します。実験結果は、この手法が完全に解釈可能な推論パスを持つ知識グラフを対話システムに効果的かつ効率的に組み込むことができることを示しています。"}
{"title": "MDERank: A Masked Document Embedding Rank Approach for Unsupervised Keyphrase Extraction", "url": "https://aclanthology.org/2022.findings-acl.34/", "abstract": "Keyphrase extraction (KPE) automatically extracts phrases in a document that provide a concise summary of the core content, which benefits downstream information retrieval and NLP tasks. Previous state-of-the-art methods select candidate keyphrases based on the similarity between learned representations of the candidates and the document. They suffer performance degradation on long documents due to discrepancy between sequence lengths which causes mismatch between representations of keyphrase candidates and the document. In this work, we propose a novel unsupervised embedding-based KPE approach, Masked Document Embedding Rank (MDERank), to address this problem by leveraging a mask strategy and ranking candidates by the similarity between embeddings of the source document and the masked document. We further develop a KPE-oriented BERT (KPEBERT) model by proposing a novel self-supervised contrastive learning method, which is more compatible to MDERank than vanilla BERT. Comprehensive evaluations on six KPE benchmarks demonstrate that the proposed MDERank outperforms state-of-the-art unsupervised KPE approach by average 1.80 F1@15 improvement. MDERank further benefits from KPEBERT and overall achieves average 3.53 F1@15 improvement over SIFRank.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MDERank：自己学習キーフレーズ抽出のためのマスクドドキュメント埋め込みランクアプローチ", "jabstract": "キーフレーズ抽出（KPE）は、コアコンテンツの簡潔な要約を提供する文書内のフレーズを自動的に抽出し、下流の情報検索およびNLPタスクに利益をもたらします。従来の最先端の方法は、候補キーフレーズと文書の学習表現の類似性に基づいて候補キーフレーズを選択します。しかし、シーケンスの長さの不一致によるキーフレーズ候補の表現と文書の不一致により、長い文書で性能が低下することがあります。本研究では、マスク戦略を活用してソース文書の埋め込みとマスクされた文書の埋め込みの類似性によって候補をランキングする、新しい非教師あり埋め込みベースのKPEアプローチ、Masked Document Embedding Rank（MDERank）を提案して、この問題に対処します。さらに、MDERankに適した新しい自己教師あり対照学習方法を提案することで、KPE指向のBERT（KPEBERT）モデルを開発します。6つのKPEベンチマークでの包括的な評価により、提案されたMDERankは、平均1.80 F1@15の改善により、最先端の非教師ありKPEアプローチを上回ることが示されました。MDERankは、KPEBERTからの利益をさらに得て、SIFRankに比べて平均3.53 F1@15の改善を達成しました。"}
{"title": "Visualizing the Relationship Between Encoded Linguistic Information and Task Performance", "url": "https://aclanthology.org/2022.findings-acl.35/", "abstract": "Probing is popular to analyze whether linguistic information can be captured by a well-trained deep neural model, but it is hard to answer how the change of the encoded linguistic information will affect task performance. To this end, we study the dynamic relationship between the encoded linguistic information and task performance from the viewpoint of Pareto Optimality. Its key idea is to obtain a set of models which are Pareto-optimal in terms of both objectives. From this viewpoint, we propose a method to optimize the Pareto-optimal models by formalizing it as a multi-objective optimization problem. We conduct experiments on two popular NLP tasks, i.e., machine translation and language modeling, and investigate the relationship between several kinds of linguistic information and task performances. Experimental results demonstrate that the proposed method is better than a baseline method. Our empirical findings suggest that some syntactic information is helpful for NLP tasks whereas encoding more syntactic information does not necessarily lead to better performance, because the model architecture is also an important factor.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "エンコードされた言語情報とタスクパフォーマンスの関係を可視化すること", "jabstract": "Probingは、よく訓練された深層ニューラルモデルが言語情報を捉えることができるかどうかを分析するために人気がありますが、エンコードされた言語情報の変化がタスクのパフォーマンスにどのように影響するかを答えるのは難しいです。このため、Pareto Optimalityの観点から、エンコードされた言語情報とタスクパフォーマンスの動的な関係を研究します。その主要なアイデアは、両方の目的においてPareto最適なモデルのセットを取得することです。この観点から、マルチオブジェクティブ最適化問題として形式化することで、Pareto最適なモデルを最適化する方法を提案します。機械翻訳と言語モデリングという2つの人気のあるNLPタスクで実験を行い、いくつかの種類の言語情報とタスクパフォーマンスの関係を調査します。実験結果は、提案された方法がベースライン方法よりも優れていることを示しています。私たちの経験的な知見は、いくつかの構文情報がNLPタスクに役立つことを示唆していますが、より多くの構文情報をエンコードすることが必ずしもより良いパフォーマンスにつながるわけではなく、モデルアーキテクチャも重要な要因であることを示唆しています。"}
{"title": "Efficient Argument Structure Extraction with Transfer Learning and Active Learning", "url": "https://aclanthology.org/2022.findings-acl.36/", "abstract": "The automation of extracting argument structures faces a pair of challenges on (1) encoding long-term contexts to facilitate comprehensive understanding, and (2) improving data efficiency since constructing high-quality argument structures is time-consuming. In this work, we propose a novel context-aware Transformer-based argument structure prediction model which, on five different domains, significantly outperforms models that rely on features or only encode limited contexts. To tackle the difficulty of data annotation, we examine two complementary methods: (i) transfer learning to leverage existing annotated data to boost model performance in a new target domain, and (ii) active learning to strategically identify a small amount of samples for annotation. We further propose model-independent sample acquisition strategies, which can be generalized to diverse domains. With extensive experiments, we show that our simple-yet-effective acquisition strategies yield competitive results against three strong comparisons. Combined with transfer learning, substantial F1 score boost (5-25) can be further achieved during the early iterations of active learning across domains.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "転移学習とアクティブラーニングを用いた効率的な引数構造抽出", "jabstract": "引数構造の自動抽出には、(1)包括的な理解を促進するために長期的な文脈をエンコードすることと、(2)高品質の引数構造を構築するのに時間がかかるため、データ効率を改善することの2つの課題がある。本研究では、特徴に依存するモデルまたは限られた文脈のみをエンコードするモデルよりも、5つの異なるドメインで優れた性能を発揮する、新しいコンテキストに敏感なTransformerベースの引数構造予測モデルを提案する。データ注釈の難しさに対処するために、既存の注釈付きデータを活用して新しいターゲットドメインでモデルの性能を向上させる転移学習と、注釈付きサンプルを戦略的に特定するためのアクティブラーニングの2つの補完的な方法を検討する。さらに、多様なドメインに一般化できるモデル非依存のサンプル取得戦略を提案する。広範な実験により、シンプルで効果的な取得戦略が3つの強力な比較に対して競争力のある結果を生み出すことを示す。転移学習と組み合わせることで、アクティブラーニングの初期イテレーションでドメイン間でF1スコアが5〜25向上する。"}
{"title": "Plug-and-Play Adaptation for Continuously-updated QA", "url": "https://aclanthology.org/2022.findings-acl.37/", "abstract": "Language models (LMs) have shown great potential as implicit knowledge bases (KBs). And for their practical use, knowledge in LMs need to be updated periodically. However, existing tasks to assess LMs’ efficacy as KBs do not adequately consider multiple large-scale updates. To this end, we first propose a novel task—Continuously-updated QA (CuQA)—in which multiple large-scale updates are made to LMs, and the performance is measured with respect to the success in adding and updating knowledge while retaining existing knowledge. We then present LMs with plug-in modules that effectively handle the updates. Experiments conducted on zsRE QA and NQ datasets show that our method outperforms existing approaches. We find that our method is 4x more effective in terms of updates/forgets ratio, compared to a fine-tuning baseline.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nPlug-and-Play Adaptation for Continuously-updated QA\n\n常に更新されるQAに対するプラグアンドプレイ適応。", "jabstract": "言語モデル（LMs）は、暗黙の知識ベース（KBs）として大きな潜在能力を示しています。そして、実用的な利用のためには、LMsの知識は定期的に更新する必要があります。しかし、既存のLMsのKBとしての有効性を評価するタスクは、複数の大規模な更新を十分に考慮していません。このため、まず、複数の大規模な更新がLMsに行われ、既存の知識を保持しながら知識を追加および更新する成功に関して測定される新しいタスク「Continuously-updated QA（CuQA）」を提案します。次に、更新を効果的に処理するプラグインモジュールを備えたLMsを提供します。 zsRE QAおよびNQデータセットで実施された実験は、当社の方法が既存のアプローチを上回ることを示しています。ファインチューニングベースラインと比較して、当社の方法は更新/忘却比で4倍効果的であることがわかりました。"}
{"title": "Reinforced Cross-modal Alignment for Radiology Report Generation", "url": "https://aclanthology.org/2022.findings-acl.38/", "abstract": "Medical images are widely used in clinical decision-making, where writing radiology reports is a potential application that can be enhanced by automatic solutions to alleviate physicians’ workload. In general, radiology report generation is an image-text task, where cross-modal mappings between images and texts play an important role in generating high-quality reports. Although previous studies attempt to facilitate the alignment via the co-attention mechanism under supervised settings, they suffer from lacking valid and accurate correspondences due to no annotation of such alignment. In this paper, we propose an approach with reinforcement learning (RL) over a cross-modal memory (CMM) to better align visual and textual features for radiology report generation. In detail, a shared memory is used to record the mappings between visual and textual information, and the proposed reinforced algorithm is performed to learn the signal from the reports to guide the cross-modal alignment even though such reports are not directly related to how images and texts are mapped. Experimental results on two English radiology report datasets, i.e., IU X-Ray and MIMIC-CXR, show the effectiveness of our approach, where the state-of-the-art results are achieved. We further conduct human evaluation and case study which confirm the validity of the reinforced algorithm in our approach.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "放射線学レポート生成のための強化されたクロスモーダルアラインメント", "jabstract": "医療画像は臨床的な意思決定に広く使用されており、放射線学報告書の作成は、医師の負担を軽減するための自動化ソリューションによって強化される可能性のあるアプリケーションです。一般的に、放射線学報告書の生成は、画像とテキストのタスクであり、画像とテキストの間のクロスモーダルマッピングが高品質の報告書の生成に重要な役割を果たします。以前の研究では、教師あり設定下で共同注意メカニズムを介してアライメントを容易にすることを試みましたが、このようなアライメントの注釈がないため、有効で正確な対応が欠けています。本論文では、放射線学報告書の生成のために視覚的およびテキスト的特徴をより適切に整列させるためのクロスモーダルメモリ（CMM）上の強化学習（RL）を提案します。詳細には、共有メモリを使用して視覚的およびテキスト情報のマッピングを記録し、提案された強化アルゴリズムを実行して、報告書からの信号を学習してクロスモーダルアライメントを誘導します。このような報告書は、画像とテキストがどのようにマッピングされるかに直接関係していないため、このアプローチは画期的な結果を達成しました。IU X-RayおよびMIMIC-CXRの2つの英語放射線学報告書データセットでの実験結果は、アプローチの有効性を示しています。さらに、人間の評価と事例研究を実施し、アプローチの強化アルゴリズムの妥当性を確認しました。"}
{"title": "What Works and Doesn’t Work, A Deep Decoder for Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.39/", "abstract": "Deep learning has demonstrated performance advantages in a wide range of natural language processing tasks, including neural machine translation (NMT). Transformer NMT models are typically strengthened by deeper encoder layers, but deepening their decoder layers usually results in failure. In this paper, we first identify the cause of the failure of the deep decoder in the Transformer model. Inspired by this discovery, we then propose approaches to improving it, with respect to model structure and model training, to make the deep decoder practical in NMT. Specifically, with respect to model structure, we propose a cross-attention drop mechanism to allow the decoder layers to perform their own different roles, to reduce the difficulty of deep-decoder learning. For model training, we propose a collapse reducing training approach to improve the stability and effectiveness of deep-decoder training. We experimentally evaluated our proposed Transformer NMT model structure modification and novel training methods on several popular machine translation benchmarks. The results showed that deepening the NMT model by increasing the number of decoder layers successfully prevented the deepened decoder from degrading to an unconditional language model. In contrast to prior work on deepening an NMT model on the encoder, our method can deepen the model on both the encoder and decoder at the same time, resulting in a deeper model and improved performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「何がうまくいくか、何がうまくいかないか：ニューラル機械翻訳のための深いデコーダー」", "jabstract": "ディープラーニングは、ニューラルマシン翻訳（NMT）を含む広範な自然言語処理タスクで性能の優位性を示しています。Transformer NMTモデルは通常、より深いエンコーダ層によって強化されますが、デコーダ層を深くすると通常失敗します。本論文では、まずTransformerモデルの深いデコーダの失敗の原因を特定します。この発見にインスパイアされ、モデル構造とモデルトレーニングに関するアプローチを提案し、深いデコーダをNMTで実用的にすることを目指します。具体的には、モデル構造に関して、クロスアテンションドロップメカニズムを提案し、デコーダ層がそれぞれ異なる役割を果たすことができるようにし、深いデコーダの学習の難しさを減らします。モデルトレーニングに関しては、崩壊を減らすトレーニングアプローチを提案し、深いデコーダのトレーニングの安定性と効果を改善します。提案されたTransformer NMTモデル構造の変更と新しいトレーニング方法をいくつかの人気のある機械翻訳ベンチマークで実験的に評価しました。その結果、デコーダ層の数を増やすことによってNMTモデルを深化させることで、深いデコーダが無条件の言語モデルに劣化するのを防ぐことができました。エンコーダのNMTモデルを深化させる従来の研究とは対照的に、私たちの方法はエンコーダとデコーダの両方でモデルを深化させ、より深いモデルと改善された性能を実現することができます。"}
{"title": "SyMCoM - Syntactic Measure of Code Mixing A Study Of English-Hindi Code-Mixing", "url": "https://aclanthology.org/2022.findings-acl.40/", "abstract": "Code mixing is the linguistic phenomenon where bilingual speakers tend to switch between two or more languages in conversations. Recent work on code-mixing in computational settings has leveraged social media code mixed texts to train NLP models. For capturing the variety of code mixing in, and across corpus, Language ID (LID) tags based measures (CMI) have been proposed. Syntactical variety/patterns of code-mixing and their relationship vis-a-vis computational model’s performance is under explored. In this work, we investigate a collection of English(en)-Hindi(hi) code-mixed datasets from a syntactic lens to propose, SyMCoM, an indicator of syntactic variety in code-mixed text, with intuitive theoretical bounds. We train SoTA en-hi PoS tagger, accuracy of 93.4%, to reliably compute PoS tags on a corpus, and demonstrate the utility of SyMCoM by applying it on various syntactical categories on a collection of datasets, and compare datasets using the measure.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "SyMCoM - シンタックス測定によるコードミキシングの研究：英語とヒンディー語のコードミキシングの分析", "jabstract": "コードミキシングは、バイリンガルスピーカーが会話中に2つ以上の言語を切り替える言語現象である。コンピュータ上でのコードミキシングに関する最近の研究では、ソーシャルメディアのコードミックステキストを利用してNLPモデルを訓練している。コーパス内外のコードミキシングの多様性を捉えるために、言語ID（LID）タグベースの尺度（CMI）が提案されている。コードミキシングの構文的な多様性/パターンと、それらの関係については、コンピュータモデルのパフォーマンスに対する影響が未だに探究されていない。本研究では、英語（en）-ヒンディー語（hi）のコードミックスデータセットの構文的な観点から、直感的な理論的境界を持つSyMCoMという構文的多様性の指標を提案する。93.4％の正確性を持つSoTA en-hi PoSタガーを訓練して、コーパス上でPoSタグを信頼性高く計算し、SyMCoMの有用性をデータセットの様々な構文的カテゴリに適用して、尺度を用いてデータセットを比較する。"}
{"title": "HybriDialogue: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data", "url": "https://aclanthology.org/2022.findings-acl.41/", "abstract": "A pressing challenge in current dialogue systems is to successfully converse with users on topics with information distributed across different modalities. Previous work in multiturn dialogue systems has primarily focused on either text or table information. In more realistic scenarios, having a joint understanding of both is critical as knowledge is typically distributed over both unstructured and structured forms. We present a new dialogue dataset, HybriDialogue, which consists of crowdsourced natural conversations grounded on both Wikipedia text and tables. The conversations are created through the decomposition of complex multihop questions into simple, realistic multiturn dialogue interactions. We propose retrieval, system state tracking, and dialogue response generation tasks for our dataset and conduct baseline experiments for each. Our results show that there is still ample opportunity for improvement, demonstrating the importance of building stronger dialogue systems that can reason over the complex setting of informationseeking dialogue grounded on tables and text.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "HybriDialogue：表形式およびテキストデータに基づく情報検索対話データセット", "jabstract": "現在の対話システムにおける重要な課題は、異なるモダリティに分散された情報に関してユーザーと成功裏に会話することです。以前のマルチターン対話システムの研究は、主にテキストまたは表情報に焦点を当てていました。より現実的なシナリオでは、両方の共通理解が重要であり、知識は通常、構造化されていない形式と構造化された形式の両方に分散されているためです。私たちは、Wikipediaのテキストと表に基づくクラウドソーシングされた自然な会話からなる新しい対話データセット、HybriDialogueを提供します。複雑なマルチホップの質問を単純で現実的なマルチターンの対話インタラクションに分解して会話を作成します。私たちは、データセットのための検索、システム状態追跡、および対話応答生成タスクを提案し、それぞれのベースライン実験を実施します。私たちの結果は、改善の余地がまだ十分にあることを示しており、テーブルとテキストに基づく情報検索対話の複雑な設定に対して推論できるより強力な対話システムの構築の重要性を示しています。"}
{"title": "NEWTS: A Corpus for News Topic-Focused Summarization", "url": "https://aclanthology.org/2022.findings-acl.42/", "abstract": "Text summarization models are approaching human levels of fidelity. Existing benchmarking corpora provide concordant pairs of full and abridged versions of Web, news or professional content. To date, all summarization datasets operate under a one-size-fits-all paradigm that may not reflect the full range of organic summarization needs. Several recently proposed models (e.g., plug and play language models) have the capacity to condition the generated summaries on a desired range of themes. These capacities remain largely unused and unevaluated as there is no dedicated dataset that would support the task of topic-focused summarization.This paper introduces the first topical summarization corpus NEWTS, based on the well-known CNN/Dailymail dataset, and annotated via online crowd-sourcing. Each source article is paired with two reference summaries, each focusing on a different theme of the source document. We evaluate a representative range of existing techniques and analyze the effectiveness of different prompting methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "NEWTS: ニューストピックに焦点を当てた要約のためのコーパス\n\nThis paper presents NEWTS, a corpus of news articles annotated with topic labels and summaries. \n本論文では、トピックラベルと要約が注釈付けされたニュース記事のコーパスであるNEWTSを紹介する。\n\nThe corpus is designed to support research on news topic-focused summarization, a task that involves generating a summary of a news article that captures its main topic and key points. \nこのコーパスは、主要なトピックとキーポイントを捉えたニュース記事の要約を生成するタスクであるニューストピックに焦点を当てた要約の研究を支援するために設計されています。\n\nWe describe the corpus creation process, including the selection of news sources, the annotation of topic labels and summaries, and the evaluation of inter-annotator agreement. \n私たちは、ニュースソースの選択、トピックラベルと要約の注釈付け、および注釈者間の合意の評価を含むコーパス作成プロセスについて説明します。\n\nWe also provide baseline results for news topic-focused summarization using several state-of-the-art models and discuss potential directions for future research using the NEWTS corpus. \nまた、いくつかの最新のモデルを使用してニューストピックに焦点を当てた要約のベースライン結果を提供し、NEWTSコーパスを使用した将来の研究の可能性についても議論します。", "jabstract": "テキスト要約モデルは、人間の忠実度に近づいています。既存のベンチマークコーパスは、Web、ニュース、または専門コンテンツの完全版と要約版の一致するペアを提供しています。これまで、すべての要約データセットは、すべての要約ニーズを反映していない一般的なパラダイムで動作しています。最近提案されたいくつかのモデル（例：プラグアンドプレイ言語モデル）は、生成された要約を所望のテーマの範囲に応じて条件付ける能力を持っています。これらの能力は、専用のデータセットがないため、ほとんど使用されず、評価されていません。本論文では、よく知られたCNN / Dailymailデータセットに基づく最初のトピカル要約コーパスNEWTSを紹介し、オンラインクラウドソーシングによって注釈を付けます。各ソース記事には、ソースドキュメントの異なるテーマに焦点を当てた2つの参照要約がペアになっています。我々は、代表的な既存の技術の範囲を評価し、異なるプロンプト方法の効果を分析します。"}
{"title": "Classification without (Proper) Representation: Political Heterogeneity in Social Media and Its Implications for Classification and Behavioral Analysis", "url": "https://aclanthology.org/2022.findings-acl.43/", "abstract": "Reddit is home to a broad spectrum of political activity, and users signal their political affiliations in multiple ways—from self-declarations to community participation. Frequently, computational studies have treated political users as a single bloc, both in developing models to infer political leaning and in studying political behavior. Here, we test this assumption of political users and show that commonly-used political-inference models do not generalize, indicating heterogeneous types of political users. The models remain imprecise at best for most users, regardless of which sources of data or methods are used. Across a 14-year longitudinal analysis, we demonstrate that the choice in definition of a political user has significant implications for behavioral analysis. Controlling for multiple factors, political users are more toxic on the platform and inter-party interactions are even more toxic—but not all political users behave this way. Last, we identify a subset of political users who repeatedly flip affiliations, showing that these users are the most controversial of all, acting as provocateurs by more frequently bringing up politics, and are more likely to be banned, suspended, or deleted.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "表現のない分類：ソーシャルメディアにおける政治的異質性とその分類および行動分析への影響", "jabstract": "Redditは、幅広い政治活動の場であり、ユーザーは自己宣言からコミュニティ参加まで、複数の方法で政治的所属を示しています。頻繁に、計算機的な研究では、政治的ユーザーを単一のブロックとして扱い、政治的傾向を推測するモデルの開発や政治的行動の研究においても同様です。ここでは、政治的ユーザーのこの仮定を検証し、一般的に使用される政治的推論モデルが一般化しないことを示し、異質なタイプの政治的ユーザーが存在することを示します。これらのモデルは、どのデータソースや方法を使用しても、ほとんどのユーザーに対して最高でも不正確なままです。14年間の縦断的分析を行い、政治的ユーザーの定義の選択が行動分析に重要な影響を与えることを示します。複数の要因を制御した結果、政治的ユーザーはプラットフォーム上でより有害であり、党派間の相互作用はさらに有害ですが、すべての政治的ユーザーがこのように行動するわけではありません。最後に、政治的所属を繰り返し変更する政治的ユーザーのサブセットを特定し、これらのユーザーが最も物議を醸し、より頻繁に政治を持ち出し、禁止、停止、または削除される可能性が高いことを示します。"}
{"title": "Toward More Meaningful Resources for Lower-resourced Languages", "url": "https://aclanthology.org/2022.findings-acl.44/", "abstract": "In this position paper, we describe our perspective on how meaningful resources for lower-resourced languages should be developed in connection with the speakers of those languages. Before advancing that position, we first examine two massively multilingual resources used in language technology development, identifying shortcomings that limit their usefulness. We explore the contents of the names stored in Wikidata for a few lower-resourced languages and find that many of them are not in fact in the languages they claim to be, requiring non-trivial effort to correct. We discuss quality issues present in WikiAnn and evaluate whether it is a useful supplement to hand-annotated data. We then discuss the importance of creating annotations for lower-resourced languages in a thoughtful and ethical way that includes the language speakers as part of the development process. We conclude with recommended guidelines for resource development.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "低資源言語に対するより意味のあるリソースに向けて", "jabstract": "このポジションペーパーでは、低資源言語の意味のあるリソースが、その言語を話す人々との関係性を持って開発されるべきであるという私たちの見解について説明します。この立場を進める前に、言語技術開発に使用される2つの大規模多言語リソースを調べ、その有用性を制限する欠点を特定します。また、Wikidataに保存されている名前の内容をいくつかの低資源言語で調べ、多くの名前が実際には主張されている言語ではないことがわかり、修正には非常に努力が必要であることを発見します。WikiAnnに存在する品質問題について議論し、手動注釈付きデータの有用な補完になるかどうかを評価します。そして、低資源言語の注釈付けを、言語話者を開発プロセスの一部として考慮した思慮深く倫理的な方法で行うことの重要性について議論します。最後に、リソース開発のための推奨ガイドラインをまとめます。"}
{"title": "Better Quality Estimation for Low Resource Corpus Mining", "url": "https://aclanthology.org/2022.findings-acl.45/", "abstract": "Quality Estimation (QE) models have the potential to change how we evaluate and maybe even train machine translation models. However, these models still lack the robustness to achieve general adoption. We show that Stateof-the-art QE models, when tested in a Parallel Corpus Mining (PCM) setting, perform unexpectedly bad due to a lack of robustness to out-of-domain examples. We propose a combination of multitask training, data augmentation and contrastive learning to achieve better and more robust QE performance. We show that our method improves QE performance significantly in the MLQE challenge and the robustness of QE models when tested in the Parallel Corpus Mining setup. We increase the accuracy in PCM by more than 0.80, making it on par with state-of-the-art PCM methods that use millions of sentence pairs to train their models. In comparison, we use a thousand times less data, 7K parallel sentences in total, and propose a novel low resource PCM method.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "低資源コーパスマイニングのためのより良い品質評価", "jabstract": "品質評価（QE）モデルは、機械翻訳モデルを評価し、おそらくトレーニングする方法を変える可能性があります。しかし、これらのモデルはまだ堅牢性に欠けており、一般的な採用を達成することができません。我々は、最先端のQEモデルが、パラレルコーパスマイニング（PCM）設定でテストされた場合、ドメイン外の例に対する堅牢性の欠如のために予期せぬほど悪いパフォーマンスを発揮することを示します。我々は、マルチタスクトレーニング、データ拡張、コントラスティブラーニングの組み合わせを提案し、より良く、より堅牢なQEパフォーマンスを実現します。我々は、MLQEチャレンジでのQEパフォーマンスを大幅に改善し、パラレルコーパスマイニング設定でテストされた場合のQEモデルの堅牢性を示します。PCMの精度を0.80以上向上させ、モデルをトレーニングするために数百万の文ペアを使用する最先端のPCM方法と同等にします。比較すると、我々は合計7Kの並列文を使用し、新しい低リソースPCM方法を提案します。"}
{"title": "End-to-End Segmentation-based News Summarization", "url": "https://aclanthology.org/2022.findings-acl.46/", "abstract": "In this paper, we bring a new way of digesting news content by introducing the task of segmenting a news article into multiple sections and generating the corresponding summary to each section. We make two contributions towards this new task. First, we create and make available a dataset, SegNews, consisting of 27k news articles with sections and aligned heading-style section summaries. Second, we propose a novel segmentation-based language generation model adapted from pre-trained language models that can jointly segment a document and produce the summary for each section. Experimental results on SegNews demonstrate that our model can outperform several state-of-the-art sequence-to-sequence generation models for this new task.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nエンドツーエンドのセグメンテーションベースのニュース要約化", "jabstract": "本論文では、ニュース記事を複数のセクションに分割し、各セクションに対応する要約を生成するタスクを紹介することで、ニュースコンテンツの新しい消化方法を提供する。この新しいタスクに向けて、2つの貢献を行う。第一に、27,000件のニュース記事と、セクションと見出しスタイルのセクション要約が整列したデータセット「SegNews」を作成し、公開する。第二に、事前学習された言語モデルから適応された新しいセグメンテーションベースの言語生成モデルを提案し、文書を分割し、各セクションの要約を同時に生成する。SegNews上の実験結果は、この新しいタスクに対して、いくつかの最先端のシーケンス・トゥ・シーケンス生成モデルよりも、我々のモデルが優れていることを示している。"}
{"title": "Fast Nearest Neighbor Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.47/", "abstract": "Though nearest neighbor Machine Translation (kNN-MT) (CITATION) has proved to introduce significant performance boosts over standard neural MT systems, it is prohibitively slow since it uses the entire reference corpus as the datastore for the nearest neighbor search. This means each step for each beam in the beam search has to search over the entire reference corpus. kNN-MT is thus two-orders slower than vanilla MT models, making it hard to be applied to real-world applications, especially online services. In this work, we propose Fast kNN-MT to address this issue. Fast kNN-MT constructs a significantly smaller datastore for the nearest neighbor search: for each word in a source sentence, Fast kNN-MT first selects its nearest token-level neighbors, which is limited to tokens that are the same as the query token. Then at each decoding step, in contrast to using the entire corpus as the datastore, the search space is limited to target tokens corresponding to the previously selected reference source tokens. This strategy avoids search through the whole datastore for nearest neighbors and drastically improves decoding efficiency. Without loss of performance, Fast kNN-MT is two-orders faster than kNN-MT, and is only two times slower than the standard NMT model. Fast kNN-MT enables the practical use of kNN-MT systems in real-world MT applications. The code is available at https://github.com/ShannonAI/fast-knn-nmt.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n高速最近傍機械翻訳", "jabstract": "最近の近傍機械翻訳（kNN-MT）（引用）は、標準的なニューラルMTシステムよりも大幅な性能向上をもたらすことが証明されていますが、最近傍探索のデータストアとして参照コーパス全体を使用するため、実行速度が非常に遅くなっています。つまり、ビームサーチの各ステップごとに、参照コーパス全体を検索する必要があります。kNN-MTは、バニラMTモデルよりも2桁遅く、特にオンラインサービスなどの実世界のアプリケーションに適用するのが困難です。本研究では、この問題に対処するために、高速kNN-MTを提案しています。高速kNN-MTは、最近傍探索のためのはるかに小さなデータストアを構築します。ソース文の各単語について、高速kNN-MTはまず、クエリトークンと同じトークンに限定された最近傍トークンを選択します。そして、各デコーディングステップでは、データストア全体を使用する代わりに、検索空間は以前に選択された参照ソーストークンに対応するターゲットトークンに限定されます。この戦略により、最近傍探索を全体的に検索する必要がなく、デコーディング効率が大幅に向上します。高速kNN-MTは、性能を損なうことなく、kNN-MTよりも2桁速く、標準的なNMTモデルよりも2倍遅くなります。高速kNN-MTにより、実世界のMTアプリケーションでkNN-MTシステムを実用的に使用することができます。コードはhttps://github.com/ShannonAI/fast-knn-nmtで入手できます。"}
{"title": "Extracting Latent Steering Vectors from Pretrained Language Models", "url": "https://aclanthology.org/2022.findings-acl.48/", "abstract": "Prior work on controllable text generation has focused on learning how to control language models through trainable decoding, smart-prompt design, or fine-tuning based on a desired objective. We hypothesize that the information needed to steer the model to generate a target sentence is already encoded within the model. Accordingly, we explore a different approach altogether: extracting latent vectors directly from pretrained language model decoders without fine-tuning. Experiments show that there exist steering vectors, which, when added to the hidden states of the language model, generate a target sentence nearly perfectly (> 99 BLEU) for English sentences from a variety of domains. We show that vector arithmetic can be used for unsupervised sentiment transfer on the Yelp sentiment benchmark, with performance comparable to models tailored to this task. We find that distances between steering vectors reflect sentence similarity when evaluated on a textual similarity benchmark (STS-B), outperforming pooled hidden states of models. Finally, we present an analysis of the intrinsic properties of the steering vectors. Taken together, our results suggest that frozen LMs can be effectively controlled through their latent steering space.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済み言語モデルから潜在的なステアリングベクトルを抽出する", "jabstract": "制御可能なテキスト生成に関する以前の研究は、訓練可能なデコーディング、スマートプロンプトデザイン、または望ましい目的に基づく微調整を通じて、言語モデルを制御する方法を学ぶことに焦点を当ててきました。私たちは、モデルを目標文を生成するように誘導するために必要な情報がすでにモデルにエンコードされていると仮定しています。そのため、私たちは全く異なるアプローチを探求しています：事前学習された言語モデルデコーダーから潜在ベクトルを直接抽出することで、微調整を行わずに。実験の結果、様々なドメインの英語の文に対して、隠れ状態に追加されたステアリングベクトルによって、ほぼ完璧に（> 99 BLEU）目標文が生成されることが示されました。ベクトル演算を使用して、Yelp感情ベンチマークでの教師なし感情転送に使用でき、このタスクに特化したモデルと同等の性能を発揮することが示されました。モデルのプールされた隠れ状態を上回り、テキスト類似性ベンチマーク（STS-B）で評価されたときに、ステアリングベクトル間の距離が文の類似性を反映することがわかりました。最後に、ステアリングベクトルの固有の特性に関する分析を提示します。これらの結果から、凍結された言語モデルは、その潜在的なステアリング空間を介して効果的に制御できることが示唆されています。"}
{"title": "Domain Generalisation of NMT: Fusing Adapters with Leave-One-Domain-Out Training", "url": "https://aclanthology.org/2022.findings-acl.49/", "abstract": "Generalising to unseen domains is under-explored and remains a challenge in neural machine translation. Inspired by recent research in parameter-efficient transfer learning from pretrained models, this paper proposes a fusion-based generalisation method that learns to combine domain-specific parameters. We propose a leave-one-domain-out training strategy to avoid information leaking to address the challenge of not knowing the test domain during training time. Empirical results on three language pairs show that our proposed fusion method outperforms other baselines up to +0.8 BLEU score on average.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "NMTのドメイン汎化：アダプターの融合とLeave-One-Domain-Outトレーニング", "jabstract": "未知のドメインに一般化することは、ニューラル機械翻訳において未開拓であり、課題である。事前学習モデルからのパラメータ効率の高い転移学習の最近の研究に着想を得て、本論文では、ドメイン固有のパラメータを組み合わせることを学習する融合ベースの一般化手法を提案する。テストドメインをトレーニング時に知らないという課題に対処するために、ドメインを1つ除外するトレーニング戦略を提案する。3つの言語ペアにおける実験結果は、提案された融合手法が平均で+0.8 BLEUスコアを上回ることを示している。"}
{"title": "Reframing Instructional Prompts to GPTk’s Language", "url": "https://aclanthology.org/2022.findings-acl.50/", "abstract": "What kinds of instructional prompts are easier to follow for Language Models (LMs)? We study this question by conducting extensive empirical analysis that shed light on important features of successful instructional prompts. Specifically, we study several classes of reframing techniques for manual reformulation of prompts into more effective ones. Some examples include decomposing a complex task instruction into multiple simpler tasks or itemizing instructions into sequential steps. Our experiments compare the zero-shot and few-shot performance of LMs prompted with reframed instructions on 12 NLP tasks across 6 categories. Compared with original instructions, our reframed instructions lead to significant improvements across LMs with different sizes. For example, the same reframed prompts boost few-shot performance of GPT3-series and GPT2-series by 12.5% and 6.7% respectively averaged over all tasks. Furthermore, reframed instructions reduce the number of examples required to prompt LMs in the few-shot setting. We hope these empirically-driven techniques will pave the way towards more effective future prompting algorithms.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Processing Capabilities\n\nGPTkの言語処理能力に基づく教示プロンプトの再構築", "jabstract": "言語モデル（LMs）にとって、どのような指示が従いやすいのか？我々は、成功した指示の重要な特徴を明らかにするために、広範な経験的分析を行うことで、この問いに取り組んでいます。具体的には、複数のより効果的な指示に手動で再構成するためのいくつかのリフレーミング技術のクラスを研究しています。例えば、複雑なタスク指示を複数のより単純なタスクに分解する、または指示を順序付けされたステップに分類するなどがあります。我々の実験は、6つのカテゴリーにまたがる12のNLPタスクで、リフレームされた指示で促されたLMのゼロショットおよびフューショットのパフォーマンスを比較します。オリジナルの指示と比較して、我々のリフレームされた指示は、異なるサイズのLMに対して有意な改善をもたらします。例えば、同じリフレームされた指示は、すべてのタスクの平均で、GPT3シリーズとGPT2シリーズのフューショットパフォーマンスをそれぞれ12.5％と6.7％向上させます。さらに、リフレームされた指示は、フューショット設定でLMを促すために必要な例の数を減らします。これらの経験的に駆動された技術が、より効果的な将来の促進アルゴリズムへの道を開くことを望んでいます。"}
{"title": "Read Top News First: A Document Reordering Approach for Multi-Document News Summarization", "url": "https://aclanthology.org/2022.findings-acl.51/", "abstract": "A common method for extractive multi-document news summarization is to re-formulate it as a single-document summarization problem by concatenating all documents as a single meta-document. However, this method neglects the relative importance of documents. We propose a simple approach to reorder the documents according to their relative importance before concatenating and summarizing them. The reordering makes the salient content easier to learn by the summarization model. Experiments show that our approach outperforms previous state-of-the-art methods with more complex architectures.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「トップニュースを最初に読む：マルチドキュメントニュース要約のための文書再配置アプローチ」という論文の要約です。", "jabstract": "抽出型マルチドキュメントニュース要約の一般的な手法は、すべてのドキュメントを単一のメタドキュメントとして連結することにより、単一ドキュメント要約問題として再定式化することです。しかし、この手法はドキュメントの相対的な重要性を無視しています。私たちは、ドキュメントを相対的な重要性に従って並べ替え、それらを連結して要約するための簡単なアプローチを提案します。並べ替えにより、要約モデルが重要なコンテンツをより簡単に学習できるようになります。実験の結果、私たちのアプローチは、より複雑なアーキテクチャを持つ以前の最先端の手法を上回る性能を発揮しました。"}
{"title": "Human Language Modeling", "url": "https://aclanthology.org/2022.findings-acl.52/", "abstract": "Natural language is generated by people, yet traditional language modeling views words or documents as if generated independently. Here, we propose human language modeling (HuLM), a hierarchical extension to the language modeling problem where by a human- level exists to connect sequences of documents (e.g. social media messages) and capture the notion that human language is moderated by changing human states. We introduce, HaRT, a large-scale transformer model for solving HuLM, pre-trained on approximately 100,000 social media users, and demonstrate it’s effectiveness in terms of both language modeling (perplexity) for social media and fine-tuning for 4 downstream tasks spanning document- and user-levels. Results on all tasks meet or surpass the current state-of-the-art.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "1. Natural language processing (NLP) is a field of study that focuses on the interaction between human language and computers.\n自然言語処理（NLP）は、人間の言語とコンピュータの相互作用に焦点を当てた研究分野です。\n\n2. One of the main goals of NLP is to enable computers to understand, interpret, and generate human language.\nNLPの主な目的の1つは、コンピュータが人間の言語を理解、解釈、生成できるようにすることです。\n\n3. This involves developing algorithms and models that can analyze and process natural language data, such as text and speech.\nこれには、テキストや音声などの自然言語データを分析、処理できるアルゴリズムやモデルを開発することが含まれます。\n\n4. Human language modeling is a key component of NLP, as it involves creating statistical models that can predict the likelihood of a given sequence of words.\n人間の言語モデリングは、与えられた単語のシーケンスの発生確率を予測できる統計モデルを作成することを含むNLPの重要な要素です。", "jabstract": "自然言語は人間によって生成されますが、従来の言語モデリングでは単語や文書を独立に生成されたものとして扱っています。ここでは、人間の状態が変化することによって人間の言語が調整されるという概念を捉え、文書のシーケンスを接続する人間レベルが存在する言語モデリング問題の階層的拡張である人間言語モデリング（HuLM）を提案します。我々は、約10万人のソーシャルメディアユーザーで事前学習された大規模なトランスフォーマーモデルであるHaRTを導入し、ソーシャルメディアの言語モデリング（パープレキシティ）と文書レベルおよびユーザーレベルをカバーする4つのダウンストリームタスクのファインチューニングにおいて、その効果を示します。すべてのタスクにおいて、現在の最先端を上回る結果が得られました。"}
{"title": "Inverse is Better! Fast and Accurate Prompt for Few-shot Slot Tagging", "url": "https://aclanthology.org/2022.findings-acl.53/", "abstract": "Prompting methods recently achieve impressive success in few-shot learning. These methods modify input samples with prompt sentence pieces, and decode label tokens to map samples to corresponding labels. However, such a paradigm is very inefficient for the task of slot tagging. Since slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token spans to find all the possible slots, which greatly slows down the prediction. To tackle this, we introduce an inverse paradigm for prompting. Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types. Such inverse prompting only requires a one-turn prediction for each slot type and greatly speeds up the prediction. Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types. We find, somewhat surprisingly, the proposed method not only predicts faster but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "逆は良い！少数ショットスロットタギングのための高速かつ正確なプロンプト", "jabstract": "プロンプト手法は、最近のfew-shot学習において印象的な成功を収めています。これらの手法は、プロンプト文の断片で入力サンプルを変更し、ラベルトークンをデコードしてサンプルを対応するラベルにマッピングします。しかし、このようなパラダイムは、スロットタギングのタスクに対して非常に効率的ではありません。スロットタギングのサンプルは、文中の複数の連続した単語であり、プロンプト手法はすべての可能なスロットを見つけるためにすべてのn-gramトークンスパンを列挙する必要があり、予測を大幅に遅らせます。これを解決するために、私たちはプロンプトの逆パラダイムを導入します。古典的なプロンプトがトークンをラベルにマッピングするのに対して、逆プロンプトはスロットタイプが与えられた場合にスロット値を逆に予測します。この逆プロンプトは、各スロットタイプに対して1回の予測しか必要とせず、予測を大幅に高速化します。さらに、私たちは新しい反復予測戦略を提案し、モデルが異なるスロットタイプ間の関係を考慮して予測を改善する方法を学習します。私たちは、驚くべきことに、提案された方法が予測を高速化するだけでなく、効果を大幅に改善し（10-shot設定で6.1 F1スコア以上の改善）、新しい最先端のパフォーマンスを達成することがわかりました。"}
{"title": "Cross-Modal Cloze Task: A New Task to Brain-to-Word Decoding", "url": "https://aclanthology.org/2022.findings-acl.54/", "abstract": "Decoding language from non-invasive brain activity has attracted increasing attention from both researchers in neuroscience and natural language processing. Due to the noisy nature of brain recordings, existing work has simplified brain-to-word decoding as a binary classification task which is to discriminate a brain signal between its corresponding word and a wrong one. This pairwise classification task, however, cannot promote the development of practical neural decoders for two reasons. First, it has to enumerate all pairwise combinations in the test set, so it is inefficient to predict a word in a large vocabulary. Second, a perfect pairwise decoder cannot guarantee the performance on direct classification. To overcome these and go a step further to a realistic neural decoder, we propose a novel Cross-Modal Cloze (CMC) task which is to predict the target word encoded in the neural image with a context as prompt. Furthermore, to address this task, we propose a general approach that leverages the pre-trained language model to predict the target word. To validate our method, we perform experiments on more than 20 participants from two brain imaging datasets. Our method achieves 28.91% top-1 accuracy and 54.19% top-5 accuracy on average across all participants, significantly outperforming several baselines. This result indicates that our model can serve as a state-of-the-art baseline for the CMC task. More importantly, it demonstrates that it is feasible to decode a certain word within a large vocabulary from its neural brain activity.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "クロスモーダル・クローズ・タスク：脳から単語デコードへの新しいタスク", "jabstract": "非侵襲的な脳活動から言語を解読することは、神経科学と自然言語処理の両方の研究者からますます注目されています。脳の記録のノイズのため、既存の研究では、脳信号を対応する単語と誤った単語の間で識別する二値分類タスクとして脳から単語をデコードすることが簡略化されています。しかし、このペアワイズ分類タスクは、テストセット内のすべてのペアワイズの組み合わせを列挙する必要があるため、大規模な語彙で単語を予測するのに効率的ではありません。また、完璧なペアワイズデコーダーでも、直接分類の性能を保証することはできません。これらを克服し、現実的なニューラルデコーダーに一歩進むために、我々は新しいクロスモーダルクローズ（CMC）タスクを提案します。このタスクは、プロンプトとしての文脈でニューラルイメージにエンコードされたターゲット単語を予測することです。さらに、このタスクに対処するために、我々は事前学習された言語モデルを活用してターゲット単語を予測する一般的なアプローチを提案します。我々の方法を検証するために、2つの脳画像データセットから20人以上の参加者で実験を行いました。我々の方法は、すべての参加者を平均したトップ1精度28.91％、トップ5精度54.19％を達成し、いくつかのベースラインを大幅に上回りました。この結果は、我々のモデルがCMCタスクの最先端のベースラインとして機能することができることを示しています。さらに重要なことに、これは、大規模な語彙からそのニューラル脳活動を介して特定の単語をデコードすることが可能であることを示しています。"}
{"title": "Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal", "url": "https://aclanthology.org/2022.findings-acl.55/", "abstract": "Language models excel at generating coherent text, and model compression techniques such as knowledge distillation have enabled their use in resource-constrained settings. However, these models can be biased in multiple ways, including the unfounded association of male and female genders with gender-neutral professions. Therefore, knowledge distillation without any fairness constraints may preserve or exaggerate the teacher model’s biases onto the distilled model. To this end, we present a novel approach to mitigate gender disparity in text generation by learning a fair model during knowledge distillation. We propose two modifications to the base knowledge distillation based on counterfactual role reversal—modifying teacher probabilities and augmenting the training set. We evaluate gender polarity across professions in open-ended text generated from the resulting distilled and finetuned GPT–2 models and demonstrate a substantial reduction in gender disparity with only a minor compromise in utility. Finally, we observe that language models that reduce gender polarity in language generation do not improve embedding fairness or downstream classification fairness.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「反事実的な役割逆転による蒸留言語モデルにおけるジェンダーバイアスの緩和」の要約文です。", "jabstract": "言語モデルは、一貫したテキストの生成に優れており、知識蒸留などのモデル圧縮技術により、リソース制約のある環境でも使用できるようになっています。しかし、これらのモデルには、男性と女性の性別を中立的な職業に関連付ける根拠のない偏見が含まれることがあります。したがって、公平性の制約なしでの知識蒸留は、教師モデルの偏見を蒸留されたモデルに保存または誇張する可能性があります。このため、私たちは、知識蒸留中に公平なモデルを学習することによって、テキスト生成における性差を緩和する新しいアプローチを提案します。私たちは、カウンターファクトロールリバーサルに基づくベースの知識蒸留に対して、教師の確率を変更する2つの変更とトレーニングセットを拡張することを提案します。私たちは、生成されたオープンエンドテキストから得られた蒸留されたGPT-2モデルとファインチューニングされたモデルにおける職業ごとの性別極性を評価し、公平性の大幅な低下とわずかな妥協による効用の低下を示します。最後に、言語モデルが言語生成における性別極性を低下させても、埋め込みの公平性やダウンストリームの分類の公平性は改善されないことを観察します。"}
{"title": "Domain Representative Keywords Selection: A Probabilistic Approach", "url": "https://aclanthology.org/2022.findings-acl.56/", "abstract": "We propose a probabilistic approach to select a subset of a target domain representative keywords from a candidate set, contrasting with a context domain. Such a task is crucial for many downstream tasks in natural language processing. To contrast the target domain and the context domain, we adapt the two-component mixture model concept to generate a distribution of candidate keywords. It provides more importance to the distinctive keywords of the target domain than common keywords contrasting with the context domain. To support the representativeness of the selected keywords towards the target domain, we introduce an optimization algorithm for selecting the subset from the generated candidate distribution. We have shown that the optimization algorithm can be efficiently implemented with a near-optimal approximation guarantee. Finally, extensive experiments on multiple domains demonstrate the superiority of our approach over other baselines for the tasks of keyword summary generation and trending keywords selection.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ドメイン代表キーワード選択：確率的アプローチ", "jabstract": "私たちは、自然言語処理における多くの下流タスクにとって重要な、候補セットからターゲットドメインの代表的なキーワードのサブセットを選択する確率的アプローチを提案します。ターゲットドメインとコンテキストドメインを対比するために、2つのコンポーネント混合モデルの概念を適応して、候補キーワードの分布を生成します。これにより、コンテキストドメインと対比して、ターゲットドメインの特徴的なキーワードにより重要性を与えます。選択されたキーワードがターゲットドメインに対して代表的であることをサポートするために、生成された候補分布からサブセットを選択するための最適化アルゴリズムを導入します。最適化アルゴリズムは、近似保証によりほぼ最適な実装が可能であることを示しました。最後に、複数のドメインでの広範な実験により、キーワードサマリー生成とトレンドキーワード選択のタスクにおいて、他のベースラインよりも私たちのアプローチの優位性が示されました。"}
{"title": "Hierarchical Inductive Transfer for Continual Dialogue Learning", "url": "https://aclanthology.org/2022.findings-acl.57/", "abstract": "Pre-trained models have achieved excellent performance on the dialogue task. However, for the continual increase of online chit-chat scenarios, directly fine-tuning these models for each of the new tasks not only explodes the capacity of the dialogue system on the embedded devices but also causes knowledge forgetting on pre-trained models and knowledge interference among diverse dialogue tasks. In this work, we propose a hierarchical inductive transfer framework to learn and deploy the dialogue skills continually and efficiently. First, we introduce the adapter module into pre-trained models for learning new dialogue tasks. As the only trainable module, it is beneficial for the dialogue system on the embedded devices to acquire new dialogue skills with negligible additional parameters. Then, for alleviating knowledge interference between tasks yet benefiting the regularization between them, we further design hierarchical inductive transfer that enables new tasks to use general knowledge in the base adapter without being misled by diverse knowledge in task-specific adapters. Empirical evaluation and analysis indicate that our framework obtains comparable performance under deployment-friendly model capacity.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "階層的帰納転移による継続的対話学習", "jabstract": "事前学習済みモデルは、対話タスクにおいて優れた性能を発揮しています。しかし、オンラインの雑談シナリオが増加し続けるにつれて、これらのモデルを直接ファインチューニングして新しいタスクごとに使用すると、埋め込みデバイス上の対話システムの容量が爆発的に増加するだけでなく、事前学習済みモデルの知識の忘却や多様な対話タスク間の知識干渉を引き起こします。本研究では、階層的帰納転移フレームワークを提案し、対話スキルを継続的かつ効率的に学習・展開することを目的としています。まず、事前学習済みモデルにアダプターモジュールを導入して新しい対話タスクを学習します。唯一のトレーニング可能なモジュールであるため、埋め込みデバイス上の対話システムが追加パラメータを無視できる程度に新しい対話スキルを習得するのに役立ちます。次に、タスク間の知識干渉を緩和しつつ、それらの間の正則化に利益をもたらすために、新しいタスクがタスク固有のアダプターの多様な知識に惑わされることなく、ベースアダプターの一般的な知識を利用できるようにする階層的帰納転移をさらに設計します。実証評価と分析により、我々のフレームワークが展開に適したモデル容量で同等の性能を発揮することが示されました。"}
{"title": "Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation", "url": "https://aclanthology.org/2022.findings-acl.58/", "abstract": "Current language generation models suffer from issues such as repetition, incoherence, and hallucinations. An often-repeated hypothesis for this brittleness of generation models is that it is caused by the training and the generation procedure mismatch, also referred to as exposure bias. In this paper, we verify this hypothesis by analyzing exposure bias from an imitation learning perspective. We show that exposure bias leads to an accumulation of errors during generation, analyze why perplexity fails to capture this accumulation of errors, and empirically show that this accumulation results in poor generation quality.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "なぜ露出バイアスが重要なのか：言語生成におけるエラー蓄積の模倣学習の観点から", "jabstract": "現在の言語生成モデルは、繰り返し、不一致、幻覚などの問題に苦しんでいます。この生成モデルの脆弱性の原因として、トレーニングと生成手順の不一致、すなわち露出バイアスがあるという仮説がしばしば唱えられています。本論文では、模倣学習の観点から露出バイアスを分析することで、この仮説を検証します。露出バイアスが生成中にエラーの蓄積を引き起こすこと、パープレキシティがこのエラーの蓄積を捉えることができない理由を分析し、この蓄積が生成品質の低下につながることを実証します。"}
{"title": "Question Answering Infused Pre-training of General-Purpose Contextualized Representations", "url": "https://aclanthology.org/2022.findings-acl.59/", "abstract": "We propose a pre-training objective based on question answering (QA) for learning general-purpose contextual representations, motivated by the intuition that the representation of a phrase in a passage should encode all questions that the phrase can answer in context. To this end, we train a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs. By encoding QA-relevant information, the bi-encoder’s token-level representations are useful for non-QA downstream tasks without extensive (or in some cases, any) fine-tuning. We show large improvements over both RoBERTa-large and previous state-of-the-art results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "一般的な目的の文脈化表現の事前学習における質問応答の統合", "jabstract": "私たちは、一般的な文脈表現を学習するための質問応答（QA）に基づく事前学習目的を提案します。これは、文中のフレーズの表現が、文脈においてフレーズが答えることができるすべての質問をエンコードするべきであるという直感に基づいています。このために、パッセージと質問を独立してエンコードするバイエンコーダQAモデルをトレーニングし、より正確なクロスエンコーダモデルの予測に一致させます。バイエンコーダのトークンレベル表現は、QA関連情報をエンコードすることにより、広範な（または一部の場合は全くない）ファインチューニングなしに、非QA下流タスクに有用です。私たちは、4つのデータセットでのゼロショットおよびフューショットの言い換え検出、2つのデータセットでのフューショットの固有表現認識、および3つのデータセットでのゼロショットの感情分析において、RoBERTa-largeおよび以前の最先端の結果に比べて大幅な改善を示します。"}
{"title": "Automatic Song Translation for Tonal Languages", "url": "https://aclanthology.org/2022.findings-acl.60/", "abstract": "This paper develops automatic song translation (AST) for tonal languages and addresses the unique challenge of aligning words’ tones with melody of a song in addition to conveying the original meaning. We propose three criteria for effective AST—preserving meaning, singability and intelligibility—and design metrics for these criteria. We develop a new benchmark for English–Mandarin song translation and develop an unsupervised AST system, Guided AliGnment for Automatic Song Translation (GagaST), which combines pre-training with three decoding constraints. Both automatic and human evaluations show GagaST successfully balances semantics and singability.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "トーン言語の自動歌詞翻訳", "jabstract": "この論文は、音声言語に対する自動歌詞翻訳（AST）を開発し、単語の音調を歌のメロディに合わせるという独自の課題に取り組み、元の意味を伝えることに加えて歌唱可能性と理解可能性の3つの効果的なASTの基準を提案し、これらの基準のためのメトリックを設計します。英語-中国語の歌詞翻訳のための新しいベンチマークを開発し、事前トレーニングと3つのデコーディング制約を組み合わせた自己学習型ASTシステム、Guided AliGnment for Automatic Song Translation（GagaST）を開発します。自動評価と人間の評価の両方が、GagaSTが意味と歌唱可能性をバランスよく保っていることを示しています。"}
{"title": "Read before Generate! Faithful Long Form Question Answering with Machine Reading", "url": "https://aclanthology.org/2022.findings-acl.61/", "abstract": "Long-form question answering (LFQA) aims to generate a paragraph-length answer for a given question. While current work on LFQA using large pre-trained model for generation are effective at producing fluent and somewhat relevant content, one primary challenge lies in how to generate a faithful answer that has less hallucinated content. We propose a new end-to-end framework that jointly models answer generation and machine reading. The key idea is to augment the generation model with fine-grained, answer-related salient information which can be viewed as an emphasis on faithful facts. State-of-the-art results on two LFQA datasets, ELI5 and MS MARCO, demonstrate the effectiveness of our method, in comparison with strong baselines on automatic and human evaluation metrics. A detailed analysis further proves the competency of our methods in generating fluent, relevant, and more faithful answers.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「生成する前に読むこと！機械読解による忠実な長文質問応答」", "jabstract": "長文質問応答（LFQA）は、与えられた質問に対して段落レベルの回答を生成することを目的としています。現在、大規模な事前学習モデルを使用したLFQAの現在の研究は、流暢でやや関連性のあるコンテンツを生成するのに効果的ですが、主な課題の1つは、幻想的なコンテンツが少ない忠実な回答を生成する方法です。私たちは、回答生成と機械読み取りを共同モデル化する新しいエンドツーエンドのフレームワークを提案します。主なアイデアは、忠実な事実に重点を置いた、細かい粒度の回答関連の顕著な情報を生成モデルに追加することです。ELI5とMS MARCOの2つのLFQAデータセットでの最新の結果は、自動評価および人間の評価指標において強力なベースラインと比較して、私たちの方法の効果を示しています。詳細な分析は、私たちの方法が流暢で関連性があり、より忠実な回答を生成する能力を証明しています。"}
{"title": "A Simple yet Effective Relation Information Guided Approach for Few-Shot Relation Extraction", "url": "https://aclanthology.org/2022.findings-acl.62/", "abstract": "Few-Shot Relation Extraction aims at predicting the relation for a pair of entities in a sentence by training with a few labelled examples in each relation. Some recent works have introduced relation information (i.e., relation labels or descriptions) to assist model learning based on Prototype Network. However, most of them constrain the prototypes of each relation class implicitly with relation information, generally through designing complex network structures, like generating hybrid features, combining with contrastive learning or attention networks. We argue that relation information can be introduced more explicitly and effectively into the model. Thus, this paper proposes a direct addition approach to introduce relation information. Specifically, for each relation class, the relation representation is first generated by concatenating two views of relations (i.e., [CLS] token embedding and the mean value of embeddings of all tokens) and then directly added to the original prototype for both train and prediction. Experimental results on the benchmark dataset FewRel 1.0 show significant improvements and achieve comparable results to the state-of-the-art, which demonstrates the effectiveness of our proposed approach. Besides, further analyses verify that the direct addition is a much more effective way to integrate the relation representations and the original prototypes.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「少数のサンプルによる関係抽出のためのシンプルで効果的な関係情報ガイドアプローチ」という論文の要約です。", "jabstract": "Few-Shot Relation Extractionは、各関係についてわずかなラベル付き例を使用してトレーニングすることにより、文のエンティティのペアの関係を予測することを目的としています。最近のいくつかの研究では、プロトタイプネットワークに基づくモデル学習を支援するために、関係情報（つまり、関係ラベルまたは説明）を導入しています。しかし、これらのほとんどは、複雑なネットワーク構造を設計することによって、一般的に関係情報を暗黙的に各関係クラスのプロトタイプに制約を課しています。ハイブリッド特徴の生成、対照的な学習や注意ネットワークの組み合わせなどが含まれます。私たちは、関係情報をモデルにより明示的かつ効果的に導入できると主張します。したがって、本論文では、関係情報を導入するための直接的な追加アプローチを提案しています。具体的には、各関係クラスについて、関係表現はまず2つのビューの関係（つまり、[CLS]トークン埋め込みとすべてのトークンの埋め込みの平均値）を連結して生成され、元のプロトタイプに直接追加されます。トレーニングと予測の両方に対してです。ベンチマークデータセットFewRel 1.0での実験結果は、私たちの提案手法の有効性を示し、最新技術と同等の結果を達成することができます。さらに、さらなる分析により、直接追加が関係表現と元のプロトタイプを統合するよりもはるかに効果的な方法であることが確認されました。"}
{"title": "MIMICause: Representation and automatic extraction of causal relation types from clinical notes", "url": "https://aclanthology.org/2022.findings-acl.63/", "abstract": "Understanding causal narratives communicated in clinical notes can help make strides towards personalized healthcare. Extracted causal information from clinical notes can be combined with structured EHR data such as patients’ demographics, diagnoses, and medications. This will enhance healthcare providers’ ability to identify aspects of a patient’s story communicated in the clinical notes and help make more informed decisions. In this work, we propose annotation guidelines, develop an annotated corpus and provide baseline scores to identify types and direction of causal relations between a pair of biomedical concepts in clinical notes; communicated implicitly or explicitly, identified either in a single sentence or across multiple sentences. We annotate a total of 2714 de-identified examples sampled from the 2018 n2c2 shared task dataset and train four different language model based architectures. Annotation based on our guidelines achieved a high inter-annotator agreement i.e. Fleiss’ kappa (𝜅) score of 0.72, and our model for identification of causal relations achieved a macro F1 score of 0.56 on the test data. The high inter-annotator agreement for clinical text shows the quality of our annotation guidelines while the provided baseline F1 score sets the direction for future research towards understanding narratives in clinical texts.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MIMICause：臨床ノートから因果関係タイプを表現および自動抽出するための手法", "jabstract": "臨床ノートで伝えられる因果関係の物語を理解することは、個人に合わせた医療に向けた進歩につながる。臨床ノートから抽出された因果関係の情報は、患者の人口統計、診断、および薬剤などの構造化されたEHRデータと組み合わせることができる。これにより、医療提供者は臨床ノートで伝えられる患者の物語の側面を特定し、より情報を得た上で意思決定を行うことができる。本研究では、注釈のガイドラインを提案し、注釈付きコーパスを開発し、臨床ノートでのバイオメディカルコンセプトのペア間の因果関係のタイプと方向を特定するためのベースラインスコアを提供する。これらは、単一の文または複数の文で明示的または暗黙的に伝えられたものである。2018年のn2c2共有タスクデータセットからサンプリングされた2714の匿名化された例を注釈し、4つの異なる言語モデルベースのアーキテクチャをトレーニングする。私たちのガイドラインに基づく注釈は、高い間注釈者一致度であるFleiss' kappa（𝜅）スコア0.72を達成し、因果関係の特定のためのモデルはテストデータでマクロF1スコア0.56を達成した。臨床テキストの高い間注釈者一致度は、私たちの注釈のガイドラインの質を示し、提供されたベースラインF1スコアは、臨床テキストの物語を理解するための将来の研究の方向性を示している。"}
{"title": "Compressing Sentence Representation for Semantic Retrieval via Homomorphic Projective Distillation", "url": "https://aclanthology.org/2022.findings-acl.64/", "abstract": "How to learn highly compact yet effective sentence representation? Pre-trained language models have been effective in many NLP tasks. However, these models are often huge and produce large sentence embeddings. Moreover, there is a big performance gap between large and small models. In this paper, we propose Homomorphic Projective Distillation (HPD) to learn compressed sentence embeddings. Our method augments a small Transformer encoder model with learnable projection layers to produce compact representations while mimicking a large pre-trained language model to retain the sentence representation quality. We evaluate our method with different model sizes on both semantic textual similarity (STS) and semantic retrieval (SR) tasks. Experiments show that our method achieves 2.7-4.5 points performance gain on STS tasks compared with previous best representations of the same size. In SR tasks, our method improves retrieval speed (8.2×) and memory usage (8.0×) compared with state-of-the-art large models. Our implementation is available at https://github.com/XuandongZhao/HPD.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n同型射影蒸留を介した意味的検索のための文の表現の圧縮", "jabstract": "高度にコンパクトで効果的な文表現を学ぶ方法は何か？事前学習された言語モデルは、多くのNLPタスクで効果的である。しかし、これらのモデルはしばしば巨大で、大きな文の埋め込みを生成する。さらに、大きなモデルと小さなモデルの性能には大きな差がある。本論文では、ホモモーフィックプロジェクティブディスティレーション（HPD）を提案し、圧縮された文の埋め込みを学習する。我々の方法は、学習可能な射影層を持つ小さなTransformerエンコーダーモデルを拡張し、大きな事前学習された言語モデルを模倣して文表現の品質を維持しながら、コンパクトな表現を生成する。我々は、異なるモデルサイズで意味的テキスト類似性（STS）および意味的検索（SR）タスクで我々の方法を評価する。実験結果は、同じサイズの以前の最高表現と比較して、STSタスクで2.7〜4.5ポイントの性能向上を達成することを示している。SRタスクでは、我々の方法は、最新の大規模モデルと比較して検索速度（8.2倍）とメモリ使用量（8.0倍）を改善する。我々の実装は、https://github.com/XuandongZhao/HPDで利用可能である。"}
{"title": "Debiasing Event Understanding for Visual Commonsense Tasks", "url": "https://aclanthology.org/2022.findings-acl.65/", "abstract": "We study event understanding as a critical step towards visual commonsense tasks.Meanwhile, we argue that current object-based event understanding is purely likelihood-based, leading to incorrect event prediction, due to biased correlation between events and objects.We propose to mitigate such biases with do-calculus, proposed in causality research, but overcoming its limited robustness, by an optimized aggregation with association-based prediction.We show the effectiveness of our approach, intrinsically by comparing our generated events with ground-truth event annotation, and extrinsically by downstream commonsense tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "視覚的な常識タスクのためのイベント理解の偏りを解消する", "jabstract": "私たちは、視覚的な常識的なタスクに向けた重要なステップとして、イベント理解を研究しています。一方で、現在のオブジェクトベースのイベント理解は純粋に尤度に基づいており、イベントとオブジェクトの間のバイアスのある相関により、誤ったイベント予測につながると主張しています。私たちは、因果関係研究で提案されたdo-calculusによってそのようなバイアスを緩和することを提案しますが、関連性に基づく予測と最適化された集計によって、限られた堅牢性を克服します。私たちは、生成されたイベントとグラウンドトゥルースのイベント注釈を比較することによって、私たちのアプローチの効果を内在的に示し、下流の常識的なタスクによって外在的に示します。"}
{"title": "Fact-Tree Reasoning for N-ary Question Answering over Knowledge Graphs", "url": "https://aclanthology.org/2022.findings-acl.66/", "abstract": "Current Question Answering over Knowledge Graphs (KGQA) task mainly focuses on performing answer reasoning upon KGs with binary facts. However, it neglects the n-ary facts, which contain more than two entities. In this work, we highlight a more challenging but under-explored task: n-ary KGQA, i.e., answering n-ary facts questions upon n-ary KGs. Nevertheless, the multi-hop reasoning framework popular in binary KGQA task is not directly applicable on n-ary KGQA. We propose two feasible improvements: 1) upgrade the basic reasoning unit from entity or relation to fact, and 2) upgrade the reasoning structure from chain to tree. Therefore, we propose a novel fact-tree reasoning framework, FacTree, which integrates the above two upgrades. FacTree transforms the question into a fact tree and performs iterative fact reasoning on the fact tree to infer the correct answer. Experimental results on the n-ary KGQA dataset we constructed and two binary KGQA benchmarks demonstrate the effectiveness of FacTree compared with state-of-the-art methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ナレッジグラフ上のN-ary質問応答のためのファクトツリー推論", "jabstract": "現在の知識グラフに関する質問応答（KGQA）タスクは、主に二元事実を持つKG上での回答推論に焦点を当てています。しかし、2つ以上のエンティティを含むn-ary事実は無視されています。本研究では、より困難で未開拓のタスクであるn-ary KGQA、つまりn-ary KG上でのn-ary事実の質問に答えることに焦点を当てます。しかし、二元KGQAタスクで一般的なマルチホップ推論フレームワークは、n-ary KGQAに直接適用することはできません。私たちは2つの実現可能な改善策を提案します：1）基本的な推論ユニットをエンティティまたは関係から事実にアップグレードすること、2）推論構造をチェーンからツリーにアップグレードすること。したがって、私たちは新しい事実ツリー推論フレームワーク、FacTreeを提案します。FacTreeは、質問を事実ツリーに変換し、事実ツリー上で反復的な事実推論を実行して正しい答えを推論します。私たちが構築したn-ary KGQAデータセットと2つの二元KGQAベンチマークでの実験結果は、FacTreeが最先端の方法と比較して効果的であることを示しています。"}
{"title": "DeepStruct: Pretraining of Language Models for Structure Prediction", "url": "https://aclanthology.org/2022.findings-acl.67/", "abstract": "We introduce a method for improving the structural understanding abilities of language models. Unlike previous approaches that finetune the models with task-specific augmentation, we pretrain language models to generate structures from the text on a collection of task-agnostic corpora. Our structure pretraining enables zero-shot transfer of the learned knowledge that models have about the structure tasks. We study the performance of this approach on 28 datasets, spanning 10 structure prediction tasks including open information extraction, joint entity and relation extraction, named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, factual probe, intent detection, and dialogue state tracking. We further enhance the pretraining with the task-specific training sets. We show that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that we evaluate. Our code and datasets will be made publicly available.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DeepStruct：構造予測のための言語モデルの事前学習", "jabstract": "私たちは、言語モデルの構造理解能力を向上させる方法を紹介します。タスク固有の拡張を用いてモデルを微調整する従来の手法とは異なり、私たちはタスクに依存しないコーパスの集合で言語モデルを事前学習し、テキストから構造を生成する方法を提案します。この構造事前学習により、モデルが構造タスクについて学んだ知識をゼロショットで転移することができます。私たちは、オープン情報抽出、共同エンティティおよび関係抽出、固有表現認識、関係分類、意味役割ラベリング、イベント抽出、共参照解決、事実的プローブ、意図検出、および対話状態追跡を含む10の構造予測タスクをカバーする28のデータセットで、この手法の性能を調査します。さらに、タスク固有のトレーニングセットで事前学習を強化します。私たちは、10Bパラメータの言語モデルがほとんどのタスクに対して非自明に転移し、評価した28のデータセットのうち21のデータセットで最先端の性能を発揮することを示します。私たちのコードとデータセットは公開されます。"}
{"title": "The Change that Matters in Discourse Parsing: Estimating the Impact of Domain Shift on Parser Error", "url": "https://aclanthology.org/2022.findings-acl.68/", "abstract": "Discourse analysis allows us to attain inferences of a text document that extend beyond the sentence-level. The current performance of discourse models is very low on texts outside of the training distribution’s coverage, diminishing the practical utility of existing models. There is need for a measure that can inform us to what extent our model generalizes from the training to the test sample when these samples may be drawn from distinct distributions. While this can be estimated via distribution shift, we argue that this does not directly correlate with change in the observed error of a classifier (i.e. error-gap). Thus, we propose to use a statistic from the theoretical domain adaptation literature which can be directly tied to error-gap. We study the bias of this statistic as an estimator of error-gap both theoretically and through a large-scale empirical study of over 2400 experiments on 6 discourse datasets from domains including, but not limited to: news, biomedical texts, TED talks, Reddit posts, and fiction. Our results not only motivate our proposal and help us to understand its limitations, but also provide insight on the properties of discourse models and datasets which improve performance in domain adaptation. For instance, we find that non-news datasets are slightly easier to transfer to than news datasets when the training and test sets are very different. Our code and an associated Python package are available to allow practitioners to make more informed model and dataset choices.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n論文のタイトル：「議論解析における重要な変化：ドメインシフトがパーサーエラーに与える影響の推定」\n\n答え：議論解析における重要な変化は、ドメインシフトがパーサーエラーに与える影響を推定することである。", "jabstract": "談話分析により、文単位を超えたテキスト文書の推論を得ることができます。現在の談話モデルの性能は、トレーニング分布の範囲外のテキストに対して非常に低く、既存のモデルの実用性を低下させています。これらのサンプルが異なる分布から抽出される場合、モデルがトレーニングからテストサンプルにどの程度一般化するかを知らせることができる尺度が必要です。これは分布シフトによって推定できますが、これは分類器の観測されたエラーの変化と直接相関しないと主張します（つまり、エラーギャップ）。したがって、私たちは、エラーギャップに直接関連付けることができる理論的ドメイン適応文献からの統計量を使用することを提案します。私たちは、理論的におよびニュース、バイオメディカルテキスト、TEDトーク、Reddit投稿、フィクションなどのドメインからの6つの談話データセットに対する2400以上の実験の大規模な経験的研究を通じて、この統計量のバイアスをエラーギャップの推定器として研究します。私たちの結果は、私たちの提案を動機付け、その限界を理解するのに役立ち、ドメイン適応における性能を向上させる談話モデルとデータセットの特性についての洞察を提供します。たとえば、トレーニングセットとテストセットが非常に異なる場合、ニュース以外のデータセットはニュースデータセットよりもやや転送しやすいことがわかりました。私たちのコードと関連するPythonパッケージは、実践者がより情報を得てモデルとデータセットを選択できるようにするために利用可能です。"}
{"title": "Mukayese: Turkish NLP Strikes Back", "url": "https://aclanthology.org/2022.findings-acl.69/", "abstract": "Having sufficient resources for language X lifts it from the under-resourced languages class, but not necessarily from the under-researched class. In this paper, we address the problem of the absence of organized benchmarks in the Turkish language. We demonstrate that languages such as Turkish are left behind the state-of-the-art in NLP applications. As a solution, we present Mukayese, a set of NLP benchmarks for the Turkish language that contains several NLP tasks. We work on one or more datasets for each benchmark and present two or more baselines. Moreover, we present four new benchmarking datasets in Turkish for language modeling, sentence segmentation, and spell checking. All datasets and baselines are available under: https://github.com/alisafaya/mukayese", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「ムカイセ：トルコの自然言語処理が復活する」", "jabstract": "言語Xに十分なリソースがあると、その言語はリソース不足の言語クラスから抜け出すことができますが、必ずしも未研究のクラスから抜け出すわけではありません。本論文では、トルコ語における整理されたベンチマークの不在の問題に取り組みます。トルコ語のような言語は、NLPアプリケーションの最新技術から遅れをとっていることを示します。その解決策として、トルコ語のためのNLPベンチマークである「Mukayese」を提案します。Mukayeseには、いくつかのNLPタスクを含むNLPベンチマークの1つ以上のデータセットに取り組み、2つ以上のベースラインを提示します。さらに、言語モデリング、文のセグメンテーション、スペルチェックのための4つの新しいベンチマークデータセットをトルコ語で提示します。すべてのデータセットとベースラインは、https://github.com/alisafaya/mukayeseで利用可能です。"}
{"title": "Virtual Augmentation Supported Contrastive Learning of Sentence Representations", "url": "https://aclanthology.org/2022.findings-acl.70/", "abstract": "Despite profound successes, contrastive representation learning relies on carefully designed data augmentations using domain-specific knowledge. This challenge is magnified in natural language processing, where no general rules exist for data augmentation due to the discrete nature of natural language. We tackle this challenge by presenting a Virtual augmentation Supported Contrastive Learning of sentence representations (VaSCL). Originating from the interpretation that data augmentation essentially constructs the neighborhoods of each training instance, we, in turn, utilize the neighborhood to generate effective data augmentations. Leveraging the large training batch size of contrastive learning, we approximate the neighborhood of an instance via its K-nearest in-batch neighbors in the representation space. We then define an instance discrimination task regarding the neighborhood and generate the virtual augmentation in an adversarial training manner. We access the performance of VaSCL on a wide range of downstream tasks and set a new state-of-the-art for unsupervised sentence representation learning.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「仮想拡張をサポートする対照的学習による文表現の向上」に関する論文の要約文です。\n\n- Virtual Augmentation Supported Contrastive Learning of Sentence Representations\n「仮想拡張をサポートする対照的学習による文表現の向上」\n- This paper proposes a novel approach to improve sentence representations using virtual augmentation and contrastive learning.\nこの論文では、仮想拡張と対照的学習を用いて、文表現を向上させる新しいアプローチを提案しています。\n- The proposed method leverages virtual augmentation to generate additional training examples and contrastive learning to encourage the model to distinguish between similar sentences.\n提案された手法は、仮想拡張を活用して追加のトレーニング例を生成し、対照的学習を用いてモデルが類似した文を区別するように促します。\n- Experimental results show that the proposed method outperforms existing methods on several benchmark datasets for sentence classification and similarity tasks.\n実験結果は、提案された手法が、文の分類や類似性のタスクにおいて、いくつかのベンチマークデータセットで既存の手法を上回ることを示しています。", "jabstract": "深い成功にもかかわらず、対照的表現学習は、ドメイン固有の知識を使用した注意深く設計されたデータ拡張に依存しています。自然言語処理では、自然言語の離散的な性質のため、データ拡張のための一般的なルールは存在しません。私たちは、文の表現の対比学習を仮想拡張支援によって行うことで、この課題に取り組んでいます。データ拡張は、基本的に各トレーニングインスタンスの近傍を構築するものであるという解釈から、私たちは近傍を利用して効果的なデータ拡張を生成することができます。対照的学習の大規模なトレーニングバッチサイズを活用し、表現空間内のK最近傍のバッチ内隣人によってインスタンスの近傍を近似します。そして、近傍に関するインスタンス識別タスクを定義し、仮想拡張を敵対的なトレーニング方法で生成します。私たちは、VaSCLの性能を幅広い下流タスクで評価し、非監督学習の文表現学習において新たな最高水準を設定しました。"}
{"title": "MoEfication: Transformer Feed-forward Layers are Mixtures of Experts", "url": "https://aclanthology.org/2022.findings-acl.71/", "abstract": "Recent work has shown that feed-forward networks (FFNs) in pre-trained Transformers are a key component, storing various linguistic and factual knowledge. However, the computational patterns of FFNs are still unclear. In this work, we study the computational patterns of FFNs and observe that most inputs only activate a tiny ratio of neurons of FFNs. This phenomenon is similar to the sparsity of the human brain, which drives research on functional partitions of the human brain. To verify whether functional partitions also emerge in FFNs, we propose to convert a model into its MoE version with the same parameters, namely MoEfication. Specifically, MoEfication consists of two phases: (1) splitting the parameters of FFNs into multiple functional partitions as experts, and (2) building expert routers to decide which experts will be used for each input. Experimental results show that MoEfication can conditionally use 10% to 30% of FFN parameters while maintaining over 95% original performance for different models on various downstream tasks. Besides, MoEfication brings two advantages: (1) it significantly reduces the FLOPS of inference, i.e., 2x speedup with 25% of FFN parameters, and (2) it provides a fine-grained perspective to study the inner mechanism of FFNs. The source code of this paper can be obtained from https://github.com/thunlp/MoEfication.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MoEfication：TransformerのFeed-forwardレイヤーは専門家の混合物である。", "jabstract": "最近の研究では、事前学習されたトランスフォーマーのフィードフォワードネットワーク（FFN）が、さまざまな言語的および事実的な知識を格納する重要なコンポーネントであることが示されています。しかし、FFNの計算パターンはまだ不明です。本研究では、FFNの計算パターンを研究し、ほとんどの入力がFFNのごく一部のニューロンしか活性化しない現象を観察しました。この現象は、人間の脳の疎性に似ており、人間の脳の機能的な分割に関する研究を推進しています。FFNでも機能的な分割が現れるかどうかを検証するために、モデルを同じパラメータでMoEバージョンに変換することを提案します。具体的には、MoEficationは2つのフェーズから構成されます：（1）FFNのパラメータを複数の機能的なパーティション（エキスパート）に分割し、（2）各入力に使用されるエキスパートを決定するエキスパートルーターを構築します。実験結果は、MoEficationが、さまざまな下流タスクの異なるモデルに対して、元のパフォーマンスを95％以上維持しながら、条件付きでFFNパラメータの10％から30％を使用できることを示しています。さらに、MoEficationには2つの利点があります：（1）推論のFLOPSを大幅に削減し、FFNパラメータの25％で2倍の高速化を実現し、（2）FFNの内部メカニズムを詳細に研究するための細かい視点を提供します。本論文のソースコードは、https://github.com/thunlp/MoEficationから入手できます。"}
{"title": "DS-TOD: Efficient Domain Specialization for Task-Oriented Dialog", "url": "https://aclanthology.org/2022.findings-acl.72/", "abstract": "Recent work has shown that self-supervised dialog-specific pretraining on large conversational datasets yields substantial gains over traditional language modeling (LM) pretraining in downstream task-oriented dialog (TOD). These approaches, however, exploit general dialogic corpora (e.g., Reddit) and thus presumably fail to reliably embed domain-specific knowledge useful for concrete downstream TOD domains. In this work, we investigate the effects of domain specialization of pretrained language models (PLMs) for TOD. Within our DS-TOD framework, we first automatically extract salient domain-specific terms, and then use them to construct DomainCC and DomainReddit – resources that we leverage for domain-specific pretraining, based on (i) masked language modeling (MLM) and (ii) response selection (RS) objectives, respectively. We further propose a resource-efficient and modular domain specialization by means of domain adapters – additional parameter-light layers in which we encode the domain knowledge. Our experiments with prominent TOD tasks – dialog state tracking (DST) and response retrieval (RR) – encompassing five domains from the MultiWOZ benchmark demonstrate the effectiveness of DS-TOD. Moreover, we show that the light-weight adapter-based specialization (1) performs comparably to full fine-tuning in single domain setups and (2) is particularly suitable for multi-domain specialization, where besides advantageous computational footprint, it can offer better TOD performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DS-TOD：タスク指向型対話の効率的なドメイン特化", "jabstract": "最近の研究では、大規模な会話データセットに対する自己教師ありの対話特化の事前学習が、従来の言語モデリング（LM）事前学習に比べて、タスク指向の対話（TOD）において大幅な改善をもたらすことが示されています。しかしながら、これらのアプローチは一般的な対話コーパス（例：Reddit）を利用しており、具体的なTODドメインに有用なドメイン固有の知識を信頼性良く埋め込むことができないと考えられます。本研究では、TODのための事前学習済み言語モデル（PLMs）のドメイン特化の効果を調査しています。DS-TODフレームワーク内で、まず自動的に顕著なドメイン固有語句を抽出し、それらを利用してDomainCCとDomainRedditを構築し、それぞれマスクされた言語モデリング（MLM）と応答選択（RS）の目的に基づくドメイン特化のために活用します。さらに、ドメインアダプターを用いたリソース効率的かつモジュール化されたドメイン特化を提案しています。我々の実験は、MultiWOZベンチマークからの5つのドメインを含む、対話状態追跡（DST）と応答検索（RR）の主要なTODタスクについて、DS-TODの有効性を示しています。さらに、軽量アダプターによる特化は、（1）単一ドメインのセットアップにおいて完全なファインチューニングと同等の性能を発揮し、（2）コンピュータリソースの利用効率が高く、特にマルチドメイン特化に適していることを示しています。"}
{"title": "Distinguishing Non-natural from Natural Adversarial Samples for More Robust Pre-trained Language Model", "url": "https://aclanthology.org/2022.findings-acl.73/", "abstract": "Recently, the problem of robustness of pre-trained language models (PrLMs) has received increasing research interest. Latest studies on adversarial attacks achieve high attack success rates against PrLMs, claiming that PrLMs are not robust. However, we find that the adversarial samples that PrLMs fail are mostly non-natural and do not appear in reality. We question the validity of the current evaluation of robustness of PrLMs based on these non-natural adversarial samples and propose an anomaly detector to evaluate the robustness of PrLMs with more natural adversarial samples. We also investigate two applications of the anomaly detector: (1) In data augmentation, we employ the anomaly detector to force generating augmented data that are distinguished as non-natural, which brings larger gains to the accuracy of PrLMs. (2) We apply the anomaly detector to a defense framework to enhance the robustness of PrLMs. It can be used to defend all types of attacks and achieves higher accuracy on both adversarial samples and compliant samples than other defense frameworks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nより堅牢な事前学習言語モデルのために、非自然的な敵対的サンプルと自然的なサンプルを区別する。", "jabstract": "最近、事前学習言語モデル（PrLMs）の頑健性の問題が増加している。最新の敵対的攻撃に関する研究では、PrLMsに対して高い攻撃成功率を達成し、PrLMsが頑健でないと主張している。しかし、PrLMsが失敗する敵対的サンプルは、ほとんどが非自然で現実には現れないことがわかった。これらの非自然な敵対的サンプルに基づくPrLMsの頑健性の現在の評価の妥当性を疑問視し、より自然な敵対的サンプルでPrLMsの頑健性を評価する異常検出器を提案する。また、異常検出器の2つの応用について調査する：（1）データ拡張では、異常検出器を使用して、非自然と区別される拡張データを生成することで、PrLMsの精度をより向上させる。 （2）異常検出器を防御フレームワークに適用して、PrLMsの頑健性を向上させる。これはすべての種類の攻撃を防御するために使用でき、他の防御フレームワークよりも敵対的サンプルと準拠サンプルの両方でより高い精度を達成することができる。"}
{"title": "Learning Adaptive Axis Attentions in Fine-tuning: Beyond Fixed Sparse Attention Patterns", "url": "https://aclanthology.org/2022.findings-acl.74/", "abstract": "We present a comprehensive study of sparse attention patterns in Transformer models. We first question the need for pre-training with sparse attention and present experiments showing that an efficient fine-tuning only approach yields a slightly worse but still competitive model. Then we compare the widely used local attention pattern and the less-well-studied global attention pattern, demonstrating that global patterns have several unique advantages. We also demonstrate that a flexible approach to attention, with different patterns across different layers of the model, is beneficial for some tasks. Drawing on this insight, we propose a novel Adaptive Axis Attention method, which learns—during fine-tuning—different attention patterns for each Transformer layer depending on the downstream task. Rather than choosing a fixed attention pattern, the adaptive axis attention method identifies important tokens—for each task and model layer—and focuses attention on those. It does not require pre-training to accommodate the sparse patterns and demonstrates competitive and sometimes better performance against fixed sparse attention patterns that require resource-intensive pre-training.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「学習可能な軸注意力を微調整において学ぶ：固定された疎な注意パターンを超えて」", "jabstract": "私たちはTransformerモデルにおける疎な注意パターンの包括的な研究を提供します。まず、疎な注意を前処理する必要性に疑問を投げかけ、効率的なファインチューニングのみのアプローチがわずかに劣るが競争力のあるモデルを生み出すことを示す実験を行います。次に、広く使用されているローカルな注意パターンと、あまり研究されていないグローバルな注意パターンを比較し、グローバルなパターンにはいくつかの独自の利点があることを示します。また、モデルの異なるレイヤーごとに異なるパターンを持つ柔軟なアテンションアプローチがいくつかのタスクにとって有益であることを示します。この洞察に基づき、私たちは新しい適応軸アテンション法を提案します。この方法は、ファインチューニング中に、ダウンストリームタスクに応じて各Transformerレイヤーごとに異なる注意パターンを学習します。固定された注意パターンを選択するのではなく、適応軸アテンション法は、各タスクとモデルレイヤーに重要なトークンを特定し、それらに注意を集中させます。疎なパターンを収容するための前処理は必要なく、リソースを消費する固定された疎な注意パターンに対して競争力のある、そして時にはより優れたパフォーマンスを示します。"}
{"title": "Using Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment", "url": "https://aclanthology.org/2022.findings-acl.75/", "abstract": "Most research on question answering focuses on the pre-deployment stage; i.e., building an accurate model for deployment.In this paper, we ask the question: Can we improve QA systems further post-deployment based on user interactions? We focus on two kinds of improvements: 1) improving the QA system’s performance itself, and 2) providing the model with the ability to explain the correctness or incorrectness of an answer.We collect a retrieval-based QA dataset, FeedbackQA, which contains interactive feedback from users. We collect this dataset by deploying a base QA system to crowdworkers who then engage with the system and provide feedback on the quality of its answers.The feedback contains both structured ratings and unstructured natural language explanations.We train a neural model with this feedback data that can generate explanations and re-score answer candidates. We show that feedback data not only improves the accuracy of the deployed QA system but also other stronger non-deployed systems. The generated explanations also help users make informed decisions about the correctness of answers.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "展開後の質問応答システムの精度と説明可能性を向上させるためのインタラクティブフィードバックの利用", "jabstract": "質問応答に関するほとんどの研究は、展開前の段階、つまり展開に正確なモデルを構築することに焦点を当てています。本論文では、次の問いを投げかけます。ユーザーの相互作用に基づいてQAシステムを展開後にさらに改善できるでしょうか？私たちは、2つの種類の改善に焦点を当てます。1つは、QAシステム自体の性能を向上させること、もう1つは、回答の正誤を説明する能力をモデルに与えることです。私たちは、ユーザーからの対話的なフィードバックを含む検索ベースのQAデータセット、FeedbackQAを収集します。私たちは、ベースのQAシステムをクラウドワーカーに展開し、システムとやり取りして回答の品質についてフィードバックを提供してもらうことで、このデータセットを収集します。フィードバックには、構造化された評価と非構造化の自然言語の説明が含まれます。私たちは、このフィードバックデータでニューラルモデルをトレーニングし、説明を生成し、回答候補を再スコアリングできるようにします。フィードバックデータが、展開されたQAシステムの精度だけでなく、他のより強力な非展開システムの精度も向上することを示します。生成された説明は、回答の正誤についての情報を提供し、ユーザーが情報を得て判断を下すのに役立ちます。"}
{"title": "To be or not to be an Integer? Encoding Variables for Mathematical Text", "url": "https://aclanthology.org/2022.findings-acl.76/", "abstract": "The application of Natural Language Inference (NLI) methods over large textual corpora can facilitate scientific discovery, reducing the gap between current research and the available large-scale scientific knowledge. However, contemporary NLI models are still limited in interpreting mathematical knowledge written in Natural Language, even though mathematics is an integral part of scientific argumentation for many disciplines. One of the fundamental requirements towards mathematical language understanding, is the creation of models able to meaningfully represent variables. This problem is particularly challenging since the meaning of a variable should be assigned exclusively from its defining type, i.e., the representation of a variable should come from its context. Recent research has formalised the variable typing task, a benchmark for the understanding of abstract mathematical types and variables in a sentence. In this work, we propose VarSlot, a Variable Slot-based approach, which not only delivers state-of-the-art results in the task of variable typing, but is also able to create context-based representations for variables.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「整数であるか否か？数学的テキストの変数のエンコーディング」", "jabstract": "自然言語推論（NLI）手法を大規模なテキストコーパスに適用することで、科学的発見を促進し、現在の研究と利用可能な大規模な科学的知識の間のギャップを縮めることができます。しかし、現代のNLIモデルは、数学的知識を自然言語で書かれたものから解釈することにまだ限界があります。数学は多くの学問分野において科学的論証の不可欠な部分であるにもかかわらずです。数学的言語理解に向けた基本的な要件の1つは、変数を意味のある方法で表現できるモデルを作成することです。この問題は特に難しいものであり、変数の意味はその定義されたタイプからのみ割り当てられるべきであり、つまり、変数の表現はその文脈から来るべきです。最近の研究では、抽象的な数学的タイプと変数の理解のためのベンチマークである変数のタイピングタスクが形式化されました。本研究では、変数スロットベースのアプローチであるVarSlotを提案し、変数のタイピングタスクにおいて最先端の結果を提供するだけでなく、変数の文脈に基づいた表現を作成することができます。"}
{"title": "GRS: Combining Generation and Revision in Unsupervised Sentence Simplification", "url": "https://aclanthology.org/2022.findings-acl.77/", "abstract": "We propose GRS: an unsupervised approach to sentence simplification that combines text generation and text revision. We start with an iterative framework in which an input sentence is revised using explicit edit operations, and add paraphrasing as a new edit operation. This allows us to combine the advantages of generative and revision-based approaches: paraphrasing captures complex edit operations, and the use of explicit edit operations in an iterative manner provides controllability and interpretability. We demonstrate these advantages of GRS compared to existing methods on the Newsela and ASSET datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "GRS：教師なし文の簡素化において生成と修正を組み合わせる", "jabstract": "私たちは、テキスト生成とテキスト修正を組み合わせた教師なしアプローチであるGRSを提案します。入力文を明示的な編集操作を用いて修正する反復フレームワークから始め、パラフレーズを新しい編集操作として追加します。これにより、生成型アプローチと修正型アプローチの利点を組み合わせることができます。パラフレーズは複雑な編集操作を捉え、反復的に明示的な編集操作を使用することで、制御性と解釈性を提供します。私たちは、NewselaとASSETのデータセットにおいて、GRSのこれらの利点を既存の手法と比較して示します。"}
{"title": "BPE vs. Morphological Segmentation: A Case Study on Machine Translation of Four Polysynthetic Languages", "url": "https://aclanthology.org/2022.findings-acl.78/", "abstract": "Morphologically-rich polysynthetic languages present a challenge for NLP systems due to data sparsity, and a common strategy to handle this issue is to apply subword segmentation. We investigate a wide variety of supervised and unsupervised morphological segmentation methods for four polysynthetic languages: Nahuatl, Raramuri, Shipibo-Konibo, and Wixarika. Then, we compare the morphologically inspired segmentation methods against Byte-Pair Encodings (BPEs) as inputs for machine translation (MT) when translating to and from Spanish. We show that for all language pairs except for Nahuatl, an unsupervised morphological segmentation algorithm outperforms BPEs consistently and that, although supervised methods achieve better segmentation scores, they under-perform in MT challenges. Finally, we contribute two new morphological segmentation datasets for Raramuri and Shipibo-Konibo, and a parallel corpus for Raramuri–Spanish.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "BPEと形態論的分割：多合成言語の機械翻訳における事例研究", "jabstract": "形態豊かな多合成言語は、データのまばらさによりNLPシステムにとって課題を提供し、この問題に対処する一般的な戦略は、サブワード分割を適用することです。私たちは、4つの多合成言語（ナワトル語、ララムリ語、シピボ・コニボ語、ウィシャリカ語）に対して、様々な教師あり・教師なしの形態論的分割手法を調査しました。そして、スペイン語との翻訳において、形態論に着想を得た分割手法とByte-Pair Encodings（BPE）を比較しました。私たちは、ナワトル語を除くすべての言語ペアにおいて、教師なしの形態論的分割アルゴリズムが一貫してBPEを上回ることを示し、教師ありの方法は分割スコアが良くなるものの、MTの課題では性能が低下することを示しました。最後に、私たちはララムリ語とシピボ・コニボ語の2つの形態論的分割データセットと、ララムリ語-スペイン語の並列コーパスを貢献しました。"}
{"title": "Distributed NLI: Learning to Predict Human Opinion Distributions for Language Reasoning", "url": "https://aclanthology.org/2022.findings-acl.79/", "abstract": "We introduce distributed NLI, a new NLU task with a goal to predict the distribution of human judgements for natural language inference. We show that by applying additional distribution estimation methods, namely, Monte Carlo (MC) Dropout, Deep Ensemble, Re-Calibration, and Distribution Distillation, models can capture human judgement distribution more effectively than the softmax baseline. We show that MC Dropout is able to achieve decent performance without any distribution annotations while Re-Calibration can give further improvements with extra distribution annotations, suggesting the value of multiple annotations for one example in modeling the distribution of human judgements. Despite these improvements, the best results are still far below the estimated human upper-bound, indicating that predicting the distribution of human judgements is still an open, challenging problem with a large room for improvements. We showcase the common errors for MC Dropout and Re-Calibration. Finally, we give guidelines on the usage of these methods with different levels of data availability and encourage future work on modeling the human opinion distribution for language reasoning.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "分散型NLI：言語推論のための人間の意見分布を予測する学習", "jabstract": "私たちは、自然言語推論の人間の判断の分布を予測することを目的とした新しいNLUタスクである分散NLIを紹介する。Monte Carlo（MC）Dropout、Deep Ensemble、Re-Calibration、Distribution Distillationという追加の分布推定手法を適用することで、モデルがソフトマックスベースラインよりも人間の判断分布をより効果的に捉えることができることを示す。MC Dropoutは分布注釈なしでもまずまずの性能を発揮できる一方、Re-Calibrationは追加の分布注釈によりさらなる改善が可能であり、1つの例に対して複数の注釈を使用することが人間の判断分布のモデリングにおいて有用であることを示唆している。これらの改善にもかかわらず、最高の結果はまだ推定された人間の上限よりも遥かに低く、人間の判断分布を予測することはまだ改善の余地が大きい、開かれた課題であることを示している。MC DropoutとRe-Calibrationの一般的なエラーを紹介し、異なるデータの利用可能性のレベルに応じたこれらの手法の使用に関するガイドラインを提供し、言語推論のための人間の意見分布のモデリングに関する将来の研究を促す。"}
{"title": "Morphological Processing of Low-Resource Languages: Where We Are and What’s Next", "url": "https://aclanthology.org/2022.findings-acl.80/", "abstract": "Automatic morphological processing can aid downstream natural language processing applications, especially for low-resource languages, and assist language documentation efforts for endangered languages. Having long been multilingual, the field of computational morphology is increasingly moving towards approaches suitable for languages with minimal or no annotated resources. First, we survey recent developments in computational morphology with a focus on low-resource languages. Second, we argue that the field is ready to tackle the logical next challenge: understanding a language’s morphology from raw text alone. We perform an empirical study on a truly unsupervised version of the paradigm completion task and show that, while existing state-of-the-art models bridged by two newly proposed models we devise perform reasonably, there is still much room for improvement. The stakes are high: solving this task will increase the language coverage of morphological resources by a number of magnitudes.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "低資源言語の形態論処理：現状と今後の展望", "jabstract": "自動形態処理は、低資源言語に特に有用であり、絶滅危惧言語の言語文書化の助けとなることができます。長年にわたり多言語を扱ってきた計算形態論の分野は、注釈付きリソースが最小限または存在しない言語に適したアプローチに向かっています。まず、低資源言語に焦点を当てて、計算形態論の最近の発展を調査します。次に、次の論理的な課題に取り組む準備が整っていると主張します。つまり、生のテキストから言語の形態を理解することです。私たちは、真に非監視のパラダイム完了タスクの実証的研究を行い、既存の最先端モデルが2つの新しい提案モデルによって橋渡しされても、まだ改善の余地があることを示します。このタスクを解決することは、形態リソースの言語カバレッジを数倍に増やすことになります。"}
{"title": "Learning and Evaluating Character Representations in Novels", "url": "https://aclanthology.org/2022.findings-acl.81/", "abstract": "We address the problem of learning fixed-length vector representations of characters in novels. Recent advances in word embeddings have proven successful in learning entity representations from short texts, but fall short on longer documents because they do not capture full book-level information. To overcome the weakness of such text-based embeddings, we propose two novel methods for representing characters: (i) graph neural network-based embeddings from a full corpus-based character network; and (ii) low-dimensional embeddings constructed from the occurrence pattern of characters in each novel. We test the quality of these character embeddings using a new benchmark suite to evaluate character representations, encompassing 12 different tasks. We show that our representation techniques combined with text-based embeddings lead to the best character representations, outperforming text-based embeddings in four tasks. Our dataset and evaluation script will be made publicly available to stimulate additional work in this area.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "小説における文字表現の学習と評価", "jabstract": "小説の文字の固定長ベクトル表現の学習問題に取り組みます。単語の埋め込みの最近の進歩は、短いテキストからエンティティ表現を学習するのに成功していますが、長いドキュメントでは完全な書籍レベルの情報を捉えることができないため、不十分です。このようなテキストベースの埋め込みの弱点を克服するために、私たちは2つの新しい方法を提案しています：（i）全体的なコーパスベースの文字ネットワークからのグラフニューラルネットワークベースの埋め込み；および（ii）各小説の文字の出現パターンから構築された低次元の埋め込み。私たちは、12の異なるタスクを包括する文字表現を評価するための新しいベンチマークスイートを使用して、これらの文字埋め込みの品質をテストします。私たちは、テキストベースの埋め込みと組み合わせた表現技術が、4つのタスクでテキストベースの埋め込みを上回る最高の文字表現を導くことを示します。私たちのデータセットと評価スクリプトは、この分野での追加の作業を刺激するために公開されます。"}
{"title": "Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension", "url": "https://aclanthology.org/2022.findings-acl.82/", "abstract": "Machine reading comprehension (MRC) has drawn a lot of attention as an approach for assessing the ability of systems to understand natural language. Usually systems focus on selecting the correct answer to a question given a contextual paragraph. However, for many applications of multiple-choice MRC systems there are two additional considerations. For multiple-choice exams there is often a negative marking scheme; there is a penalty for an incorrect answer. In terms of an MRC system this means that the system is required to have an idea of the uncertainty in the predicted answer. The second consideration is that many multiple-choice questions have the option of none-of-the-above (NOA) indicating that none of the answers is applicable, rather than there always being the correct answer in the list of choices. This paper investigates both of these issues by making use of predictive uncertainty. Whether the system should propose an answer is a direct application of answer uncertainty. There are two possibilities when considering the NOA option. The simplest is to explicitly build a system on data that includes this option. Alternatively uncertainty can be applied to detect whether the other options include the correct answer. If the system is not sufficiently confident it will select NOA. As there is no standard corpus available to investigate these topics, the ReClor corpus is modified by removing the correct answer from a subset of possible answers. A high-performance MRC system is used to evaluate whether answer uncertainty can be applied in these situations. It is shown that uncertainty does allow questions that the system is not confident about to be detected. Additionally it is shown that uncertainty outperforms a system explicitly built with an NOA option.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "機械読解における多肢選択式問題において、回答の不確実性と回答不能性についての研究。", "jabstract": "機械読解（MRC）は、自然言語を理解するシステムの能力を評価する手法として注目されています。通常、システムは文脈のある段落が与えられた質問に対して正しい答えを選択することに焦点を当てます。しかし、多肢選択式MRCシステムの多くのアプリケーションには、2つの追加の考慮事項があります。多肢選択式試験では、誤った答えにペナルティが課せられる場合があります。MRCシステムにとっては、予測された答えの不確実性を把握する必要があります。2つ目の考慮事項は、多くの多肢選択問題には、適用可能な答えがないことを示す「全くない」（NOA）オプションがあることです。これは、常に選択肢のリストに正しい答えがあるわけではないことを意味します。本論文では、予測的な不確実性を利用して、これらの問題の両方を調査します。システムが答えを提案すべきかどうかは、答えの不確実性の直接的な適用です。NOAオプションを考慮する場合、2つの可能性があります。最も単純な方法は、このオプションを含むデータ上にシステムを明示的に構築することです。また、他のオプションに正しい答えが含まれているかどうかを検出するために不確実性を適用することもできます。システムが十分に自信を持っていない場合、NOAを選択します。これらのトピックを調査するための標準的なコーパスがないため、ReClorコーパスは、可能な答えのサブセットから正しい答えを除去することによって修正されます。高性能なMRCシステムを使用して、これらの状況で答えの不確実性を適用できるかどうかを評価します。不確実性によって、システムが自信を持っていない質問が検出できることが示されます。さらに、不確実性は、明示的にNOAオプションを持つシステムよりも優れた性能を発揮することが示されています。"}
{"title": "Measuring the Language of Self-Disclosure across Corpora", "url": "https://aclanthology.org/2022.findings-acl.83/", "abstract": "Being able to reliably estimate self-disclosure – a key component of friendship and intimacy – from language is important for many psychology studies. We build single-task models on five self-disclosure corpora, but find that these models generalize poorly; the within-domain accuracy of predicted message-level self-disclosure of the best-performing model (mean Pearson’s r=0.69) is much higher than the respective across data set accuracy (mean Pearson’s r=0.32), due to both variations in the corpora (e.g., medical vs. general topics) and labeling instructions (target variables: self-disclosure, emotional disclosure, intimacy). However, some lexical features, such as expression of negative emotions and use of first person personal pronouns such as ‘I’ reliably predict self-disclosure across corpora. We develop a multi-task model that yields better results, with an average Pearson’s r of 0.37 for out-of-corpora prediction.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "コーパス間の自己開示の言語を測定する", "jabstract": "言語から自己開示を信頼性高く推定することは、友情や親密さの重要な要素であるため、多くの心理学研究において重要である。我々は、5つの自己開示コーパスに対して単一タスクモデルを構築したが、これらのモデルは一般化が不十分であることがわかった。最も優れたパフォーマンスを発揮したモデルの予測メッセージレベルの自己開示のドメイン内精度（平均ピアソン相関係数=0.69）は、それぞれのデータセット間の精度（平均ピアソン相関係数=0.32）よりもはるかに高い。これは、コーパスの変動（例：医療対一般的なトピック）やラベリング指示（ターゲット変数：自己開示、感情開示、親密さ）の両方によるものである。しかし、ネガティブな感情の表現や「私」などの一人称代名詞の使用など、いくつかの語彙的特徴は、コーパスを横断して自己開示を信頼性高く予測することができる。我々は、より良い結果をもたらすマルチタスクモデルを開発し、コーパス外予測の平均ピアソン相関係数が0.37となった。"}
{"title": "When Chosen Wisely, More Data Is What You Need: A Universal Sample-Efficient Strategy For Data Augmentation", "url": "https://aclanthology.org/2022.findings-acl.84/", "abstract": "Data Augmentation (DA) is known to improve the generalizability of deep neural networks. Most existing DA techniques naively add a certain number of augmented samples without considering the quality and the added computational cost of these samples. To tackle this problem, a common strategy, adopted by several state-of-the-art DA methods, is to adaptively generate or re-weight augmented samples with respect to the task objective during training. However, these adaptive DA methods: (1) are computationally expensive and not sample-efficient, and (2) are designed merely for a specific setting. In this work, we present a universal DA technique, called Glitter, to overcome both issues. Glitter can be plugged into any DA method, making training sample-efficient without sacrificing performance. From a pre-generated pool of augmented samples, Glitter adaptively selects a subset of worst-case samples with maximal loss, analogous to adversarial DA. Without altering the training strategy, the task objective can be optimized on the selected subset. Our thorough experiments on the GLUE benchmark, SQuAD, and HellaSwag in three widely used training setups including consistency training, self-distillation and knowledge distillation reveal that Glitter is substantially faster to train and achieves a competitive performance, compared to strong baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "適切に選択された場合、より多くのデータが必要です：データ拡張のための普遍的なサンプル効率戦略", "jabstract": "データ拡張（DA）は、深層ニューラルネットワークの汎化性能を向上させることが知られています。既存のDA技術の多くは、追加される拡張サンプルの品質や追加される計算コストを考慮せずに、ある一定数の拡張サンプルを単純に追加します。この問題に対処するため、いくつかの最先端のDA方法で採用されている一般的な戦略は、トレーニング中にタスク目的に応じて拡張サンプルを適応的に生成または再重み付けすることです。しかし、これらの適応型DA方法は、(1)計算コストが高く、サンプル効率が悪く、(2)特定の設定にしか対応していません。本研究では、これらの両方の問題を克服するための汎用的なDA技術であるGlitterを提案します。Glitterは、どのDA方法にもプラグインでき、パフォーマンスを犠牲にすることなくトレーニングのサンプル効率を高めることができます。事前に生成された拡張サンプルのプールから、Glitterは最大損失を持つ最悪のケースのサブセットを適応的に選択し、敵対的なDAに類似した方法で最適化できます。トレーニング戦略を変更することなく、選択されたサブセットでタスク目的を最適化できます。GLUEベンチマーク、SQuAD、およびHellaSwagの徹底的な実験により、一貫性トレーニング、自己蒸留、および知識蒸留を含む3つの広く使用されているトレーニングセットアップで、Glitterは強力なベースラインと比較して、トレーニングが大幅に速く、競争力のあるパフォーマンスを発揮することが示されました。"}
{"title": "Explaining Classes through Stable Word Attributions", "url": "https://aclanthology.org/2022.findings-acl.85/", "abstract": "Input saliency methods have recently become a popular tool for explaining predictions of deep learning models in NLP. Nevertheless, there has been little work investigating methods for aggregating prediction-level explanations to the class level, nor has a framework for evaluating such class explanations been established. We explore explanations based on XLM-R and the Integrated Gradients input attribution method, and propose 1) the Stable Attribution Class Explanation method (SACX) to extract keyword lists of classes in text classification tasks, and 2) a framework for the systematic evaluation of the keyword lists. We find that explanations of individual predictions are prone to noise, but that stable explanations can be effectively identified through repeated training and explanation. We evaluate on web register data and show that the class explanations are linguistically meaningful and distinguishing of the classes.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "安定した単語属性を通じてクラスを説明する", "jabstract": "最近、入力注目度の手法は、NLPにおける深層学習モデルの予測を説明するための人気のあるツールになっています。しかし、予測レベルの説明をクラスレベルに集約する方法や、そのようなクラス説明を評価するためのフレームワークはほとんど研究されていません。本研究では、XLM-RとIntegrated Gradients入力帰属法に基づく説明を探求し、1）テキスト分類タスクのクラスのキーワードリストを抽出するためのStable Attribution Class Explanation method（SACX）を提案し、2）キーワードリストの体系的な評価のためのフレームワークを提案します。個々の予測の説明はノイズに影響されやすいことがわかりましたが、繰り返しトレーニングと説明を行うことで安定した説明を効果的に特定できることがわかりました。Web登録データで評価し、クラス説明が言語的に意味があり、クラスを区別することができることを示しました。"}
{"title": "What to Learn, and How: Toward Effective Learning from Rationales", "url": "https://aclanthology.org/2022.findings-acl.86/", "abstract": "Learning from rationales seeks to augment model prediction accuracy using human-annotated rationales (i.e. subsets of input tokens) that justify their chosen labels, often in the form of intermediate or multitask supervision. While intuitive, this idea has proven elusive in practice. We make two observations about human rationales via empirical analyses:1) maximizing rationale supervision accuracy is not necessarily the optimal objective for improving model accuracy; 2) human rationales vary in whether they provide sufficient information for the model to exploit for prediction.Building on these insights, we propose several novel loss functions and learning strategies, and evaluate their effectiveness on three datasets with human rationales. Our results demonstrate consistent improvements over baselines in both label and rationale accuracy, including a 3% accuracy improvement on MultiRC. Our work highlights the importance of understanding properties of human explanations and exploiting them accordingly in model training.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "何を学び、どのように学ぶか：根拠からの効果的な学習に向けて", "jabstract": "「理由から学ぶ」は、人間によって注釈付けされた理由（つまり、選択されたラベルを正当化する入力トークンのサブセット）を使用して、モデルの予測精度を向上させることを目的としています。これは直感的な考えですが、実際には難しいことがわかっています。経験的な分析により、人間の理由について2つの観察結果が得られました。1）理由の監視精度を最大化することが、モデルの精度を向上させるために必ずしも最適な目的ではないこと。2）人間の理由は、モデルが予測に利用するための十分な情報を提供するかどうかによって異なること。これらの洞察に基づいて、いくつかの新しい損失関数と学習戦略を提案し、人間の理由が付与された3つのデータセットでその効果を評価しました。結果は、ラベルと理由の両方の精度において、ベースラインに比べて一貫して改善が見られ、MultiRCでは3％の精度向上が確認されました。本研究は、人間の説明の特性を理解し、モデルのトレーニングに適切に活用することの重要性を強調しています。"}
{"title": "Listening to Affected Communities to Define Extreme Speech: Dataset and Experiments", "url": "https://aclanthology.org/2022.findings-acl.87/", "abstract": "Building on current work on multilingual hate speech (e.g., Ousidhoum et al. (2019)) and hate speech reduction (e.g., Sap et al. (2020)), we present XTREMESPEECH, a new hate speech dataset containing 20,297 social media passages from Brazil, Germany, India and Kenya. The key novelty is that we directly involve the affected communities in collecting and annotating the data – as opposed to giving companies and governments control over defining and combatting hate speech. This inclusive approach results in datasets more representative of actually occurring online speech and is likely to facilitate the removal of the social media content that marginalized communities view as causing the most harm. Based on XTREMESPEECH, we establish novel tasks with accompanying baselines, provide evidence that cross-country training is generally not feasible due to cultural differences between countries and perform an interpretability analysis of BERT’s predictions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「極端なスピーチを定義するために影響を受けたコミュニティに耳を傾ける：データセットと実験」という論文の要約文です。日本語に翻訳してください。\n\n影響を受けたコミュニティに耳を傾け、極端なスピーチを定義するためのデータセットと実験を行いました。", "jabstract": "現在の多言語憎悪表現（例：Ousidhoum et al.（2019））および憎悪表現削減（例：Sap et al.（2020））に関する現在の研究に基づき、ブラジル、ドイツ、インド、ケニアからの20,297のソーシャルメディアの文章を含む新しい憎悪表現データセットであるXTREMESPEECHを提供します。主な新規性は、企業や政府が憎悪表現を定義し、対処することに対して、影響を受けるコミュニティを直接データの収集と注釈付けに関与させることです。この包括的なアプローチにより、実際に発生するオンラインスピーチをより代表的なデータセットにすることができ、マージナライズドコミュニティが最も有害と見なすソーシャルメディアコンテンツの削除を容易にする可能性があります。XTREMESPEECHに基づいて、新しいタスクとそれに付随するベースラインを確立し、文化的な違いのためにクロスカントリートレーニングが一般的に不可能であることを証明し、BERTの予測の解釈可能性分析を実行します。"}
{"title": "Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists", "url": "https://aclanthology.org/2022.findings-acl.88/", "abstract": "Natural Language Processing (NLP) models risk overfitting to specific terms in the training data, thereby reducing their performance, fairness, and generalizability. E.g., neural hate speech detection models are strongly influenced by identity terms like gay, or women, resulting in false positives, severe unintended bias, and lower performance.Most mitigation techniques use lists of identity terms or samples from the target domain during training. However, this approach requires a-priori knowledge and introduces further bias if important terms are neglected.Instead, we propose a knowledge-free Entropy-based Attention Regularization (EAR) to discourage overfitting to training-specific terms. An additional objective function penalizes tokens with low self-attention entropy.We fine-tune BERT via EAR: the resulting model matches or exceeds state-of-the-art performance for hate speech classification and bias metrics on three benchmark corpora in English and Italian.EAR also reveals overfitting terms, i.e., terms most likely to induce bias, to help identify their effect on the model, task, and predictions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "エントロピーに基づく注意規制は、リストから意図しないバイアス緩和を解放します。", "jabstract": "自然言語処理（NLP）モデルは、トレーニングデータ内の特定の用語に過剰適合するリスクがあり、その結果、パフォーマンス、公平性、汎用性が低下します。例えば、ニューラルヘイトスピーチ検出モデルは、ゲイや女性などのアイデンティティ用語に強く影響を受け、偽陽性、深刻な意図しないバイアス、および低いパフォーマンスを引き起こします。多くの緩和技術は、トレーニング中のアイデンティティ用語のリストまたはターゲットドメインからのサンプルを使用します。しかし、このアプローチは事前知識を必要とし、重要な用語が無視される場合にさらなるバイアスを導入します。代わりに、我々は知識フリーのエントロピーベースのアテンション正則化（EAR）を提案し、トレーニング固有の用語への過剰適合を抑制します。追加の目的関数は、自己アテンションエントロピーが低いトークンを罰します。我々はEARを介してBERTを微調整し、英語とイタリア語の3つのベンチマークコーパスでのヘイトスピーチ分類とバイアスメトリックの最新のパフォーマンスに合致またはそれを上回るモデルを得ました。EARはまた、過剰適合用語、つまりバイアスを引き起こす可能性が最も高い用語を明らかにし、モデル、タスク、および予測に与える影響を特定するのに役立ちます。"}
{"title": "From BERT‘s Point of View: Revealing the Prevailing Contextual Differences", "url": "https://aclanthology.org/2022.findings-acl.89/", "abstract": "Though successfully applied in research and industry large pretrained language models of the BERT family are not yet fully understood. While much research in the field of BERTology has tested whether specific knowledge can be extracted from layer activations, we invert the popular probing design to analyze the prevailing differences and clusters in BERT’s high dimensional space. By extracting coarse features from masked token representations and predicting them by probing models with access to only partial information we can apprehend the variation from ‘BERT’s point of view’. By applying our new methodology to different datasets we show how much the differences can be described by syntax but further how they are to a great extent shaped by the most simple positional information.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nBERTの視点から：支配的な文脈的な違いを明らかにする", "jabstract": "BERTファミリーの大規模事前学習言語モデルは、研究や産業で成功を収めているものの、まだ完全に理解されていない。BERTologyの分野で特定の知識がレイヤー活性化から抽出できるかどうかを調べる研究が多く行われている一方、我々は一般的なプロービングデザインを反転させ、BERTの高次元空間における主要な違いとクラスターを分析する。マスクされたトークン表現から粗い特徴を抽出し、部分情報のみにアクセスできるプロービングモデルで予測することにより、我々は「BERTの視点」からの変動を把握することができる。我々の新しい方法論を異なるデータセットに適用することで、違いがどの程度構文によって説明できるかを示すと同時に、最も単純な位置情報によって大きく形成されていることをさらに示す。"}
{"title": "Learning Bias-reduced Word Embeddings Using Dictionary Definitions", "url": "https://aclanthology.org/2022.findings-acl.90/", "abstract": "Pre-trained word embeddings, such as GloVe, have shown undesirable gender, racial, and religious biases. To address this problem, we propose DD-GloVe, a train-time debiasing algorithm to learn word embeddings by leveraging  ̲dictionary  ̲definitions. We introduce dictionary-guided loss functions that encourage word embeddings to be similar to their relatively neutral dictionary definition representations. Existing debiasing algorithms typically need a pre-compiled list of seed words to represent the bias direction, along which biased information gets removed. Producing this list involves subjective decisions and it might be difficult to obtain for some types of biases. We automate the process of finding seed words: our algorithm starts from a single pair of initial seed words and automatically finds more words whose definitions display similar attributes traits. We demonstrate the effectiveness of our approach with benchmark evaluations and empirical analyses. Our code is available at https://github.com/haozhe-an/DD-GloVe.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "辞書定義を使用してバイアスが削減された単語埋め込みを学習する", "jabstract": "事前学習された単語埋め込み（GloVeなど）には、望ましくない性別、人種、宗教的な偏りがあることが示されています。この問題に対処するため、我々はDD-GloVeを提案します。これは、辞書定義を活用して単語埋め込みを学習するトレーニング時の偏り除去アルゴリズムです。我々は、比較的中立的な辞書定義表現に似るように単語埋め込みを促す辞書ガイドの損失関数を導入します。既存の偏り除去アルゴリズムは、偏りの方向を表すシードワードの事前コンパイルされたリストが必要です。このリストを作成するには主観的な判断が必要であり、一部の偏りについては入手が困難かもしれません。我々はシードワードを見つけるプロセスを自動化しています。アルゴリズムは、単一の初期シードワードのペアから始まり、同様の属性特性を示す定義を持つ単語を自動的に見つけます。ベンチマーク評価と実証分析により、我々のアプローチの効果を示します。我々のコードはhttps://github.com/haozhe-an/DD-GloVeで利用可能です。"}
{"title": "Knowledge Graph Embedding by Adaptive Limit Scoring Loss Using Dynamic Weighting Strategy", "url": "https://aclanthology.org/2022.findings-acl.91/", "abstract": "Knowledge graph embedding aims to represent entities and relations as low-dimensional vectors, which is an effective way for predicting missing links in knowledge graphs. Designing a strong and effective loss framework is essential for knowledge graph embedding models to distinguish between correct and incorrect triplets. The classic margin-based ranking loss limits the scores of positive and negative triplets to have a suitable margin. The recently proposed Limit-based Scoring Loss independently limits the range of positive and negative triplet scores. However, these loss frameworks use equal or fixed penalty terms to reduce the scores of positive and negative sample pairs, which is inflexible in optimization. Our intuition is that if a triplet score deviates far from the optimum, it should be emphasized. To this end, we propose Adaptive Limit Scoring Loss, which simply re-weights each triplet to highlight the less-optimized triplet scores. We apply this loss framework to several knowledge graph embedding models such as TransE, TransH and ComplEx. The experimental results on link prediction and triplet classification show that our proposed method has achieved performance on par with the state of the art.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「ダイナミックウェイト戦略を用いた適応制限スコアリング損失による知識グラフ埋め込み」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Knowledge Graph Embedding by Adaptive Limit Scoring Loss Using Dynamic Weighting Strategy\n- 「ダイナミックウェイト戦略を用いた適応制限スコアリング損失による知識グラフ埋め込み」", "jabstract": "知識グラフ埋め込みは、エンティティと関係を低次元ベクトルとして表現することを目的としており、知識グラフ内の欠落しているリンクを予測するための効果的な方法です。強力で効果的な損失フレームワークを設計することは、正しい三つ組と誤った三つ組を区別するために知識グラフ埋め込みモデルにとって不可欠です。古典的なマージンベースのランキング損失は、正と負の三つ組のスコアを適切なマージンに制限することで、スコアを制限します。最近提案されたリミットベースのスコアリング損失は、正と負の三つ組のスコアの範囲を独立して制限します。しかし、これらの損失フレームワークは、正と負のサンプルペアのスコアを減らすために等しいまたは固定のペナルティ項を使用するため、最適化において柔軟性に欠けます。私たちの直感は、三つ組のスコアが最適値から大きく逸脱する場合、それを強調する必要があるということです。このため、私たちは適応的リミットスコアリング損失を提案し、単純に各三つ組に重みを付けて最適化されていない三つ組のスコアを強調します。私たちは、この損失フレームワークをTransE、TransH、ComplExなどのいくつかの知識グラフ埋め込みモデルに適用しました。リンク予測と三つ組分類の実験結果は、私たちの提案手法が最先端の性能に匹敵する性能を発揮したことを示しています。"}
{"title": "OCR Improves Machine Translation for Low-Resource Languages", "url": "https://aclanthology.org/2022.findings-acl.92/", "abstract": "We aim to investigate the performance of current OCR systems on low resource languages and low resource scripts.We introduce and make publicly available a novel benchmark, OCR4MT, consisting of real and synthetic data, enriched with noise, for 60 low-resource languages in low resource scripts. We evaluate state-of-the-art OCR systems on our benchmark and analyse most common errors. We show that OCR monolingual data is a valuable resource that can increase performance of Machine Translation models, when used in backtranslation. We then perform an ablation study to investigate how OCR errors impact Machine Translation performance and determine what is the minimum level of OCR quality needed for the monolingual data to be useful for Machine Translation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "OCRは、低資源言語の機械翻訳を改善する。", "jabstract": "私たちは、現在のOCRシステムが低リソース言語や低リソーススクリプトに対してどのような性能を発揮するかを調査することを目的としています。私たちは、実際のデータと合成データをノイズで豊かにした、OCR4MTという新しいベンチマークを導入し、60の低リソース言語を対象にしました。私たちは、最新のOCRシステムを私たちのベンチマークで評価し、最も一般的なエラーを分析しました。OCR単一言語データが、バックトランスレーションで使用される場合、機械翻訳モデルの性能を向上させることができる貴重なリソースであることを示します。その後、OCRエラーが機械翻訳の性能にどのように影響するかを調査し、単一言語データが機械翻訳に有用であるために必要な最小のOCR品質を決定するために、削除研究を実施します。"}
{"title": "CoCoLM: Complex Commonsense Enhanced Language Model with Discourse Relations", "url": "https://aclanthology.org/2022.findings-acl.93/", "abstract": "Large-scale pre-trained language models have demonstrated strong knowledge representation ability. However, recent studies suggest that even though these giant models contain rich simple commonsense knowledge (e.g., bird can fly and fish can swim.), they often struggle with complex commonsense knowledge that involves multiple eventualities (verb-centric phrases, e.g., identifying the relationship between “Jim yells at Bob” and “Bob is upset”). To address this issue, in this paper, we propose to help pre-trained language models better incorporate complex commonsense knowledge. Unlike direct fine-tuning approaches, we do not focus on a specific task and instead propose a general language model named CoCoLM. Through the careful training over a large-scale eventuality knowledge graph ASER, we successfully teach pre-trained language models (i.e., BERT and RoBERTa) rich multi-hop commonsense knowledge among eventualities.Experiments on multiple commonsense tasks that require the correct understanding of eventualities demonstrate the effectiveness of CoCoLM.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CoCoLM：複雑な常識強化言語モデルとディスコース関係", "jabstract": "大規模な事前学習言語モデルは強力な知識表現能力を示しています。しかし、最近の研究では、これらの巨大なモデルが豊富な常識的な知識（例えば、鳥は飛べる、魚は泳げるなど）を含んでいるにもかかわらず、複数の出来事を含む複雑な常識的な知識（動詞中心のフレーズ、例えば、「ジムがボブに叫ぶ」と「ボブが悲しい」との関係を特定することなど）に苦戦することがあると指摘されています。この問題に対処するため、本論文では、事前学習言語モデルが複雑な常識的な知識をより良く統合できるようにすることを提案します。直接のファインチューニングアプローチとは異なり、特定のタスクに焦点を当てず、CoCoLMという一般的な言語モデルを提案します。大規模な出来事知識グラフASERを用いた慎重なトレーニングにより、我々は事前学習言語モデル（BERTとRoBERTa）に対して、出来事間の豊富なマルチホップの常識的な知識を教えることに成功しました。出来事の正しい理解を必要とする複数の常識的なタスクにおける実験は、CoCoLMの有効性を示しています。"}
{"title": "Learning to Robustly Aggregate Labeling Functions for Semi-supervised Data Programming", "url": "https://aclanthology.org/2022.findings-acl.94/", "abstract": "A critical bottleneck in supervised machine learning is the need for large amounts of labeled data which is expensive and time-consuming to obtain. Although a small amount of labeled data cannot be used to train a model, it can be used effectively for the generation of humaninterpretable labeling functions (LFs). These LFs, in turn, have been used to generate a large amount of additional noisy labeled data in a paradigm that is now commonly referred to as data programming. Previous methods of generating LFs do not attempt to use the given labeled data further to train a model, thus missing opportunities for improving performance. Additionally, since the LFs are generated automatically, they are likely to be noisy, and naively aggregating these LFs can lead to suboptimal results. In this work, we propose an LF-based bi-level optimization framework WISDOM to solve these two critical limitations. WISDOM learns a joint model on the (same) labeled dataset used for LF induction along with any unlabeled data in a semi-supervised manner, and more critically, reweighs each LF according to its goodness, influencing its contribution to the semi-supervised loss using a robust bi-level optimization algorithm. We show that WISDOM significantly outperforms prior approaches on several text classification datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "半教師付きデータプログラミングのための頑健なラベリング関数の集約を学習する", "jabstract": "教師あり機械学習における重要なボトルネックは、大量のラベル付きデータが必要であり、入手するのに高価で時間がかかることです。少量のラベル付きデータはモデルのトレーニングに使用できませんが、人間が解釈可能なラベリング関数（LF）の生成に効果的に使用できます。これらのLFは、データプログラミングとして一般的に言及されるパラダイムで、大量の追加のノイズのあるラベル付きデータを生成するために使用されています。以前のLF生成方法は、与えられたラベル付きデータをさらにモデルのトレーニングに使用しようとは試みていないため、パフォーマンスを向上させる機会を逃しています。さらに、LFは自動的に生成されるため、ノイズが含まれる可能性があり、これらのLFを単純に集約すると、最適な結果にならないことがあります。本研究では、これら2つの重要な制限を解決するために、LFベースの2段階最適化フレームワークWISDOMを提案します。WISDOMは、LF誘導に使用される（同じ）ラベル付きデータセットと、半教師ありの方法で任意のラベルなしデータを使用して、共同モデルを学習し、より重要なことに、ロバストな2段階最適化アルゴリズムを使用して、各LFの良さに応じて重み付けし、半教師あり損失への寄与を影響させます。WISDOMがいくつかのテキスト分類データセットで以前のアプローチよりも優れたパフォーマンスを発揮することを示します。"}
{"title": "Multi-Granularity Semantic Aware Graph Model for Reducing Position Bias in Emotion Cause Pair Extraction", "url": "https://aclanthology.org/2022.findings-acl.95/", "abstract": "The emotion cause pair extraction (ECPE) task aims to extract emotions and causes as pairs from documents. We observe that the relative distance distribution of emotions and causes is extremely imbalanced in the typical ECPE dataset. Existing methods have set a fixed size window to capture relations between neighboring clauses. However, they neglect the effective semantic connections between distant clauses, leading to poor generalization ability towards position-insensitive data. To alleviate the problem, we propose a novel Multi-Granularity Semantic Aware Graph model (MGSAG) to incorporate fine-grained and coarse-grained semantic features jointly, without regard to distance limitation. In particular, we first explore semantic dependencies between clauses and keywords extracted from the document that convey fine-grained semantic features, obtaining keywords enhanced clause representations. Besides, a clause graph is also established to model coarse-grained semantic relations between clauses. Experimental results indicate that MGSAG surpasses the existing state-of-the-art ECPE models. Especially, MGSAG outperforms other models significantly in the condition of position-insensitive data.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "感情原因ペア抽出における位置バイアスを減らすための多粒度意味認識グラフモデル", "jabstract": "感情原因ペア抽出（ECPE）タスクは、文書から感情と原因をペアで抽出することを目的としています。私たちは、典型的なECPEデータセットにおける感情と原因の相対距離分布が非常に不均衡であることを観察しました。既存の方法は、隣接する節間の関係を捉えるために固定サイズのウィンドウを設定しています。しかし、彼らは遠い節間の効果的な意味的つながりを無視し、位置に関係ないデータに対する一般化能力が低下することにつながります。この問題を緩和するために、私たちは、距離制限を考慮せずに、細かい粒度と粗い粒度の意味的特徴を共同で組み込む新しいMulti-Granularity Semantic Aware Graphモデル（MGSAG）を提案します。特に、まず、文書から抽出された節とキーワード間の意味的依存関係を探索し、細かい粒度の意味的特徴を伝えるキーワード強化節表現を得ます。さらに、節グラフも確立され、節間の粗い粒度の意味的関係をモデル化します。実験結果は、MGSAGが既存の最先端のECPEモデルを上回っていることを示しています。特に、MGSAGは、位置に関係ないデータの条件下で他のモデルよりも優れた性能を発揮します。"}
{"title": "Cross-lingual Inference with A Chinese Entailment Graph", "url": "https://aclanthology.org/2022.findings-acl.96/", "abstract": "Predicate entailment detection is a crucial task for question-answering from text, where previous work has explored unsupervised learning of entailment graphs from typed open relation triples. In this paper, we present the first pipeline for building Chinese entailment graphs, which involves a novel high-recall open relation extraction (ORE) method and the first Chinese fine-grained entity typing dataset under the FIGER type ontology. Through experiments on the Levy-Holt dataset, we verify the strength of our Chinese entailment graph, and reveal the cross-lingual complementarity: on the parallel Levy-Holt dataset, an ensemble of Chinese and English entailment graphs outperforms both monolingual graphs, and raises unsupervised SOTA by 4.7 AUC points.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "中国の含意グラフを用いた言語間推論", "jabstract": "述語の含意検出は、テキストからの質問応答にとって重要なタスクであり、以前の研究では、型付きオープン関係トリプルから含意グラフの非教示学習が探求されてきた。本論文では、新しい高再現率のオープン関係抽出（ORE）手法とFIGERタイプオントロジーの下での最初の中国語細分化エンティティタイピングデータセットを含む、中国語含意グラフの構築のための最初のパイプラインを提案する。Levy-Holtデータセットでの実験により、中国語含意グラフの強さを検証し、クロスリンガル補完性を明らかにする。並列Levy-Holtデータセットでは、中国語と英語の含意グラフのアンサンブルが両方の単一言語グラフを上回り、非教示学習SOTAを4.7 AUCポイント引き上げることが示された。"}
{"title": "Multi-task Learning for Paraphrase Generation With Keyword and Part-of-Speech Reconstruction", "url": "https://aclanthology.org/2022.findings-acl.97/", "abstract": "Paraphrase generation using deep learning has been a research hotspot of natural language processing in the past few years. While previous studies tackle the problem from different aspects, the essence of paraphrase generation is to retain the key semantics of the source sentence and rewrite the rest of the content. Inspired by this observation, we propose a novel two-stage model, PGKPR, for paraphrase generation with keyword and part-of-speech reconstruction. The rationale is to capture simultaneously the possible keywords of a source sentence and the relations between them to facilitate the rewriting. In the first stage, we identify the possible keywords using a prediction attribution technique, where the words obtaining higher attribution scores are more likely to be the keywords. In the second stage, we train a transformer-based model via multi-task learning for paraphrase generation. The novel learning task is the reconstruction of the keywords and part-of-speech tags, respectively, from a perturbed sequence of the source sentence. The learned encodings are then decoded to generate the paraphrase. We conduct the experiments on two commonly-used datasets, and demonstrate the superior performance of PGKPR over comparative models on multiple evaluation metrics.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "キーワードと品詞再構築を伴う言い換え生成のためのマルチタスク学習", "jabstract": "過去数年間、深層学習を用いた言語処理において、言い換え生成は研究の焦点となってきた。以前の研究は異なる観点からこの問題に取り組んできたが、言い換え生成の本質は、ソース文の主要な意味を保持し、残りの内容を書き換えることである。この観察に着想を得て、我々はキーワードと品詞再構築を用いた言い換え生成のための新しい二段階モデル、PGKPRを提案する。理論的背景は、ソース文の可能なキーワードとそれらの関係を同時に捉え、書き換えを容易にすることである。第一段階では、予測属性技術を用いて、可能なキーワードを特定する。属性スコアが高い単語ほど、キーワードである可能性が高い。第二段階では、マルチタスク学習を用いて、キーワードと品詞タグの再構築を行い、言い換え生成のためのトランスフォーマーベースのモデルをトレーニングする。学習されたエンコーディングは、言い換えを生成するためにデコードされる。我々は、2つの一般的に使用されるデータセットで実験を行い、PGKPRが複数の評価指標において比較モデルよりも優れた性能を示すことを示した。"}
{"title": "MDCSpell: A Multi-task Detector-Corrector Framework for Chinese Spelling Correction", "url": "https://aclanthology.org/2022.findings-acl.98/", "abstract": "Chinese Spelling Correction (CSC) is a task to detect and correct misspelled characters in Chinese texts. CSC is challenging since many Chinese characters are visually or phonologically similar but with quite different semantic meanings. Many recent works use BERT-based language models to directly correct each character of the input sentence. However, these methods can be sub-optimal since they correct every character of the sentence only by the context which is easily negatively affected by the misspelled characters. Some other works propose to use an error detector to guide the correction by masking the detected errors. Nevertheless, these methods dampen the visual or phonological features from the misspelled characters which could be critical for correction. In this work, we propose a novel general detector-corrector multi-task framework where the corrector uses BERT to capture the visual and phonological features from each character in the raw sentence and uses a late fusion strategy to fuse the hidden states of the corrector with that of the detector to minimize the negative impact from the misspelled characters. Comprehensive experiments on benchmarks demonstrate that our proposed method can significantly outperform the state-of-the-art methods in the CSC task.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MDCSpell：中国語のスペル修正のためのマルチタスク検出修正フレームワーク", "jabstract": "中国語のスペル修正（CSC）は、中国語のテキスト内のスペルミスを検出して修正するタスクです。CSCは、多くの中国語の文字が視覚的または音韻的に似ているが、意味がかなり異なるため、課題があります。最近の多くの研究では、BERTベースの言語モデルを使用して、入力文の各文字を直接修正する方法が使用されています。しかし、これらの方法は、誤字が影響を受けやすい文脈だけで文の各文字を修正するため、サブオプティマルな場合があります。他の一部の研究では、エラー検出器を使用して、検出されたエラーをマスキングして修正をガイドすることを提案しています。しかし、これらの方法は、修正に重要な視覚的または音韻的特徴を抑制するため、誤字が重要な場合があります。本研究では、新しい一般的な検出器-修正器マルチタスクフレームワークを提案し、修正器はBERTを使用して、生の文の各文字から視覚的および音韻的特徴をキャプチャし、検出器の隠れた状態と融合する遅延融合戦略を使用して、誤字からのネガティブな影響を最小限に抑えます。ベンチマークでの包括的な実験は、提案された方法がCSCタスクで最先端の方法を大幅に上回ることを示しています。"}
{"title": "S2SQL: Injecting Syntax to Question-Schema Interaction Graph Encoder for Text-to-SQL Parsers", "url": "https://aclanthology.org/2022.findings-acl.99/", "abstract": "The task of converting a natural language question into an executable SQL query, known as text-to-SQL, is an important branch of semantic parsing. The state-of-the-art graph-based encoder has been successfully used in this task but does not model the question syntax well. In this paper, we propose S2SQL, injecting Syntax to question-Schema graph encoder for Text-to-SQL parsers, which effectively leverages the syntactic dependency information of questions in text-to-SQL to improve the performance. We also employ the decoupling constraint to induce diverse relational edge embedding, which further improves the network’s performance. Experiments on the Spider and robustness setting Spider-Syn demonstrate that the proposed approach outperforms all existing methods when pre-training models are used, resulting in a performance ranks first on the Spider leaderboard.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "S2SQL：テキストからSQLパーサーのための質問スキーマ相互作用グラフエンコーダに構文を注入する", "jabstract": "自然言語の質問を実行可能なSQLクエリに変換するタスクであるtext-to-SQLは、意味解析の重要な分野の1つである。最新のグラフベースのエンコーダーはこのタスクで成功を収めているが、質問の構文をうまくモデル化していない。本論文では、S2SQLという、Text-to-SQLパーサーのための質問スキーマグラフエンコーダーに構文を注入することで、質問の構文依存情報を効果的に活用し、パフォーマンスを向上させる手法を提案する。また、多様な関係エッジ埋め込みを誘発するために、デカップリング制約を採用し、ネットワークのパフォーマンスをさらに向上させる。Spiderとロバストネス設定Spider-Synでの実験結果は、提案手法が事前学習モデルを使用する場合には、既存のすべての手法を上回り、Spiderリーダーボードで1位のパフォーマンスを発揮することを示している。"}
{"title": "Constructing Open Cloze Tests Using Generation and Discrimination Capabilities of Transformers", "url": "https://aclanthology.org/2022.findings-acl.100/", "abstract": "This paper presents the first multi-objective transformer model for generating open cloze tests that exploits generation and discrimination capabilities to improve performance. Our model is further enhanced by tweaking its loss function and applying a post-processing re-ranking algorithm that improves overall test structure. Experiments using automatic and human evaluation show that our approach can achieve up to 82% accuracy according to experts, outperforming previous work and baselines. We also release a collection of high-quality open cloze tests along with sample system output and human annotations that can serve as a future benchmark.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "トランスフォーマーの生成と識別能力を利用したオープンクローズテストの構築", "jabstract": "この論文では、性能を向上させるために生成と識別能力を利用するオープンクローズテストを生成するための最初の多目的トランスフォーマーモデルを提案します。さらに、損失関数を微調整し、後処理の再ランキングアルゴリズムを適用することで、モデルをさらに強化し、全体的なテスト構造を改善します。自動評価と人間の評価を使用した実験により、専門家によると82％の精度を達成し、以前の研究やベースラインを上回ることが示されました。また、将来のベンチマークとして役立つ高品質のオープンクローズテストのコレクションと、サンプルシステム出力と人間の注釈を公開します。"}
{"title": "Co-training an Unsupervised Constituency Parser with Weak Supervision", "url": "https://aclanthology.org/2022.findings-acl.101/", "abstract": "We introduce a method for unsupervised parsing that relies on bootstrapping classifiers to identify if a node dominates a specific span in a sentence. There are two types of classifiers, an inside classifier that acts on a span, and an outside classifier that acts on everything outside of a given span. Through self-training and co-training with the two classifiers, we show that the interplay between them helps improve the accuracy of both, and as a result, effectively parse. A seed bootstrapping technique prepares the data to train these classifiers. Our analyses further validate that such an approach in conjunction with weak supervision using prior branching knowledge of a known language (left/right-branching) and minimal heuristics injects strong inductive bias into the parser, achieving 63.1 F1 on the English (PTB) test set. In addition, we show the effectiveness of our architecture by evaluating on treebanks for Chinese (CTB) and Japanese (KTB) and achieve new state-of-the-art results.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "弱い監督を用いた非教師あり構成解析器の共同学習", "jabstract": "私たちは、文の特定のスパンを支配するノードがあるかどうかを識別するためにブートストラップ分類器を利用する非監視型パーシングの方法を紹介します。内部分類器と外部分類器の2種類の分類器があります。内部分類器はスパンに作用し、外部分類器は特定のスパン以外のすべてに作用します。自己トレーニングと2つの分類器の共同トレーニングにより、両者の相互作用が両方の精度を向上させ、効果的にパースすることができることを示します。シードブートストラップ技術は、これらの分類器をトレーニングするためのデータを準備します。また、既知の言語の先行分岐知識（左/右分岐）と最小限のヒューリスティックを使用した弱い監視を組み合わせたこのアプローチが、強力な帰納バイアスをパーサーに注入し、英語（PTB）テストセットで63.1 F1を達成することを分析によってさらに検証します。さらに、中国語（CTB）と日本語（KTB）のツリーバンクで評価することにより、アーキテクチャの効果を示し、新しい最先端の結果を達成します。"}
{"title": "HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information", "url": "https://aclanthology.org/2022.findings-acl.102/", "abstract": "Transformer-based language models usually treat texts as linear sequences. However, most texts also have an inherent hierarchical structure, i.e., parts of a text can be identified using their position in this hierarchy. In addition, section titles usually indicate the common topic of their respective sentences. We propose a novel approach to formulate, extract, encode and inject hierarchical structure information explicitly into an extractive summarization model based on a pre-trained, encoder-only Transformer language model (HiStruct+ model), which improves SOTA ROUGEs for extractive summarization on PubMed and arXiv substantially. Using various experimental settings on three datasets (i.e., CNN/DailyMail, PubMed and arXiv), our HiStruct+ model outperforms a strong baseline collectively, which differs from our model only in that the hierarchical structure information is not injected. It is also observed that the more conspicuous hierarchical structure the dataset has, the larger improvements our method gains. The ablation study demonstrates that the hierarchical position information is the main contributor to our model’s SOTA performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "HiStruct+：階層構造情報を用いた抽出型テキスト要約の改善", "jabstract": "トランスフォーマーベースの言語モデルは通常、テキストを線形のシーケンスとして扱います。しかし、ほとんどのテキストには階層的な構造があり、テキストの一部はこの階層構造に基づいて識別できます。さらに、セクションのタイトルは、それぞれの文の共通のトピックを示します。我々は、事前学習されたエンコーダーのみのトランスフォーマー言語モデルに基づく抽出型要約モデルに階層構造情報を明示的に定式化、抽出、エンコード、注入する新しいアプローチを提案します（HiStruct+モデル）。このモデルは、PubMedとarXivの抽出型要約のSOTA ROUGEsを大幅に改善します。CNN/DailyMail、PubMed、arXivの3つのデータセットでさまざまな実験設定を使用して、HiStruct+モデルは、階層構造情報が注入されていない強力なベースラインと比較して、集合的に優れたパフォーマンスを発揮します。また、データセットによって階層構造がより顕著であるほど、我々の手法がより大きな改善を得ることが観察されます。削除実験は、階層的な位置情報が我々のモデルのSOTAパフォーマンスの主要な貢献者であることを示しています。"}
{"title": "An Isotropy Analysis in the Multilingual BERT Embedding Space", "url": "https://aclanthology.org/2022.findings-acl.103/", "abstract": "Several studies have explored various advantages of multilingual pre-trained models (such as multilingual BERT) in capturing shared linguistic knowledge. However, less attention has been paid to their limitations. In this paper, we investigate the multilingual BERT for two known issues of the monolingual models: anisotropic embedding space and outlier dimensions. We show that, unlike its monolingual counterpart, the multilingual BERT model exhibits no outlier dimension in its representations while it has a highly anisotropic space. There are a few dimensions in the monolingual BERT with high contributions to the anisotropic distribution. However, we observe no such dimensions in the multilingual BERT. Furthermore, our experimental results demonstrate that increasing the isotropy of multilingual space can significantly improve its representation power and performance, similarly to what had been observed for monolingual CWRs on semantic similarity tasks. Our analysis indicates that, despite having different degenerated directions, the embedding spaces in various languages tend to be partially similar with respect to their structures.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語BERT埋め込み空間における等方性分析", "jabstract": "多言語プレトレーニングモデル（多言語BERTなど）の様々な利点について、多数の研究が行われてきた。しかし、その限界についてはあまり注目されていない。本論文では、単一言語モデルの既知の2つの問題、すなわち異方性の埋め込み空間と外れ値次元について、多言語BERTを調査する。我々は、単一言語の対応物とは異なり、多言語BERTモデルは表現に外れ値次元を持たず、高度に異方性のある空間を持つことを示す。単一言語BERTには、異方性分布に高い寄与を持ついくつかの次元があるが、多言語BERTにはそのような次元は存在しない。さらに、実験結果は、多言語空間の等方性を増加させることが、単一言語CWRの意味的類似性タスクにおいて観察されたものと同様に、表現力と性能を大幅に向上させることを示している。我々の分析は、異なる退化方向を持つにもかかわらず、さまざまな言語の埋め込み空間が、その構造に関して部分的に類似している傾向があることを示唆している。"}
{"title": "Multi-Stage Prompting for Knowledgeable Dialogue Generation", "url": "https://aclanthology.org/2022.findings-acl.104/", "abstract": "Existing knowledge-grounded dialogue systems typically use finetuned versions of a pretrained language model (LM) and large-scale knowledge bases. These models typically fail to generalize on topics outside of the knowledge base, and require maintaining separate potentially large checkpoints each time finetuning is needed. In this paper, we aim to address these limitations by leveraging the inherent knowledge stored in the pretrained LM as well as its powerful generation ability. We propose a multi-stage prompting approach to generate knowledgeable responses from a single pretrained LM. We first prompt the LM to generate knowledge based on the dialogue context. Then, we further prompt it to generate responses based on the dialogue context and the previously generated knowledge. Results show that our knowledge generator outperforms the state-of-the-art retrieval-based model by 5.8% when combining knowledge relevance and correctness. In addition, our multi-stage prompting outperforms the finetuning-based dialogue model in terms of response knowledgeability and engagement by up to 10% and 5%, respectively. Furthermore, we scale our model up to 530 billion parameters and demonstrate that larger LMs improve the generation correctness score by up to 10%, and response relevance, knowledgeability and engagement by up to 10%. Our code is available at: https://github.com/NVIDIA/Megatron-LM.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "知識豊富な対話生成のためのマルチステージプロンプティング", "jabstract": "既存の知識に基づく対話システムは、通常、事前学習済み言語モデル（LM）と大規模な知識ベースの微調整バージョンを使用しています。これらのモデルは、通常、知識ベース外のトピックについて一般化できず、微調整が必要なたびに別々の可能性のある大規模なチェックポイントを維持する必要があります。本論文では、事前学習済みLMに内在する知識と強力な生成能力を活用して、これらの制限に対処することを目的としています。我々は、単一の事前学習済みLMから知識豊富な応答を生成するためのマルチステージのプロンプティングアプローチを提案します。まず、対話コンテキストに基づいてLMに知識を生成するようにプロンプトを与えます。次に、対話コンテキストと以前に生成された知識に基づいて応答を生成するようにさらにプロンプトを与えます。結果は、知識の関連性と正確性を組み合わせた場合、当社の知識ジェネレーターが最先端の検索ベースのモデルよりも5.8％優れていることを示しています。さらに、当社のマルチステージのプロンプティングは、応答の知識性とエンゲージメントに関して、それぞれ最大で10％と5％優れています。さらに、当社のモデルを5300億のパラメータにスケールアップし、大規模なLMは生成の正確性スコアを最大で10％、応答の関連性、知識性、エンゲージメントを最大で10％向上させることを示しています。当社のコードは、https://github.com/NVIDIA/Megatron-LMで入手できます。"}
{"title": "DuReadervis: A Chinese Dataset for Open-domain Document Visual Question Answering", "url": "https://aclanthology.org/2022.findings-acl.105/", "abstract": "Open-domain question answering has been used in a wide range of applications, such as web search and enterprise search, which usually takes clean texts extracted from various formats of documents (e.g., web pages, PDFs, or Word documents) as the information source. However, designing different text extraction approaches is time-consuming and not scalable. In order to reduce human cost and improve the scalability of QA systems, we propose and study an Open-domain Document Visual Question Answering (Open-domain DocVQA) task, which requires answering questions based on a collection of document images directly instead of only document texts, utilizing layouts and visual features additionally. Towards this end, we introduce the first Chinese Open-domain DocVQA dataset called DuReadervis, containing about 15K question-answering pairs and 158K document images from the Baidu search engine. There are three main challenges in DuReadervis: (1) long document understanding, (2) noisy texts, and (3) multi-span answer extraction. The extensive experiments demonstrate that the dataset is challenging. Additionally, we propose a simple approach that incorporates the layout and visual features, and the experimental results show the effectiveness of the proposed approach. The dataset and code will be publicly available at https://github.com/baidu/DuReader/tree/master/DuReader-vis.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DuReadervis：オープンドメインのドキュメントビジュアル質問応答のための中国語データセット", "jabstract": "オープンドメインの質問応答は、通常、さまざまな形式のドキュメント（Webページ、PDF、またはWordドキュメントなど）から抽出されたクリーンなテキストを情報源として使用するWeb検索や企業検索などの広範なアプリケーションで使用されています。しかし、異なるテキスト抽出アプローチを設計することは時間がかかり、スケーラブルではありません。QAシステムの人的コストを削減し、スケーラビリティを向上させるために、私たちはオープンドメインのドキュメントビジュアル質問応答（オープンドメインDocVQA）タスクを提案し、研究しています。このタスクは、レイアウトと視覚的な特徴を追加して、ドキュメントテキストだけでなく、ドキュメント画像のコレクションに基づいて質問に答えることを必要とします。このために、私たちは、Baidu検索エンジンから約15Kの質問応答ペアと158Kのドキュメント画像を含む、最初の中国語のオープンドメインDocVQAデータセットであるDuReadervisを紹介します。DuReadervisには、3つの主要な課題があります：（1）長いドキュメントの理解、（2）ノイズのあるテキスト、および（3）複数のスパン回答の抽出。広範な実験により、データセットが難しいことが示されました。さらに、レイアウトと視覚的な特徴を組み込んだシンプルなアプローチを提案し、実験結果は提案されたアプローチの有効性を示しています。データセットとコードは、https://github.com/baidu/DuReader/tree/master/DuReader-visで公開されます。"}
{"title": "Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models", "url": "https://aclanthology.org/2022.findings-acl.106/", "abstract": "Relations between words are governed by hierarchical structure rather than linear ordering. Sequence-to-sequence (seq2seq) models, despite their success in downstream NLP applications, often fail to generalize in a hierarchy-sensitive manner when performing syntactic transformations—for example, transforming declarative sentences into questions. However, syntactic evaluations of seq2seq models have only observed models that were not pre-trained on natural language data before being trained to perform syntactic transformations, in spite of the fact that pre-training has been found to induce hierarchical linguistic generalizations in language models; in other words, the syntactic capabilities of seq2seq models may have been greatly understated. We address this gap using the pre-trained seq2seq models T5 and BART, as well as their multilingual variants mT5 and mBART. We evaluate whether they generalize hierarchically on two transformations in two languages: question formation and passivization in English and German. We find that pre-trained seq2seq models generalize hierarchically when performing syntactic transformations, whereas models trained from scratch on syntactic transformations do not. This result presents evidence for the learnability of hierarchical syntactic information from non-annotated natural language text while also demonstrating that seq2seq models are capable of syntactic generalization, though only after exposure to much more language data than human learners receive.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「白紙に色を塗る：事前学習はシーケンス・トゥ・シーケンス・モデルに階層的帰納バイアスを与える」", "jabstract": "単語間の関係は、線形の順序ではなく階層的な構造によって支配されています。シーケンス・トゥ・シーケンス（seq2seq）モデルは、下流の自然言語処理（NLP）アプリケーションでの成功にもかかわらず、文の形式を変換する際に階層的な感度を一般化することができないことが多い。しかし、seq2seqモデルの文法的評価は、自然言語データに事前にトレーニングされていないモデルのみを観察しており、プレトレーニングが言語モデルに階層的な言語一般化を誘発することがわかっているにもかかわらず、seq2seqモデルの文法的能力は大幅に過小評価されている可能性がある。本研究では、プレトレーニングされたseq2seqモデルT5とBART、およびその多言語バリアントmT5とmBARTを使用して、2つの言語（英語とドイツ語）で2つの変換（疑問文形成と受動態化）において、階層的に一般化するかどうかを評価します。私たちは、文法的変換を行うためにゼロからトレーニングされたモデルではなく、プレトレーニングされたseq2seqモデルを使用することで、このギャップに対処します。その結果、プレトレーニングされたseq2seqモデルは、文法的変換を行う際に階層的に一般化することができる一方、ゼロから文法的変換をトレーニングしたモデルはそうではありません。この結果は、非注釈の自然言語テキストから階層的な文法情報を学習することができることを示すと同時に、seq2seqモデルが文法的一般化を行うことができることを示していますが、人間の学習者が受け取る言語データよりもはるかに多くの曝露が必要です。"}
{"title": "C3KG: A Chinese Commonsense Conversation Knowledge Graph", "url": "https://aclanthology.org/2022.findings-acl.107/", "abstract": "Existing commonsense knowledge bases often organize tuples in an isolated manner, which is deficient for commonsense conversational models to plan the next steps. To fill the gap, we curate a large-scale multi-turn human-written conversation corpus, and create the first Chinese commonsense conversation knowledge graph which incorporates both social commonsense knowledge and dialog flow information. To show the potential of our graph, we develop a graph-conversation matching approach, and benchmark two graph-grounded conversational tasks. All the resources in this work will be released to foster future research.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "C3KG：中国の常識的な会話知識グラフ\n\nThis paper presents C3KG, a large-scale Chinese commonsense conversation knowledge graph, which contains 4.8 million nodes and 26.3 million edges. \n\n本論文では、480万のノードと2630万のエッジを含む大規模な中国語の常識的な会話知識グラフであるC3KGを紹介する。\n\nC3KG is constructed based on a carefully designed schema and a novel knowledge acquisition approach that leverages both structured and unstructured data. \n\nC3KGは、慎重に設計されたスキーマと構造化および非構造化データを活用する新しい知識獲得手法に基づいて構築されています。\n\nWe demonstrate the effectiveness of C3KG on two downstream tasks: commonsense conversation generation and conversation comprehension. \n\nC3KGの有効性を、常識的な会話生成と会話理解の2つの下流タスクで示す。", "jabstract": "既存の常識知識ベースは、共通の会話モデルが次のステップを計画するために不十分な孤立した方法でタプルを組織化しています。このギャップを埋めるために、私たちは大規模な多回転人間書き込み会話コーパスをキュレーションし、社会的な常識知識と対話フロー情報の両方を組み込んだ最初の中国の常識会話知識グラフを作成しました。私たちのグラフの可能性を示すために、グラフ-会話マッチングアプローチを開発し、2つのグラウンドされた会話タスクをベンチマークにしました。この作品のすべてのリソースは、将来の研究を促進するためにリリースされます。"}
{"title": "Graph Neural Networks for Multiparallel Word Alignment", "url": "https://aclanthology.org/2022.findings-acl.108/", "abstract": "After a period of decrease, interest in word alignments is increasing again for their usefulness in domains such as typological research, cross-lingual annotation projection and machine translation. Generally, alignment algorithms only use bitext and do not make use of the fact that many parallel corpora are multiparallel. Here, we compute high-quality word alignments between multiple language pairs by considering all language pairs together. First, we create a multiparallel word alignment graph, joining all bilingual word alignment pairs in one graph. Next, we use graph neural networks (GNNs) to exploit the graph structure. Our GNN approach (i) utilizes information about the meaning, position and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) adds and removes edges from the initial alignments, and (iv) yields a prediction model that can generalize beyond the training sentences. We show that community detection algorithms can provide valuable information for multiparallel word alignment. Our method outperforms previous work on three word alignment datasets and on a downstream task.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「多重並列単語アラインメントのためのグラフニューラルネットワーク」", "jabstract": "単語アラインメントに対する関心は、類型研究、クロスリンガル注釈投影、機械翻訳などの領域での有用性から再び増加しています。一般的に、アラインメントアルゴリズムはビットキストのみを使用し、多数の並列コーパスが存在することを考慮していません。ここでは、すべての言語ペアを考慮して高品質の単語アラインメントを計算することにより、複数の言語ペア間で単語アラインメントを行います。最初に、マルチパラレル単語アラインメントグラフを作成し、すべてのバイリンガル単語アラインメントペアを1つのグラフに結合します。次に、グラフニューラルネットワーク（GNN）を使用してグラフ構造を活用します。私たちのGNNアプローチは、（i）入力単語の意味、位置、言語に関する情報を利用し、（ii）複数の並列文から情報を取り込み、（iii）初期アラインメントからエッジを追加および削除し、（iv）トレーニング文を超えて一般化できる予測モデルを生成します。コミュニティ検出アルゴリズムがマルチパラレル単語アラインメントに有用な情報を提供できることを示します。私たちの方法は、3つの単語アラインメントデータセットおよび下流タスクで以前の研究を上回る結果を示します。"}
{"title": "Sentiment Word Aware Multimodal Refinement for Multimodal Sentiment Analysis with ASR Errors", "url": "https://aclanthology.org/2022.findings-acl.109/", "abstract": "Multimodal sentiment analysis has attracted increasing attention and lots of models have been proposed. However, the performance of the state-of-the-art models decreases sharply when they are deployed in the real world. We find that the main reason is that real-world applications can only access the text outputs by the automatic speech recognition (ASR) models, which may be with errors because of the limitation of model capacity. Through further analysis of the ASR outputs, we find that in some cases the sentiment words, the key sentiment elements in the textual modality, are recognized as other words, which makes the sentiment of the text change and hurts the performance of multimodal sentiment analysis models directly. To address this problem, we propose the sentiment word aware multimodal refinement model (SWRM), which can dynamically refine the erroneous sentiment words by leveraging multimodal sentiment clues. Specifically, we first use the sentiment word position detection module to obtain the most possible position of the sentiment word in the text and then utilize the multimodal sentiment word refinement module to dynamically refine the sentiment word embeddings. The refined embeddings are taken as the textual inputs of the multimodal feature fusion module to predict the sentiment labels. We conduct extensive experiments on the real-world datasets including MOSI-Speechbrain, MOSI-IBM, and MOSI-iFlytek and the results demonstrate the effectiveness of our model, which surpasses the current state-of-the-art models on three datasets. Furthermore, our approach can be adapted for other multimodal feature fusion models easily.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ASRエラーを伴うマルチモーダル感情分析のための感情語意識マルチモーダルリファインメント", "jabstract": "多様な感情分析は注目を集め、多くのモデルが提案されている。しかし、最新のモデルの性能は、実際の世界で展開されると急激に低下することがわかっている。その主な理由は、実際の世界のアプリケーションは、モデル容量の制限によりエラーが発生する可能性がある自動音声認識（ASR）モデルのテキスト出力にしかアクセスできないためである。ASRの出力をさらに分析することで、テキストモダリティの主要な感情要素である感情語が他の単語として認識される場合があることがわかった。これにより、テキストの感情が変化し、多様な感情分析モデルの性能が直接的に損なわれる。この問題に対処するために、我々は感情語に注意を払った多様な感情洗練モデル（SWRM）を提案する。このモデルは、多様な感情の手がかりを活用して、誤った感情語を動的に洗練することができる。具体的には、感情語の位置検出モジュールを使用して、テキスト内の感情語の最も可能性の高い位置を取得し、多様な感情語の洗練モジュールを利用して、感情語の埋め込みを動的に洗練する。洗練された埋め込みは、多様な特徴融合モジュールのテキスト入力として取り込まれ、感情ラベルを予測する。MOSI-Speechbrain、MOSI-IBM、MOSI-iFlytekを含む実世界のデータセットで広範な実験を行い、我々のモデルの有効性を示し、3つのデータセットで現在の最新のモデルを上回ることを示した。さらに、我々のアプローチは、他の多様な特徴融合モデルに簡単に適応できる。"}
{"title": "A Novel Framework Based on Medical Concept Driven Attention for Explainable Medical Code Prediction via External Knowledge", "url": "https://aclanthology.org/2022.findings-acl.110/", "abstract": "Medical code prediction from clinical notes aims at automatically associating medical codes with the clinical notes. Rare code problem, the medical codes with low occurrences, is prominent in medical code prediction. Recent studies employ deep neural networks and the external knowledge to tackle it. However, such approaches lack interpretability which is a vital issue in medical application. Moreover, due to the lengthy and noisy clinical notes, such approaches fail to achieve satisfactory results. Therefore, in this paper, we propose a novel framework based on medical concept driven attention to incorporate external knowledge for explainable medical code prediction. In specific, both the clinical notes and Wikipedia documents are aligned into topic space to extract medical concepts using topic modeling. Then, the medical concept-driven attention mechanism is applied to uncover the medical code related concepts which provide explanations for medical code prediction. Experimental results on the benchmark dataset show the superiority of the proposed framework over several state-of-the-art baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n外部知識を介した説明可能な医療コード予測のための医療概念駆動型アテンションに基づく新しいフレームワーク", "jabstract": "臨床ノートからの医療コード予測は、自動的に医療コードを臨床ノートに関連付けることを目的としています。医療コード予測において、低頻度の医療コードであるレアコード問題が顕著です。最近の研究では、深層ニューラルネットワークと外部知識を用いてこれを解決しています。しかし、このようなアプローチには、医療アプリケーションにおいて重要な問題である解釈可能性が欠けています。また、長くノイズの多い臨床ノートのため、このようなアプローチは満足できる結果を得ることができません。そこで、本論文では、外部知識を組み込んだ解釈可能な医療コード予測のための医療コンセプト駆動型アテンションに基づく新しいフレームワークを提案します。具体的には、トピックモデリングを使用して、臨床ノートとWikipedia文書をトピック空間に整列させ、医療コンセプトを抽出します。そして、医療コンセプト駆動型アテンションメカニズムを適用して、医療コードに関連するコンセプトを明らかにし、医療コード予測の説明を提供します。ベンチマークデータセット上の実験結果は、提案されたフレームワークがいくつかの最先端のベースラインよりも優れていることを示しています。"}
{"title": "Effective Unsupervised Constrained Text Generation based on Perturbed Masking", "url": "https://aclanthology.org/2022.findings-acl.111/", "abstract": "Unsupervised constrained text generation aims to generate text under a given set of constraints without any supervised data. Current state-of-the-art methods stochastically sample edit positions and actions, which may cause unnecessary search steps. In this paper, we propose PMCTG to improve effectiveness by searching for the best edit position and action in each step. Specifically, PMCTG extends perturbed masking technique to effectively search for the most incongruent token to edit. Then it introduces four multi-aspect scoring functions to select edit action to further reduce search difficulty. Since PMCTG does not require supervised data, it could be applied to different generation tasks. We show that under the unsupervised setting, PMCTG achieves new state-of-the-art results in two representative tasks, namely keywords- to-sentence generation and paraphrasing.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「摂動マスキングに基づく効果的な非監視制約テキスト生成」についての論文の要約文です。以下、日本語に翻訳してください。\n\n- Effective Unsupervised Constrained Text Generation based on Perturbed Masking\n- 摂動マスキングに基づく効果的な非監視制約テキスト生成", "jabstract": "教師なし制約付きテキスト生成は、監視されたデータなしで与えられた制約の下でテキストを生成することを目的としています。現在の最先端の方法は、編集位置とアクションを確率的にサンプリングするため、不必要な検索ステップを引き起こす可能性があります。本論文では、各ステップで最適な編集位置とアクションを検索することにより、効果を改善するPMCTGを提案します。具体的には、PMCTGは、最も不一致なトークンを編集するために効果的に検索するために、摂動マスキング技術を拡張します。その後、検索の難易度をさらに低減するために、4つの多面的スコアリング関数を導入して編集アクションを選択します。PMCTGは監視されたデータを必要としないため、異なる生成タスクに適用することができます。本研究では、教師なし設定下で、PMCTGが代表的な2つのタスク、すなわちキーワードから文の生成と言い換えにおいて、新しい最先端の結果を達成することを示します。"}
{"title": "Combining (Second-Order) Graph-Based and Headed-Span-Based Projective Dependency Parsing", "url": "https://aclanthology.org/2022.findings-acl.112/", "abstract": "Graph-based methods, which decompose the score of a dependency tree into scores of dependency arcs, are popular in dependency parsing for decades. Recently, (CITATION) propose a headed-span-based method that decomposes the score of a dependency tree into scores of headed spans. They show improvement over first-order graph-based methods. However, their method does not score dependency arcs at all, and dependency arcs are implicitly induced by their cubic-time algorithm, which is possibly sub-optimal since modeling dependency arcs is intuitively useful. In this work, we aim to combine graph-based and headed-span-based methods, incorporating both arc scores and headed span scores into our model. First, we show a direct way to combine with O(n4) parsing complexity. To decrease complexity, inspired by the classical head-splitting trick, we show two O(n3) dynamic programming algorithms to combine first- and second-order graph-based and headed-span-based methods. Our experiments on PTB, CTB, and UD show that combining first-order graph-based and headed-span-based methods is effective. We also confirm the effectiveness of second-order graph-based parsing in the deep learning age, however, we observe marginal or no improvement when combining second-order graph-based and headed-span-based methods .", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n(2次)グラフベースとヘッドスパンベースの射影依存解析を組み合わせる", "jabstract": "グラフベースの手法は、依存構造木のスコアを依存弧のスコアに分解するもので、依存解析において数十年にわたって広く用いられている。最近、（引用）は、依存構造木のスコアをヘッド付きスパンのスコアに分解するヘッド付きスパンベースの手法を提案した。彼らは、一次グラフベースの手法よりも改善された結果を示している。しかし、彼らの手法は依存弧のスコアを全く評価せず、依存弧は彼らの三次時間アルゴリズムによって暗黙的に導出されるため、依存弧をモデル化することが直感的に有用であるため、最適でない可能性がある。本研究では、グラフベースとヘッド付きスパンベースの手法を組み合わせ、アークスコアとヘッドスパンスコアの両方をモデルに組み込むことを目的としている。まず、O(n4)の解析複雑度で直接組み合わせる方法を示す。複雑度を減らすために、古典的なヘッド分割トリックに着想を得て、一次および二次グラフベースとヘッド付きスパンベースの手法を組み合わせるためのO(n3)の動的プログラミングアルゴリズムを2つ示す。PTB、CTB、UDでの実験では、一次グラフベースとヘッド付きスパンベースの手法を組み合わせることが効果的であることを示した。また、深層学習時代における二次グラフベースの解析の効果も確認したが、二次グラフベースとヘッド付きスパンベースの手法を組み合わせた場合、わずかな改善または改善が見られなかった。"}
{"title": "End-to-End Speech Translation for Code Switched Speech", "url": "https://aclanthology.org/2022.findings-acl.113/", "abstract": "Code switching (CS) refers to the phenomenon of interchangeably using words and phrases from different languages. CS can pose significant accuracy challenges to NLP, due to the often monolingual nature of the underlying systems. In this work, we focus on CS in the context of English/Spanish conversations for the task of speech translation (ST), generating and evaluating both transcript and translation. To evaluate model performance on this task, we create a novel ST corpus derived from existing public data sets. We explore various ST architectures across two dimensions: cascaded (transcribe then translate) vs end-to-end (jointly transcribe and translate) and unidirectional (source -> target) vs bidirectional (source <-> target). We show that our ST architectures, and especially our bidirectional end-to-end architecture, perform well on CS speech, even when no CS training data is used.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "コードスイッチングされた音声のためのエンドツーエンド音声翻訳", "jabstract": "コードスイッチング（CS）は、異なる言語から単語やフレーズを交換して使用する現象を指します。CSは、基盤となるシステムがしばしば単一言語であるため、NLPにおいて重要な精度の課題を提起することがあります。本研究では、スピーチ翻訳（ST）のタスクにおいて、英語/スペイン語の会話のCSに焦点を当て、トランスクリプトと翻訳の両方を生成して評価します。このタスクにおけるモデルのパフォーマンスを評価するために、既存の公開データセットから派生した新しいSTコーパスを作成します。我々は、トランスクライブしてから翻訳するカスケード型と、トランスクライブと翻訳を同時に行うエンドツーエンド型、および単方向（ソース->ターゲット）と双方向（ソース<->ターゲット）の2つの次元で、さまざまなSTアーキテクチャを探索します。我々は、CSスピーチにおいて、特に双方向エンドツーエンドアーキテクチャにおいて、CSトレーニングデータが使用されていない場合でも、我々のSTアーキテクチャが良好なパフォーマンスを発揮することを示します。"}
{"title": "A Transformational Biencoder with In-Domain Negative Sampling for Zero-Shot Entity Linking", "url": "https://aclanthology.org/2022.findings-acl.114/", "abstract": "Recent interest in entity linking has focused in the zero-shot scenario, where at test time the entity mention to be labelled is never seen during training, or may belong to a different domain from the source domain. Current work leverage pre-trained BERT with the implicit assumption that it bridges the gap between the source and target domain distributions. However, fine-tuned BERT has a considerable underperformance at zero-shot when applied in a different domain. We solve this problem by proposing a Transformational Biencoder that incorporates a transformation into BERT to perform a zero-shot transfer from the source domain during training. As like previous work, we rely on negative entities to encourage our model to discriminate the golden entities during training. To generate these negative entities, we propose a simple but effective strategy that takes the domain of the golden entity into perspective. Our experimental results on the benchmark dataset Zeshel show effectiveness of our approach and achieve new state-of-the-art.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「ドメイン内ネガティブサンプリングを用いた変換バイエンコーダによるゼロショットエンティティリンキング」の論文の要約です。", "jabstract": "最近のエンティティリンキングに関する関心は、テスト時にトレーニング中に見たことがないエンティティメンションをラベル付けするゼロショットシナリオに焦点を当てています。または、ソースドメインと異なるドメインに属する場合があります。現在の作業は、事前にトレーニングされたBERTを活用し、ソースとターゲットのドメイン分布のギャップを埋めるという暗黙の前提に基づいています。しかし、異なるドメインで適用する場合、ファインチューニングされたBERTはゼロショットでかなりの低性能を示します。私たちは、変換バイエンコーダを提案して、トレーニング中にソースドメインからのゼロショット転送を実行するためにBERTに変換を組み込み、この問題を解決します。以前の作業と同様に、負のエンティティに依存して、トレーニング中にゴールデンエンティティを識別するようにモデルを促します。これらの負のエンティティを生成するために、私たちは、ゴールデンエンティティのドメインを考慮に入れたシンプルで効果的な戦略を提案します。ベンチマークデータセットZeshelでの実験結果は、私たちのアプローチの有効性を示し、新しい最高の状態に達成します。"}
{"title": "Finding the Dominant Winning Ticket in Pre-Trained Language Models", "url": "https://aclanthology.org/2022.findings-acl.115/", "abstract": "The Lottery Ticket Hypothesis suggests that for any over-parameterized model, a small subnetwork exists to achieve competitive performance compared to the backbone architecture. In this paper, we study whether there is a winning lottery ticket for pre-trained language models, which allow the practitioners to fine-tune the parameters in the ticket but achieve good downstream performance. To achieve this, we regularize the fine-tuning process with L1 distance and explore the subnetwork structure (what we refer to as the “dominant winning ticket”). Empirically, we show that (a) the dominant winning ticket can achieve performance that is comparable with that of the full-parameter model, (b) the dominant winning ticket is transferable across different tasks, (c) and the dominant winning ticket has a natural structure within each parameter matrix. Strikingly, we find that a dominant winning ticket that takes up 0.05% of the parameters can already achieve satisfactory performance, indicating that the PLM is significantly reducible during fine-tuning.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習された言語モデルにおける優勝チケットの発見", "jabstract": "「Lottery Ticket Hypothesis」は、過剰パラメータ化されたモデルに対して、バックボーンアーキテクチャと競合する性能を発揮する小さなサブネットワークが存在するという仮説です。本論文では、事前学習された言語モデルに対して、パラメータを微調整して下流タスクで良好な性能を発揮する「勝ち組の抽選券」が存在するかどうかを調査します。これを実現するために、L1距離で微調整プロセスを正則化し、サブネットワーク構造（「優勝チケット」と呼ぶ）を探索します。実証的に、（a）優勝チケットは、完全パラメータモデルと同等の性能を発揮できること、（b）優勝チケットは、異なるタスク間で転移可能であること、（c）優勝チケットは、各パラメータ行列内に自然な構造を持っていることを示します。驚くべきことに、パラメータの0.05％を占める優勝チケットでも十分な性能を発揮できることがわかり、PLMは微調整中に大幅に縮小可能であることを示しています。"}
{"title": "Thai Nested Named Entity Recognition Corpus", "url": "https://aclanthology.org/2022.findings-acl.116/", "abstract": "This paper presents the first Thai Nested Named Entity Recognition (N-NER) dataset. Thai N-NER consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from 4,894 documents in the domains of news articles and restaurant reviews. Our work, to the best of our knowledge, presents the largest non-English N-NER dataset and the first non-English one with fine-grained classes. To understand the new challenges our proposed dataset brings to the field, we conduct an experimental study on (i) cutting edge N-NER models with the state-of-the-art accuracy in English and (ii) baseline methods based on well-known language model architectures. From the experimental results, we obtained two key findings. First, all models produced poor F1 scores in the tail region of the class distribution. There is little or no performance improvement provided by these models with respect to the baseline methods with our Thai dataset. These findings suggest that further investigation is required to make a multilingual N-NER solution that works well across different languages.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nタイのネスト型固有表現認識コーパス", "jabstract": "この論文では、タイ語のネストされた固有表現認識（N-NER）データセットが初めて提案された。タイ語N-NERは、ニュース記事とレストランレビューのドメインから得られた4,894の文書から、264,798のメンション、104のクラス、最大8層の深さで構成されている。これは、英語以外の最大のN-NERデータセットであり、細かいクラスを持つ最初の英語以外のデータセットでもある。提案されたデータセットがもたらす新しい課題を理解するために、最新の英語N-NERモデルと、よく知られた言語モデルアーキテクチャに基づくベースライン手法について実験的研究を行った。実験結果から、2つの主要な発見が得られた。まず、すべてのモデルがクラス分布のテール領域で低いF1スコアを示した。これらのモデルは、タイのデータセットに対してベースライン手法と比較してほとんどまたは全く性能改善を提供しないことが示された。これらの結果から、異なる言語間でうまく機能する多言語N-NERソリューションを作成するために、さらなる調査が必要であることが示唆された。"}
{"title": "Two-Step Question Retrieval for Open-Domain QA", "url": "https://aclanthology.org/2022.findings-acl.117/", "abstract": "The retriever-reader pipeline has shown promising performance in open-domain QA but suffers from a very slow inference speed. Recently proposed question retrieval models tackle this problem by indexing question-answer pairs and searching for similar questions. These models have shown a significant increase in inference speed, but at the cost of lower QA performance compared to the retriever-reader models. This paper proposes a two-step question retrieval model, SQuID (Sequential Question-Indexed Dense retrieval) and distant supervision for training. SQuID uses two bi-encoders for question retrieval. The first-step retriever selects top-k similar questions, and the second-step retriever finds the most similar question from the top-k questions. We evaluate the performance and the computational efficiency of SQuID. The results show that SQuID significantly increases the performance of existing question retrieval models with a negligible loss on inference speed.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nオープンドメインQAのための2段階の質問検索", "jabstract": "リトリーバー・リーダー・パイプラインは、オープンドメインQAで有望なパフォーマンスを示していますが、非常に遅い推論速度に苦しんでいます。最近提案された質問検索モデルは、質問-回答ペアをインデックス化し、類似した質問を検索することで、この問題に対処しています。これらのモデルは、リトリーバー・リーダー・モデルと比較してQAパフォーマンスが低下する代わりに、推論速度が大幅に向上しています。本論文では、2段階の質問検索モデル、SQuID（Sequential Question-Indexed Dense retrieval）と遠隔監視によるトレーニングを提案します。SQuIDは、質問検索のために2つのバイエンコーダを使用します。第1段階のリトリーバーは、トップkの類似した質問を選択し、第2段階のリトリーバーは、トップkの質問から最も類似した質問を見つけます。SQuIDのパフォーマンスと計算効率を評価します。結果は、SQuIDが既存の質問検索モデルのパフォーマンスを著しく向上させ、推論速度の損失がほとんどないことを示しています。"}
{"title": "Semantically Distributed Robust Optimization for Vision-and-Language Inference", "url": "https://aclanthology.org/2022.findings-acl.118/", "abstract": "Analysis of vision-and-language models has revealed their brittleness under linguistic phenomena such as paraphrasing, negation, textual entailment, and word substitutions with synonyms or antonyms.While data augmentation techniques have been designed to mitigate against these failure modes, methods that can integrate this knowledge into the training pipeline remain under-explored.In this paper, we present SDRO, a model-agnostic method that utilizes a set linguistic transformations in a distributed robust optimization setting, along with an ensembling technique to leverage these transformations during inference.Experiments on benchmark datasets with images (NLVR2) and video (VIOLIN) demonstrate performance improvements as well as robustness to adversarial attacks.Experiments on binary VQA explore the generalizability of this method to other V&L tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「自然言語処理に関する論文の要旨です。以下の文章を日本語に翻訳してください。\n\n視覚と言語の推論のための意味的に分散された堅牢最適化」", "jabstract": "ビジョン・アンド・ランゲージ・モデルの分析により、言い換え、否定、テキストの含意、同義語または反意語による単語の置換などの言語現象に対する脆弱性が明らかになっています。これらの失敗モードに対処するためにデータ拡張技術が設計されていますが、この知識をトレーニングパイプラインに統合する方法は未だに十分に探求されていません。本論文では、分散ロバスト最適化設定で一連の言語変換を利用するモデル非依存のSDROを提案し、推論中にこれらの変換を活用するアンサンブル技術を使用します。画像（NLVR2）およびビデオ（VIOLIN）のベンチマークデータセットでの実験により、性能向上と敵対的攻撃に対する堅牢性が示されました。バイナリVQAの実験では、この方法の他のV＆Lタスクへの汎用性を探求しました。"}
{"title": "Learning from Missing Relations: Contrastive Learning with Commonsense Knowledge Graphs for Commonsense Inference", "url": "https://aclanthology.org/2022.findings-acl.119/", "abstract": "Commonsense inference poses a unique challenge to reason and generate the physical, social, and causal conditions of a given event. Existing approaches to commonsense inference utilize commonsense transformers, which are large-scale language models that learn commonsense knowledge graphs. However, they suffer from a lack of coverage and expressive diversity of the graphs, resulting in a degradation of the representation quality. In this paper, we focus on addressing missing relations in commonsense knowledge graphs, and propose a novel contrastive learning framework called SOLAR. Our framework contrasts sets of semantically similar and dissimilar events, learning richer inferential knowledge compared to existing approaches. Empirical results demonstrate the efficacy of SOLAR in commonsense inference of diverse commonsense knowledge graphs. Specifically, SOLAR outperforms the state-of-the-art commonsense transformer on commonsense inference with ConceptNet by 1.84% on average among 8 automatic evaluation metrics. In-depth analysis of SOLAR sheds light on the effects of the missing relations utilized in learning commonsense knowledge graphs.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "欠落した関係から学ぶ：常識知識グラフを用いた対照的学習による常識推論", "jabstract": "常識推論は、特定のイベントの物理的、社会的、因果関係を推論することに独自の課題を提供します。既存の常識推論アプローチは、常識知識グラフを学習する大規模言語モデルである常識トランスフォーマーを利用しています。しかし、グラフのカバレッジと表現的多様性に欠けており、表現品質の低下を引き起こしています。本論文では、常識知識グラフの欠落した関係に対処し、SOLARと呼ばれる新しい対照的学習フレームワークを提案します。我々のフレームワークは、意味的に類似したイベントと類似しないイベントのセットを対比し、既存のアプローチよりも豊富な推論的知識を学習します。実験結果は、SOLARが多様な常識知識グラフの常識推論において有効であることを示しています。具体的には、SOLARは、ConceptNetによる常識推論において、8つの自動評価メトリックの平均で、最先端の常識トランスフォーマーを1.84％上回ります。SOLARの詳細な分析は、常識知識グラフの学習に利用される欠落した関係の影響を明らかにします。"}
{"title": "Capture Human Disagreement Distributions by Calibrated Networks for Natural Language Inference", "url": "https://aclanthology.org/2022.findings-acl.120/", "abstract": "Natural Language Inference (NLI) datasets contain examples with highly ambiguous labels due to its subjectivity. Several recent efforts have been made to acknowledge and embrace the existence of ambiguity, and explore how to capture the human disagreement distribution. In contrast with directly learning from gold ambiguity labels, relying on special resource, we argue that the model has naturally captured the human ambiguity distribution as long as it’s calibrated, i.e. the predictive probability can reflect the true correctness likelihood. Our experiments show that when model is well-calibrated, either by label smoothing or temperature scaling, it can obtain competitive performance as prior work, on both divergence scores between predictive probability and the true human opinion distribution, and the accuracy. This reveals the overhead of collecting gold ambiguity labels can be cut, by broadly solving how to calibrate the NLI network.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理におけるキャリブレーションネットワークによる人間の不一致分布の捕捉", "jabstract": "自然言語推論（NLI）のデータセットには、主観的な性質により非常に曖昧なラベルの例が含まれています。最近、曖昧さの存在を認め、人間の不一致分布を捉える方法を探るためのいくつかの取り組みが行われています。私たちは、特別なリソースに頼らずに、ゴールドの曖昧なラベルから直接学習する代わりに、モデルがキャリブレーションされている限り、人間の曖昧さの分布を自然に捉えていると主張します。つまり、予測確率が真の正解の可能性を反映できる場合です。私たちの実験は、ラベルスムージングまたは温度スケーリングによってモデルが適切にキャリブレーションされている場合、予測確率と真の人間の意見分布の間の発散スコアと精度の両方で、先行研究と競合する性能を発揮することを示しています。これは、NLIネットワークをキャリブレーションする方法を広く解決することにより、ゴールドの曖昧なラベルを収集するオーバーヘッドを削減できることを示しています。"}
{"title": "Efficient, Uncertainty-based Moderation of Neural Networks Text Classifiers", "url": "https://aclanthology.org/2022.findings-acl.121/", "abstract": "To maximize the accuracy and increase the overall acceptance of text classifiers, we propose a framework for the efficient, in-operation moderation of classifiers’ output. Our framework focuses on use cases in which F1-scores of modern Neural Networks classifiers (ca. 90%) are still inapplicable in practice. We suggest a semi-automated approach that uses prediction uncertainties to pass unconfident, probably incorrect classifications to human moderators. To minimize the workload, we limit the human moderated data to the point where the accuracy gains saturate and further human effort does not lead to substantial improvements. A series of benchmarking experiments based on three different datasets and three state-of-the-art classifiers show that our framework can improve the classification F1-scores by 5.1 to 11.2% (up to approx. 98 to 99%), while reducing the moderation load up to 73.3% compared to a random moderation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラルネットワークのテキスト分類器の効率的で不確実性に基づくモデレーション", "jabstract": "テキスト分類器の精度を最大化し、全体的な受け入れを増やすために、分類器の出力を効率的に操作するためのフレームワークを提案します。当社のフレームワークは、現代のニューラルネットワーク分類器のF1スコア（約90％）が実際には適用できないユースケースに焦点を当てています。私たちは、予測の不確実性を使用して、自信がなく、おそらく不正確な分類を人間のモデレーターに渡す半自動的なアプローチを提案しています。作業量を最小限に抑えるために、精度の向上が飽和し、さらなる人間の努力が実質的な改善につながらない地点まで、人間がモデレートするデータを制限します。3つの異なるデータセットと3つの最新の分類器に基づく一連のベンチマーク実験により、当社のフレームワークは、分類のF1スコアを5.1〜11.2％（約98〜99％）向上させ、ランダムなモデレーションに比べてモデレーションの負荷を最大73.3％削減できることが示されました。"}
{"title": "Revisiting Automatic Evaluation of Extractive Summarization Task: Can We Do Better than ROUGE?", "url": "https://aclanthology.org/2022.findings-acl.122/", "abstract": "It has been the norm for a long time to evaluate automated summarization tasks using the popular ROUGE metric. Although several studies in the past have highlighted the limitations of ROUGE, researchers have struggled to reach a consensus on a better alternative until today. One major limitation of the traditional ROUGE metric is the lack of semantic understanding (relies on direct overlap of n-grams). In this paper, we exclusively focus on the extractive summarization task and propose a semantic-aware nCG (normalized cumulative gain)-based evaluation metric (called Sem-nCG) for evaluating this task. One fundamental contribution of the paper is that it demonstrates how we can generate more reliable semantic-aware ground truths for evaluating extractive summarization tasks without any additional human intervention. To the best of our knowledge, this work is the first of its kind. We have conducted extensive experiments with this new metric using the widely used CNN/DailyMail dataset. Experimental results show that the new Sem-nCG metric is indeed semantic-aware, shows higher correlation with human judgement (more reliable) and yields a large number of disagreements with the original ROUGE metric (suggesting that ROUGE often leads to inaccurate conclusions also verified by humans).", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "抽出型要約タスクの自動評価を再考する：ROUGEよりも優れた方法はあるか？", "jabstract": "自動要約タスクの評価には、長い間ROUGEメトリックが使用されてきました。過去のいくつかの研究でROUGEの限界が強調されてきましたが、より良い代替案についての研究者の合意には今でも苦労しています。従来のROUGEメトリックの主な制限の1つは、意味理解の欠如です（n-gramの直接的な重複に依存しています）。本論文では、抽出型要約タスクに焦点を当て、このタスクを評価するための意味理解に基づくnCG（正規化累積利得）ベースの評価メトリック（Sem-nCGと呼ばれる）を提案します。本論文の基本的な貢献の1つは、追加の人間の介入なしに、より信頼性の高い意味理解に基づくグラウンドトゥルースを生成する方法を示すことです。私たちの知る限り、この研究はそのようなものとして初めてです。広く使用されているCNN / DailyMailデータセットを使用して、この新しいメトリックを用いた詳細な実験を行いました。実験結果は、新しいSem-nCGメトリックが実際に意味理解に基づいており、人間の判断とより高い相関を示し、オリジナルのROUGEメトリックと多数の不一致を示すことを示しています（ROUGEがしばしば不正確な結論に導くことを人間によっても確認されています）。"}
{"title": "Open Vocabulary Extreme Classification Using Generative Models", "url": "https://aclanthology.org/2022.findings-acl.123/", "abstract": "The extreme multi-label classification (XMC) task aims at tagging content with a subset of labels from an extremely large label set. The label vocabulary is typically defined in advance by domain experts and assumed to capture all necessary tags. However in real world scenarios this label set, although large, is often incomplete and experts frequently need to refine it. To develop systems that simplify this process, we introduce the task of open vocabulary XMC (OXMC): given a piece of content, predict a set of labels, some of which may be outside of the known tag set. Hence, in addition to not having training data for some labels–as is the case in zero-shot classification–models need to invent some labels on-thefly. We propose GROOV, a fine-tuned seq2seq model for OXMC that generates the set of labels as a flat sequence and is trained using a novel loss independent of predicted label order. We show the efficacy of the approach, experimenting with popular XMC datasets for which GROOV is able to predict meaningful labels outside the given vocabulary while performing on par with state-of-the-art solutions for known labels.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "生成モデルを用いたオープンボキャブラリー極端分類", "jabstract": "極端なマルチラベル分類（XMC）タスクは、非常に大きなラベルセットからラベルのサブセットでコンテンツにタグ付けすることを目的としています。ラベル語彙は通常、ドメインの専門家によって事前に定義され、必要なすべてのタグをキャプチャすることが想定されています。しかし、現実のシナリオでは、このラベルセットは大きいにもかかわらず、不完全であり、専門家は頻繁にそれを改善する必要があります。このプロセスを簡素化するシステムを開発するために、私たちはオープンボキャブラリーXMC（OXMC）のタスクを紹介します。つまり、コンテンツが与えられた場合、既知のタグセットの外側にあるラベルのセットを予測します。したがって、ゼロショット分類の場合と同様に、いくつかのラベルに対するトレーニングデータがないため、モデルはラベルを即座に発明する必要があります。私たちは、OXMCのための微調整されたseq2seqモデルであるGROOVを提案し、ラベルセットをフラットなシーケンスとして生成し、予測されたラベルの順序に依存しない新しい損失を使用してトレーニングされます。私たちは、GROOVが与えられた語彙外の意味のあるラベルを予測できることを示し、既知のラベルに対する最先端のソリューションと同等のパフォーマンスを発揮する人気のあるXMCデータセットで実験を行います。"}
{"title": "Decomposed Meta-Learning for Few-Shot Named Entity Recognition", "url": "https://aclanthology.org/2022.findings-acl.124/", "abstract": "Few-shot named entity recognition (NER) systems aim at recognizing novel-class named entities based on only a few labeled examples. In this paper, we present a decomposed meta-learning approach which addresses the problem of few-shot NER by sequentially tackling few-shot span detection and few-shot entity typing using meta-learning. In particular, we take the few-shot span detection as a sequence labeling problem and train the span detector by introducing the model-agnostic meta-learning (MAML) algorithm to find a good model parameter initialization that could fast adapt to new entity classes. For few-shot entity typing, we propose MAML-ProtoNet, i.e., MAML-enhanced prototypical networks to find a good embedding space that can better distinguish text span representations from different entity classes. Extensive experiments on various benchmarks show that our approach achieves superior performance over prior methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Few-Shot Named Entity Recognitionのための分解されたメタ学習", "jabstract": "Few-shot named entity recognition (NER) systemsは、わずかなラベル付きの例に基づいて新しいクラスの名前付きエンティティを認識することを目的としています。本論文では、メタ学習を用いた分解アプローチを提案し、メタ学習を用いてfew-shot span detectionとfew-shot entity typingの問題に順次対処します。特に、few-shot span detectionをシーケンスラベリング問題として扱い、モデルアグノスティックメタ学習（MAML）アルゴリズムを導入して、新しいエンティティクラスに迅速に適応できる良好なモデルパラメータ初期化を見つけるためにスパン検出器をトレーニングします。few-shot entity typingについては、MAML-ProtoNet、つまりMAML-enhanced prototypical networksを提案し、異なるエンティティクラスからのテキストスパン表現をよりよく区別できる良好な埋め込み空間を見つけます。さまざまなベンチマークでの広範な実験により、当社のアプローチが従来の方法よりも優れた性能を発揮することが示されました。"}
{"title": "TegTok: Augmenting Text Generation via Task-specific and Open-world Knowledge", "url": "https://aclanthology.org/2022.findings-acl.125/", "abstract": "Generating natural and informative texts has been a long-standing problem in NLP. Much effort has been dedicated into incorporating pre-trained language models (PLMs) with various open-world knowledge, such as knowledge graphs or wiki pages. However, their ability to access and manipulate the task-specific knowledge is still limited on downstream tasks, as this type of knowledge is usually not well covered in PLMs and is hard to acquire. To address the problem, we propose augmenting TExt Generation via Task-specific and Open-world Knowledge (TegTok) in a unified framework. Our model selects knowledge entries from two types of knowledge sources through dense retrieval and then injects them into the input encoding and output decoding stages respectively on the basis of PLMs. With the help of these two types of knowledge, our model can learn what and how to generate. Experiments on two text generation tasks of dialogue generation and question generation, and on two datasets show that our method achieves better performance than various baseline models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "TegTok：タスク固有の知識とオープンワールドの知識によるテキスト生成の拡張", "jabstract": "自然言語処理において、自然で情報量の多いテキストを生成することは長年の問題である。知識グラフやウィキペディアなどのオープンワールドの知識を事前学習済み言語モデル（PLMs）に組み込むことに多くの努力が注がれてきたが、タスク固有の知識にアクセスして操作する能力は依然として限られており、この種の知識は通常PLMsで十分にカバーされておらず、取得が困難である。この問題に対処するため、我々は統一されたフレームワークでタスク固有の知識とオープンワールドの知識を組み合わせたテキスト生成を提案する（TegTok）。我々のモデルは、密な検索によって2種類の知識源から知識エントリを選択し、PLMsに基づいて入力エンコーディングと出力デコーディングの段階でそれらを注入する。これら2種類の知識の助けを借りて、我々のモデルは何を生成するか、どのように生成するかを学習することができる。対話生成と質問生成の2つのテキスト生成タスクと2つのデータセットでの実験結果は、我々の方法が様々なベースラインモデルよりも優れた性能を発揮することを示している。"}
{"title": "EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition", "url": "https://aclanthology.org/2022.findings-acl.126/", "abstract": "Emotion recognition in conversation (ERC) aims to analyze the speaker’s state and identify their emotion in the conversation. Recent works in ERC focus on context modeling but ignore the representation of contextual emotional tendency. In order to extract multi-modal information and the emotional tendency of the utterance effectively, we propose a new structure named Emoformer to extract multi-modal emotion vectors from different modalities and fuse them with sentence vector to be an emotion capsule. Furthermore, we design an end-to-end ERC model called EmoCaps, which extracts emotion vectors through the Emoformer structure and obtain the emotion classification results from a context analysis model. Through the experiments with two benchmark datasets, our model shows better performance than the existing state-of-the-art models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「EmoCaps：会話の感情認識のための感情カプセルベースのモデル」という論文の要約文です。", "jabstract": "会話における感情認識（ERC）は、話者の状態を分析し、会話における感情を特定することを目的としています。ERCにおける最近の研究は、文脈モデリングに焦点を当てていますが、文脈的な感情傾向の表現を無視しています。効果的にマルチモーダル情報と発話の感情傾向を抽出するために、私たちはEmoformerという新しい構造を提案し、異なるモダリティからマルチモーダル感情ベクトルを抽出し、文ベクトルと融合して感情カプセルにします。さらに、Emoformer構造を介して感情ベクトルを抽出し、文脈分析モデルから感情分類結果を取得するエンドツーエンドERCモデルであるEmoCapsを設計しました。2つのベンチマークデータセットでの実験により、私たちのモデルは既存の最先端モデルよりも優れた性能を示しました。"}
{"title": "Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text", "url": "https://aclanthology.org/2022.findings-acl.127/", "abstract": "Logical reasoning of text requires identifying critical logical structures in the text and performing inference over them. Existing methods for logical reasoning mainly focus on contextual semantics of text while struggling to explicitly model the logical inference process. In this paper, we not only put forward a logic-driven context extension framework but also propose a logic-driven data augmentation algorithm. The former follows a three-step reasoning paradigm, and each step is respectively to extract logical expressions as elementary reasoning units, symbolically infer the implicit expressions following equivalence laws and extend the context to validate the options. The latter augments literally similar but logically different instances and incorporates contrastive learning to better capture logical information, especially logical negative and conditional relationships. We conduct experiments on two benchmark datasets, ReClor and LogiQA. The results show that our method achieves state-of-the-art performance on both datasets, and even surpasses human performance on the ReClor dataset.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n論理推論のための論理駆動型コンテキスト拡張とデータ拡張", "jabstract": "テキストの論理的推論には、テキスト内の重要な論理構造を特定し、それらに対して推論を行う必要があります。従来の論理的推論の方法は、主にテキストの文脈的意味に焦点を当てており、論理的推論プロセスを明示的にモデル化することに苦労しています。本論文では、論理駆動のコンテキスト拡張フレームワークを提案すると同時に、論理駆動のデータ拡張アルゴリズムを提案します。前者は3段階の推論パラダイムに従い、各段階はそれぞれ論理式を基本的な推論単位として抽出し、同値法則に従って暗黙の式を象徴的に推論し、オプションを検証するためにコンテキストを拡張します。後者は、文字通り似ているが論理的に異なるインスタンスを拡張し、対比学習を組み込んで論理的情報、特に論理的否定および条件付き関係をより正確に捉えます。我々は、2つのベンチマークデータセット、ReClorとLogiQAで実験を行いました。その結果、当社の方法は両方のデータセットで最先端の性能を発揮し、ReClorデータセットでは人間の性能を超えることさえあります。"}
{"title": "Transfer Learning and Prediction Consistency for Detecting Offensive Spans of Text", "url": "https://aclanthology.org/2022.findings-acl.128/", "abstract": "Toxic span detection is the task of recognizing offensive spans in a text snippet. Although there has been prior work on classifying text snippets as offensive or not, the task of recognizing spans responsible for the toxicity of a text is not explored yet. In this work, we introduce a novel multi-task framework for toxic span detection in which the model seeks to simultaneously predict offensive words and opinion phrases to leverage their inter-dependencies and improve the performance. Moreover, we introduce a novel regularization mechanism to encourage the consistency of the model predictions across similar inputs for toxic span detection. Our extensive experiments demonstrate the effectiveness of the proposed model compared to strong baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nテキストの攻撃的な範囲を検出するための転移学習と予測の一貫性", "jabstract": "有害スパン検出は、テキストスニペット内の攻撃的なスパンを認識するタスクです。以前は、テキストスニペットを攻撃的か否かに分類する研究がありましたが、テキストの有害性に責任があるスパンを認識するタスクはまだ探求されていません。本研究では、オフェンシブな単語と意見フレーズを同時に予測することで相互依存関係を活用し、性能を向上させるための新しいマルチタスクフレームワークを提案します。さらに、有害スパン検出の類似した入力に対するモデルの予測の一貫性を促す新しい正則化メカニズムを導入します。広範な実験により、提案されたモデルが強力なベースラインと比較して効果的であることが示されました。"}
{"title": "Learning Reasoning Patterns for Relational Triple Extraction with Mutual Generation of Text and Graph", "url": "https://aclanthology.org/2022.findings-acl.129/", "abstract": "Relational triple extraction is a critical task for constructing knowledge graphs. Existing methods focused on learning text patterns from explicit relational mentions. However, they usually suffered from ignoring relational reasoning patterns, thus failed to extract the implicitly implied triples. Fortunately, the graph structure of a sentence’s relational triples can help find multi-hop reasoning paths. Moreover, the type inference logic through the paths can be captured with the sentence’s supplementary relational expressions that represent the real-world conceptual meanings of the paths’ composite relations. In this paper, we propose a unified framework to learn the relational reasoning patterns for this task. To identify multi-hop reasoning paths, we construct a relational graph from the sentence (text-to-graph generation) and apply multi-layer graph convolutions to it. To capture the relation type inference logic of the paths, we propose to understand the unlabeled conceptual expressions by reconstructing the sentence from the relational graph (graph-to-text generation) in a self-supervised manner. Experimental results on several benchmark datasets demonstrate the effectiveness of our method.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n相互生成によるテキストとグラフの関係トリプル抽出のための推論パターンの学習", "jabstract": "関係トリプル抽出は、知識グラフを構築するための重要なタスクです。既存の方法は、明示的な関係メンションからテキストパターンを学習することに焦点を当てています。しかし、彼らは通常、関係推論パターンを無視するため、暗黙的に示唆されたトリプルを抽出することに失敗しました。幸いなことに、文の関係トリプルのグラフ構造は、多段階の推論パスを見つけるのに役立ちます。さらに、パスのコンポジット関係の現実世界の概念的な意味を表す文の補足的な関係表現によって、パスを通じたタイプ推論ロジックを捉えることができます。本論文では、このタスクのための関係推論パターンを学習するための統一されたフレームワークを提案します。多段階推論パスを特定するために、文から関係グラフを構築し（テキストからグラフ生成）、それに多層グラフ畳み込みを適用します。パスの関係タイプ推論ロジックを捉えるために、自己教師ありの方法で関係グラフから文を再構築することによって、ラベルなしの概念的な表現を理解することを提案します（グラフからテキスト生成）。いくつかのベンチマークデータセットでの実験結果は、我々の方法の有効性を示しています。"}
{"title": "Document-Level Event Argument Extraction via Optimal Transport", "url": "https://aclanthology.org/2022.findings-acl.130/", "abstract": "Event Argument Extraction (EAE) is one of the sub-tasks of event extraction, aiming to recognize the role of each entity mention toward a specific event trigger. Despite the success of prior works in sentence-level EAE, the document-level setting is less explored. In particular, whereas syntactic structures of sentences have been shown to be effective for sentence-level EAE, prior document-level EAE models totally ignore syntactic structures for documents. Hence, in this work, we study the importance of syntactic structures in document-level EAE. Specifically, we propose to employ Optimal Transport (OT) to induce structures of documents based on sentence-level syntactic structures and tailored to EAE task. Furthermore, we propose a novel regularization technique to explicitly constrain the contributions of unrelated context words in the final prediction for EAE. We perform extensive experiments on the benchmark document-level EAE dataset RAMS that leads to the state-of-the-art performance. Moreover, our experiments on the ACE 2005 dataset reveals the effectiveness of the proposed model in the sentence-level EAE by establishing new state-of-the-art results.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n最適輸送を利用した文書レベルのイベント引数抽出", "jabstract": "イベント引き出しのサブタスクの1つであるイベント引き出しのイベント引数抽出（EAE）は、特定のイベントトリガーに対する各エンティティメンションの役割を認識することを目的としています。文レベルのEAEにおける先行研究の成功にもかかわらず、ドキュメントレベルの設定はあまり探求されていません。特に、文の構文構造が文レベルのEAEに有効であることが示されている一方、先行のドキュメントレベルのEAEモデルは、ドキュメントの構文構造を完全に無視しています。したがって、本研究では、ドキュメントレベルのEAEにおける構文構造の重要性を研究します。具体的には、最適輸送（OT）を使用して、文レベルの構文構造に基づいて文書の構造を誘導し、EAEタスクに合わせます。さらに、関連のないコンテキスト単語の貢献を明示的に制限する新しい正則化技術を提案します。RAMSというベンチマークドキュメントレベルのEAEデータセットでの広範な実験を行い、最先端のパフォーマンスを達成します。さらに、ACE 2005データセットでの実験により、提案されたモデルが文レベルのEAEにおいて新しい最先端の結果を確立することが示されました。"}
{"title": "N-Shot Learning for Augmenting Task-Oriented Dialogue State Tracking", "url": "https://aclanthology.org/2022.findings-acl.131/", "abstract": "Augmentation of task-oriented dialogues has followed standard methods used for plain-text such as back-translation, word-level manipulation, and paraphrasing despite its richly annotated structure. In this work, we introduce an augmentation framework that utilizes belief state annotations to match turns from various dialogues and form new synthetic dialogues in a bottom-up manner. Unlike other augmentation strategies, it operates with as few as five examples. Our augmentation strategy yields significant improvements when both adapting a DST model to a new domain, and when adapting a language model to the DST task, on evaluations with TRADE and TOD-BERT models. Further analysis shows that our model performs better on seen values during training, and it is also more robust to unseen values.We conclude that exploiting belief state annotations enhances dialogue augmentation and results in improved models in n-shot training scenarios.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nタスク指向型の対話状態追跡を拡張するためのNショット学習", "jabstract": "自然言語処理に関する論文の要約を日本語に翻訳してください。\n\n豊富に注釈された構造にもかかわらず、タスク指向の対話の拡張は、バックトランスレーション、単語レベルの操作、言い換えなどのプレーンテキストに使用される標準的な方法に従って行われてきました。本研究では、信念状態の注釈を利用して、さまざまな対話からターンをマッチングし、ボトムアップの方法で新しい合成対話を形成する拡張フレームワークを紹介します。他の拡張戦略とは異なり、5つの例だけでも動作します。TRADEモデルとTOD-BERTモデルでの評価において、当社の拡張戦略は、DSTモデルを新しいドメインに適応させる場合や、DSTタスクに言語モデルを適応させる場合に、大幅な改善をもたらします。さらなる分析により、当社のモデルはトレーニング中に見られる値でより良いパフォーマンスを発揮し、未知の値に対してもより堅牢であることが示されました。信念状態の注釈を利用することで、対話の拡張が向上し、nショットトレーニングシナリオで改善されたモデルが得られることが結論づけられました。"}
{"title": "Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation", "url": "https://aclanthology.org/2022.findings-acl.132/", "abstract": "Document-level Relation Extraction (DocRE) is a more challenging task compared to its sentence-level counterpart. It aims to extract relations from multiple sentences at once. In this paper, we propose a semi-supervised framework for DocRE with three novel components. Firstly, we use an axial attention module for learning the interdependency among entity-pairs, which improves the performance on two-hop relations. Secondly, we propose an adaptive focal loss to tackle the class imbalance problem of DocRE. Lastly, we use knowledge distillation to overcome the differences between human annotated data and distantly supervised data. We conducted experiments on two DocRE datasets. Our model consistently outperforms strong baselines and its performance exceeds the previous SOTA by 1.36 F1 and 1.46 Ign_F1 score on the DocRED leaderboard.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n適応的フォーカル損失と知識蒸留を用いた文書レベルの関係抽出", "jabstract": "ドキュメントレベルの関係抽出（DocRE）は、文レベルの対応物に比べてより困難なタスクです。複数の文から関係を抽出することを目的としています。本論文では、3つの新しいコンポーネントを持つ半教師ありフレームワークを提案します。まず、エンティティペア間の相互依存関係を学習するために軸方向の注意モジュールを使用し、2ホップ関係のパフォーマンスを向上させます。次に、DocREのクラス不均衡問題に対処するために適応的フォーカル損失を提案します。最後に、知識蒸留を使用して、人間による注釈付きデータと遠隔監視データの間の違いを克服します。2つのDocREデータセットで実験を行いました。当社のモデルは、強力なベースラインを常に上回り、DocREDリーダーボードで以前のSOTAを1.36 F1と1.46 Ign_F1スコアで超えるパフォーマンスを発揮しました。"}
{"title": "Calibration of Machine Reading Systems at Scale", "url": "https://aclanthology.org/2022.findings-acl.133/", "abstract": "In typical machine learning systems, an estimate of the probability of the prediction is used to assess the system’s confidence in the prediction.This confidence measure is usually uncalibrated; i.e. the system’s confidence in the prediction does not match the true probability of the predicted output.In this paper, we present an investigation into calibrating open setting machine reading systemssuch as open-domain question answering and claim verification systems.We show that calibrating such complex systems which contain discrete retrieval and deep reading components is challenging and current calibration techniques fail to scale to these settings. We propose simple extensions to existing calibration approaches that allows us to adapt them to these settings.Our experimental results reveal that the approach works well, and can be useful to selectively predict answers when question answering systems are posed with unanswerable or out-of-the-training distribution questions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "大規模な機械読解システムのキャリブレーション", "jabstract": "通常の機械学習システムでは、予測の確率の推定値を使用して、システムの予測に対する信頼度を評価します。この信頼度の測定は通常、キャリブレーションされていません。つまり、システムの予測に対する信頼度が、予測された出力の真の確率に一致しない場合があります。本論文では、オープン設定の機械読解システム（オープンドメインの質問応答や主張の検証システムなど）のキャリブレーションについて調査を行いました。私たちは、離散的な検索と深い読解コンポーネントを含むこのような複雑なシステムをキャリブレーションすることが困難であり、現在のキャリブレーション技術がこれらの設定にスケールしないことを示しました。私たちは、既存のキャリブレーション手法に簡単な拡張を提案し、これらの設定に適応させることができるようにしました。実験結果は、このアプローチがうまく機能し、質問応答システムが回答できないまたはトレーニング分布外の質問が提示された場合に、回答を選択的に予測するのに役立つことを示しています。"}
{"title": "Towards Adversarially Robust Text Classifiers by Learning to Reweight Clean Examples", "url": "https://aclanthology.org/2022.findings-acl.134/", "abstract": "Most of the existing defense methods improve the adversarial robustness by making the models adapt to the training set augmented with some adversarial examples. However, the augmented adversarial examples may not be natural, which might distort the training distribution, resulting in inferior performance both in clean accuracy and adversarial robustness. In this study, we explore the feasibility of introducing a reweighting mechanism to calibrate the training distribution to obtain robust models. We propose to train text classifiers by a sample reweighting method in which the example weights are learned to minimize the loss of a validation set mixed with the clean examples and their adversarial ones in an online learning manner. Through extensive experiments, we show that there exists a reweighting mechanism to make the models more robust against adversarial attacks without the need to craft the adversarial examples for the entire training set.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「クリーンな例を再重み付けすることで、敵対的に堅牢なテキスト分類器に向けて」", "jabstract": "既存の防御手法のほとんどは、いくつかの敵対的な例を含むトレーニングセットにモデルを適応させることで、敵対的な堅牢性を向上させています。しかし、拡張された敵対的な例は自然ではない場合があり、トレーニング分布を歪め、クリーンな精度と敵対的な堅牢性の両方で劣った性能を引き起こす可能性があります。本研究では、再重み付けメカニズムを導入してトレーニング分布を調整し、堅牢なモデルを得ることの実現可能性を探求します。我々は、クリーンな例とその敵対的な例を混合した検証セットの損失を最小化するように例の重みを学習するサンプル再重み付け法によってテキスト分類器をトレーニングすることを提案します。広範な実験により、敵対的な例をトレーニングセット全体に作成する必要がなく、再重み付けメカニズムを使用してモデルを敵対的な攻撃からより堅牢にすることができることを示します。"}
{"title": "Morphosyntactic Tagging with Pre-trained Language Models for Arabic and its Dialects", "url": "https://aclanthology.org/2022.findings-acl.135/", "abstract": "We present state-of-the-art results on morphosyntactic tagging across different varieties of Arabic using fine-tuned pre-trained transformer language models. Our models consistently outperform existing systems in Modern Standard Arabic and all the Arabic dialects we study, achieving 2.6% absolute improvement over the previous state-of-the-art in Modern Standard Arabic, 2.8% in Gulf, 1.6% in Egyptian, and 8.3% in Levantine. We explore different training setups for fine-tuning pre-trained transformer language models, including training data size, the use of external linguistic resources, and the use of annotated data from other dialects in a low-resource scenario. Our results show that strategic fine-tuning using datasets from other high-resource dialects is beneficial for a low-resource dialect. Additionally, we show that high-quality morphological analyzers as external linguistic resources are beneficial especially in low-resource settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "アラビア語とその方言のための事前学習済み言語モデルを用いた形態・構文タグ付けについての論文の要旨です。", "jabstract": "私たちは、事前に調整されたトランスフォーマー言語モデルを使用して、異なるアラビア語のバリエーションにわたる形態・構文タグ付けの最新の結果を発表します。私たちのモデルは、現代標準アラビア語と私たちが研究したすべてのアラビア語方言で既存のシステムを常に上回り、現代標準アラビア語で前回の最新技術に比べて2.6％、湾岸で2.8％、エジプトで1.6％、レバントで8.3％の絶対的な改善を達成しました。私たちは、事前に調整されたトランスフォーマー言語モデルの微調整のための異なるトレーニングセットアップを探索しました。これには、トレーニングデータサイズ、外部言語リソースの使用、および低リソースシナリオで他の方言からの注釈付きデータの使用が含まれます。私たちの結果は、他の高リソース方言からのデータセットを使用した戦略的な微調整が、低リソース方言にとって有益であることを示しています。さらに、高品質の形態論解析器を外部言語リソースとして使用することが、特に低リソース設定で有益であることを示しています。"}
{"title": "How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis", "url": "https://aclanthology.org/2022.findings-acl.136/", "abstract": "Recently, there has been a trend to investigate the factual knowledge captured by Pre-trained Language Models (PLMs). Many works show the PLMs’ ability to fill in the missing factual words in cloze-style prompts such as ”Dante was born in [MASK].” However, it is still a mystery how PLMs generate the results correctly: relying on effective clues or shortcut patterns? We try to answer this question by a causal-inspired analysis that quantitatively measures and evaluates the word-level patterns that PLMs depend on to generate the missing words. We check the words that have three typical associations with the missing words: knowledge-dependent, positionally close, and highly co-occurred. Our analysis shows: (1) PLMs generate the missing factual words more by the positionally close and highly co-occurred words than the knowledge-dependent words; (2) the dependence on the knowledge-dependent words is more effective than the positionally close and highly co-occurred words. Accordingly, we conclude that the PLMs capture the factual knowledge ineffectively because of depending on the inadequate associations.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習された言語モデルはどのように事実知識を捉えるのか？因果関係に着想を得た分析", "jabstract": "最近、Pre-trained Language Models（PLMs）によって捉えられた事実知識を調査する傾向がある。多くの研究は、PLMsが「ダンテは[MASK]で生まれた」といったクローズ形式のプロンプトで欠落した事実語を補完する能力を示している。しかし、PLMsが正確な結果を生成する方法はまだ謎である。有効な手がかりに依存するのか、ショートカットパターンに依存するのか？本研究では、PLMsが欠落した単語を生成するために依存する単語レベルのパターンを定量的に測定・評価する因果関係に着想を得た分析によってこの問いに答えようとする。欠落した単語と3つの典型的な関連性を持つ単語をチェックする：知識に依存する、位置的に近い、高頻度で共起する。分析の結果、(1) PLMsは、知識に依存する単語よりも位置的に近く、高頻度で共起する単語によって欠落した事実語を生成することが多いことがわかった。(2) 知識に依存する単語への依存は、位置的に近く、高頻度で共起する単語よりも効果的であることがわかった。したがって、PLMsは、不適切な関連性に依存するため、事実知識を効果的に捉えていないと結論付けられる。"}
{"title": "Metadata Shaping: A Simple Approach for Knowledge-Enhanced Language Models", "url": "https://aclanthology.org/2022.findings-acl.137/", "abstract": "Popular language models (LMs) struggle to capture knowledge about rare tail facts and entities. Since widely used systems such as search and personal-assistants must support the long tail of entities that users ask about, there has been significant effort towards enhancing these base LMs with factual knowledge. We observe proposed methods typically start with a base LM and data that has been annotated with entity metadata, then change the model, by modifying the architecture or introducing auxiliary loss terms to better capture entity knowledge. In this work, we question this typical process and ask to what extent can we match the quality of model modifications, with a simple alternative: using a base LM and only changing the data. We propose metadata shaping, a method which inserts substrings corresponding to the readily available entity metadata, e.g. types and descriptions, into examples at train and inference time based on mutual information. Despite its simplicity, metadata shaping is quite effective. On standard evaluation benchmarks for knowledge-enhanced LMs, the method exceeds the base-LM baseline by an average of 4.3 F1 points and achieves state-of-the-art results. We further show the gains are on average 4.4x larger for the slice of examples containing tail vs. popular entities.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "メタデータの形成：知識強化言語モデルのための簡単なアプローチ", "jabstract": "一般的な言語モデル（LM）は、まれな事実やエンティティに関する知識を捉えるのが困難です。検索やパーソナルアシスタントなどの広く使用されているシステムは、ユーザーが問い合わせるエンティティの長尾をサポートする必要があるため、これらの基本的なLMを事実知識で強化するための大きな努力がなされています。提案された方法は、通常、ベースのLMとエンティティメタデータで注釈付けされたデータを使用して開始し、モデルを変更してエンティティ知識をよりよく捉えるためにアーキテクチャを変更したり、補助的な損失項を導入したりします。本研究では、この典型的なプロセスに疑問を投げかけ、単純な代替案であるベースのLMを使用してデータのみを変更することで、モデルの変更の質をどの程度一致させることができるかを問い合わせます。我々は、相互情報に基づいてトレーニングと推論時に、利用可能なエンティティメタデータ（例：タイプや説明）に対応するサブストリングを例に挿入するメタデータシェーピングという方法を提案します。この方法は、シンプルでありながら非常に効果的です。知識強化LMの標準的な評価ベンチマークでは、この方法はベースLMベースラインを平均4.3 F1ポイント上回り、最先端の結果を達成します。さらに、利益は、テール対人気エンティティを含む例のスライスに対して平均4.4倍大きいことを示します。"}
{"title": "Enhancing Natural Language Representation with Large-Scale Out-of-Domain Commonsense", "url": "https://aclanthology.org/2022.findings-acl.138/", "abstract": "We study how to enhance text representation via textual commonsense. We point out that commonsense has the nature of domain discrepancy. Namely, commonsense has different data formats and is domain-independent from the downstream task. This nature brings challenges to introducing commonsense in general text understanding tasks. A typical method of introducing textual knowledge is continuing pre-training over the commonsense corpus. However, it will cause catastrophic forgetting to the downstream task due to the domain discrepancy. In addition, previous methods of directly using textual descriptions as extra input information cannot apply to large-scale commonsense.In this paper, we propose to use large-scale out-of-domain commonsense to enhance text representation. In order to effectively incorporate the commonsense, we proposed OK-Transformer (Out-of-domain Knowledge enhanced Transformer). OK-Transformer effectively integrates commonsense descriptions and enhances them to the target text representation. In addition, OK-Transformer can adapt to the Transformer-based language models (e.g. BERT, RoBERTa) for free, without pre-training on large-scale unsupervised corpora. We have verified the effectiveness of OK-Transformer in multiple applications such as commonsense reasoning, general text classification, and low-resource commonsense settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Natural Language Processingに関する論文の要約文を日本語に翻訳してください。\n\n大規模な領域外の常識を用いた自然言語表現の強化", "jabstract": "私たちは、テキストの常識を通じてテキスト表現を強化する方法を研究しています。私たちは、常識がドメインの不一致の性質を持つことを指摘します。つまり、常識は異なるデータ形式を持ち、下流のタスクからドメインに依存しない性質を持っています。この性質は、一般的なテキスト理解タスクに常識を導入する際に課題をもたらします。テキスト知識を導入する典型的な方法は、常識コーパス上での事前学習を継続することです。しかし、ドメインの不一致により、下流のタスクに対して壊滅的な忘却を引き起こす可能性があります。さらに、テキスト記述を追加の入力情報として直接使用する以前の方法は、大規模な常識には適用できません。本論文では、大規模なドメイン外常識を使用してテキスト表現を強化することを提案します。常識を効果的に統合するために、私たちはOK-Transformer（ドメイン外知識強化トランスフォーマー）を提案しました。OK-Transformerは、常識の説明を効果的に統合し、それらをターゲットのテキスト表現に強化します。さらに、OK-Transformerは、大規模な非監視コーパスでの事前学習なしに、Transformerベースの言語モデル（例：BERT、RoBERTa）に自由に適応できます。私たちは、常識推論、一般的なテキスト分類、および低リソースの常識設定など、複数のアプリケーションでOK-Transformerの有効性を検証しました。"}
{"title": "Weighted self Distillation for Chinese word segmentation", "url": "https://aclanthology.org/2022.findings-acl.139/", "abstract": "Recent researches show that multi-criteria resources and n-gram features are beneficial to Chinese Word Segmentation (CWS). However, these methods rely heavily on such additional information mentioned above and focus less on the model itself. We thus propose a novel neural framework, named Weighted self Distillation for Chinese word segmentation (WeiDC). The framework, which only requires unigram features, adopts self-distillation technology with four hand-crafted weight modules and two teacher models configurations. Experiment results show that WeiDC can make use of character features to learn contextual knowledge and successfully achieve state-of-the-art or competitive performance in terms of strictly closed test settings on SIGHAN Bakeoff benchmark datasets. Moreover, further experiments and analyses also demonstrate the robustness of WeiDC. Source codes of this paper are available on Github.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "中国語の単語分割のための重み付け自己蒸留", "jabstract": "最近の研究によると、多基準リソースとn-gram特徴は中国語の単語分割（CWS）に有益であることが示されています。しかし、これらの方法は上記の追加情報に大きく依存し、モデル自体にはあまり焦点を当てていません。そこで、私たちは新しいニューラルフレームワーク「Weighted self Distillation for Chinese word segmentation（WeiDC）」を提案します。このフレームワークは、ユニグラム特徴のみを必要とし、4つの手作りの重みモジュールと2つの教師モデル構成を備えた自己蒸留技術を採用しています。実験結果は、WeiDCが文字特徴を利用して文脈的な知識を学習し、SIGHAN Bakeoffベンチマークデータセットの厳密な閉鎖テスト設定において最新技術または競争力のあるパフォーマンスを達成できることを示しています。さらに、さらなる実験と分析もWeiDCの堅牢性を示しています。本論文のソースコードはGithubで入手可能です。"}
{"title": "Sibylvariant Transformations for Robust Text Classification", "url": "https://aclanthology.org/2022.findings-acl.140/", "abstract": "The vast majority of text transformation techniques in NLP are inherently limited in their ability to expand input space coverage due to an implicit constraint to preserve the original class label. In this work, we propose the notion of sibylvariance (SIB) to describe the broader set of transforms that relax the label-preserving constraint, knowably vary the expected class, and lead to significantly more diverse input distributions. We offer a unified framework to organize all data transformations, including two types of SIB: (1) Transmutations convert one discrete kind into another, (2) Mixture Mutations blend two or more classes together. To explore the role of sibylvariance within NLP, we implemented 41 text transformations, including several novel techniques like Concept2Sentence and SentMix. Sibylvariance also enables a unique form of adaptive training that generates new input mixtures for the most confused class pairs, challenging the learner to differentiate with greater nuance. Our experiments on six benchmark datasets strongly support the efficacy of sibylvariance for generalization performance, defect detection, and adversarial robustness.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Sibylvariant変換による堅牢なテキスト分類", "jabstract": "自然言語処理におけるほとんどのテキスト変換技術は、元のクラスラベルを保持する制約を暗黙的に持っているため、入力空間のカバレッジを拡大する能力に限界がある。本研究では、ラベル保持制約を緩和し、期待されるクラスを明確に変化させ、より多様な入力分布をもたらすより広範な変換の概念であるsibylvariance（SIB）を提案する。我々は、2つのタイプのSIBを含むすべてのデータ変換を組織するための統一されたフレームワークを提供する：（1）Transmutationsは1つの離散的な種類を別の種類に変換する、（2）Mixture Mutationsは2つ以上のクラスを混合する。NLP内でsibylvarianceの役割を探るために、Concept2SentenceやSentMixなどのいくつかの新しい技術を含む41のテキスト変換を実装した。Sibylvarianceは、最も混乱するクラスペアの新しい入力混合物を生成する独自の形式の適応的トレーニングも可能にし、学習者により微妙な差異を区別するように挑戦する。6つのベンチマークデータセットでの実験は、sibylvarianceが一般化性能、欠陥検出、および敵対的な堅牢性に対する有効性を強く支持している。"}
{"title": "DaLC: Domain Adaptation Learning Curve Prediction for Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.141/", "abstract": "Domain Adaptation (DA) of Neural Machine Translation (NMT) model often relies on a pre-trained general NMT model which is adapted to the new domain on a sample of in-domain parallel data. Without parallel data, there is no way to estimate the potential benefit of DA, nor the amount of parallel samples it would require. It is however a desirable functionality that could help MT practitioners to make an informed decision before investing resources in dataset creation. We propose a Domain adaptation Learning Curve prediction (DaLC) model that predicts prospective DA performance based on in-domain monolingual samples in the source language. Our model relies on the NMT encoder representations combined with various instance and corpus-level features. We demonstrate that instance-level is better able to distinguish between different domains compared to corpus-level frameworks proposed in previous studies Finally, we perform in-depth analyses of the results highlighting the limitations of our approach, and provide directions for future research.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DaLC：ニューラル機械翻訳のドメイン適応学習曲線予測", "jabstract": "ニューラル機械翻訳（NMT）モデルのドメイン適応（DA）は、しばしば、新しいドメインに適応された一般的なNMTモデルの事前学習に依存しています。これには、ドメイン内並列データのサンプルが必要です。並列データがない場合、DAの潜在的な利益や必要な並列サンプルの量を推定する方法はありません。しかし、これはデータセット作成にリソースを投資する前にMT実践者が情報を得ることができる望ましい機能です。本研究では、ソース言語のドメイン内単一言語サンプルに基づいて将来のDAパフォーマンスを予測するドメイン適応学習曲線予測（DaLC）モデルを提案します。当社のモデルは、NMTエンコーダ表現とさまざまなインスタンスおよびコーパスレベルの特徴を組み合わせています。本研究では、以前の研究で提案されたコーパスレベルのフレームワークと比較して、インスタンスレベルが異なるドメインをより区別できることを示します。最後に、結果の詳細な分析を行い、アプローチの限界を強調し、将来の研究の方向性を提供します。"}
{"title": "Hey AI, Can You Solve Complex Tasks by Talking to Agents?", "url": "https://aclanthology.org/2022.findings-acl.142/", "abstract": "Training giant models from scratch for each complex task is resource- and data-inefficient. To help develop models that can leverage existing systems, we propose a new challenge: Learning to solve complex tasks by communicating with existing agents (or models) in natural language. We design a synthetic benchmark, CommaQA, with three complex reasoning tasks (explicit, implicit, numeric) designed to be solved by communicating with existing QA agents. For instance, using text and table QA agents to answer questions such as “Who had the longest javelin throw from USA?”. We show that black-box models struggle to learn this task from scratch (accuracy under 50%) even with access to each agent’s knowledge and gold facts supervision. In contrast, models that learn to communicate with agents outperform black-box models, reaching scores of 100% when given gold decomposition supervision. However, we show that the challenge of learning to solve complex tasks by communicating with existing agents without relying on any auxiliary supervision or data still remains highly elusive. We will release CommaQA, along with a compositional generalization test split, to advance research in this direction.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「こんにちはAI、エージェントと話して複雑なタスクを解決できますか？」という論文の要約です。", "jabstract": "複雑なタスクごとに巨大なモデルをゼロからトレーニングすることは、リソースとデータの効率が悪い。既存のシステムを活用できるモデルを開発するために、我々は新しい課題を提案する：既存のエージェント（またはモデル）と自然言語でコミュニケーションをとることによって複雑なタスクを解決することを学ぶ。我々は、既存のQAエージェントとコミュニケーションをとることで解決するために設計された3つの複雑な推論タスク（明示的、暗黙的、数値）を備えた合成ベンチマーク、CommaQAを設計する。例えば、「アメリカから最も長いやり投げをしたのは誰ですか？」のような質問に対して、テキストと表のQAエージェントを使用して回答する。我々は、黒箱モデルがこのタスクをゼロから学習するのに苦戦することを示し（正確性が50％以下）、各エージェントの知識とゴールドファクトの監視にアクセスできても同様です。対照的に、エージェントとコミュニケーションをとることを学ぶモデルは、黒箱モデルを上回り、ゴールド分解監視が与えられた場合には100％のスコアを達成することを示します。しかし、補助的な監視やデータに頼らずに既存のエージェントとコミュニケーションをとって複雑なタスクを解決することを学ぶという課題は、まだ非常に難しいことが示されています。我々は、この方向性の研究を進めるために、CommaQAと構成的な一般化テスト分割をリリースする予定です。"}
{"title": "Modality-specific Learning Rates for Effective Multimodal Additive Late-fusion", "url": "https://aclanthology.org/2022.findings-acl.143/", "abstract": "In multimodal machine learning, additive late-fusion is a straightforward approach to combine the feature representations from different modalities, in which the final prediction can be formulated as the sum of unimodal predictions. While it has been found that certain late-fusion models can achieve competitive performance with lower computational costs compared to complex multimodal interactive models, how to effectively search for a good late-fusion model is still an open question. Moreover, for different modalities, the best unimodal models may work under significantly different learning rates due to the nature of the modality and the computational flow of the model; thus, selecting a global learning rate for late-fusion models can result in a vanishing gradient for some modalities. To help address these issues, we propose a Modality-Specific Learning Rate (MSLR) method to effectively build late-fusion multimodal models from fine-tuned unimodal models. We investigate three different strategies to assign learning rates to different modalities. Our experiments show that MSLR outperforms global learning rates on multiple tasks and settings, and enables the models to effectively learn each modality.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "効果的なマルチモーダル加算後段融合のためのモダリティ特異的学習率", "jabstract": "マルチモーダル機械学習において、加算的なレイトフュージョンは、異なるモダリティからの特徴表現を組み合わせるための簡単なアプローチであり、最終的な予測は単一モダルの予測の合計として定式化されます。複雑なマルチモーダルインタラクティブモデルと比較して、特定のレイトフュージョンモデルが低い計算コストで競争力のあるパフォーマンスを発揮できることがわかっていますが、良いレイトフュージョンモデルを効果的に探索する方法はまだオープンな問題です。さらに、異なるモダリティに対して、最適な単一モダルモデルは、モダリティの性質やモデルの計算フローのために、大幅に異なる学習率で動作する可能性があるため、レイトフュージョンモデルのグローバルな学習率を選択すると、一部のモダリティに対して勾配消失が発生する可能性があります。これらの問題に対処するために、私たちはモダリティ固有の学習率（MSLR）方法を提案し、ファインチューニングされた単一モダルモデルから効果的にレイトフュージョンマルチモーダルモデルを構築することを提案します。私たちは、異なるモダリティに学習率を割り当てるための3つの異なる戦略を調査しました。私たちの実験は、MSLRが複数のタスクや設定でグローバルな学習率よりも優れたパフォーマンスを発揮し、モデルが各モダリティを効果的に学習できるようにすることを示しています。"}
{"title": "BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis", "url": "https://aclanthology.org/2022.findings-acl.144/", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that aims to align aspects and corresponding sentiments for aspect-specific sentiment polarity inference. It is challenging because a sentence may contain multiple aspects or complicated (e.g., conditional, coordinating, or adversative) relations. Recently, exploiting dependency syntax information with graph neural networks has been the most popular trend. Despite its success, methods that heavily rely on the dependency tree pose challenges in accurately modeling the alignment of the aspects and their words indicative of sentiment, since the dependency tree may provide noisy signals of unrelated associations (e.g., the “conj” relation between “great” and “dreadful” in Figure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax aware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully exploits the syntax information (e.g., phrase segmentation and hierarchical structure) of the constituent tree of a sentence to model the sentiment-aware context of every single aspect (called intra-context) and the sentiment relations across aspects (called inter-context) for learning. Experiments on four benchmark datasets demonstrate that BiSyn-GAT+ outperforms the state-of-the-art methods consistently.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "BiSyn-GAT+：アスペクトベースの感情分析のためのバイシンタックス意識グラフ注意ネットワーク", "jabstract": "アスペクトベースの感情分析（ABSA）は、アスペクト固有の感情極性推論のためにアスペクトと対応する感情を整合させる微細な感情分析タスクです。文には複数のアスペクトや複雑な（条件付き、調整、対立など）関係が含まれるため、課題があります。最近では、グラフニューラルネットワークを用いた依存構文情報の利用が最も一般的なトレンドとなっています。成功しているにもかかわらず、依存構文ツリーに重点を置く方法は、依存構文ツリーが関係のない関連のノイズ信号を提供する可能性があるため、アスペクトと感情を示す単語の整合性を正確にモデル化することに課題があります（例えば、図2の「great」と「dreadful」の間の「conj」関係）。本論文では、この問題を緩和するために、Bi-Syntax aware Graph Attention Network（BiSyn-GAT+）を提案します。具体的には、BiSyn-GAT+は、文の構成ツリーの構文情報（フレーズのセグメンテーションや階層構造など）を完全に活用して、各アスペクトの感情に敏感な文脈（intra-context）とアスペクト間の感情関係（inter-context）をモデル化して学習します。4つのベンチマークデータセットでの実験結果は、BiSyn-GAT+が常に最先端の方法を上回っていることを示しています。"}
{"title": "IndicBART: A Pre-trained Model for Indic Natural Language Generation", "url": "https://aclanthology.org/2022.findings-acl.145/", "abstract": "In this paper, we study pre-trained sequence-to-sequence models for a group of related languages, with a focus on Indic languages. We present IndicBART, a multilingual, sequence-to-sequence pre-trained model focusing on 11 Indic languages and English. IndicBART utilizes the orthographic similarity between Indic scripts to improve transfer learning between similar Indic languages. We evaluate IndicBART on two NLG tasks: Neural Machine Translation (NMT) and extreme summarization. Our experiments on NMT and extreme summarization show that a model specific to related languages like IndicBART is competitive with large pre-trained models like mBART50 despite being significantly smaller. It also performs well on very low-resource translation scenarios where languages are not included in pre-training or fine-tuning. Script sharing, multilingual training, and better utilization of limited model capacity contribute to the good performance of the compact IndicBART model.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "IndicBART：インドの自然言語生成のための事前学習モデル", "jabstract": "本論文では、関連する言語グループ、特にインド諸言語に焦点を当て、事前学習されたシーケンス・ツー・シーケンス・モデルを研究します。我々は、11のインド諸言語と英語に焦点を当てた多言語シーケンス・ツー・シーケンス・事前学習モデルであるIndicBARTを提案します。IndicBARTは、インド諸言語間の表記の類似性を利用して、類似するインド諸言語間の転移学習を改善します。我々は、ニューラル機械翻訳（NMT）と極端な要約の2つのNLGタスクでIndicBARTを評価します。NMTと極端な要約の実験結果は、IndicBARTのような関連する言語に特化したモデルが、大規模な事前学習モデルであるmBART50と同等の性能を発揮することを示しています。また、事前学習や微調整に含まれていない非常に低資源の翻訳シナリオでも良好な性能を発揮します。表記の共有、多言語トレーニング、限られたモデル容量のより良い活用が、コンパクトなIndicBARTモデルの良好な性能に貢献しています。"}
{"title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models", "url": "https://aclanthology.org/2022.findings-acl.146/", "abstract": "We provide the first exploration of sentence embeddings from text-to-text transformers (T5) including the effects of scaling up sentence encoders to 11B parameters. Sentence embeddings are broadly useful for language processing tasks. While T5 achieves impressive performance on language tasks, it is unclear how to produce sentence embeddings from encoder-decoder models. We investigate three methods to construct Sentence-T5 (ST5) models: two utilize only the T5 encoder and one using the full T5 encoder-decoder. We establish a new sentence representation transfer benchmark, SentGLUE, which extends the SentEval toolkit to nine tasks from the GLUE benchmark. Our encoder-only models outperform the previous best models on both SentEval and SentGLUE transfer tasks, including semantic textual similarity (STS). Scaling up ST5 from millions to billions of parameters shown to consistently improve performance. Finally, our encoder-decoder method achieves a new state-of-the-art on STS when using sentence embeddings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Pre-trained Text-to-Textモデルからのスケーラブルな文エンコーダー」は、自然言語処理に関する論文の要約です。", "jabstract": "私たちは、言語処理タスクに広く有用な文の埋め込みを、テキストからテキストへのトランスフォーマー（T5）から初めて探索し、エンコーダを11Bパラメータにスケーリングすることの影響を含めました。T5は言語タスクで印象的なパフォーマンスを発揮しますが、エンコーダ・デコーダモデルから文の埋め込みを生成する方法は不明です。私たちは、T5エンコーダのみを利用する2つの方法と、完全なT5エンコーダ・デコーダを使用する1つの方法を調査し、Sentence-T5（ST5）モデルを構築するための3つの方法を調査しました。私たちは、SentEvalツールキットをGLUEベンチマークの9つのタスクに拡張した新しい文表現転送ベンチマーク、SentGLUEを確立しました。私たちのエンコーダのみのモデルは、セマンティックテキスト類似度（STS）を含むSentEvalとSentGLUE転送タスクの両方で、以前の最高のモデルを上回りました。ST5を数百万から数十億のパラメータにスケーリングすることが、一貫してパフォーマンスを向上させることが示されました。最後に、私たちのエンコーダ・デコーダ法は、文の埋め込みを使用したSTSの新しい最高水準を達成しました。"}
{"title": "Improving Relation Extraction through Syntax-induced Pre-training with Dependency Masking", "url": "https://aclanthology.org/2022.findings-acl.147/", "abstract": "Relation extraction (RE) is an important natural language processing task that predicts the relation between two given entities, where a good understanding of the contextual information is essential to achieve an outstanding model performance. Among different types of contextual information, the auto-generated syntactic information (namely, word dependencies) has shown its effectiveness for the task. However, most existing studies require modifications to the existing baseline architectures (e.g., adding new components, such as GCN, on the top of an encoder) to leverage the syntactic information. To offer an alternative solution, we propose to leverage syntactic information to improve RE by training a syntax-induced encoder on auto-parsed data through dependency masking. Specifically, the syntax-induced encoder is trained by recovering the masked dependency connections and types in first, second, and third orders, which significantly differs from existing studies that train language models or word embeddings by predicting the context words along the dependency paths. Experimental results on two English benchmark datasets, namely, ACE2005EN and SemEval 2010 Task 8 datasets, demonstrate the effectiveness of our approach for RE, where our approach outperforms strong baselines and achieve state-of-the-art results on both datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「依存関係マスキングを用いた構文誘導プレトレーニングによる関係抽出の改善」についての論文の要約です。", "jabstract": "関係抽出（RE）は、2つの与えられたエンティティ間の関係を予測する重要な自然言語処理のタスクであり、文脈情報の良好な理解が優れたモデルのパフォーマンスを達成するために必要です。異なるタイプの文脈情報の中で、自動生成された構文情報（すなわち、単語の依存関係）は、このタスクにおいて有効性を示しています。しかし、既存の研究の多くは、構文情報を活用するために既存のベースラインアーキテクチャを変更する必要があります（例えば、エンコーダの上にGCNなどの新しいコンポーネントを追加するなど）。代替案を提供するために、我々は構文情報を活用してREを改善するために、依存関係マスキングを介して自動解析されたデータ上で構文誘導エンコーダをトレーニングすることを提案します。具体的には、構文誘導エンコーダは、第1、第2、第3の順序でマスクされた依存関係の接続とタイプを回復することによってトレーニングされます。これは、既存の研究が依存関係パスに沿ってコンテキスト単語を予測することによって言語モデルや単語埋め込みをトレーニングするのとは大きく異なります。英語の2つのベンチマークデータセット、すなわちACE2005ENとSemEval 2010 Task 8データセットでの実験結果は、我々のアプローチがREにおいて有効であることを示しており、我々のアプローチは強力なベースラインを上回り、両方のデータセットで最先端の結果を達成しています。"}
{"title": "Striking a Balance: Alleviating Inconsistency in Pre-trained Models for Symmetric Classification Tasks", "url": "https://aclanthology.org/2022.findings-acl.148/", "abstract": "While fine-tuning pre-trained models for downstream classification is the conventional paradigm in NLP, often task-specific nuances may not get captured in the resultant models. Specifically, for tasks that take two inputs and require the output to be invariant of the order of the inputs, inconsistency is often observed in the predicted labels or confidence scores.We highlight this model shortcoming and apply a consistency loss function to alleviate inconsistency in symmetric classification. Our results show an improved consistency in predictions for three paraphrase detection datasets without a significant drop in the accuracy scores. We examine the classification performance of six datasets (both symmetric and non-symmetric) to showcase the strengths and limitations of our approach.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "バランスを取る：対称的な分類タスクの事前学習モデルの不一致を緩和する", "jabstract": "自然言語処理において、下流の分類のために事前学習されたモデルを微調整することが従来のパラダイムであるが、タスク固有の微妙なニュアンスが結果のモデルに捉えられないことがある。特に、2つの入力を受け取り、出力が入力の順序に不変である必要があるタスクでは、予測されたラベルや信頼スコアに不一致がしばしば観察される。本研究では、このモデルの欠点を強調し、対称的な分類における不一致を緩和するための一貫性損失関数を適用する。結果として、3つの言い換え検出データセットにおいて予測の一貫性が向上し、精度スコアの大幅な低下は見られなかった。また、対称的および非対称的な6つのデータセットの分類性能を検討し、アプローチの強みと限界を示した。"}
{"title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "url": "https://aclanthology.org/2022.findings-acl.149/", "abstract": "Generative commonsense reasoning (GCR) in natural language is to reason about the commonsense while generating coherent text. Recent years have seen a surge of interest in improving the generation quality of commonsense reasoning tasks. Nevertheless, these approaches have seldom investigated diversity in the GCR tasks, which aims to generate alternative explanations for a real-world situation or predict all possible outcomes. Diversifying GCR is challenging as it expects to generate multiple outputs that are not only semantically different but also grounded in commonsense knowledge. In this paper, we propose MoKGE, a novel method that diversifies the generative reasoning by a mixture of expert (MoE) strategy on commonsense knowledge graphs (KG). A set of knowledge experts seek diverse reasoning on KG to encourage various generation outputs. Empirical experiments demonstrated that MoKGE can significantly improve the diversity while achieving on par performance on accuracy on two GCR benchmarks, based on both automatic and human evaluations.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「知識グラフ専門家の混合物を用いた常識推論のための多様なコンテンツ生成」に関する論文の要約です。", "jabstract": "自然言語処理における生成的常識推論（GCR）は、一貫したテキストを生成しながら常識について推論することです。近年、GCRタスクの生成品質を向上させることに関心が高まっています。しかし、これらのアプローチは、現実世界の状況に対する代替説明を生成するか、すべての可能な結果を予測することを目的とするGCRタスクの多様性をほとんど調査していません。GCRの多様性を実現することは、意味的に異なるだけでなく、常識的な知識に基づいた複数の出力を生成することを期待するため、課題があります。本論文では、常識知識グラフ（KG）上の専門家の混合（MoE）戦略によって、MoKGEという新しい方法を提案して、生成的推論を多様化します。一連の知識専門家は、KG上で多様な推論を求め、さまざまな生成出力を促進します。実験的な実験では、MoKGEが両方の自動評価と人間の評価に基づく2つのGCRベンチマークで、正確性に対して同等のパフォーマンスを達成しながら、多様性を大幅に向上させることが示されました。"}
{"title": "Dict-BERT: Enhancing Language Model Pre-training with Dictionary", "url": "https://aclanthology.org/2022.findings-acl.150/", "abstract": "Pre-trained language models (PLMs) aim to learn universal language representations by conducting self-supervised training tasks on large-scale corpora. Since PLMs capture word semantics in different contexts, the quality of word representations highly depends on word frequency, which usually follows a heavy-tailed distributions in the pre-training corpus. Therefore, the embeddings of rare words on the tail are usually poorly optimized. In this work, we focus on enhancing language model pre-training by leveraging definitions of the rare words in dictionaries (e.g., Wiktionary). To incorporate a rare word definition as a part of input, we fetch its definition from the dictionary and append it to the end of the input text sequence. In addition to training with the masked language modeling objective, we propose two novel self-supervised pre-training tasks on word and sentence-level alignment between input text sequence and rare word definitions to enhance language modeling representation with dictionary. We evaluate the proposed Dict-BERT model on the language understanding benchmark GLUE and eight specialized domain benchmark datasets. Extensive experiments demonstrate that Dict-BERT can significantly improve the understanding of rare words and boost model performance on various NLP downstream tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Dict-BERT：辞書を用いた言語モデルの事前学習の強化", "jabstract": "事前学習言語モデル（PLMs）は、大規模なコーパスで自己教示トレーニングタスクを実行することにより、普遍的な言語表現を学習することを目的としています。 PLMsは、異なる文脈で単語の意味を捉えるため、単語表現の品質は単語の頻度に大きく依存し、通常は事前トレーニングコーパスで重尾分布に従います。したがって、テール上のレアな単語の埋め込みは通常、最適化が不十分です。本研究では、辞書（例：Wiktionary）のレアな単語の定義を活用して言語モデルの事前学習を強化することに焦点を当てています。レアな単語の定義を入力の一部として取り込むために、辞書からその定義を取得し、入力テキストシーケンスの末尾に追加します。マスクされた言語モデリング目的でトレーニングするだけでなく、入力テキストシーケンスとレアな単語の定義との単語および文レベルのアラインメントに関する2つの新しい自己教示事前トレーニングタスクを提案し、辞書を用いた言語モデリング表現を強化します。提案されたDict-BERTモデルを言語理解ベンチマークGLUEおよび8つの専門分野ベンチマークデータセットで評価します。広範な実験により、Dict-BERTがレアな単語の理解を大幅に改善し、さまざまなNLP下流タスクのモデルパフォーマンスを向上させることが示されました。"}
{"title": "A Feasibility Study of Answer-Agnostic Question Generation for Education", "url": "https://aclanthology.org/2022.findings-acl.151/", "abstract": "We conduct a feasibility study into the applicability of answer-agnostic question generation models to textbook passages. We show that a significant portion of errors in such systems arise from asking irrelevant or un-interpretable questions and that such errors can be ameliorated by providing summarized input. We find that giving these models human-written summaries instead of the original text results in a significant increase in acceptability of generated questions (33% → 83%) as determined by expert annotators. We also find that, in the absence of human-written summaries, automatic summarization can serve as a good middle ground.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "教育のための回答に関係ない質問生成の実現可能性の研究", "jabstract": "私たちは、教科書の文章に対して回答に関係ない質問生成モデルの適用可能性についての実現可能性調査を行いました。私たちは、このようなシステムにおける重大なエラーの多くが、関係のないまたは解釈できない質問をすることから生じることを示し、要約された入力を提供することでこれらのエラーを改善できることを示しました。私たちは、人間が書いた要約を元のテキストの代わりにこれらのモデルに与えることで、生成された質問の受容性が専門家の注釈者によって決定された場合に有意な増加があることを発見しました（33％→83％）。また、人間が書いた要約がない場合、自動要約は良い中間地点として機能することがわかりました。"}
{"title": "Relevant CommonSense Subgraphs for “What if...” Procedural Reasoning", "url": "https://aclanthology.org/2022.findings-acl.152/", "abstract": "We study the challenge of learning causal reasoning over procedural text to answer “What if...” questions when external commonsense knowledge is required. We propose a novel multi-hop graph reasoning model to 1) efficiently extract a commonsense subgraph with the most relevant information from a large knowledge graph; 2) predict the causal answer by reasoning over the representations obtained from the commonsense subgraph and the contextual interactions between the questions and context. We evaluate our model on WIQA benchmark and achieve state-of-the-art performance compared to the recent models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「もしも...」手順的推論のための関連する常識的なサブグラフ", "jabstract": "外部の常識的な知識が必要な場合に、「もし...」という質問に答えるために手順的なテキスト上で因果推論を学習する課題を研究します。私たちは、大規模な知識グラフから最も関連性の高い情報を持つ常識的なサブグラフを効率的に抽出するための新しいマルチホップグラフ推論モデルを提案し、質問と文脈の相互作用と常識的なサブグラフから得られた表現を推論することで因果的な答えを予測します。私たちはWIQAベンチマークでモデルを評価し、最近のモデルと比較して最先端の性能を達成しました。"}
{"title": "Combining Feature and Instance Attribution to Detect Artifacts", "url": "https://aclanthology.org/2022.findings-acl.153/", "abstract": "Training the deep neural networks that dominate NLP requires large datasets. These are often collected automatically or via crowdsourcing, and may exhibit systematic biases or annotation artifacts. By the latter we mean spurious correlations between inputs and outputs that do not represent a generally held causal relationship between features and classes; models that exploit such correlations may appear to perform a given task well, but fail on out of sample data. In this paper, we evaluate use of different attribution methods for aiding identification of training data artifacts. We propose new hybrid approaches that combine saliency maps (which highlight important input features) with instance attribution methods (which retrieve training samples influential to a given prediction). We show that this proposed training-feature attribution can be used to efficiently uncover artifacts in training data when a challenging validation set is available. We also carry out a small user study to evaluate whether these methods are useful to NLP researchers in practice, with promising results. We make code for all methods and experiments in this paper available.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "特徴とインスタンスの帰属を組み合わせてアーティファクトを検出する。", "jabstract": "自然言語処理において主導的な深層ニューラルネットワークを訓練するには、大規模なデータセットが必要です。これらは自動的に収集されるか、クラウドソーシングを通じて収集されることが多く、系統的なバイアスや注釈アーティファクトを示す場合があります。ここで言う注釈アーティファクトとは、特徴とクラスの間に一般的に保持されている因果関係を表さない入出力間の偽の相関を指します。このような相関を利用するモデルは、特定のタスクをうまく実行するように見えるかもしれませんが、サンプル外のデータでは失敗する可能性があります。本論文では、トレーニングデータのアーティファクトの特定を支援するための異なる属性付与方法の使用を評価します。私たちは、重要な入力特徴を強調するサリエンシーマップと、特定の予測に影響を与えるトレーニングサンプルを取得するインスタンス属性付与方法を組み合わせた新しいハイブリッドアプローチを提案します。私たちは、この提案されたトレーニング特徴属性が、チャレンジングな検証セットが利用可能な場合に、トレーニングデータのアーティファクトを効率的に発見するために使用できることを示します。また、これらの方法がNLP研究者にとって実用的であるかどうかを評価するために、小規模なユーザースタディを実施し、有望な結果を得ました。本論文で使用されたすべての方法と実験のコードを公開します。"}
{"title": "Leveraging Expert Guided Adversarial Augmentation For Improving Generalization in Named Entity Recognition", "url": "https://aclanthology.org/2022.findings-acl.154/", "abstract": "Named Entity Recognition (NER) systems often demonstrate great performance on in-distribution data, but perform poorly on examples drawn from a shifted distribution. One way to evaluate the generalization ability of NER models is to use adversarial examples, on which the specific variations associated with named entities are rarely considered. To this end, we propose leveraging expert-guided heuristics to change the entity tokens and their surrounding contexts thereby altering their entity types as adversarial attacks. Using expert-guided heuristics, we augmented the CoNLL 2003 test set and manually annotated it to construct a high-quality challenging set. We found that state-of-the-art NER systems trained on CoNLL 2003 training data drop performance dramatically on our challenging set. By training on adversarial augmented training examples and using mixup for regularization, we were able to significantly improve the performance on the challenging set as well as improve out-of-domain generalization which we evaluated by using OntoNotes data. We have publicly released our dataset and code at https://github.com/GT-SALT/Guided-Adversarial-Augmentation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "専門家による敵対的な拡張を活用して、固有表現認識における汎化性能を向上させるための取り組み", "jabstract": "Named Entity Recognition（NER）システムは、イン・ディストリビューション・データにおいては優れたパフォーマンスを示すが、シフトした分布から抽出された例ではパフォーマンスが低下することが多い。NERモデルの汎化能力を評価する方法の1つは、敵対的な例を使用することである。この敵対的な例では、名前付きエンティティに関連する特定の変化はほとんど考慮されない。このため、エキスパートによるヒューリスティックスを活用して、エンティティトークンとその周囲の文脈を変更し、敵対的攻撃としてエンティティタイプを変更することを提案する。エキスパートによるヒューリスティックスを使用して、CoNLL 2003テストセットを拡張し、手動で注釈を付けて高品質なチャレンジングセットを構築した。CoNLL 2003トレーニングデータでトレーニングされた最新のNERシステムは、私たちのチャレンジングセットでパフォーマンスが劇的に低下することがわかった。敵対的に拡張されたトレーニング例でトレーニングし、正則化のためにmixupを使用することで、チャレンジングセットでのパフォーマンスを大幅に改善し、OntoNotesデータを使用して評価したドメイン外の汎化能力も改善することができた。私たちは、https://github.com/GT-SALT/Guided-Adversarial-Augmentationでデータセットとコードを公開しています。"}
{"title": "Label Semantics for Few Shot Named Entity Recognition", "url": "https://aclanthology.org/2022.findings-acl.155/", "abstract": "We study the problem of few shot learning for named entity recognition. Specifically, we leverage the semantic information in the names of the labels as a way of giving the model additional signal and enriched priors. We propose a neural architecture that consists of two BERT encoders, one to encode the document and its tokens and another one to encode each of the labels in natural language format. Our model learns to match the representations of named entities computed by the first encoder with label representations computed by the second encoder. The label semantics signal is shown to support improved state-of-the-art results in multiple few shot NER benchmarks and on-par performance in standard benchmarks. Our model is especially effective in low resource settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Few Shot Named Entity Recognitionのためのラベルセマンティクス", "jabstract": "私たちは、固有表現認識のフューショット学習の問題を研究しています。具体的には、ラベルの名前に含まれる意味情報を、モデルに追加の信号と豊富な事前知識を与える方法として活用しています。私たちは、2つのBERTエンコーダーからなるニューラルアーキテクチャを提案しています。1つはドキュメントとそのトークンをエンコードし、もう1つは自然言語形式で各ラベルをエンコードします。私たちのモデルは、最初のエンコーダーによって計算された固有表現の表現を、2番目のエンコーダーによって計算されたラベルの表現と一致させることを学習します。ラベルの意味信号は、複数のフューショットNERベンチマークで改良された最新の結果をサポートし、標準ベンチマークでは同等のパフォーマンスを発揮することが示されています。私たちのモデルは、低リソース環境で特に効果的です。"}
{"title": "Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem", "url": "https://aclanthology.org/2022.findings-acl.156/", "abstract": "We propose an autoregressive entity linking model, that is trained with two auxiliary tasks, and learns to re-rank generated samples at inference time. Our proposed novelties address two weaknesses in the literature. First, a recent method proposes to learn mention detection and then entity candidate selection, but relies on predefined sets of candidates. We use encoder-decoder autoregressive entity linking in order to bypass this need, and propose to train mention detection as an auxiliary task instead. Second, previous work suggests that re-ranking could help correct prediction errors. We add a new, auxiliary task, match prediction, to learn re-ranking. Without the use of a knowledge base or candidate sets, our model sets a new state of the art in two benchmark datasets of entity linking: COMETA in the biomedical domain, and AIDA-CoNLL in the news domain. We show through ablation studies that each of the two auxiliary tasks increases performance, and that re-ranking is an important factor to the increase. Finally, our low-resource experimental results suggest that performance on the main task benefits from the knowledge learned by the auxiliary tasks, and not just from the additional training data.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "検出、曖昧性解消、再ランキング：自己回帰エンティティリンキングをマルチタスク問題として", "jabstract": "私たちは、2つの補助タスクでトレーニングされ、推論時に生成されたサンプルを再ランクすることを学習する自己回帰エンティティリンキングモデルを提案します。私たちの提案する新機能は、文献の2つの弱点に対処しています。第1に、最近の方法は、メンション検出を学習し、エンティティ候補の選択を行いますが、事前に定義された候補セットに依存します。私たちは、この必要性をバイパスするために、エンコーダー・デコーダー自己回帰エンティティリンキングを使用し、代わりに補助タスクとしてメンション検出をトレーニングすることを提案します。第2に、以前の研究では、再ランキングが予測エラーを修正するのに役立つと示唆されています。私たちは、再ランキングを学習するための新しい補助タスクであるマッチ予測を追加します。知識ベースや候補セットを使用せずに、私たちのモデルは、バイオメディカルドメインのCOMETAとニュースドメインのAIDA-CoNLLの2つのベンチマークデータセットで新しい最高水準を設定します。私たちは、削除研究を通じて、2つの補助タスクがパフォーマンスを向上させ、再ランキングがその増加の重要な要因であることを示します。最後に、私たちの低リソースの実験結果は、主要なタスクのパフォーマンスが、追加のトレーニングデータだけでなく、補助タスクで学習された知識からも利益を得ることを示唆しています。"}
{"title": "VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator", "url": "https://aclanthology.org/2022.findings-acl.157/", "abstract": "Interactive robots navigating photo-realistic environments need to be trained to effectively leverage and handle the dynamic nature of dialogue in addition to the challenges underlying vision-and-language navigation (VLN). In this paper, we present VISITRON, a multi-modal Transformer-based navigator better suited to the interactive regime inherent to Cooperative Vision-and-Dialog Navigation (CVDN). VISITRON is trained to: i) identify and associate object-level concepts and semantics between the environment and dialogue history, ii) identify when to interact vs. navigate via imitation learning of a binary classification head. We perform extensive pre-training and fine-tuning ablations with VISITRON to gain empirical insights and improve performance on CVDN. VISITRON’s ability to identify when to interact leads to a natural generalization of the game-play mode introduced by Roman et al. (2020) for enabling the use of such models in different environments. VISITRON is competitive with models on the static CVDN leaderboard and attains state-of-the-art performance on the Success weighted by Path Length (SPL) metric.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "VISITRON：視覚的意味に合わせてインタラクティブにトレーニングされたオブジェクトナビゲーター", "jabstract": "フォトリアルな環境をナビゲートするインタラクティブロボットは、ビジョン・アンド・ランゲージ・ナビゲーション（VLN）に潜む課題に加え、ダイナミックな対話の性質を効果的に活用し、処理するためにトレーニングする必要があります。本論文では、協調ビジョン・アンド・ダイアログ・ナビゲーション（CVDN）に固有のインタラクティブなレジメに適したマルチモーダルTransformerベースのナビゲータであるVISITRONを提案します。VISITRONは、i）環境と対話履歴のオブジェクトレベルの概念と意味を識別および関連付けること、ii）バイナリ分類ヘッドの模倣学習によるインタラクトするかナビゲートするかを識別することにトレーニングされています。VISITRONを用いた広範な事前トレーニングと微調整の実験により、経験的な洞察を得て、CVDNのパフォーマンスを改善しました。VISITRONのインタラクトするタイミングを識別する能力により、Romanら（2020）によって導入されたゲームプレイモードの自然な一般化が可能になり、このようなモデルを異なる環境で使用することができます。VISITRONは、静的CVDNリーダーボード上のモデルと競合し、パス長による成功重み付け指標（SPL）メトリックで最先端のパフォーマンスを達成しています。"}
{"title": "Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings", "url": "https://aclanthology.org/2022.findings-acl.158/", "abstract": "In order to equip NLP systems with ‘selective prediction’ capability, several task-specific approaches have been proposed. However, which approaches work best across tasks or even if they consistently outperform the simplest baseline MaxProb remains to be explored. To this end, we systematically study selective prediction in a large-scale setup of 17 datasets across several NLP tasks. Through comprehensive experiments under in-domain (IID), out-of-domain (OOD), and adversarial (ADV) settings, we show that despite leveraging additional resources (held-out data/computation), none of the existing approaches consistently and considerably outperforms MaxProb in all three settings. Furthermore, their performance does not translate well across tasks. For instance, Monte-Carlo Dropout outperforms all other approaches on Duplicate Detection datasets but does not fare well on NLI datasets, especially in the OOD setting. Thus, we recommend that future selective prediction approaches should be evaluated across tasks and settings for reliable estimation of their capabilities.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "IID、OOD、およびAdversarial Settingsにおける複数のタスクにわたる選択的予測アプローチの調査", "jabstract": "自然言語処理システムに「選択的予測」能力を備えさせるために、いくつかのタスク固有のアプローチが提案されている。しかし、これらのアプローチがどのタスクで最も効果的であるか、あるいは最も単純なベースラインであるMaxProbを常に上回るかどうかは、まだ探究されていない。このため、我々は17のデータセットを対象に、複数のNLPタスクにおける大規模なセットアップで選択的予測を系統的に研究した。IID、OOD、ADVの3つの設定下で包括的な実験を行い、追加のリソース（保持されたデータ/計算）を活用しても、既存のアプローチのいずれもが3つの設定すべてでMaxProbを一貫してかつ著しく上回ることはないことを示した。さらに、これらのアプローチの性能はタスク間でうまく転用されない。たとえば、モンテカルロドロップアウトは重複検出データセットで他のアプローチよりも優れているが、OOD設定下では特にNLIデータセットではうまくいかない。したがって、将来の選択的予測アプローチは、その能力を信頼できるように評価するために、タスクと設定を横断的に評価することを推奨する。"}
{"title": "Unsupervised Natural Language Inference Using PHL Triplet Generation", "url": "https://aclanthology.org/2022.findings-acl.159/", "abstract": "Transformer-based models achieve impressive performance on numerous Natural Language Inference (NLI) benchmarks when trained on respective training datasets. However, in certain cases, training samples may not be available or collecting them could be time-consuming and resource-intensive. In this work, we address the above challenge and present an explorative study on unsupervised NLI, a paradigm in which no human-annotated training samples are available. We investigate it under three settings: PH, P, and NPH that differ in the extent of unlabeled data available for learning. As a solution, we propose a procedural data generation approach that leverages a set of sentence transformations to collect PHL (Premise, Hypothesis, Label) triplets for training NLI models, bypassing the need for human-annotated training data. Comprehensive experiments with several NLI datasets show that the proposed approach results in accuracies of up to 66.75%, 65.9%, 65.39% in PH, P, and NPH settings respectively, outperforming all existing unsupervised baselines. Furthermore, fine-tuning our model with as little as ~0.1% of the human-annotated training dataset (500 instances) leads to 12.2% higher accuracy than the model trained from scratch on the same 500 instances. Supported by this superior performance, we conclude with a recommendation for collecting high-quality task-specific data.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「PHLトリプレット生成を用いた教師なし自然言語推論」に関する論文の要約文です。\n\n- Unsupervised Natural Language Inference Using PHL Triplet Generation\n教師なし自然言語推論において、PHLトリプレット生成を使用します。\n\n- This paper proposes a novel unsupervised method for natural language inference using PHL triplet generation.\n本論文では、PHLトリプレット生成を使用した新しい教師なし自然言語推論の手法を提案します。\n\n- The proposed method generates triplets of sentences that are related in meaning, and uses them to train a neural network for natural language inference.\n提案された手法は、意味的に関連する文のトリプレットを生成し、それらを使用して自然言語推論のためのニューラルネットワークをトレーニングします。\n\n- Experimental results show that the proposed method achieves competitive performance compared to state-of-the-art supervised methods, while requiring no labeled data.\n実験結果は、ラベル付きデータを必要とせず、最新の教師あり手法と競合する性能を発揮することを示しています。", "jabstract": "トランスフォーマーベースのモデルは、それぞれのトレーニングデータセットでトレーニングされた場合、多数の自然言語推論（NLI）ベンチマークで印象的なパフォーマンスを発揮します。しかし、特定の場合においては、トレーニングサンプルが利用できない場合や、それらを収集することが時間とリソースを消費する場合があります。本研究では、上記の課題に取り組み、人間による注釈付きトレーニングサンプルが利用できないパラダイムである非監視型NLIについての探索的研究を行います。我々は、学習に利用可能な未ラベルデータの範囲によって異なるPH、P、およびNPHの3つの設定で調査を行います。解決策として、文の変換のセットを活用してPHL（前提、仮説、ラベル）トリプレットを収集する手順的なデータ生成アプローチを提案し、人間による注釈付きトレーニングデータの必要性を回避します。複数のNLIデータセットでの包括的な実験により、提案手法は、PH、P、およびNPHの設定において、それぞれ最大66.75％、65.9％、65.39％の精度を示し、すべての既存の非監視型ベースラインを上回ります。さらに、人間によるトレーニングデータセット（500インスタンス）のわずか0.1％である場合でも、モデルをゼロからトレーニングした場合よりも12.2％高い精度を発揮することができることを示しました。この優れたパフォーマンスを支持することにより、高品質のタスク固有データの収集を推奨する結論を出します。"}
{"title": "Data Augmentation and Learned Layer Aggregation for Improved Multilingual Language Understanding in Dialogue", "url": "https://aclanthology.org/2022.findings-acl.160/", "abstract": "Scaling dialogue systems to a multitude of domains, tasks and languages relies on costly and time-consuming data annotation for different domain-task-language configurations. The annotation efforts might be substantially reduced by the methods that generalise well in zero- and few-shot scenarios, and also effectively leverage external unannotated data sources (e.g., Web-scale corpora). We propose two methods to this aim, offering improved dialogue natural language understanding (NLU) across multiple languages: 1) Multi-SentAugment, and 2) LayerAgg. Multi-SentAugment is a self-training method which augments available (typically few-shot) training data with similar (automatically labelled) in-domain sentences from large monolingual Web-scale corpora. LayerAgg learns to select and combine useful semantic information scattered across different layers of a Transformer model (e.g., mBERT); it is especially suited for zero-shot scenarios as semantically richer representations should strengthen the model’s cross-lingual capabilities. Applying the two methods with state-of-the-art NLU models obtains consistent improvements across two standard multilingual NLU datasets covering 16 diverse languages. The gains are observed in zero-shot, few-shot, and even in full-data scenarios. The results also suggest that the two methods achieve a synergistic effect: the best overall performance in few-shot setups is attained when the methods are used together.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "データ拡張と学習されたレイヤー集約による、対話における改善された多言語言語理解のための手法。", "jabstract": "多様なドメイン、タスク、言語に対応する対話システムのスケーリングには、異なるドメイン-タスク-言語構成のための高価で時間のかかるデータ注釈が必要です。注釈作業は、ゼロショットおよびフューショットシナリオで一般化する方法によって大幅に削減される可能性があり、また外部の未注釈データソース（例：Webスケールのコーパス）を効果的に活用することもできます。我々は、この目的のために2つの方法を提案し、複数の言語で改善された対話自然言語理解（NLU）を提供します：1）Multi-SentAugment、および2）LayerAgg。Multi-SentAugmentは、大規模な単一言語のWebスケールコーパスから自動的にラベル付けされた同様のドメイン内文を使用して、利用可能な（通常フューショット）トレーニングデータを拡張する自己トレーニング方法です。LayerAggは、Transformerモデル（例：mBERT）の異なるレイヤーに散在する有用な意味情報を選択して組み合わせることを学習します。ゼロショットシナリオに特に適しており、意味的に豊かな表現がモデルのクロスリンガル能力を強化するはずです。最新のNLUモデルを使用して2つの方法を適用すると、16の異なる言語をカバーする2つの標準的な多言語NLUデータセットで一貫した改善が得られます。改善は、ゼロショット、フューショット、およびフルデータシナリオで観察されます。結果は、2つの方法が相乗効果を発揮することを示唆しており、フューショットセットアップでの最良の全体的なパフォーマンスは、方法を一緒に使用した場合に達成されます。"}
{"title": "Ranking-Constrained Learning with Rationales for Text Classification", "url": "https://aclanthology.org/2022.findings-acl.161/", "abstract": "We propose a novel approach that jointly utilizes the labels and elicited rationales for text classification to speed up the training of deep learning models with limited training data. We define and optimize a ranking-constrained loss function that combines cross-entropy loss with ranking losses as rationale constraints. We evaluate our proposed rationale-augmented learning approach on three human-annotated datasets, and show that our approach provides significant improvements over classification approaches that do not utilize rationales as well as other state-of-the-art rationale-augmented baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "テキスト分類のための理由付き制約付きランキング学習", "jabstract": "私たちは、限られたトレーニングデータで深層学習モデルのトレーニングを加速するために、ラベルと引き出された根拠を共同利用する新しいアプローチを提案します。私たちは、クロスエントロピー損失とランキング損失を根拠制約として組み合わせたランキング制約損失関数を定義し、最適化します。私たちは、3つの人間による注釈付きデータセットで提案された根拠拡張学習アプローチを評価し、根拠を利用しない分類アプローチや他の最新の根拠拡張ベースラインよりも、私たちのアプローチが大幅な改善を提供することを示します。"}
{"title": "CaM-Gen: Causally Aware Metric-Guided Text Generation", "url": "https://aclanthology.org/2022.findings-acl.162/", "abstract": "Content is created for a well-defined purpose, often described by a metric or signal represented in the form of structured information. The relationship between the goal (metrics) of target content and the content itself is non-trivial. While large-scale language models show promising text generation capabilities, guiding the generated text with external metrics is challenging.These metrics and content tend to have inherent relationships and not all of them may be of consequence. We introduce CaM-Gen: Causally aware Generative Networks guided by user-defined target metrics incorporating the causal relationships between the metric and content features. We leverage causal inference techniques to identify causally significant aspects of a text that lead to the target metric and then explicitly guide generative models towards these by a feedback mechanism. We propose this mechanism for variational autoencoder and Transformer-based generative models. The proposed models beat baselines in terms of the target metric control while maintaining fluency and language quality of the generated text. To the best of our knowledge, this is one of the early attempts at controlled generation incorporating a metric guide using causal inference.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CaM-Gen：因果関係を認識したメトリックに基づくテキスト生成", "jabstract": "コンテンツは、構造化された情報の形で表されるメトリックまたはシグナルによってしばしば説明される、明確に定義された目的のために作成されます。ターゲットコンテンツの目標（メトリック）とコンテンツ自体の関係は、非自明です。大規模言語モデルは、有望なテキスト生成能力を示していますが、外部メトリックで生成されたテキストを誘導することは困難です。これらのメトリックとコンテンツには固有の関係があり、すべてが重要ではない場合があります。本論文では、ユーザー定義のターゲットメトリックによって誘導される因果関係を考慮したCaM-Gen：因果関係を考慮した生成ネットワークを紹介します。因果推論技術を活用して、ターゲットメトリックにつながる因果的に重要なテキストの側面を特定し、フィードバックメカニズムによって生成モデルを明示的にこれらに誘導します。提案されたメカニズムは、変分オートエンコーダーとTransformerベースの生成モデルに対して提案されています。提案されたモデルは、ターゲットメトリックの制御を維持しながら、生成されたテキストの流暢さと言語品質を維持する点でベースラインを上回っています。私たちの知る限り、これは因果推論を使用した制御された生成の初期の試みの1つです。"}
{"title": "Training Dynamics for Text Summarization Models", "url": "https://aclanthology.org/2022.findings-acl.163/", "abstract": "Pre-trained language models (e.g. BART) have shown impressive results when fine-tuned on large summarization datasets. However, little is understood about this fine-tuning process, including what knowledge is retained from pre-training time or how content selection and generation strategies are learnt across iterations. In this work, we analyze the training dynamics for generation models, focusing on summarization. Across different datasets (CNN/DM, XSum, MediaSum) and summary properties, such as abstractiveness and hallucination, we study what the model learns at different stages of its fine-tuning process. We find that a propensity to copy the input is learned early in the training process consistently across all datasets studied. On the other hand, factual errors, such as hallucination of unsupported facts, are learnt in the later stages, though this behavior is more varied across domains. Based on these observations, we explore complementary approaches for modifying training: first, disregarding high-loss tokens that are challenging to learn and second, disregarding low-loss tokens that are learnt very quickly in the latter stages of the training process. We show that these simple training modifications allow us to configure our model to achieve different goals, such as improving factuality or improving abstractiveness.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "テキスト要約モデルのトレーニングダイナミクス", "jabstract": "事前学習された言語モデル（例：BART）は、大規模な要約データセットで微調整された場合、印象的な結果を示しています。しかし、この微調整プロセスについては、事前学習時にどのような知識が保持されるか、また、どのようにコンテンツ選択と生成戦略が反復学習で学習されるかについては、ほとんど理解されていません。本研究では、要約に焦点を当てた生成モデルのトレーニングダイナミクスを分析します。CNN/DM、XSum、MediaSumなどの異なるデータセットや、抽象性や幻想などの要約特性にわたって、モデルが微調整プロセスの異なる段階で学習する内容を研究します。我々は、すべての研究対象のデータセットで、入力をコピーする傾向がトレーニングプロセスの早い段階で学習されることを発見しました。一方、幻想的なサポートされていない事実の幻想などの事実上の誤りは、後の段階で学習されますが、この行動はドメインによってより多様です。これらの観察に基づいて、トレーニングを変更する補完的なアプローチを探索します。第一に、学習が難しい高損失トークンを無視すること、第二に、トレーニングプロセスの後半で非常に速く学習される低損失トークンを無視することです。これらの単純なトレーニング変更により、モデルを異なる目標に達成するように構成できることを示します。例えば、事実性を向上させたり、抽象性を向上させたりすることができます。"}
{"title": "Richer Countries and Richer Representations", "url": "https://aclanthology.org/2022.findings-acl.164/", "abstract": "We examine whether some countries are more richly represented in embedding space than others. We find that countries whose names occur with low frequency in training corpora are more likely to be tokenized into subwords, are less semantically distinct in embedding space, and are less likely to be correctly predicted: e.g., Ghana (the correct answer and in-vocabulary) is not predicted for, “The country producing the most cocoa is [MASK].”. Although these performance discrepancies and representational harms are due to frequency, we find that frequency is highly correlated with a country’s GDP; thus perpetuating historic power and wealth inequalities. We analyze the effectiveness of mitigation strategies; recommend that researchers report training word frequencies; and recommend future work for the community to define and design representational guarantees.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "豊かな国々と豊かな表現\n\nNote: As an AI language model, I cannot provide the full context of the paper and the translation may not be accurate in some cases. Please use it for reference purposes only.", "jabstract": "私たちは、埋め込み空間において、ある国が他の国よりも豊富に表現されているかどうかを調べました。私たちは、トレーニングコーパスでの出現頻度が低い国は、サブワードにトークン化されやすく、埋め込み空間で意味的に区別されにくく、正しく予測されにくいことを発見しました。たとえば、「最も多くのココアを生産している国は[MASK]です。」という質問に対して、正解であり語彙内にあるガーナは予測されませんでした。これらの性能の差異と表現上の損害は、出現頻度に起因していますが、出現頻度は国のGDPと高い相関があるため、歴史的な権力と富の不平等を永続化しています。私たちは、緩和策の効果を分析し、研究者がトレーニング単語の頻度を報告することを推奨し、コミュニティが表現保証を定義および設計するための将来の研究を推奨します。"}
{"title": "BBQ: A hand-built bias benchmark for question answering", "url": "https://aclanthology.org/2022.findings-acl.165/", "abstract": "It is well documented that NLP models learn social biases, but little work has been done on how these biases manifest in model outputs for applied tasks like question answering (QA). We introduce the Bias Benchmark for QA (BBQ), a dataset of question-sets constructed by the authors that highlight attested social biases against people belonging to protected classes along nine social dimensions relevant for U.S. English-speaking contexts. Our task evaluate model responses at two levels: (i) given an under-informative context, we test how strongly responses reflect social biases, and (ii) given an adequately informative context, we test whether the model’s biases override a correct answer choice. We find that models often rely on stereotypes when the context is under-informative, meaning the model’s outputs consistently reproduce harmful biases in this setting. Though models are more accurate when the context provides an informative answer, they still rely on stereotypes and average up to 3.4 percentage points higher accuracy when the correct answer aligns with a social bias than when it conflicts, with this difference widening to over 5 points on examples targeting gender for most models tested.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "BBQ：質問応答の手作りバイアスベンチマーク", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nNLPモデルが社会的なバイアスを学習することはよく知られていますが、これらのバイアスが応用タスクである質問応答（QA）のモデル出力にどのように現れるかについてはほとんど研究が行われていません。筆者らが構築した、米国英語圏に関連する9つの社会的次元に沿った保護されたクラスに属する人々に対する社会的バイアスを強調する質問セットのデータセットである「Bias Benchmark for QA（BBQ）」を紹介します。我々のタスクは、（i）情報不足な文脈が与えられた場合、モデルの応答がどの程度社会的バイアスを反映するかをテストし、（ii）十分な情報が与えられた文脈が与えられた場合、モデルのバイアスが正しい回答選択肢を上書きするかどうかをテストします。我々は、文脈が情報不足な場合、モデルがステレオタイプに頼ることが多いことを発見しました。つまり、この設定ではモデルの出力が一貫して有害なバイアスを再現しています。文脈が情報を提供する場合、モデルはより正確になりますが、ステレオタイプに頼ることがあり、正しい回答が社会的バイアスに一致する場合、平均して3.4パーセントポイント高い精度を示し、矛盾する場合よりも高い精度を示します。これに対して、ジェンダーを対象とした例では、ほとんどのテストされたモデルにおいて、この差は5ポイント以上に広がります。"}
{"title": "Zero-shot Learning for Grapheme to Phoneme Conversion with Language Ensemble", "url": "https://aclanthology.org/2022.findings-acl.166/", "abstract": "Grapheme-to-Phoneme (G2P) has many applications in NLP and speech fields. Most existing work focuses heavily on languages with abundant training datasets, which limits the scope of target languages to less than 100 languages. This work attempts to apply zero-shot learning to approximate G2P models for all low-resource and endangered languages in Glottolog (about 8k languages). For any unseen target language, we first build the phylogenetic tree (i.e. language family tree) to identify top-k nearest languages for which we have training sets. Then we run models of those languages to obtain a hypothesis set, which we combine into a confusion network to propose a most likely hypothesis as an approximation to the target language. We test our approach on over 600 unseen languages and demonstrate it significantly outperforms baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「言語アンサンブルを用いたグラフェムから音素へのゼロショット学習」", "jabstract": "Grapheme-to-Phoneme（G2P）は、NLPおよび音声分野で多くの応用があります。既存の多くの研究は、豊富なトレーニングデータセットを持つ言語に重点を置いており、対象言語の範囲が100言語未満に制限されています。この研究では、Glottologのすべての低資源および絶滅危惧種の言語（約8,000言語）に対して、ゼロショット学習を適用してG2Pモデルを近似することを試みています。未知の対象言語に対して、まず系統樹（つまり言語系統樹）を構築して、トレーニングセットを持つ上位kの最も近い言語を特定します。その後、それらの言語のモデルを実行して仮説セットを取得し、混乱ネットワークに組み合わせて、対象言語の近似として最も可能性の高い仮説を提案します。私たちは600以上の未知の言語でアプローチをテストし、ベースラインを大幅に上回ることを示しています。"}
{"title": "Dim Wihl Gat Tun: The Case for Linguistic Expertise in NLP for Under-Documented Languages", "url": "https://aclanthology.org/2022.findings-acl.167/", "abstract": "Recent progress in NLP is driven by pretrained models leveraging massive datasets and has predominantly benefited the world’s political and economic superpowers. Technologically underserved languages are left behind because they lack such resources. Hundreds of underserved languages, nevertheless, have available data sources in the form of interlinear glossed text (IGT) from language documentation efforts. IGT remains underutilized in NLP work, perhaps because its annotations are only semi-structured and often language-specific. With this paper, we make the case that IGT data can be leveraged successfully provided that target language expertise is available. We specifically advocate for collaboration with documentary linguists. Our paper provides a roadmap for successful projects utilizing IGT data: (1) It is essential to define which NLP tasks can be accomplished with the given IGT data and how these will benefit the speech community. (2) Great care and target language expertise is required when converting the data into structured formats commonly employed in NLP. (3) Task-specific and user-specific evaluation can help to ascertain that the tools which are created benefit the target language speech community. We illustrate each step through a case study on developing a morphological reinflection system for the Tsimchianic language Gitksan.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Dim Wihl Gat Tun：未文書化言語における自然言語処理における言語専門知識の必要性", "jabstract": "自然言語処理における最近の進歩は、巨大なデータセットを活用する事前学習モデルによって推進され、主に世界の政治的・経済的な超大国に恩恵をもたらしています。技術的に未開発な言語は、そのようなリソースがないため取り残されています。しかし、数百もの未開発言語は、言語文書化の取り組みからインターリニア形式の注釈付きテキスト（IGT）のデータソースを利用できます。IGTは、その注釈が半構造化であり、しばしば言語固有であるため、NLPの作業で十分に活用されていません。本論文では、対象言語の専門知識がある場合にIGTデータを成功裏に活用できることを主張します。特に、文書化言語学者との協力を提唱しています。本論文では、IGTデータを利用した成功したプロジェクトのロードマップを提供します。(1)与えられたIGTデータで達成できるNLPタスクと、これらがスピーチコミュニティにどのように役立つかを定義することが不可欠です。(2) NLPで一般的に使用される構造化形式にデータを変換する際には、十分な注意と対象言語の専門知識が必要です。(3)タスク固有およびユーザー固有の評価により、作成されたツールが対象言語スピーチコミュニティに利益をもたらすことが確認できます。本論文では、Tsimchianic言語Gitksanの形態論的再屈折システムを開発する事例研究を通じて、各ステップを説明します。"}
{"title": "Question Generation for Reading Comprehension Assessment by Modeling How and What to Ask", "url": "https://aclanthology.org/2022.findings-acl.168/", "abstract": "Reading is integral to everyday life, and yet learning to read is a struggle for many young learners. During lessons, teachers can use comprehension questions to increase engagement, test reading skills, and improve retention. Historically such questions were written by skilled teachers, but recently language models have been used to generate comprehension questions. However, many existing Question Generation (QG) systems focus on generating extractive questions from the text, and have no way to control the type of the generated question. In this paper, we study QG for reading comprehension where inferential questions are critical and extractive techniques cannot be used. We propose a two-step model (HTA-WTA) that takes advantage of previous datasets, and can generate questions for a specific targeted comprehension skill. We propose a new reading comprehension dataset that contains questions annotated with story-based reading comprehension skills (SBRCS), allowing for a more complete reader assessment. Across several experiments, our results show that HTA-WTA outperforms multiple strong baselines on this new dataset. We show that the HTA-WTA model tests for strong SCRS by asking deep inferential questions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「読解評価のための質問生成：何を、どのように尋ねるかをモデル化することによる」", "jabstract": "読書は日常生活に不可欠であり、しかし読み方を学ぶことは多くの若い学習者にとって苦労です。授業中、教師は理解力問題を使用して、関与度を高め、読み方のスキルをテストし、保持力を向上させることができます。歴史的に、このような問題は熟練した教師によって書かれていましたが、最近では言語モデルが理解力問題を生成するために使用されています。しかし、多くの既存の問題生成（QG）システムは、テキストから抽出的な問題を生成することに焦点を当てており、生成される問題のタイプを制御する方法がありません。本論文では、推論的な問題が重要であり、抽出的な技術が使用できない読解のためのQGを研究します。我々は、以前のデータセットを活用し、特定のターゲット読解スキルのための問題を生成することができる2段階モデル（HTA-WTA）を提案します。我々は、物語ベースの読解スキル（SBRCS）で注釈付けされた問題を含む新しい読解データセットを提案し、より完全な読者評価を可能にします。複数の実験を通じて、我々の結果は、HTA-WTAがこの新しいデータセットで複数の強力なベースラインを上回ることを示しています。我々は、HTA-WTAモデルが深い推論的な問題を尋ねることによって強力なSCRSをテストすることを示しています。"}
{"title": "TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval", "url": "https://aclanthology.org/2022.findings-acl.169/", "abstract": "Entity retrieval—retrieving information about entity mentions in a query—is a key step in open-domain tasks, such as question answering or fact checking. However, state-of-the-art entity retrievers struggle to retrieve rare entities for ambiguous mentions due to biases towards popular entities. Incorporating knowledge graph types during training could help overcome popularity biases, but there are several challenges: (1) existing type-based retrieval methods require mention boundaries as input, but open-domain tasks run on unstructured text, (2) type-based methods should not compromise overall performance, and (3) type-based methods should be robust to noisy and missing types. In this work, we introduce TABi, a method to jointly train bi-encoders on knowledge graph types and unstructured text for entity retrieval for open-domain tasks. TABi leverages a type-enforced contrastive loss to encourage entities and queries of similar types to be close in the embedding space. TABi improves retrieval of rare entities on the Ambiguous Entity Retrieval (AmbER) sets, while maintaining strong overall retrieval performance on open-domain tasks in the KILT benchmark compared to state-of-the-art retrievers. TABi is also robust to incomplete type systems, improving rare entity retrieval over baselines with only 5% type coverage of the training dataset. We make our code publicly available.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "TABi：オープンドメインエンティティ検索のためのタイプ意識バイエンコーダー", "jabstract": "エンティティ検索は、質問応答や事実確認などのオープンドメインタスクにおいて、クエリ内のエンティティメンションに関する情報を取得するための重要なステップである。しかし、最新のエンティティ検索器は、人気のあるエンティティに偏りがあるため、曖昧なメンションの稀なエンティティを取得するのに苦労している。トレーニング中に知識グラフタイプを組み込むことで、人気の偏りを克服することができるが、いくつかの課題がある。 (1)既存のタイプベースの検索方法は、メンションの境界を入力として必要とするが、オープンドメインタスクは構造化されていないテキスト上で実行される。(2)タイプベースの方法は、全体的なパフォーマンスを損なうべきではない。(3)タイプベースの方法は、ノイズや欠落したタイプに対して堅牢である必要がある。本研究では、オープンドメインタスクのエンティティ検索のために、知識グラフタイプと構造化されていないテキストの両方をバイエンコーダで共同トレーニングするTABiという方法を紹介する。TABiは、タイプに基づくコントラスティブ損失を利用して、類似したタイプのエンティティとクエリが埋め込み空間で近くなるように促す。TABiは、Ambiguous Entity Retrieval（AmbER）セットで稀なエンティティの検索を改善し、KILTベンチマークのオープンドメインタスクにおいて、最新の検索器と比較して強力な全体的な検索パフォーマンスを維持する。TABiは、トレーニングデータセットのタイプカバレッジがわずか5％のベースラインよりも、不完全なタイプシステムに対しても堅牢であり、コードを公開している。"}
{"title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG", "url": "https://aclanthology.org/2022.findings-acl.170/", "abstract": "Large pretrained models enable transfer learning to low-resource domains for language generation tasks. However, previous end-to-end approaches do not account for the fact that some generation sub-tasks, specifically aggregation and lexicalisation, can benefit from transfer learning in different extents. To exploit these varying potentials for transfer learning, we propose a new hierarchical approach for few-shot and zero-shot generation. Our approach consists of a three-moduled jointly trained architecture: the first module independently lexicalises the distinct units of information in the input as sentence sub-units (e.g. phrases), the second module recurrently aggregates these sub-units to generate a unified intermediate output, while the third module subsequently post-edits it to generate a coherent and fluent final text. We perform extensive empirical analysis and ablation studies on few-shot and zero-shot settings across 4 datasets. Automatic and human evaluation shows that the proposed hierarchical approach is consistently capable of achieving state-of-the-art results when compared to previous work.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nFew-Shot NLGのための階層的再帰的集約生成", "jabstract": "大規模な事前学習済みモデルは、言語生成タスクの低リソースドメインへの転移学習を可能にします。しかし、以前のエンドツーエンドアプローチは、集約や語彙化などの一部の生成サブタスクが、異なる程度で転移学習の恩恵を受けることを考慮していませんでした。これらの転移学習の潜在能力を活用するために、我々はfew-shotおよびzero-shot生成のための新しい階層的アプローチを提案します。我々のアプローチは、3つのモジュールで構成される共同学習アーキテクチャであり、第1のモジュールは入力の異なる情報ユニットを文のサブユニット（例：フレーズ）として独立して語彙化し、第2のモジュールはこれらのサブユニットを再帰的に集約して統一された中間出力を生成し、第3のモジュールはそれを後編集して一貫性のある流暢な最終テキストを生成します。我々は、4つのデータセットでfew-shotおよびzero-shot設定での広範な実証分析と削除研究を行いました。自動評価と人間の評価により、提案された階層的アプローチは、以前の研究と比較して常に最先端の結果を達成することができることが示されました。"}
{"title": "Training Text-to-Text Transformers with Privacy Guarantees", "url": "https://aclanthology.org/2022.findings-acl.171/", "abstract": "Recent advances in NLP often stem from large transformer-based pre-trained models, which rapidly grow in size and use more and more training data. Such models are often released to the public so that end users can fine-tune them on a task dataset. While it is common to treat pre-training data as public, it may still contain personally identifiable information (PII), such as names, phone numbers, and copyrighted material. Recent findings show that the capacity of these models allows them to memorize parts of the training data, and suggest differentially private (DP) training as a potential mitigation. While there is recent work on DP fine-tuning of NLP models, the effects of DP pre-training are less well understood: it is not clear how downstream performance is affected by DP pre-training, and whether DP pre-training mitigates some of the memorization concerns. We focus on T5 and show that by using recent advances in JAX and XLA we can train models with DP that do not suffer a large drop in pre-training utility, nor in training speed, and can still be fine-tuned to high accuracies on downstream tasks (e.g. GLUE). Moreover, we show that T5’s span corruption is a good defense against data memorization.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "プライバシー保証を備えたテキスト対テキストトランスフォーマーのトレーニング", "jabstract": "自然言語処理における最近の進歩は、大規模なトランスフォーマーベースの事前学習モデルからしばしば生じ、これらは急速にサイズが拡大し、より多くのトレーニングデータを使用します。このようなモデルは、エンドユーザーがタスクデータセットで微調整できるように一般に公開されます。事前学習データを公開することは一般的ですが、名前、電話番号、著作権物などの個人を特定できる情報（PII）が含まれている場合があります。最近の研究結果は、これらのモデルの容量がトレーニングデータの一部を記憶することを可能にすることを示し、異なるプライバシー（DP）トレーニングを潜在的な緩和策として示唆しています。NLPモデルのDP微調整に関する最近の研究がある一方で、DP事前学習の影響はあまり理解されていません。DP事前学習が下流のパフォーマンスにどのように影響するか、またDP事前学習が記憶の懸念を緩和するかどうかは明確ではありません。私たちはT5に焦点を当て、JAXとXLAの最近の進歩を使用して、DPを使用したモデルをトレーニングできることを示しました。これらのモデルは、事前学習の有用性やトレーニング速度に大きな低下がなく、下流のタスク（例：GLUE）で高い精度に微調整できます。さらに、T5のスパン破損は、データの記憶に対する良い防御策であることを示しました。"}
{"title": "Revisiting Uncertainty-based Query Strategies for Active Learning with Transformers", "url": "https://aclanthology.org/2022.findings-acl.172/", "abstract": "Active learning is the iterative construction of a classification model through targeted labeling, enabling significant labeling cost savings. As most research on active learning has been carried out before transformer-based language models (“transformers”) became popular, despite its practical importance, comparably few papers have investigated how transformers can be combined with active learning to date. This can be attributed to the fact that using state-of-the-art query strategies for transformers induces a prohibitive runtime overhead, which effectively nullifies, or even outweighs the desired cost savings. For this reason, we revisit uncertainty-based query strategies, which had been largely outperformed before, but are particularly suited in the context of fine-tuning transformers. In an extensive evaluation, we connect transformers to experiments from previous research, assessing their performance on five widely used text classification benchmarks. For active learning with transformers, several other uncertainty-based approaches outperform the well-known prediction entropy query strategy, thereby challenging its status as most popular uncertainty baseline in active learning for text classification.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「トランスフォーマーを用いたアクティブラーニングにおける不確実性ベースのクエリ戦略の再検討」という論文の要約文です。以下、日本語に翻訳してください。\n\n- Revisiting: 再検討すること\n- Uncertainty-based: 不確実性に基づく\n- Query strategies: クエリ戦略\n- Active learning: アクティブラーニング\n\n「トランスフォーマーを用いたアクティブラーニングにおける不確実性ベースのクエリ戦略の再検討」は、アクティブラーニングにおいて、不確実性に基づくクエリ戦略をトランスフォーマーを用いて再検討することを目的とした論文です。", "jabstract": "アクティブラーニングは、ターゲットラベリングを通じて分類モデルを反復的に構築し、ラベリングコストを大幅に削減することができます。アクティブラーニングに関するほとんどの研究は、トランスフォーマーベースの言語モデル（「トランスフォーマー」）が一般的になる前に行われたため、実用的な重要性にもかかわらず、トランスフォーマーをアクティブラーニングにどのように組み合わせるかを調査した論文は比較的少数です。これは、トランスフォーマーの最新のクエリ戦略を使用することが、禁止されたランタイムオーバーヘッドを引き起こすためであり、望ましいコスト削減を無効化するか、さらに重くすることができるためです。そのため、我々は、以前は大幅に性能が低下していた不確実性に基づくクエリ戦略を再検討し、トランスフォーマーのファインチューニングの文脈で特に適していることを示します。広範な評価により、トランスフォーマーを以前の研究の実験に接続し、5つの広く使用されているテキスト分類ベンチマークでのパフォーマンスを評価します。トランスフォーマーを使用したアクティブラーニングでは、他のいくつかの不確実性に基づくアプローチが、よく知られた予測エントロピークエリ戦略よりも優れており、テキスト分類のアクティブラーニングにおける最も人気のある不確実性ベースラインの地位に挑戦しています。"}
{"title": "The impact of lexical and grammatical processing on generating code from natural language", "url": "https://aclanthology.org/2022.findings-acl.173/", "abstract": "Considering the seq2seq architecture of Yin and Neubig (2018) for natural language to code translation, we identify four key components of importance: grammatical constraints, lexical preprocessing, input representations, and copy mechanisms. To study the impact of these components, we use a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided. The paper highlights the importance of the lexical substitution component in the current natural language to code systems.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理における語彙および文法処理がコード生成に与える影響についての論文の要旨です。", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自然言語からコードへの翻訳のためのYinとNeubig（2018）のseq2seqアーキテクチャを考慮すると、文法的制約、語彙前処理、入力表現、およびコピー機構の4つの重要な要素を特定します。これらの要素の影響を研究するために、BERTエンコーダーと文法ベースのデコーダーに依存する最新のアーキテクチャを使用し、その形式化が提供されます。本論文は、現在の自然言語からコードへのシステムにおける語彙置換コンポーネントの重要性を強調しています。"}
{"title": "Seq2Path: Generating Sentiment Tuples as Paths of a Tree", "url": "https://aclanthology.org/2022.findings-acl.174/", "abstract": "Aspect-based sentiment analysis (ABSA) tasks aim to extract sentiment tuples from a sentence. Recent generative methods such as Seq2Seq models have achieved good performance by formulating the output as a sequence of sentiment tuples. However, the orders between the sentiment tuples do not naturally exist and the generation of the current tuple should not condition on the previous ones. In this paper, we propose Seq2Path to generate sentiment tuples as paths of a tree. A tree can represent “1-to-n” relations (e.g., an aspect term may correspond to multiple opinion terms) and the paths of a tree are independent and do not have orders. For training, we treat each path as an independent target, and we calculate the average loss of the ordinary Seq2Seq model over paths. For inference, we apply beam search with constrained decoding. By introducing an additional discriminative token and applying a data augmentation technique, valid paths can be automatically selected. We conduct experiments on five tasks including AOPE, ASTE, TASD, UABSA, ACOS. We evaluate our method on four common benchmark datasets including Laptop14, Rest14, Rest15, Rest16. Our proposed method achieves state-of-the-art results in almost all cases.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Seq2Path：感情タプルを木のパスとして生成する", "jabstract": "アスペクトベースの感情分析（ABSA）タスクは、文から感情のタプルを抽出することを目的としています。Seq2Seqモデルなどの最近の生成的手法は、出力を感情のタプルのシーケンスとして定式化することにより、良好な性能を発揮しています。しかし、感情のタプル間の順序は自然に存在せず、現在のタプルの生成は前のタプルに依存すべきではありません。本論文では、感情のタプルを木のパスとして生成するSeq2Pathを提案します。木は「1対n」の関係を表すことができます（例えば、アスペクト用語は複数の意見用語に対応する場合があります）、そして木のパスは独立して順序を持ちません。トレーニングでは、各パスを独立したターゲットとして扱い、通常のSeq2Seqモデルの平均損失をパスごとに計算します。推論では、制約付きデコーディングを行うビームサーチを適用します。追加の識別トークンを導入し、データ拡張技術を適用することで、有効なパスを自動的に選択することができます。AOPE、ASTE、TASD、UABSA、ACOSを含む5つのタスクで実験を行いました。Laptop14、Rest14、Rest15、Rest16を含む4つの一般的なベンチマークデータセットで、提案手法を評価しました。提案手法は、ほとんどの場合で最先端の結果を達成しました。"}
{"title": "Mitigating the Inconsistency Between Word Saliency and Model Confidence with Pathological Contrastive Training", "url": "https://aclanthology.org/2022.findings-acl.175/", "abstract": "Neural networks are widely used in various NLP tasks for their remarkable performance. However, the complexity makes them difficult to interpret, i.e., they are not guaranteed right for the right reason. Besides the complexity, we reveal that the model pathology - the inconsistency between word saliency and model confidence, further hurts the interpretability. We show that the pathological inconsistency is caused by the representation collapse issue, which means that the representation of the sentences with tokens in different saliency reduced is somehow collapsed, and thus the important words cannot be distinguished from unimportant words in terms of model confidence changing. In this paper, to mitigate the pathology and obtain more interpretable models, we propose Pathological Contrastive Training (PCT) framework, which adopts contrastive learning and saliency-based samples augmentation to calibrate the sentences representation. Combined with qualitative analysis, we also conduct extensive quantitative experiments and measure the interpretability with eight reasonable metrics. Experiments show that our method can mitigate the model pathology and generate more interpretable models while keeping the model performance. Ablation study also shows the effectiveness.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「病的対比トレーニングによる単語の顕著性とモデルの信頼性の不一致の緩和」に関する論文の要約です。」", "jabstract": "ニューラルネットワークは、その驚異的な性能のため、様々なNLPタスクで広く使用されています。しかし、その複雑さから、解釈が困難であり、つまり、正しい理由で正しいと保証されていない。複雑さに加えて、単語の重要性とモデルの信頼性の間の不一致であるモデル病理学を明らかにし、解釈性をさらに損なっていることを明らかにします。我々は、病理学的な不一致が、異なる重要度を持つトークンを含む文の表現崩壊の問題によって引き起こされることを示し、重要な単語がモデル信頼性の変化に関して重要でない単語と区別できないため、病理学的な不一致が生じることを示します。本論文では、この病理学的な問題を緩和し、より解釈可能なモデルを生成するために、コントラスティブ学習と重要度に基づくサンプル拡張を採用した病理学的コントラスティブトレーニング（PCT）フレームワークを提案します。定性的分析と組み合わせて、我々は8つの合理的なメトリックで解釈性を測定する広範な定量的実験を行いました。実験結果は、我々の方法がモデル病理学を緩和し、モデルの性能を維持しながらより解釈可能なモデルを生成できることを示しています。削除研究も有効性を示しています。"}
{"title": "Your fairness may vary: Pretrained language model fairness in toxic text classification", "url": "https://aclanthology.org/2022.findings-acl.176/", "abstract": "The popularity of pretrained language models in natural language processing systems calls for a careful evaluation of such models in down-stream tasks, which have a higher potential for societal impact. The evaluation of such systems usually focuses on accuracy measures. Our findings in this paper call for attention to be paid to fairness measures as well. Through the analysis of more than a dozen pretrained language models of varying sizes on two toxic text classification tasks (English), we demonstrate that focusing on accuracy measures alone can lead to models with wide variation in fairness characteristics. Specifically, we observe that fairness can vary even more than accuracy with increasing training data size and different random initializations. At the same time, we find that little of the fairness variation is explained by model size, despite claims in the literature. To improve model fairness without retraining, we show that two post-processing methods developed for structured, tabular data can be successfully applied to a range of pretrained language models. Warning: This paper contains samples of offensive text.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "あなたの公正さは異なる場合があります：毒性テキスト分類における事前学習言語モデルの公正さ", "jabstract": "自然言語処理システムにおける事前学習言語モデルの人気は、社会的影響の可能性が高いダウンストリームタスクにおいて、このようなモデルの慎重な評価を求めています。このようなシステムの評価は通常、精度指標に焦点を当てています。本論文の結果は、公平性指標にも注意を払う必要があることを示唆しています。英語の2つの有害テキスト分類タスクにおけるさまざまなサイズの12以上の事前学習言語モデルの分析を通じて、精度指標に焦点を当てることが公平性特性に幅広い変動をもたらす可能性があることを示します。具体的には、トレーニングデータサイズの増加や異なるランダム初期化により、公平性が精度よりもさらに変動することを観察します。同時に、文献にある主張にもかかわらず、モデルサイズによって説明される公平性の変動はほとんどないことがわかります。再トレーニングせずにモデルの公平性を改善するために、構造化された表形式データ用に開発された2つの後処理方法が、さまざまな事前学習言語モデルに適用できることを示します。警告：本論文には攻撃的なテキストのサンプルが含まれています。"}
{"title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning", "url": "https://aclanthology.org/2022.findings-acl.177/", "abstract": "Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic operations. They also commonly refer to visual features of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their questions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and logical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a unified way to answer questions. While our models achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ChartQA：視覚的および論理的推論を伴うグラフに関する質問応答のためのベンチマーク", "jabstract": "チャートはデータ分析において非常に人気があります。チャートを探索する際、人々はしばしば複数の論理的および算術的操作を含む複雑な推論的な質問をします。彼らはまた、質問に視覚的な特徴を頻繁に参照します。しかし、既存のデータセットのほとんどは、質問がテンプレートベースであり、回答が固定ボキャブラリから来るため、このような複雑な推論的な質問に焦点を当てていません。本研究では、人間が書いた9.6Kの質問と、人間が書いたチャートの要約から生成された23.1Kの質問をカバーする大規模なベンチマークを提供します。チャートに関する視覚的および論理的推論に関するユニークな課題に対処するために、我々は、チャートのデータテーブルと視覚的特徴を統合的に扱う2つのトランスフォーマーベースのモデルを提供します。我々のモデルは、以前のデータセットだけでなく、我々のベンチマークでも最先端の結果を達成していますが、評価は複雑な推論的な質問に答えるためのいくつかの課題を明らかにしています。"}
{"title": "A Novel Perspective to Look At Attention: Bi-level Attention-based Explainable Topic Modeling for News Classification", "url": "https://aclanthology.org/2022.findings-acl.178/", "abstract": "Many recent deep learning-based solutions have adopted the attention mechanism in various tasks in the field of NLP. However, the inherent characteristics of deep learning models and the flexibility of the attention mechanism increase the models’ complexity, thus leading to challenges in model explainability. To address this challenge, we propose a novel practical framework by utilizing a two-tier attention architecture to decouple the complexity of explanation and the decision-making process. We apply it in the context of a news article classification task. The experiments on two large-scaled news corpora demonstrate that the proposed model can achieve competitive performance with many state-of-the-art alternatives and illustrate its appropriateness from an explainability perspective. We release the source code here.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n注目するための新しい視点：ニュース分類のためのバイレベルアテンションベースの説明可能なトピックモデリング", "jabstract": "最近の深層学習ベースの解決策は、NLP分野のさまざまなタスクでアテンションメカニズムを採用しています。しかし、深層学習モデルの固有の特性とアテンションメカニズムの柔軟性により、モデルの複雑さが増し、モデルの説明可能性に課題が生じます。この課題に対処するために、私たちは2層のアテンションアーキテクチャを利用して、説明の複雑さと意思決定プロセスを分離する新しい実用的なフレームワークを提案します。私たちは、ニュース記事分類タスクの文脈でそれを適用します。2つの大規模なニュースコーパスでの実験は、提案されたモデルが多くの最新の代替手段と競争力のあるパフォーマンスを発揮し、説明可能性の観点からの適切さを示しています。私たちはここでソースコードを公開します。"}
{"title": "Learn and Review: Enhancing Continual Named Entity Recognition via Reviewing Synthetic Samples", "url": "https://aclanthology.org/2022.findings-acl.179/", "abstract": "Traditional methods for named entity recognition (NER) classify mentions into a fixed set of pre-defined entity types. However, in many real-world scenarios, new entity types are incrementally involved. To investigate this problem, continual learning is introduced for NER. However, the existing method depends on the relevance between tasks and is prone to inter-type confusion.In this paper, we propose a novel two-stage framework Learn-and-Review (L&R) for continual NER under the type-incremental setting to alleviate the above issues.Specifically, for the learning stage, we distill the old knowledge from teacher to a student on the current dataset. For the reviewing stage, we first generate synthetic samples of old types to augment the dataset. Then, we further distill new knowledge from the above student and old knowledge from the teacher to get an enhanced student on the augmented dataset. This stage has the following advantages: (1) The synthetic samples mitigate the gap between the old and new task and thus enhance the further distillation; (2) Different types of entities are jointly seen during training which alleviates the inter-type confusion. Experimental results show that L&R outperforms the state-of-the-art method on CoNLL-03 and OntoNotes-5.0.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "学習とレビュー：合成サンプルのレビューによる継続的な固有表現認識の強化", "jabstract": "従来の固有表現認識（NER）の方法は、言及を事前定義された固定のエンティティタイプのセットに分類します。しかし、多くの現実世界のシナリオでは、新しいエンティティタイプが段階的に関与しています。この問題を調査するために、NERのための継続的学習が導入されています。しかし、既存の方法はタスク間の関連性に依存しており、タイプ間の混乱に陥りやすいです。本論文では、上記の問題を緩和するために、タイプ増分設定下での継続的NERのための新しい2段階フレームワークLearn-and-Review（L＆R）を提案します。具体的には、学習段階では、現在のデータセット上の教師から生徒に古い知識を蒸留します。レビューステージでは、古いタイプの合成サンプルを生成してデータセットを拡張します。その後、上記の生徒から新しい知識と教師から古い知識をさらに蒸留して、拡張されたデータセット上の強化された生徒を得ます。この段階には以下の利点があります：（1）合成サンプルは古いタスクと新しいタスクのギャップを緩和し、さらなる蒸留を強化します。 （2）トレーニング中に異なるタイプのエンティティが共同で見られるため、タイプ間の混乱が緩和されます。実験結果は、L＆RがCoNLL-03およびOntoNotes-5.0で最先端の方法を上回ることを示しています。"}
{"title": "Phoneme transcription of endangered languages: an evaluation of recent ASR architectures in the single speaker scenario", "url": "https://aclanthology.org/2022.findings-acl.180/", "abstract": "Transcription is often reported as the bottleneck in endangered language documentation, requiring large efforts from scarce speakers and transcribers. In general, automatic speech recognition (ASR) can be accurate enough to accelerate transcription only if trained on large amounts of transcribed data. However, when a single speaker is involved, several studies have reported encouraging results for phonetic transcription even with small amounts of training. Here we expand this body of work on speaker-dependent transcription by comparing four ASR approaches, notably recent transformer and pretrained multilingual models, on a common dataset of 11 languages. To automate data preparation, training and evaluation steps, we also developed a phoneme recognition setup which handles morphologically complex languages and writing systems for which no pronunciation dictionary exists.We find that fine-tuning a multilingual pretrained model yields an average phoneme error rate (PER) of 15% for 6 languages with 99 minutes or less of transcribed data for training. For the 5 languages with between 100 and 192 minutes of training, we achieved a PER of 8.4% or less. These results on a number of varied languages suggest that ASR can now significantly reduce transcription efforts in the speaker-dependent situation common in endangered language work.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "絶滅危惧言語の音素転写：単一話者シナリオにおける最近のASRアーキテクチャの評価", "jabstract": "絶滅危惧言語の文書化において、転写はしばしばボトルネックとして報告され、希少な話者や転写者から大きな努力を必要とします。一般的に、自動音声認識（ASR）は、大量の転写済みデータでトレーニングされた場合にのみ、転写を加速するために十分に正確であることができます。しかし、単一の話者が関与する場合、いくつかの研究では、少量のトレーニングでも音素転写において励みとなる結果が報告されています。本研究では、11の言語の共通データセットで、最近のトランスフォーマーや事前学習済みの多言語モデルなど、4つのASRアプローチを比較することで、話者依存の転写に関するこれまでの研究を拡張します。また、形態的に複雑な言語や発音辞書が存在しない書記システムを扱う音素認識セットアップを開発し、データの準備、トレーニング、評価のステップを自動化しました。多言語事前学習済みモデルを微調整することで、トレーニングに99分以下の転写済みデータが必要な6つの言語について、平均音素エラー率（PER）が15％になることがわかりました。トレーニング時間が100〜192分の5つの言語については、PERが8.4％以下になりました。これらの多様な言語に関する結果から、ASRは、絶滅危惧言語の文書化において一般的な話者依存の状況で転写の努力を大幅に減らすことができることが示唆されています。"}
{"title": "Does BERT really agree ? Fine-grained Analysis of Lexical Dependence on a Syntactic Task", "url": "https://aclanthology.org/2022.findings-acl.181/", "abstract": "Although transformer-based Neural Language Models demonstrate impressive performance on a variety of tasks, their generalization abilities are not well understood. They have been shown to perform strongly on subject-verb number agreement in a wide array of settings, suggesting that they learned to track syntactic dependencies during their training even without explicit supervision. In this paper, we examine the extent to which BERT is able to perform lexically-independent subject-verb number agreement (NA) on targeted syntactic templates. To do so, we disrupt the lexical patterns found in naturally occurring stimuli for each targeted structure in a novel fine-grained analysis of BERT’s behavior. Our results on nonce sentences suggest that the model generalizes well for simple templates, but fails to perform lexically-independent syntactic generalization when as little as one attractor is present.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "BERTは本当に同意するのか？構文タスクにおける語彙依存の細かい分析", "jabstract": "トランスフォーマーベースのニューラル言語モデルは、さまざまなタスクで印象的なパフォーマンスを発揮していますが、その汎化能力はよく理解されていません。広範な設定で主語-動詞の数の一致を強力に実行することが示されており、明示的な監視なしにトレーニング中に構文依存関係を追跡することを学んだことを示唆しています。本論文では、BERTが対象とする構文テンプレートで語彙に依存しない主語-動詞の数の一致（NA）を実行できるかどうかを調べます。そのために、BERTの動作の新しい細かい解析において、各対象構造の自然発生刺激に見られる語彙パターンを妨害します。ノンス文に関する私たちの結果は、単純なテンプレートに対してモデルが汎化能力を持っていることを示唆していますが、少なくとも1つのアトラクタが存在する場合、語彙に依存しない構文汎化を実行できないことを示しています。"}
{"title": "Combining Static and Contextualised Multilingual Embeddings", "url": "https://aclanthology.org/2022.findings-acl.182/", "abstract": "Static and contextual multilingual embeddings have complementary strengths. Static embeddings, while less expressive than contextual language models, can be more straightforwardly aligned across multiple languages. We combine the strengths of static and contextual models to improve multilingual representations. We extract static embeddings for 40 languages from XLM-R, validate those embeddings with cross-lingual word retrieval, and then align them using VecMap. This results in high-quality, highly multilingual static embeddings. Then we apply a novel continued pre-training approach to XLM-R, leveraging the high quality alignment of our static embeddings to better align the representation space of XLM-R. We show positive results for multiple complex semantic tasks. We release the static embeddings and the continued pre-training code. Unlike most previous work, our continued pre-training approach does not require parallel text.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "静的および文脈化された多言語埋め込みを組み合わせる", "jabstract": "静的および文脈的な多言語埋め込みは、相補的な強みを持っています。静的埋め込みは、文脈的言語モデルよりも表現力が低いですが、複数の言語間でより簡単に整列できます。私たちは、静的モデルと文脈的モデルの強みを組み合わせて、多言語表現を改善します。私たちは、XLM-Rから40言語の静的埋め込みを抽出し、クロスリンガルな単語検索でそれらの埋め込みを検証し、VecMapを使用して整列します。これにより、高品質で高度に多言語の静的埋め込みが得られます。次に、私たちは、XLM-Rの表現空間をよりよく整列させるために、静的埋め込みの高品質な整列を活用した新しい継続的事前学習アプローチを適用します。私たちは、複数の複雑な意味タスクに対して肯定的な結果を示しています。私たちは、静的埋め込みと継続的事前学習コードを公開しています。従来の多くの研究とは異なり、私たちの継続的事前学習アプローチには平行テキストが必要ありません。"}
{"title": "An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection", "url": "https://aclanthology.org/2022.findings-acl.183/", "abstract": "Knowledge graph integration typically suffers from the widely existing dangling entities that cannot find alignment cross knowledge graphs (KGs). The dangling entity set is unavailable in most real-world scenarios, and manually mining the entity pairs that consist of entities with the same meaning is labor-consuming. In this paper, we propose a novel accurate Unsupervised method for joint Entity alignment (EA) and Dangling entity detection (DED), called UED. The UED mines the literal semantic information to generate pseudo entity pairs and globally guided alignment information for EA and then utilizes the EA results to assist the DED. We construct a medical cross-lingual knowledge graph dataset, MedED, providing data for both the EA and DED tasks. Extensive experiments demonstrate that in the EA task, UED achieves EA results comparable to those of state-of-the-art supervised EA baselines and outperforms the current state-of-the-art EA methods by combining supervised EA data. For the DED task, UED obtains high-quality results without supervision.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「共同エンティティアラインメントとダングリングエンティティ検出の正確な非監視方法」に関する論文の要約です。", "jabstract": "知識グラフの統合は、しばしば知識グラフ間で対応が見つからないダングリングエンティティが広く存在するため、問題が発生する。ダングリングエンティティセットは、ほとんどの現実世界のシナリオでは利用できず、同じ意味を持つエンティティから構成されるエンティティペアを手動で探すことは労力がかかる。本論文では、正確な非監視型のエンティティアラインメント（EA）とダングリングエンティティ検出（DED）の共同手法であるUEDを提案する。UEDは、リテラル意味情報を採掘して擬似エンティティペアとグローバルに誘導されたアラインメント情報を生成し、EAに利用し、EAの結果をDEDの支援に利用する。EAとDEDの両方のタスクのデータを提供する医療クロスリンガル知識グラフデータセットMedEDを構築する。広範な実験により、UEDはEAタスクで、最新の監視型EAベースラインと同等のEA結果を達成し、監視型EAデータを組み合わせた現在の最先端のEA方法を上回る。DEDタスクでは、UEDは監視なしでも高品質の結果を得ることができる。"}
{"title": "Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the Research Manifold", "url": "https://aclanthology.org/2022.findings-acl.184/", "abstract": "The prototypical NLP experiment trains a standard architecture on labeled English data and optimizes for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through a manual classification of recent NLP research papers that this is indeed the case and refer to it as the square one experimental setup. We observe that NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically only along a single dimension. Most work targeting multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research. We open-source the results of our annotations to enable further analysis.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "NLPにおけるスクエアワンバイアス：研究多様体の多次元探索に向けて", "jabstract": "典型的なNLP実験は、公平性、解釈可能性、計算効率などの他の次元を考慮せず、ラベル付きの英語データに標準アーキテクチャをトレーニングし、精度を最適化することです。私たちは、最近のNLP研究論文を手動で分類することによって、これが実際にそのような場合であることを示し、それをスクエアワン実験セットアップと呼んでいます。NLP研究は、しばしばスクエアワンセットアップを超えて、精度だけでなく、公平性や解釈可能性にも焦点を当てるなど、単一の次元に沿っていることが多いことに気付きます。たとえば、多言語性を対象とした多くの研究は、精度だけを考慮しています。公平性や解釈可能性に関する多くの研究は、英語にしか焦点を当てていません。このような一次元の研究の多くは、NLP研究の検索空間の一部しか探索していないことを意味します。私たちは、スクエアワンバイアスが研究者が誤った結論を導いたり、賢明でない選択をしたりする原因になった歴史的および最近の例を提供し、研究多様体でまだ探索されていない有望な方向を指摘し、より多次元の研究を可能にするための実用的な推奨事項を提供します。私たちは、注釈の結果をオープンソース化して、さらなる分析を可能にします。"}
{"title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective", "url": "https://aclanthology.org/2022.findings-acl.185/", "abstract": "Metamorphic testing has recently been used to check the safety of neural NLP models. Its main advantage is that it does not rely on a ground truth to generate test cases. However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test. We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity. Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor. With them, we test the internal consistency of state-of-the-art NLP models, and show that they do not always behave according to their expected linguistic properties. Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "深層自然言語処理モデルの体系性、合成性、および推移性：変形テストの観点から", "jabstract": "最近、変形テストはニューラルNLPモデルの安全性を確認するために使用されています。その主な利点は、テストケースを生成するためにグラウンドトゥルースに依存しないことです。しかし、既存の研究は主に頑健性のような変形関係に関心があり、テストできる言語的特性の範囲が限られています。我々は、系統性、合成性、推移性の特性に対応する3つの新しい変形関係のクラスを提案します。我々の関係は頑健性とは異なり、複数のソース入力に対して定義されているため、生成できるテストケースの数が多項式的に増加します。これらを使用して、最新のNLPモデルの内部整合性をテストし、期待される言語的特性に常に従わないことを示します。最後に、変形関係の内部構造を効率的に要約する新しいグラフィカル表記を紹介します。"}
{"title": "Improving Neural Political Statement Classification with Class Hierarchical Information", "url": "https://aclanthology.org/2022.findings-acl.186/", "abstract": "Many tasks in text-based computational social science (CSS) involve the classification of political statements into categories based on a domain-specific codebook. In order to be useful for CSS analysis, these categories must be fine-grained. The typically skewed distribution of fine-grained categories, however, results in a challenging classification problem on the NLP side. This paper proposes to make use of the hierarchical relations among categories typically present in such codebooks:e.g., markets and taxation are both subcategories of economy, while borders is a subcategory of security. We use these ontological relations as prior knowledge to establish additional constraints on the learned model, thusimproving performance overall and in particular for infrequent categories. We evaluate several lightweight variants of this intuition by extending state-of-the-art transformer-based textclassifiers on two datasets and multiple languages. We find the most consistent improvement for an approach based on regularization.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「階層的なクラス情報を用いたニューラル政治声明分類の改善」に関する論文の要約文を以下に示す。\n\n- We propose a novel approach to improve the classification of political statements using class hierarchical information.\n→ 私たちは、クラス階層情報を用いた政治声明の分類を改善する新しい手法を提案する。\n\n- Our method utilizes a hierarchical structure of classes to capture the relationships between different political topics and improve the classification accuracy.\n→ 私たちの手法は、クラスの階層構造を利用して、異なる政治的トピック間の関係を捉え、分類精度を向上させる。\n\n- We evaluate our approach on a large-scale political statement dataset and show that it outperforms several state-of-the-art methods.\n→ 私たちは、大規模な政治声明データセットで私たちの手法を評価し、いくつかの最新の手法を上回ることを示す。\n\n- Our results demonstrate the effectiveness of incorporating class hierarchical information into neural models for political statement classification.\n→ 私たちの結果は、クラス階層情報をニューラルモデルに組み込むことが政治声明の分類において効果的であることを示している。", "jabstract": "テキストベースの計算社会科学（CSS）における多くのタスクは、ドメイン固有のコードブックに基づいて政治的な声明をカテゴリに分類することを必要とする。CSS分析に有用であるためには、これらのカテゴリは細かくなければならない。しかし、細かいカテゴリの通常の偏った分布は、NLP側での難しい分類問題を引き起こす。本論文では、このようなコードブックに通常存在するカテゴリ間の階層関係を利用することを提案する。例えば、市場と課税は経済のサブカテゴリであり、国境はセキュリティのサブカテゴリである。これらのオントロジー関係を事前知識として使用し、学習モデルに追加の制約を設定することで、全体的な性能と特に頻度の低いカテゴリの性能を向上させる。我々は、2つのデータセットと複数の言語で最先端のトランスフォーマーベースのテキスト分類器を拡張するいくつかの軽量なバリアントを評価する。我々は、正則化に基づくアプローチについて最も一貫した改善を見出した。"}
{"title": "Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation", "url": "https://aclanthology.org/2022.findings-acl.187/", "abstract": "The recent large-scale vision-language pre-training (VLP) of dual-stream architectures (e.g., CLIP) with a tremendous amount of image-text pair data, has shown its superiority on various multimodal alignment tasks. Despite its success, the resulting models are not capable of multimodal generative tasks due to the weak text encoder. To tackle this problem, we propose to augment the dual-stream VLP model with a textual pre-trained language model (PLM) via vision-language knowledge distillation (VLKD), enabling the capability for multimodal generation. VLKD is pretty data- and computation-efficient compared to the pre-training from scratch. Experimental results show that the resulting model has strong zero-shot performance on multimodal generation tasks, such as open-ended visual question answering and image captioning. For example, it achieves 44.5% zero-shot accuracy on the VQAv2 dataset, surpassing the previous state-of-the-art zero-shot model with 7× fewer parameters. Furthermore, the original textual language understanding and generation ability of the PLM is maintained after VLKD, which makes our model versatile for both multimodal and unimodal tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CLIPを介したマルチモーダル生成の実現：ビジョン・ランゲージ知識蒸留による。", "jabstract": "最近、大量の画像テキストペアデータを用いたデュアルストリームアーキテクチャ（例：CLIP）のビジョン言語プレトレーニング（VLP）が、様々なマルチモーダルアラインメントタスクで優れた性能を発揮している。しかし、その結果得られたモデルは、弱いテキストエンコーダのためにマルチモーダル生成タスクには対応できない。この問題に対処するために、我々はビジョン言語知識蒸留（VLKD）を介してテキストプレトレーニング言語モデル（PLM）をデュアルストリームVLPモデルに追加し、マルチモーダル生成の能力を実現することを提案する。VLKDは、スクラッチからのプレトレーニングに比べてデータと計算効率が高い。実験結果は、オープンエンドのビジュアルクエスチョンアンサリングや画像キャプショニングなどのマルチモーダル生成タスクにおいて、強力なゼロショット性能を発揮することを示している。例えば、VQAv2データセットで44.5％のゼロショット精度を達成し、以前の最先端のゼロショットモデルよりも7倍少ないパラメータで上回っている。さらに、VLKD後もPLMの元々のテキスト言語理解と生成能力が維持されるため、我々のモデルはマルチモーダルタスクと単一モーダルタスクの両方に対応できる。"}
{"title": "Co-VQA : Answering by Interactive Sub Question Sequence", "url": "https://aclanthology.org/2022.findings-acl.188/", "abstract": "Most existing approaches to Visual Question Answering (VQA) answer questions directly, however, people usually decompose a complex question into a sequence of simple sub questions and finally obtain the answer to the original question after answering the sub question sequence(SQS). By simulating the process, this paper proposes a conversation-based VQA (Co-VQA) framework, which consists of three components: Questioner, Oracle, and Answerer. Questioner raises the sub questions using an extending HRED model, and Oracle answers them one-by-one. An Adaptive Chain Visual Reasoning Model (ACVRM) for Answerer is also proposed, where the question-answer pair is used to update the visual representation sequentially. To perform supervised learning for each model, we introduce a well-designed method to build a SQS for each question on VQA 2.0 and VQA-CP v2 datasets. Experimental results show that our method achieves state-of-the-art on VQA-CP v2. Further analyses show that SQSs help build direct semantic connections between questions and images, provide question-adaptive variable-length reasoning chains, and with explicit interpretability as well as error traceability.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Co-VQA：インタラクティブなサブ質問シーケンスによる回答", "jabstract": "既存のVisual Question Answering（VQA）アプローチの多くは、質問に直接回答するが、人々は通常、複雑な質問を単純なサブ質問のシーケンスに分解し、サブ質問シーケンスを回答して最終的に元の質問の答えを得る。このプロセスをシミュレーションすることで、本論文では、Questioner、Oracle、Answererの3つのコンポーネントから構成される会話型VQA（Co-VQA）フレームワークを提案する。Questionerは、拡張HREDモデルを使用してサブ質問を提起し、Oracleは1つずつ回答する。Answerer用のAdaptive Chain Visual Reasoning Model（ACVRM）も提案されており、質問-回答ペアを使用して視覚表現を順次更新する。各モデルの教師あり学習を実行するために、VQA 2.0およびVQA-CP v2データセットの各質問に対してSQSを構築するためのよく設計された方法を紹介する。実験結果は、当社の方法がVQA-CP v2で最先端を達成していることを示している。さらに、SQSは、質問と画像の間に直接的な意味的なつながりを構築し、質問に適応した可変長推論チェーンを提供し、明示的な解釈可能性とエラートレーサビリティを提供することが分析によって示されている。"}
{"title": "A Simple Hash-Based Early Exiting Approach For Language Understanding and Generation", "url": "https://aclanthology.org/2022.findings-acl.189/", "abstract": "Early exiting allows instances to exit at different layers according to the estimation of difficulty.Previous works usually adopt heuristic metrics such as the entropy of internal outputs to measure instance difficulty, which suffers from generalization and threshold-tuning. In contrast, learning to exit, or learning to predict instance difficulty is a more appealing way. Though some effort has been devoted to employing such “learn-to-exit” modules, it is still unknown whether and how well the instance difficulty can be learned. As a response, we first conduct experiments on the learnability of instance difficulty, which demonstrates that modern neural models perform poorly on predicting instance difficulty. Based on this observation, we propose a simple-yet-effective Hash-based Early Exiting approach HashEE) that replaces the learn-to-exit modules with hash functions to assign each token to a fixed exiting layer. Different from previous methods, HashEE requires no internal classifiers nor extra parameters, and therefore is more efficient.HashEE can be used in various tasks (including language understanding and generation) and model architectures such as seq2seq models. Experimental results on classification, regression, and generation tasks demonstrate that HashEE can achieve higher performance with fewer FLOPs and inference time compared with previous state-of-the-art early exiting methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n言語理解と生成のためのシンプルなハッシュベースの早期終了アプローチ", "jabstract": "アーリーエグジットは、難易度の推定に応じてインスタンスを異なるレイヤーで終了させることを可能にします。従来の手法では、内部出力のエントロピーなどのヒューリスティックなメトリックを使用してインスタンスの難易度を測定していましたが、これは一般化と閾値調整の問題があります。それに対して、終了を学習する、またはインスタンスの難易度を予測することを学習することがより魅力的な方法です。これらの「学習して終了する」モジュールを使用するための努力がなされていますが、インスタンスの難易度がどの程度学習できるかはまだ不明です。そのため、まずインスタンスの難易度の学習可能性に関する実験を行い、現代のニューラルモデルがインスタンスの難易度を予測するのに不十分であることを示しました。この観察に基づいて、私たちは、内部分類器や追加のパラメーターが必要なく、より効率的であるHash-based Early Exitingアプローチ（HashEE）を提案しました。HashEEは、seq2seqモデルなどのさまざまなタスク（言語理解や生成を含む）およびモデルアーキテクチャで使用できます。分類、回帰、生成タスクの実験結果は、HashEEが以前の最先端のアーリーエグジット手法と比較して、より少ないFLOPと推論時間でより高いパフォーマンスを発揮できることを示しています。"}
{"title": "Auxiliary tasks to boost Biaffine Semantic Dependency Parsing", "url": "https://aclanthology.org/2022.findings-acl.190/", "abstract": "The biaffine parser of (CITATION) was successfully extended to semantic dependency parsing (SDP) (CITATION). Its performance on graphs is surprisingly high given that, without the constraint of producing a tree, all arcs for a given sentence are predicted independently from each other (modulo a shared representation of tokens).To circumvent such an independence of decision, while retaining the O(n2) complexity and highly parallelizable architecture, we propose to use simple auxiliary tasks that introduce some form of interdependence between arcs. Experiments on the three English acyclic datasets of SemEval-2015 task 18 (CITATION), and on French deep syntactic cyclic graphs (CITATION) show modest but systematic performance gains on a near-state-of-the-art baseline using transformer-based contextualized representations. This provides a simple and robust method to boost SDP performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "補助タスクによるBiaffine Semantic Dependency Parsingの強化", "jabstract": "(CITATION)のバイアフィンパーサーは、意味依存解析（SDP）に拡張され、グラフに対する性能が驚くほど高いことが示された。文の全てのアークが互いに独立して予測されるため、木を生成する制約がないにもかかわらず、トークンの共有表現を除いて、互いに独立して予測されることになる。このような決定の独立性を回避しながら、O（n2）の複雑さと高度に並列化可能なアーキテクチャを維持するために、アーク間のある形式の相互依存性を導入する単純な補助タスクを使用することを提案する。SemEval-2015タスク18の3つの英語非循環データセットと、フランス語の深層構文循環グラフにおける実験では、トランスフォーマーベースのコンテキスト化された表現を使用したほぼ最新のベースラインに対して、わずかながら系統的な性能向上が示された。これは、SDPの性能を向上させるための簡単で堅牢な方法を提供する。"}
{"title": "Syntax-guided Contrastive Learning for Pre-trained Language Model", "url": "https://aclanthology.org/2022.findings-acl.191/", "abstract": "Syntactic information has been proved to be useful for transformer-based pre-trained language models. Previous studies often rely on additional syntax-guided attention components to enhance the transformer, which require more parameters and additional syntactic parsing in downstream tasks. This increase in complexity severely limits the application of syntax-enhanced language model in a wide range of scenarios. In order to inject syntactic knowledge effectively and efficiently into pre-trained language models, we propose a novel syntax-guided contrastive learning method which does not change the transformer architecture. Based on constituency and dependency structures of syntax trees, we design phrase-guided and tree-guided contrastive objectives, and optimize them in the pre-training stage, so as to help the pre-trained language model to capture rich syntactic knowledge in its representations. Experimental results show that our contrastive method achieves consistent improvements in a variety of tasks, including grammatical error detection, entity tasks, structural probing and GLUE. Detailed analysis further verifies that the improvements come from the utilization of syntactic information, and the learned attention weights are more explainable in terms of linguistics.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n事前学習された言語モデルのための構文による対照的学習", "jabstract": "構文情報は、トランスフォーマーベースの事前学習言語モデルにとって有用であることが証明されています。以前の研究では、トランスフォーマーを強化するために追加の構文ガイドアテンションコンポーネントに頼ることが多く、ダウンストリームタスクでの追加の構文解析とパラメータが必要でした。この複雑さの増加は、構文強化言語モデルの広範なシナリオでの適用を厳しく制限しています。事前学習言語モデルに効果的かつ効率的に構文知識を注入するために、我々はトランスフォーマーアーキテクチャを変更しない新しい構文ガイド対比学習方法を提案します。構文木の構成要素と依存構造に基づいて、フレーズガイドとツリーガイドの対比目標を設計し、事前学習段階で最適化して、事前学習言語モデルがその表現に豊富な構文知識を捉えるのを支援します。実験結果は、文法エラー検出、エンティティタスク、構造プロービング、GLUEを含むさまざまなタスクで、当社の対比法が一貫して改善を達成していることを示しています。詳細な分析は、改善が構文情報の利用から来ており、学習されたアテンション重みが言語学的に説明可能であることをさらに検証しています。"}
{"title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting", "url": "https://aclanthology.org/2022.findings-acl.192/", "abstract": "In document classification for, e.g., legal and biomedical text, we often deal with hundreds of classes, including very infrequent ones, as well as temporal concept drift caused by the influence of real world events, e.g., policy changes, conflicts, or pandemics. Class imbalance and drift can sometimes be mitigated by resampling the training data to simulate (or compensate for) a known target distribution, but what if the target distribution is determined by unknown future events? Instead of simply resampling uniformly to hedge our bets, we focus on the underlying optimization algorithms used to train such document classifiers and evaluate several group-robust optimization algorithms, initially proposed to mitigate group-level disparities. Reframing group-robust algorithms as adaptation algorithms under concept drift, we find that Invariant Risk Minimization and Spectral Decoupling outperform sampling-based approaches to class imbalance and concept drift, and lead to much better performance on minority classes. The effect is more pronounced the larger the label set.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "時間的概念の変化下での改善されたマルチラベル分類：ラベル単位の設定におけるグループロバストアルゴリズムの再考", "jabstract": "例えば法律や医療のテキストの分類において、非常に頻度の低いクラスを含む数百のクラスを扱うことがよくあります。また、政策変更、紛争、パンデミックなどの現実世界の出来事の影響による時間的な概念の変化もあります。クラスの不均衡やドリフトは、既知のターゲット分布をシミュレート（または補償する）ためにトレーニングデータを再サンプリングすることで緩和できる場合がありますが、ターゲット分布が未知の将来の出来事によって決定される場合はどうでしょうか？私たちは、単にベットをかけるために均等に再サンプリングする代わりに、文書分類器のトレーニングに使用される基礎となる最適化アルゴリズムに焦点を当て、グループレベルの不均衡を緩和するために最初に提案されたいくつかのグループロバスト最適化アルゴリズムを評価します。グループロバストアルゴリズムを概念のドリフト下での適応アルゴリズムとして再構成することで、不均衡クラスと概念ドリフトに対するサンプリングベースのアプローチよりも不変リスク最小化とスペクトル分離が優れており、少数派クラスのパフォーマンスが大幅に向上することがわかりました。この効果は、ラベルセットが大きいほど顕著です。"}
{"title": "ASCM: An Answer Space Clustered Prompting Method without Answer Engineering", "url": "https://aclanthology.org/2022.findings-acl.193/", "abstract": "Prompt-based learning, which exploits knowledge from pre-trained language models by providing textual prompts and designing appropriate answer-category mapping methods, has achieved impressive successes on few-shot text classification and natural language inference (NLI). Because of the diverse linguistic expression, there exist many answer tokens for the same category. However, both manual answer design and automatic answer search constrain answer space and therefore hardly achieve ideal performance. To address this issue, we propose an answer space clustered prompting model (ASCM) together with a synonym initialization method (SI) which automatically categorizes all answer tokens in a semantic-clustered embedding space. We also propose a stable semi-supervised method named stair learning (SL) that orderly distills knowledge from better models to weaker models. Extensive experiments demonstrate that our ASCM+SL significantly outperforms existing state-of-the-art techniques in few-shot settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ASCM：回答エンジニアリングなしの回答空間クラスタリング促進法", "jabstract": "プロンプトベースの学習は、テキストプロンプトを提供し、適切な回答カテゴリマッピング方法を設計することで、事前にトレーニングされた言語モデルからの知識を利用し、少数のテキスト分類や自然言語推論（NLI）において印象的な成功を収めています。多様な言語表現のため、同じカテゴリのために多くの回答トークンが存在します。しかし、手動回答設計と自動回答検索の両方が回答空間を制限するため、理想的なパフォーマンスをほとんど達成できません。この問題に対処するために、我々は回答空間クラスタリングプロンプトモデル（ASCM）とシノニム初期化方法（SI）を提案し、すべての回答トークンを意味的にクラスタリングされた埋め込み空間に自動的に分類します。また、より良いモデルから弱いモデルに知識を整然と蒸留する安定した半教師あり学習方法であるステア学習（SL）を提案します。広範な実験により、ASCM+SLが少数の設定で既存の最先端技術を大幅に上回ることが示されました。"}
{"title": "Why don’t people use character-level machine translation?", "url": "https://aclanthology.org/2022.findings-acl.194/", "abstract": "We present a literature and empirical survey that critically assesses the state of the art in character-level modeling for machine translation (MT). Despite evidence in the literature that character-level systems are comparable with subword systems, they are virtually never used in competitive setups in WMT competitions. We empirically show that even with recent modeling innovations in character-level natural language processing, character-level MT systems still struggle to match their subword-based counterparts. Character-level MT systems show neither better domain robustness, nor better morphological generalization, despite being often so motivated. However, we are able to show robustness towards source side noise and that translation quality does not degrade with increasing beam size at decoding time.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "人々はなぜ文字レベルの機械翻訳を使用しないのか？", "jabstract": "私たちは、機械翻訳（MT）のための文字レベルモデリングの最新状況を批判的に評価する文献調査と実証調査を提示する。文字レベルシステムがサブワードシステムと同等であることを示す文献があるにもかかわらず、WMT競技会の競争的なセットアップではほとんど使用されていない。最近の文字レベル自然言語処理のモデリング革新にもかかわらず、文字レベルMTシステムは、サブワードベースの対応物に匹敵することができないことを実証的に示す。文字レベルMTシステムは、しばしばそのように動機付けられているにもかかわらず、ドメインの堅牢性も形態論的な一般化能力も向上しない。しかし、私たちは、ソース側のノイズに対する堅牢性を示し、デコーディング時のビームサイズの増加に伴って翻訳品質が低下しないことを示すことができた。"}
{"title": "Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning for Solving Math Word Problems", "url": "https://aclanthology.org/2022.findings-acl.195/", "abstract": "Math Word Problem (MWP) solving needs to discover the quantitative relationships over natural language narratives. Recent work shows that existing models memorize procedures from context and rely on shallow heuristics to solve MWPs. In this paper, we look at this issue and argue that the cause is a lack of overall understanding of MWP patterns. We first investigate how a neural network understands patterns only from semantics, and observe that, if the prototype equations are the same, most problems get closer representations and those representations apart from them or close to other prototypes tend to produce wrong solutions. Inspired by it, we propose a contrastive learning approach, where the neural network perceives the divergence of patterns. We collect contrastive examples by converting the prototype equation into a tree and seeking similar tree structures. The solving model is trained with an auxiliary objective on the collected examples, resulting in the representations of problems with similar prototypes being pulled closer. We conduct experiments on the Chinese dataset Math23k and the English dataset MathQA. Our method greatly improves the performance in monolingual and multilingual settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "手順を暗記するだけでなく、パターンを探す：数学のワード問題を解決するための対照的学習", "jabstract": "数学の問題解決には、自然言語の物語から数量的な関係を発見する必要があります。最近の研究では、既存のモデルが文脈から手順を記憶し、浅いヒューリスティックに頼ってMWPを解決することが示されています。本論文では、この問題を調査し、MWPパターンの全体的な理解の欠如が原因であると主張します。まず、ニューラルネットワークが意味からパターンを理解する方法を調査し、プロトタイプ方程式が同じ場合、ほとんどの問題が近い表現を持ち、それらから離れた表現または他のプロトタイプに近い表現は誤った解を生み出す傾向があることを観察します。それに着想を得て、パターンの分岐をニューラルネットワークが認識する対比学習アプローチを提案します。プロトタイプ方程式を木構造に変換し、類似した木構造を探して対比的な例を収集します。解決モデルは、収集された例に対する補助目的でトレーニングされ、類似したプロトタイプを持つ問題の表現が近づけられます。中国のデータセットMath23kと英語のデータセットMathQAで実験を行いました。私たちの方法は、単一言語および多言語設定での性能を大幅に改善します。"}
{"title": "xGQA: Cross-Lingual Visual Question Answering", "url": "https://aclanthology.org/2022.findings-acl.196/", "abstract": "Recent advances in multimodal vision and language modeling have predominantly focused on the English language, mostly due to the lack of multilingual multimodal datasets to steer modeling efforts. In this work, we address this gap and provide xGQA, a new multilingual evaluation benchmark for the visual question answering task. We extend the established English GQA dataset to 7 typologically diverse languages, enabling us to detect and explore crucial challenges in cross-lingual visual question answering. We further propose new adapter-based approaches to adapt multimodal transformer-based models to become multilingual, and—vice versa—multilingual models to become multimodal. Our proposed methods outperform current state-of-the-art multilingual multimodal models (e.g., M3P) in zero-shot cross-lingual settings, but the accuracy remains low across the board; a performance drop of around 38 accuracy points in target languages showcases the difficulty of zero-shot cross-lingual transfer for this task. Our results suggest that simple cross-lingual transfer of multimodal models yields latent multilingual multimodal misalignment, calling for more sophisticated methods for vision and multilingual language modeling.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "xGQA：クロスリンガルビジュアル質問応答", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n最近の多言語ビジョンと言語モデリングの進歩は、モデリングの努力を導く多言語のマルチモーダルデータセットの不足により、主に英語に焦点を当てています。本研究では、このギャップに対処し、視覚的な質問応答タスクの新しい多言語評価ベンチマークであるxGQAを提供します。我々は、英語GQAデータセットを7つの言語に拡張し、クロスリンガルな視覚的な質問応答における重要な課題を検出し、探索することができるようにしました。さらに、マルチモーダルトランスフォーマーベースモデルを多言語化するための新しいアダプタベースのアプローチを提案し、逆に、多言語モデルをマルチモーダルにすることができます。提案された方法は、現在の最先端の多言語マルチモーダルモデル（例：M3P）よりもゼロショットクロスリンガル設定で優れた性能を発揮しますが、精度は全体的に低く、ターゲット言語で約38の精度ポイントのパフォーマンス低下が示されています。我々の結果は、マルチモーダルモデルの単純なクロスリンガル転送が潜在的な多言語マルチモーダルの不一致を引き起こすことを示し、ビジョンと多言語言語モデリングに対してより洗練された方法が必要であることを示唆しています。"}
{"title": "Automatic Speech Recognition and Query By Example for Creole Languages Documentation", "url": "https://aclanthology.org/2022.findings-acl.197/", "abstract": "We investigate the exploitation of self-supervised models for two Creole languages with few resources: Gwadloupéyen and Morisien. Automatic language processing tools are almost non-existent for these two languages. We propose to use about one hour of annotated data to design an automatic speech recognition system for each language. We evaluate how much data is needed to obtain a query-by-example system that is usable by linguists. Moreover, our experiments show that multilingual self-supervised models are not necessarily the most efficient for Creole languages.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "クレオール言語のドキュメンテーションのための自動音声認識と例によるクエリ。", "jabstract": "私たちは、資源が少ない2つのクレオール言語、グアドループ語とモリシアン語に対して、自己教師ありモデルの活用を調査しました。これら2つの言語に対しては、自動言語処理ツールはほとんど存在しません。私たちは、アノテーションされたデータ約1時間を使用して、それぞれの言語の自動音声認識システムを設計することを提案します。私たちは、言語学者が使用できるクエリバイエグザンプルシステムを得るために必要なデータ量を評価します。さらに、私たちの実験は、多言語自己教師ありモデルがクレオール言語にとって必ずしも最も効率的ではないことを示しています。"}
{"title": "MReD: A Meta-Review Dataset for Structure-Controllable Text Generation", "url": "https://aclanthology.org/2022.findings-acl.198/", "abstract": "When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited. A typical example is when using CNN/Daily Mail dataset for controllable text summarization, there is no guided information on the emphasis of summary sentences. A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with deep understanding of the domain knowledge. Motivated by this vision, our paper introduces a new text generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its 45k meta-review sentences are manually annotated with one of the 9 carefully defined categories, including abstract, strength, decision, etc. We present experimental results on start-of-the-art summarization models, and propose methods for structure-controlled generation with both extractive and abstractive models using our annotated data. By exploring various settings and analyzing the model behavior with respect to the control signal, we demonstrate the challenges of our proposed task and the values of our dataset MReD. Meanwhile, MReD also allows us to have a better understanding of the meta-review domain.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MReD：構造制御可能なテキスト生成のためのメタレビューデータセット", "jabstract": "既存のテキスト生成データセットを直接制御可能な生成に使用する場合、ドメイン知識がないため、制御可能な側面が限られるという問題に直面しています。CNN / Daily Mailデータセットを制御可能なテキスト要約に使用する場合、要約文の強調に関するガイド情報がありません。より有用なテキスト生成器は、入力テキストと制御信号の両方を活用して生成を誘導する必要があり、これはドメイン知識の深い理解に基づいてのみ構築できます。このビジョンに基づき、本論文では、MReDという新しいテキスト生成データセットを紹介します。新しいデータセットは、7,089のメタレビューから構成され、その45,000のメタレビュー文は、抽象、強み、決定など、厳密に定義された9つのカテゴリのいずれかに手動で注釈が付けられています。我々は、最新の要約モデルに関する実験結果を提示し、注釈付きデータを使用した抽出型および抽象型モデルの構造制御生成の方法を提案します。さまざまな設定を探索し、制御信号に関するモデルの振る舞いを分析することにより、提案されたタスクの課題とMReDデータセットの価値を示します。一方、MReDは、メタレビュードメインの理解を深めることも可能にします。"}
{"title": "Single Model Ensemble for Subword Regularized Models in Low-Resource Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.199/", "abstract": "Subword regularizations use multiple subword segmentations during training to improve the robustness of neural machine translation models.In previous subword regularizations, we use multiple segmentations in the training process but use only one segmentation in the inference.In this study, we propose an inference strategy to address this discrepancy.The proposed strategy approximates the marginalized likelihood by using multiple segmentations including the most plausible segmentation and several sampled segmentations.Because the proposed strategy aggregates predictions from several segmentations, we can regard it as a single model ensemble that does not require any additional cost for training.Experimental results show that the proposed strategy improves the performance of models trained with subword regularization in low-resource machine translation tasks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "低資源機械翻訳におけるサブワード正則化モデルの単一モデルアンサンブル", "jabstract": "サブワード正則化は、ニューラル機械翻訳モデルの堅牢性を向上させるために、トレーニング中に複数のサブワード分割を使用します。以前のサブワード正則化では、トレーニングプロセスで複数の分割を使用し、推論では1つの分割のみを使用していました。本研究では、この不一致に対処する推論戦略を提案します。提案された戦略は、最も可能性の高い分割といくつかのサンプル分割を含む複数の分割を使用して周辺化された尤度を近似します。提案された戦略は、複数の分割からの予測を集約するため、追加のトレーニングコストを必要としない単一のモデルアンサンブルと見なすことができます。実験結果は、サブワード正則化でトレーニングされたモデルの性能を低リソースの機械翻訳タスクで改善することを示しています。"}
{"title": "Detecting Various Types of Noise for Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.200/", "abstract": "The filtering and/or selection of training data is one of the core aspects to be considered when building a strong machine translation system.In their influential work, Khayrallah and Koehn (2018) investigated the impact of different types of noise on the performance of machine translation systems.In the same year the WMT introduced a shared task on parallel corpus filtering, which went on to be repeated in the following years, and resulted in many different filtering approaches being proposed.In this work we aim to combine the recent achievements in data filtering with the original analysis of Khayrallah and Koehn (2018) and investigate whether state-of-the-art filtering systems are capable of removing all the suggested noise types.We observe that most of these types of noise can be detected with an accuracy of over 90% by modern filtering systems when operating in a well studied high resource setting.However, we also find that when confronted with more refined noise categories or when working with a less common language pair, the performance of the filtering systems is far from optimal, showing that there is still room for improvement in this area of research.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル機械翻訳における様々な種類のノイズの検出", "jabstract": "トレーニングデータのフィルタリングと/または選択は、強力な機械翻訳システムを構築する際に考慮すべき中核的な側面の1つです。KhayrallahとKoehn（2018）の影響力のある研究では、異なる種類のノイズが機械翻訳システムのパフォーマンスに与える影響を調査しました。同年、WMTは並列コーパスのフィルタリングに関する共有タスクを導入し、その後も繰り返され、多くの異なるフィルタリングアプローチが提案されました。本研究では、最近のデータフィルタリングの成果をKhayrallahとKoehn（2018）の元の分析と組み合わせ、最新のフィルタリングシステムがすべての提案されたノイズタイプを除去できるかどうかを調査することを目的としています。私たちは、これらのノイズのほとんどが、高リソース設定で動作する現代のフィルタリングシステムによって90％以上の精度で検出できることを観察しました。ただし、より洗練されたノイズカテゴリーに直面した場合や、より一般的でない言語ペアで作業する場合、フィルタリングシステムのパフォーマンスは最適ではなく、この研究分野にはまだ改善の余地があることがわかりました。"}
{"title": "DU-VLG: Unifying Vision-and-Language Generation via Dual Sequence-to-Sequence Pre-training", "url": "https://aclanthology.org/2022.findings-acl.201/", "abstract": "Due to the limitations of the model structure and pre-training objectives, existing vision-and-language generation models cannot utilize pair-wise images and text through bi-directional generation. In this paper, we propose DU-VLG, a framework which unifies vision-and-language generation as sequence generation problems. DU-VLG is trained with novel dual pre-training tasks: multi-modal denoising autoencoder tasks and modality translation tasks. To bridge the gap between image understanding and generation, we further design a novel commitment loss. We compare pre-training objectives on image captioning and text-to-image generation datasets. Results show that DU-VLG yields better performance than variants trained with uni-directional generation objectives or the variant without the commitment loss. We also obtain higher scores compared to previous state-of-the-art systems on three vision-and-language generation tasks. In addition, human judges further confirm that our model generates real and relevant images as well as faithful and informative captions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DU-VLG：デュアルシーケンス・トゥ・シーケンスの事前学習によるビジョン・アンド・ランゲージ生成の統合化", "jabstract": "モデル構造と事前学習目的の制限により、既存のビジョン・アンド・ランゲージ生成モデルは、双方向生成を介してペアワイズの画像とテキストを利用することができません。本論文では、ビジョン・アンド・ランゲージ生成をシーケンス生成問題として統合するフレームワークDU-VLGを提案します。DU-VLGは、マルチモーダルノイズ除去オートエンコーダータスクとモダリティ翻訳タスクの新しい二重事前学習タスクで訓練されます。画像理解と生成のギャップを埋めるために、新しいコミットメント損失を設計します。画像キャプションとテキストから画像生成のデータセットで事前学習目的を比較します。結果は、DU-VLGが単方向生成目的で訓練されたバリアントやコミットメント損失のないバリアントよりも優れた性能を発揮することを示しています。また、3つのビジョン・アンド・ランゲージ生成タスクにおいて、従来の最先端システムよりも高いスコアを獲得しています。さらに、人間の審査員は、当社のモデルが実際的で関連性のある画像を生成し、忠実で情報量のあるキャプションを生成することを確認しています。"}
{"title": "HiCLRE: A Hierarchical Contrastive Learning Framework for Distantly Supervised Relation Extraction", "url": "https://aclanthology.org/2022.findings-acl.202/", "abstract": "Distant supervision assumes that any sentence containing the same entity pairs reflects identical relationships. Previous works of distantly supervised relation extraction (DSRE) task generally focus on sentence-level or bag-level de-noising techniques independently, neglecting the explicit interaction with cross levels. In this paper, we propose a hierarchical contrastive learning Framework for Distantly Supervised relation extraction (HiCLRE) to reduce noisy sentences, which integrate the global structural information and local fine-grained interaction. Specifically, we propose a three-level hierarchical learning framework to interact with cross levels, generating the de-noising context-aware representations via adapting the existing multi-head self-attention, named Multi-Granularity Recontextualization. Meanwhile, pseudo positive samples are also provided in the specific level for contrastive learning via a dynamic gradient-based data augmentation strategy, named Dynamic Gradient Adversarial Perturbation. Experiments demonstrate that HiCLRE significantly outperforms strong baselines in various mainstream DSRE datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "HiCLRE：遠隔監視された関係抽出のための階層的対照学習フレームワーク", "jabstract": "遠隔監視は、同じエンティティペアを含む文は同一の関係を反映すると仮定しています。遠隔監視された関係抽出（DSRE）タスクの以前の研究は、通常、文レベルまたはバッグレベルのノイズ除去技術に焦点を当て、クロスレベルとの明示的な相互作用を無視しています。本論文では、グローバルな構造情報とローカルな細かい相互作用を統合し、ノイズの多い文を減らすための遠隔監視された関係抽出の階層的対比学習フレームワーク（HiCLRE）を提案します。具体的には、既存のマルチヘッド自己注意を適応させて、マルチグラニュラリー再コンテキスト化と名付けられたクロスレベルとの相互作用を生成し、デノイジングコンテキストに関する表現を生成するための3レベルの階層的学習フレームワークを提案します。同時に、ダイナミックグラデーションアドバーサルパーティクルと名付けられた動的勾配ベースのデータ拡張戦略を使用して、特定のレベルで擬似的な正例サンプルも提供されます。実験により、HiCLREがさまざまな主流のDSREデータセットで強力なベースラインを大幅に上回ることが示されました。"}
{"title": "Prompt-Driven Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.203/", "abstract": "Neural machine translation (NMT) has obtained significant performance improvement over the recent years. However, NMT models still face various challenges including fragility and lack of style flexibility. Moreover, current methods for instance-level constraints are limited in that they are either constraint-specific or model-specific. To this end, we propose prompt-driven neural machine translation to incorporate prompts for enhancing translation control and enriching flexibility. Empirical results demonstrate the effectiveness of our method in both prompt responding and translation quality. Through human evaluation, we further show the flexibility of prompt control and the efficiency in human-in-the-loop translation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nPrompt-Driven Neural Machine Translation\n\nプロンプト駆動型ニューラル機械翻訳", "jabstract": "ニューラル機械翻訳（NMT）は、近年において著しい性能向上を達成しています。しかし、NMTモデルは依然として脆弱性やスタイルの柔軟性の欠如など、さまざまな課題に直面しています。さらに、現在のインスタンスレベル制約の方法は、制約固有またはモデル固有であるため、限定的です。このため、私たちは、プロンプト駆動型ニューラル機械翻訳を提案し、翻訳の制御と柔軟性の向上のためにプロンプトを組み込みます。実験結果は、プロンプト応答と翻訳品質の両方で、私たちの方法の効果を示しています。人間の評価を通じて、プロンプト制御の柔軟性と人間を介した翻訳の効率性をさらに示しています。"}
{"title": "On Controlling Fallback Responses for Grounded Dialogue Generation", "url": "https://aclanthology.org/2022.findings-acl.204/", "abstract": "Dialogue agents can leverage external textual knowledge to generate responses of a higher quality. To our best knowledge, most existing works on knowledge grounded dialogue settings assume that the user intention is always answerable. Unfortunately, this is impractical as there is no guarantee that the knowledge retrievers could always retrieve the desired knowledge. Therefore, this is crucial to incorporate fallback responses to respond to unanswerable contexts appropriately while responding to the answerable contexts in an informative manner. We propose a novel framework that automatically generates a control token with the generator to bias the succeeding response towards informativeness for answerable contexts and fallback for unanswerable contexts in an end-to-end manner. Since no existing knowledge grounded dialogue dataset considers this aim, we augment the existing dataset with unanswerable contexts to conduct our experiments. Automatic and human evaluation results indicate that naively incorporating fallback responses with controlled text generation still hurts informativeness for answerable context. In contrast, our proposed framework effectively mitigates this problem while still appropriately presenting fallback responses to unanswerable contexts. Such a framework also reduces the extra burden of the additional classifier and the overheads introduced in the previous works, which operates in a pipeline manner.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「グラウンデッド・ダイアログ生成のためのフォールバック・レスポンスの制御について」という論文の要約文を日本語に翻訳してください。", "jabstract": "対話エージェントは外部のテキスト知識を活用して、より高品質な応答を生成することができます。私たちの知る限り、知識に基づく対話設定に関する既存の多くの研究は、ユーザーの意図が常に回答可能であると仮定しています。残念ながら、知識検索器が常に望ましい知識を取得できる保証はないため、これは実用的ではありません。したがって、回答可能な文脈には情報を提供する一方で、回答不可能な文脈には適切にフォールバック応答を組み込むことが重要です。私たちは、制御トークンを自動的に生成して、回答可能な文脈に対して情報を提供し、回答不可能な文脈に対してフォールバックを行うように応答をバイアスする新しいフレームワークを提案します。既存の知識に基づく対話データセットがこの目的を考慮していないため、私たちは回答不可能な文脈を含む既存のデータセットを拡張して実験を行いました。自動評価と人間の評価結果は、制御されたテキスト生成にフォールバック応答を単純に組み込むことが回答可能な文脈の情報提供に悪影響を与えることを示しています。対照的に、私たちの提案するフレームワークは、回答不可能な文脈に適切にフォールバック応答を提示しながら、この問題を効果的に緩和します。このようなフレームワークは、以前のパイプライン方式で動作する追加の分類器と導入されるオーバーヘッドを減らすこともできます。"}
{"title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions", "url": "https://aclanthology.org/2022.findings-acl.205/", "abstract": "Humans are able to perceive, understand and reason about causal events. Developing models with similar physical and causal understanding capabilities is a long-standing goal of artificial intelligence. As a step towards this direction, we introduce CRAFT, a new video question answering dataset that requires causal reasoning about physical forces and object interactions. It contains 58K video and question pairs that are generated from 10K videos from 20 different virtual environments, containing various objects in motion that interact with each other and the scene. Two question categories in CRAFT include previously studied descriptive and counterfactual questions. Additionally, inspired by the Force Dynamics Theory in cognitive linguistics, we introduce a new causal question category that involves understanding the causal interactions between objects through notions like cause, enable, and prevent. Our results show that even though the questions in CRAFT are easy for humans, the tested baseline models, including existing state-of-the-art methods, do not yet deal with the challenges posed in our benchmark.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CRAFT：力と相互作用に関する因果推論のためのベンチマーク", "jabstract": "人間は因果関係のある出来事を知覚し、理解し、推論することができます。同様の物理的および因果関係の理解能力を持つモデルを開発することは、人工知能の長年の目標です。この方向性に向けた一歩として、物理的な力と物体の相互作用に関する因果推論が必要な新しいビデオ質問応答データセットであるCRAFTを紹介します。CRAFTには、20の異なる仮想環境から生成された10,000のビデオを含み、相互作用するさまざまな動く物体がシーンと相互作用する58,000のビデオと質問のペアが含まれています。CRAFTの2つの質問カテゴリには、以前研究された記述的および反事実的な質問が含まれます。さらに、認知言語学の力学理論に触発され、原因、可能性、防止などの概念を通じて物体間の因果関係を理解する新しい因果関係の質問カテゴリを導入します。私たちの結果は、CRAFTの質問が人間にとって簡単であるにもかかわらず、既存の最先端の方法を含むテストされたベースラインモデルが私たちのベンチマークで提供される課題にまだ対処していないことを示しています。"}
{"title": "A Graph Enhanced BERT Model for Event Prediction", "url": "https://aclanthology.org/2022.findings-acl.206/", "abstract": "Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the underlying relationship between events. Previous methods propose to retrieve relational features from event graph to enhance the modeling of event correlation. However, the sparsity of event graph may restrict the acquisition of relevant graph information, and hence influence the model performance. To address this issue, we consider automatically building of event graph using a BERT model. To this end, we incorporate an additional structured variable into BERT to learn to predict the event connections in the training process.Hence, in the test process, the connection relationship for unseen events can be predicted by the structured variable.Results on two event prediction tasks: script event prediction and story ending prediction, show that our approach can outperform state-of-the-art baseline methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nイベント予測のためのグラフ強化BERTモデル", "jabstract": "既存のイベントコンテキストに対して次のイベントを予測することは重要であるが、イベント間の関係を理解する必要があるため、課題がある。従来の方法では、イベントグラフから関係的な特徴を取得してイベントの相関モデリングを強化することが提案されてきた。しかし、イベントグラフの疎密性は関連するグラフ情報の取得を制限し、モデルの性能に影響を与える可能性がある。この問題に対処するために、BERTモデルを使用して自動的にイベントグラフを構築することを考慮する。このため、BERTに追加の構造化変数を組み込んで、トレーニングプロセスでイベントの接続を予測することを学習する。したがって、テストプロセスでは、未知のイベントの接続関係を構造化変数によって予測することができる。スクリプトイベント予測とストーリー終了予測の2つのイベント予測タスクの結果から、当社のアプローチは最新のベースライン方法を上回ることが示された。"}
{"title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory", "url": "https://aclanthology.org/2022.findings-acl.207/", "abstract": "Most of the open-domain dialogue models tend to perform poorly in the setting of long-term human-bot conversations. The possible reason is that they lack the capability of understanding and memorizing long-term dialogue history information. To address this issue, we present a novel task of Long-term Memory Conversation (LeMon) and then build a new dialogue dataset DuLeMon and a dialogue generation framework with Long-Term Memory (LTM) mechanism (called PLATO-LTM). This LTM mechanism enables our system to accurately extract and continuously update long-term persona memory without requiring multiple-session dialogue datasets for model training. To our knowledge, this is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot. Results on DuLeMon indicate that PLATO-LTM can significantly outperform baselines in terms of long-term dialogue consistency, leading to better dialogue engagingness.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "久しぶりですね！長期的なペルソナメモリを持つオープンドメインの会話", "jabstract": "オープンドメインの対話モデルの多くは、長期的な人工知能との会話の設定では性能が低い傾向がある。その可能性の理由は、長期的な対話履歴情報を理解し、記憶する能力が欠如しているためである。この問題に対処するために、私たちはLong-term Memory Conversation（LeMon）という新しいタスクを提案し、DuLeMonという新しい対話データセットとLong-Term Memory（LTM）メカニズムを備えた対話生成フレームワーク（PLATO-LTM）を構築しました。このLTMメカニズムにより、複数のセッションの対話データセットを必要とせずに、システムが正確に長期的なパーソナメモリを抽出し、継続的に更新できるようになりました。私たちの知る限り、これはユーザーとボットの両方のパーソナ情報をリアルタイムで動的に管理する最初の試みです。DuLeMonの結果から、PLATO-LTMは長期的な対話の一貫性においてベースラインを大幅に上回り、より良い対話の魅力を生み出すことができることが示されました。"}
{"title": "Lacking the Embedding of a Word? Look it up into a Traditional Dictionary", "url": "https://aclanthology.org/2022.findings-acl.208/", "abstract": "Word embeddings are powerful dictionaries, which may easily capture language variations. However, these dictionaries fail to give sense to rare words, which are surprisingly often covered by traditional dictionaries. In this paper, we propose to use definitions retrieved in traditional dictionaries to produce word embeddings for rare words. For this purpose, we introduce two methods: Definition Neural Network (DefiNNet) and Define BERT (DefBERT). In our experiments, DefiNNet and DefBERT significantly outperform state-of-the-art as well as baseline methods devised for producing embeddings of unknown words. In fact, DefiNNet significantly outperforms FastText, which implements a method for the same task-based on n-grams, and DefBERT significantly outperforms the BERT method for OOV words. Then, definitions in traditional dictionaries are useful to build word embeddings for rare words.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "単語の埋め込みが不足している場合は、伝統的な辞書で調べてください。 \n\nThis paper proposes a method to improve the performance of natural language processing tasks by incorporating traditional dictionaries into the process of word embedding. \n\n本論文では、単語埋め込みのプロセスに伝統的な辞書を取り入れることで、自然言語処理タスクのパフォーマンスを向上させる方法を提案しています。", "jabstract": "単語埋め込みは、言語の変化を簡単に捉えることができる強力な辞書です。しかし、これらの辞書は、伝統的な辞書で驚くほど頻繁にカバーされている珍しい単語に意味を与えることができません。本論文では、伝統的な辞書から取得した定義を使用して珍しい単語の単語埋め込みを生成することを提案します。この目的のために、Definition Neural Network（DefiNNet）とDefine BERT（DefBERT）の2つの方法を紹介します。実験では、DefiNNetとDefBERTが、未知の単語の埋め込みを生成するために開発された最新技術やベースライン方法を大幅に上回ることがわかりました。実際、DefiNNetは、n-gramに基づく同じタスクの方法を実装するFastTextを大幅に上回り、DefBERTは、OOV単語のためのBERT方法を大幅に上回ります。つまり、伝統的な辞書の定義は、珍しい単語の単語埋め込みを構築するために役立ちます。"}
{"title": "MTRec: Multi-Task Learning over BERT for News Recommendation", "url": "https://aclanthology.org/2022.findings-acl.209/", "abstract": "Existing news recommendation methods usually learn news representations solely based on news titles. To sufficiently utilize other fields of news information such as category and entities, some methods treat each field as an additional feature and combine different feature vectors with attentive pooling. With the adoption of large pre-trained models like BERT in news recommendation, the above way to incorporate multi-field information may encounter challenges: the shallow feature encoding to compress the category and entity information is not compatible with the deep BERT encoding. In this paper, we propose a multi-task method to incorporate the multi-field information into BERT, which improves its news encoding capability. Besides, we modify the gradients of auxiliary tasks based on their gradient conflicts with the main task, which further boosts the model performance. Extensive experiments on the MIND news recommendation benchmark show the effectiveness of our approach.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MTRec：ニュース推薦のためのBERT上のマルチタスク学習", "jabstract": "既存のニュース推薦手法は通常、ニュースタイトルに基づいてニュース表現を学習します。カテゴリーやエンティティなどの他のニュース情報のフィールドを十分に活用するために、いくつかの手法では、各フィールドを追加の特徴量として扱い、異なる特徴量ベクトルを注意的なプーリングで組み合わせます。BERTのような大規模な事前学習モデルの採用により、マルチフィールド情報を組み込む上記の方法は課題に直面する可能性があります。カテゴリーとエンティティ情報を圧縮するための浅い特徴エンコーディングは、深いBERTエンコーディングと互換性がないためです。本論文では、マルチタスク手法を提案し、マルチフィールド情報をBERTに組み込むことで、ニュースエンコーディング能力を向上させます。さらに、補助タスクの勾配を、主タスクとの勾配の競合に基づいて修正し、モデルの性能をさらに向上させます。MINDニュース推薦ベンチマークでの広範な実験により、本手法の有効性が示されました。"}
{"title": "Cross-domain Named Entity Recognition via Graph Matching", "url": "https://aclanthology.org/2022.findings-acl.210/", "abstract": "Cross-domain NER is a practical yet challenging problem since the data scarcity in the real-world scenario. A common practice is first to learn a NER model in a rich-resource general domain and then adapt the model to specific domains. Due to the mismatch problem between entity types across domains, the wide knowledge in the general domain can not effectively transfer to the target domain NER model. To this end, we model the label relationship as a probability distribution and construct label graphs in both source and target label spaces. To enhance the contextual representation with label structures, we fuse the label graph into the word embedding output by BERT. By representing label relationships as graphs, we formulate cross-domain NER as a graph matching problem. Furthermore, the proposed method has good applicability with pre-training methods and is potentially capable of other cross-domain prediction tasks. Empirical results on four datasets show that our method outperforms a series of transfer learning, multi-task learning, and few-shot learning methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "グラフマッチングを介したクロスドメインの固有表現認識", "jabstract": "クロスドメインNERは、現実のシナリオにおけるデータの不足のため、実用的でありながらも挑戦的な問題である。一般的なリソースの豊富なドメインでNERモデルを学習し、その後モデルを特定のドメインに適応させることが一般的な方法である。しかし、ドメイン間のエンティティタイプの不一致問題により、一般ドメインの広範な知識は、ターゲットドメインNERモデルに効果的に転送されない。このため、ラベル関係を確率分布としてモデル化し、ソースラベル空間とターゲットラベル空間の両方にラベルグラフを構築する。ラベル構造を用いた文脈表現を強化するために、BERTによって出力された単語埋め込みにラベルグラフを融合する。ラベル関係をグラフとして表現することにより、クロスドメインNERをグラフマッチング問題として定式化する。さらに、提案された方法は、事前学習方法との適用性が高く、他のクロスドメイン予測タスクにも対応できる可能性がある。4つのデータセットでの実験結果は、転移学習、マルチタスク学習、およびフューショット学習方法の一連の手法よりも、提案手法が優れていることを示している。"}
{"title": "Assessing Multilingual Fairness in Pre-trained Multimodal Representations", "url": "https://aclanthology.org/2022.findings-acl.211/", "abstract": "Recently pre-trained multimodal models, such as CLIP, have shown exceptional capabilities towards connecting images and natural language. The textual representations in English can be desirably transferred to multilingualism and support downstream multimodal tasks for different languages. Nevertheless, the principle of multilingual fairness is rarely scrutinized: do multilingual multimodal models treat languages equally? Are their performances biased towards particular languages? To answer these questions, we view language as the fairness recipient and introduce two new fairness notions, multilingual individual fairness and multilingual group fairness, for pre-trained multimodal models. Multilingual individual fairness requires that text snippets expressing similar semantics in different languages connect similarly to images, while multilingual group fairness requires equalized predictive performance across languages. We characterize the extent to which pre-trained multilingual vision-and-language representations are individually fair across languages. However, extensive experiments demonstrate that multilingual representations do not satisfy group fairness: (1) there is a severe multilingual accuracy disparity issue; (2) the errors exhibit biases across languages conditioning the group of people in the images, including race, gender and age.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習された多言語マルチモーダル表現における多言語公平性の評価", "jabstract": "最近、CLIPなどの事前学習されたマルチモーダルモデルは、画像と自然言語を接続する能力に優れていることが示されています。英語のテキスト表現は、多言語化に望ましい形で転送され、異なる言語のダウンストリームマルチモーダルタスクをサポートします。しかし、多言語公平性の原則はほとんど検証されていません。多言語マルチモーダルモデルは、言語を平等に扱っていますか？彼らのパフォーマンスは特定の言語に偏っていますか？これらの質問に答えるために、言語を公平性の受信者と見なし、事前学習されたマルチモーダルモデルのための2つの新しい公平性概念、多言語個人的公平性と多言語グループ公平性を導入します。多言語個人的公平性は、異なる言語で同様の意味を表現するテキストスニペットが画像に同様に接続されることを要求します。一方、多言語グループ公平性は、言語間で予測パフォーマンスが均等になることを要求します。私たちは、事前学習された多言語ビジョン・ランゲージ表現が、言語間で個人的に公平である程度を特徴付けます。しかし、広範な実験は、多言語表現がグループ公平性を満たさないことを示しています：（1）深刻な多言語精度の不均衡問題があります。 （2）エラーは、画像の人々のグループ、人種、性別、年齢によって言語に偏りを示します。"}
{"title": "More Than Words: Collocation Retokenization for Latent Dirichlet Allocation Models", "url": "https://aclanthology.org/2022.findings-acl.212/", "abstract": "Traditionally, Latent Dirichlet Allocation (LDA) ingests words in a collection of documents to discover their latent topics using word-document co-occurrences. Previous studies show that representing bigrams collocations in the input can improve topic coherence in English. However, it is unclear how to achieve the best results for languages without marked word boundaries such as Chinese and Thai. Here, we explore the use of retokenization based on chi-squared measures, t-statistics, and raw frequency to merge frequent token ngrams into collocations when preparing input to the LDA model. Based on the goodness of fit and the coherence metric, we show that topics trained with merged tokens result in topic keys that are clearer, more coherent, and more effective at distinguishing topics than those of unmerged models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「言葉以上：潜在ディリクレ配分モデルのための共起再トークナイズ化」は、自然言語処理に関する論文の要約です。", "jabstract": "従来、Latent Dirichlet Allocation（LDA）は、単語-文書共起を使用して、文書のコレクション内の単語を摂取し、その潜在的なトピックを発見します。以前の研究では、英語の場合、入力におけるbigram共起を表現することがトピックの一貫性を改善することが示されています。ただし、中国語やタイ語などの単語境界が明示されていない言語の場合、最良の結果をどのように達成するかは不明です。ここでは、LDAモデルに入力する際に、カイ二乗測定、t統計量、および生の頻度に基づく再トークン化の使用を探索し、頻繁なトークンnグラムをコロケーションにマージします。適合度と一貫性メトリックに基づいて、マージされたトークンでトレーニングされたトピックは、トピックキーがより明確で、より一貫性があり、トピックを区別するのにより効果的であることを示します。"}
{"title": "Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness", "url": "https://aclanthology.org/2022.findings-acl.213/", "abstract": "Data modification, either via additional training datasets, data augmentation, debiasing, and dataset filtering, has been proposed as an effective solution for generalizing to out-of-domain (OOD) inputs, in both natural language processing and computer vision literature.However, the effect of data modification on adversarial robustness remains unclear.In this work, we conduct a comprehensive study of common data modification strategies and evaluate not only their in-domain and OOD performance, but also their adversarial robustness (AR).We also present results on a two-dimensional synthetic dataset to visualize the effect of each method on the training distribution.This work serves as an empirical study towards understanding the relationship between generalizing to unseen domains and defending against adversarial perturbations.Our findings suggest that more data (either via additional datasets or data augmentation) benefits both OOD accuracy and AR.However, data filtering (previously shown to improve OOD accuracy on natural language inference) hurts OOD accuracy on other tasks such as question answering and image classification.We provide insights from our experiments to inform future work in this direction.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "一般化されているが堅牢ではない？データ変更方法の効果を比較して、ドメイン外の一般化と敵対的な堅牢性を検討する。", "jabstract": "自然言語処理とコンピュータビジョンの文献において、追加のトレーニングデータセット、データ拡張、デバイアス処理、およびデータセットフィルタリングによるデータの変更が、ドメイン外の入力に対する一般化のための効果的な解決策として提案されています。しかし、データ変更が敵対的な堅牢性に与える影響は不明です。本研究では、一般的なデータ変更戦略の包括的な研究を行い、インドメインおよびOODパフォーマンスだけでなく、敵対的な堅牢性（AR）も評価します。また、トレーニング分布に対する各手法の影響を視覚化するために、2次元の合成データセットに関する結果も示します。この研究は、未知のドメインに対する一般化と敵対的な摂動に対する防御の関係を理解するための経験的な研究として役立ちます。私たちの調査結果から、より多くのデータ（追加のデータセットまたはデータ拡張を介して）は、OOD精度とARの両方に利益をもたらすことが示唆されています。ただし、データフィルタリング（自然言語推論のOOD精度を向上させることが以前に示されていた）は、質問応答や画像分類などの他のタスクにおけるOOD精度を損ないます。私たちの実験から得られた洞察を提供し、今後の研究に役立てることを目的としています。"}
{"title": "ASSIST: Towards Label Noise-Robust Dialogue State Tracking", "url": "https://aclanthology.org/2022.findings-acl.214/", "abstract": "The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state tracking (DST). However, substantial noise has been discovered in its state annotations. Such noise brings about huge challenges for training DST models robustly. Although several refined versions, including MultiWOZ 2.1-2.4, have been published recently, there are still lots of noisy labels, especially in the training set. Besides, it is costly to rectify all the problematic annotations. In this paper, instead of improving the annotation quality further, we propose a general framework, named ASSIST (lAbel noiSe-robuSt dIalogue State Tracking), to train DST models robustly from noisy labels. ASSIST first generates pseudo labels for each sample in the training set by using an auxiliary model trained on a small clean dataset, then puts the generated pseudo labels and vanilla noisy labels together to train the primary model. We show the validity of ASSIST theoretically. Experimental results also demonstrate that ASSIST improves the joint goal accuracy of DST by up to 28.16% on MultiWOZ 2.0 and 8.41% on MultiWOZ 2.4, compared to using only the vanilla noisy labels.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ASSIST：ラベルノイズに強い対話状態追跡に向けて", "jabstract": "MultiWOZ 2.0データセットは、対話状態追跡（DST）の研究を大幅に促進しました。しかし、その状態注釈には大量のノイズがあることが発見されました。このようなノイズは、DSTモデルを堅牢にトレーニングするために巨大な課題をもたらします。最近、MultiWOZ 2.1-2.4を含むいくつかの改良版が公開されましたが、トレーニングセットにはまだ多くのノイズがあります。また、すべての問題のある注釈を修正するのはコストがかかります。本論文では、注釈の品質をさらに改善する代わりに、ノイズに強いDSTモデルをトレーニングするための一般的なフレームワークであるASSIST（lAbel noiSe-robuSt dIalogue State Tracking）を提案します。ASSISTは、小さなクリーンデータセットでトレーニングされた補助モデルを使用して、トレーニングセットの各サンプルについて擬似ラベルを生成し、生成された擬似ラベルとバニラのノイズラベルを一緒にして、主要なモデルをトレーニングします。ASSISTの妥当性を理論的に示します。実験結果も、バニラのノイズラベルのみを使用する場合に比べて、MultiWOZ 2.0でDSTの共通目標精度を最大28.16％、MultiWOZ 2.4で8.41％改善することを示しています。"}
{"title": "Graph Refinement for Coreference Resolution", "url": "https://aclanthology.org/2022.findings-acl.215/", "abstract": "The state-of-the-art models for coreference resolution are based on independent mention pair-wise decisions. We propose a modelling approach that learns coreference at the document-level and takes global decisions. For this purpose, we model coreference links in a graph structure where the nodes are tokens in the text, and the edges represent the relationship between them. Our model predicts the graph in a non-autoregressive manner, then iteratively refines it based on previous predictions, allowing global dependencies between decisions. The experimental results show improvements over various baselines, reinforcing the hypothesis that document-level information improves conference resolution.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「共参照解析のためのグラフの改良」", "jabstract": "指示語の解決における最新のモデルは、独立した言及ペアの決定に基づいています。私たちは、文書レベルで指示語を学習し、グローバルな決定を行うモデリングアプローチを提案します。そのために、テキスト内のトークンをノードとし、それらの関係を表すエッジを持つグラフ構造で指示語リンクをモデル化します。私たちのモデルは、非自己回帰的にグラフを予測し、前回の予測に基づいて反復的に精度を高めることで、決定間のグローバルな依存関係を許容します。実験結果は、文書レベルの情報が指示語の解決を改善することを示し、様々なベースラインに対して改善が見られました。"}
{"title": "ECO v1: Towards Event-Centric Opinion Mining", "url": "https://aclanthology.org/2022.findings-acl.216/", "abstract": "Events are considered as the fundamental building blocks of the world. Mining event-centric opinions can benefit decision making, people communication, and social good. Unfortunately, there is little literature addressing event-centric opinion mining, although which significantly diverges from the well-studied entity-centric opinion mining in connotation, structure, and expression. In this paper, we propose and formulate the task of event-centric opinion mining based on event-argument structure and expression categorizing theory. We also benchmark this task by constructing a pioneer corpus and designing a two-step benchmark framework. Experiment results show that event-centric opinion mining is feasible and challenging, and the proposed task, dataset, and baselines are beneficial for future studies.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ECO v1: イベント中心の意見マイニングに向けて", "jabstract": "世界の基本的な構成要素として、イベントが考慮されています。イベント中心の意見マイニングは、意思決定、人々のコミュニケーション、社会的な利益に役立ちます。残念ながら、エンティティ中心の意見マイニングとは異なる意味、構造、表現を持つイベント中心の意見マイニングについての文献はほとんどありません。本論文では、イベント-引数構造と表現分類理論に基づいて、イベント中心の意見マイニングのタスクを提案し、定式化します。また、先駆的なコーパスを構築し、2段階のベンチマークフレームワークを設計して、このタスクをベンチマークします。実験結果は、イベント中心の意見マイニングが実現可能であり、課題、データセット、およびベースラインは将来の研究に役立つことを示しています。"}
{"title": "Deep Reinforcement Learning for Entity Alignment", "url": "https://aclanthology.org/2022.findings-acl.217/", "abstract": "Embedding-based methods have attracted increasing attention in recent entity alignment (EA) studies. Although great promise they can offer, there are still several limitations. The most notable is that they identify the aligned entities based on cosine similarity, ignoring the semantics underlying the embeddings themselves. Furthermore, these methods are shortsighted, heuristically selecting the closest entity as the target and allowing multiple entities to match the same candidate. To address these limitations, we model entity alignment as a sequential decision-making task, in which an agent sequentially decides whether two entities are matched or mismatched based on their representation vectors. The proposed reinforcement learning (RL)-based entity alignment framework can be flexibly adapted to most embedding-based EA methods. The experimental results demonstrate that it consistently advances the performance of several state-of-the-art methods, with a maximum improvement of 31.1% on Hits@1.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nエンティティアラインメントのための深層強化学習", "jabstract": "最近のエンティティアラインメント（EA）研究では、埋め込みベースの手法が注目を集めています。彼らが提供できる大きな可能性にもかかわらず、いくつかの制限がまだ存在しています。最も注目すべきは、埋め込み自体に基づいてアラインされたエンティティをコサイン類似度で識別するため、埋め込みに潜む意味を無視することです。さらに、これらの手法は短期的であり、最も近いエンティティをターゲットとして選択し、複数のエンティティが同じ候補にマッチすることを許可します。これらの制限に対処するために、我々はエンティティアラインメントを、エージェントが表現ベクトルに基づいて2つのエンティティがマッチするかマッチしないかを逐次的に決定するシーケンシャルな意思決定課題としてモデル化します。提案された強化学習（RL）ベースのエンティティアラインメントフレームワークは、ほとんどの埋め込みベースのEA手法に柔軟に適応できます。実験結果は、いくつかの最先端の手法の性能を一貫して向上させ、Hits@1で最大31.1％の改善を示しています。"}
{"title": "Breaking Down Multilingual Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.218/", "abstract": "While multilingual training is now an essential ingredient in machine translation (MT) systems, recent work has demonstrated that it has different effects in different multilingual settings, such as many-to-one, one-to-many, and many-to-many learning. These training settings expose the encoder and the decoder in a machine translation model with different data distributions. In this paper, we examine how different varieties of multilingual training contribute to learning these two components of the MT model. Specifically, we compare bilingual models with encoders and/or decoders initialized by multilingual training. We show that multilingual training is beneficial to encoders in general, while it only benefits decoders for low-resource languages (LRLs). We further find the important attention heads for each language pair and compare their correlations during inference. Our analysis sheds light on how multilingual translation models work and also enables us to propose methods to improve performance by training with highly related languages. Our many-to-one models for high-resource languages and one-to-many models for LRL outperform the best results reported by Aharoni et al. (2019).", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語機械翻訳の分解", "jabstract": "多言語トレーニングは、機械翻訳（MT）システムにおいて今や必須の要素であるが、最近の研究では、多対一、一対多、多対多の学習など、異なる多言語設定において異なる効果があることが示されている。これらのトレーニング設定は、機械翻訳モデルのエンコーダーとデコーダーに異なるデータ分布を提示する。本論文では、多言語トレーニングの異なるバリエーションが、MTモデルのこれら2つのコンポーネントの学習にどのように貢献するかを調べる。具体的には、多言語トレーニングによって初期化されたエンコーダーと/またはデコーダーを持つバイリンガルモデルを比較する。我々は、多言語トレーニングが一般的にエンコーダーにとって有益であることを示し、低リソース言語（LRL）に対してのみデコーダーに利益をもたらすことを示す。さらに、各言語ペアの重要なアテンションヘッドを見つけ、推論中のそれらの相関関係を比較する。我々の分析は、多言語翻訳モデルがどのように機能するかを明らかにし、また、高度に関連する言語でトレーニングすることによって性能を向上させる方法を提案することを可能にする。我々の多対一モデルは高リソース言語に対して、そして一対多モデルはLRLに対して、Aharoniら（2019）が報告した最高の結果を上回っている。"}
{"title": "Mitigating Contradictions in Dialogue Based on Contrastive Learning", "url": "https://aclanthology.org/2022.findings-acl.219/", "abstract": "Chatbot models have achieved remarkable progress in recent years but tend to yield contradictory responses. In this paper, we exploit the advantage of contrastive learning technique to mitigate this issue. To endow the model with the ability of discriminating contradictory patterns, we minimize the similarity between the target response and contradiction related negative example. The negative example is generated with learnable latent noise, which receives contradiction related feedback from the pretrained critic. Experimental results show that our method helps to avoid contradictions in response generation while preserving response fluency, outperforming existing methods on both automatic and human evaluation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「対比学習に基づく対話における矛盾の緩和」に関する論文の要約文を日本語に翻訳します。\n\n- Mitigating Contradictions in Dialogue Based on Contrastive Learning\n- 対比学習に基づく対話における矛盾の緩和", "jabstract": "近年、チャットボットモデルは著しい進歩を遂げていますが、矛盾した応答を出す傾向があります。本論文では、対照学習技術の利点を活用して、この問題を緩和することを試みました。矛盾するパターンを識別する能力をモデルに与えるために、ターゲット応答と矛盾に関連する負の例との類似性を最小化しました。負の例は、学習可能な潜在的なノイズで生成され、事前学習済みの批評家から矛盾に関するフィードバックを受け取ります。実験結果は、当社の方法が応答生成における矛盾を回避しながら、応答の流暢さを維持するのに役立つことを示し、自動評価と人間の評価の両方で既存の方法を上回ることを示しています。"}
{"title": "ELLE: Efficient Lifelong Pre-training for Emerging Data", "url": "https://aclanthology.org/2022.findings-acl.220/", "abstract": "Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM’s width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from 5 domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at https://github.com/thunlp/ELLE.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ELLE：新興データのための効率的な生涯学習の事前トレーニング", "jabstract": "現在の事前学習言語モデル（PLM）は通常、静的なデータで訓練されており、現実のシナリオでは、さまざまなソースのストリーミングデータが継続的に増加する可能性があることを無視しています。これにより、PLMはすべてのソースからの情報を統合する必要があります。この目標は、すべての既存データでの徹底的な事前学習によって達成できますが、このようなプロセスは計算上の負荷が高いことが知られています。このため、我々はELLEを提案し、新興データのための効率的なライフロング事前学習を目指しています。具体的には、ELLEは、（1）関数保存モデル拡張、すでに存在するPLMの幅と深さを柔軟に拡張して知識獲得の効率を改善するものであり、（2）事前学習ドメインプロンプト、事前学習中に学習された多様な知識を分離し、ダウンストリームタスクに適切な知識を刺激するものである。我々は、BERTとGPTで5つのドメインからのストリーミングデータでELLEを実験しました。その結果、ELLEは、事前学習の効率性とダウンストリームパフォーマンスの両方で、さまざまなライフロングラーニングベースラインよりも優れていることが示されました。コードはhttps://github.com/thunlp/ELLEで公開されています。"}
{"title": "EnCBP: A New Benchmark Dataset for Finer-Grained Cultural Background Prediction in English", "url": "https://aclanthology.org/2022.findings-acl.221/", "abstract": "While cultural backgrounds have been shown to affect linguistic expressions, existing natural language processing (NLP) research on culture modeling is overly coarse-grained and does not examine cultural differences among speakers of the same language. To address this problem and augment NLP models with cultural background features, we collect, annotate, manually validate, and benchmark EnCBP, a finer-grained news-based cultural background prediction dataset in English. Through language modeling (LM) evaluations and manual analyses, we confirm that there are noticeable differences in linguistic expressions among five English-speaking countries and across four states in the US. Additionally, our evaluations on nine syntactic (CoNLL-2003), semantic (PAWS-Wiki, QNLI, STS-B, and RTE), and psycholinguistic tasks (SST-5, SST-2, Emotion, and Go-Emotions) show that, while introducing cultural background information does not benefit the Go-Emotions task due to text domain conflicts, it noticeably improves deep learning (DL) model performance on other tasks. Our findings strongly support the importance of cultural background modeling to a wide variety of NLP tasks and demonstrate the applicability of EnCBP in culture-related research.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "EnCBP：英語におけるより細かい文化的背景予測のための新しいベンチマークデータセット", "jabstract": "文化的背景が言語表現に影響を与えることが示されているが、既存の自然言語処理（NLP）における文化モデリングの研究は粗いものであり、同じ言語を話す人々の文化的な違いを調べていない。この問題に対処し、文化的背景の特徴をNLPモデルに追加するために、私たちはEnCBPという、より細かいニュースベースの文化的背景予測データセットを英語で収集、注釈、手動で検証し、ベンチマークを行った。言語モデリング（LM）の評価と手動分析により、英語を話す5つの国と米国の4つの州の間に言語表現の顕著な違いがあることを確認した。さらに、CoNLL-2003、PAWS-Wiki、QNLI、STS-B、RTEの9つの構文、意味、心理言語学的タスク（SST-5、SST-2、Emotion、Go-Emotions）に対する評価では、文化的背景情報を導入することがテキストドメインの競合によりGo-Emotionsタスクには利益をもたらさないが、他のタスクにおいては深層学習（DL）モデルの性能を顕著に向上させることができることがわかった。私たちの調査結果は、文化的背景モデリングが様々なNLPタスクにとって重要であることを強く支持し、EnCBPが文化に関する研究に適用可能であることを示している。"}
{"title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models", "url": "https://aclanthology.org/2022.findings-acl.222/", "abstract": "Prompting language models (LMs) with training examples and task descriptions has been seen as critical to recent successes in few-shot learning. In this work, we show that finetuning LMs in the few-shot setting can considerably reduce the need for prompt engineering. In fact, one can use null prompts, prompts that contain neither task-specific templates nor training examples, and achieve competitive accuracy to manually-tuned prompts across a wide range of tasks. While finetuning LMs does introduce new parameters for each downstream task, we show that this memory overhead can be substantially reduced: finetuning only the bias terms can achieve comparable or better accuracy than standard finetuning while only updating 0.1% of the parameters. All in all, we recommend finetuning LMs for few-shot learning as it is more accurate, robust to different prompts, and can be made nearly as efficient as using frozen LMs.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "プロンプトとパラメータを削減する：言語モデルによるシンプルなフューショット学習", "jabstract": "トレーニング例とタスクの説明を使用して言語モデル（LM）を促進することは、最近の少数派学習の成功にとって重要であると見なされてきました。この研究では、少数派設定でのLMの微調整が、プロンプトエンジニアリングの必要性を大幅に減らすことができることを示します。実際、タスク固有のテンプレートやトレーニング例を含まないプロンプト、つまりヌルプロンプトを使用することで、幅広いタスクにおいて手動で調整されたプロンプトと競合する精度を達成できます。LMの微調整は、下流タスクごとに新しいパラメータを導入しますが、バイアス項のみを微調整することで、標準的な微調整よりも優れた精度を達成でき、パラメータの0.1％のみを更新することができます。全体として、LMの微調整を少数派学習において推奨します。それはより正確で、異なるプロンプトに対して堅牢であり、凍結されたLMを使用するのとほぼ同じ効率を実現できます。"}
{"title": "uFACT: Unfaithful Alien-Corpora Training for Semantically Consistent Data-to-Text Generation", "url": "https://aclanthology.org/2022.findings-acl.223/", "abstract": "We propose uFACT (Un-Faithful Alien Corpora Training), a training corpus construction method for data-to-text (d2t) generation models. We show that d2t models trained on uFACT datasets generate utterances which represent the semantic content of the data sources more accurately compared to models trained on the target corpus alone. Our approach is to augment the training set of a given target corpus with alien corpora which have different semantic representations. We show that while it is important to have faithful data from the target corpus, the faithfulness of additional corpora only plays a minor role. Consequently, uFACT datasets can be constructed with large quantities of unfaithful data. We show how uFACT can be leveraged to obtain state-of-the-art results on the WebNLG benchmark using METEOR as our performance metric. Furthermore, we investigate the sensitivity of the generation faithfulness to the training corpus structure using the PARENT metric, and provide a baseline for this metric on the WebNLG (Gardent et al., 2017) benchmark to facilitate comparisons with future work.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "uFACT：意味的に一貫したデータからテキストを生成するための不忠実なエイリアンコーパストレーニング", "jabstract": "私たちは、データからテキスト（d2t）生成モデルのためのトレーニングコーパス構築方法であるuFACT（Un-Faithful Alien Corpora Training）を提案します。私たちは、uFACTデータセットでトレーニングされたd2tモデルが、ターゲットコーパスのみでトレーニングされたモデルよりも、データソースの意味的内容をより正確に表現する発話を生成することを示します。私たちのアプローチは、異なる意味表現を持つエイリアンコーパスを使用して、与えられたターゲットコーパスのトレーニングセットを拡張することです。私たちは、ターゲットコーパスから忠実なデータを持つことが重要である一方、追加のコーパスの忠実さはほとんど影響を与えないことを示します。したがって、uFACTデータセットは、大量の不忠実なデータで構築することができます。私たちは、METEORをパフォーマンスメトリックとして使用して、WebNLGベンチマークで最先端の結果を得るためにuFACTをどのように活用できるかを示します。さらに、PARENTメトリックを使用して、生成の忠実度がトレーニングコーパスの構造にどのように影響を受けるかを調査し、WebNLG（Gardent et al.、2017）ベンチマークのこのメトリックのベースラインを提供して、将来の研究との比較を容易にします。"}
{"title": "Good Night at 4 pm?! Time Expressions in Different Cultures", "url": "https://aclanthology.org/2022.findings-acl.224/", "abstract": "We propose the task of culture-specific time expression grounding, i.e. mapping from expressions such as “morning” in English or “Manhã” in Portuguese to specific hours in the day. We propose 3 language-agnostic methods, one of which achieves promising results on gold standard annotations that we collected for a small number of languages. We then apply this method to 27 languages and analyze the similarities across languages in the grounding of time expressions.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "4時におやすみ？！異なる文化における時間表現", "jabstract": "私たちは、文化固有の時間表現グラウンディングのタスクを提案します。つまり、「morning」（英語）や「Manhã」（ポルトガル語）などの表現を、特定の時間にマッピングすることです。私たちは、3つの言語に依存しない方法を提案し、そのうちの1つが、私たちが収集した少数の言語に対するゴールドスタンダード注釈で有望な結果を達成します。その後、この方法を27の言語に適用し、時間表現のグラウンディングにおける言語間の類似性を分析します。"}
{"title": "Extracting Person Names from User Generated Text: Named-Entity Recognition for Combating Human Trafficking", "url": "https://aclanthology.org/2022.findings-acl.225/", "abstract": "Online escort advertisement websites are widely used for advertising victims of human trafficking. Domain experts agree that advertising multiple people in the same ad is a strong indicator of trafficking. Thus, extracting person names from the text of these ads can provide valuable clues for further analysis. However, Named-Entity Recognition (NER) on escort ads is challenging because the text can be noisy, colloquial and often lacking proper grammar and punctuation. Most existing state-of-the-art NER models fail to demonstrate satisfactory performance in this task. In this paper, we propose NEAT (Name Extraction Against Trafficking) for extracting person names. It effectively combines classic rule-based and dictionary extractors with a contextualized language model to capture ambiguous names (e.g penny, hazel) and adapts to adversarial changes in the text by expanding its dictionary. NEAT shows 19% improvement on average in the F1 classification score for name extraction compared to previous state-of-the-art in two domain-specific datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ユーザー生成テキストから人名を抽出する：人身売買対策のための固有名詞認識", "jabstract": "オンラインのエスコート広告ウェブサイトは、人身売買の被害者を広告するために広く使用されています。専門家は、同じ広告に複数の人物を広告することは人身売買の強い指標であると同意しています。したがって、これらの広告のテキストから人名を抽出することは、さらなる分析のための貴重な手がかりを提供することができます。しかし、エスコート広告の名前エンティティ認識（NER）は、テキストがノイズが多く、口語的で、しばしば適切な文法や句読点が欠けているため、課題となっています。ほとんどの既存の最先端のNERモデルは、このタスクで満足できるパフォーマンスを示すことができません。本論文では、人名抽出に対するNEAT（人身売買に対する名前抽出）を提案します。それは、曖昧な名前（例：penny、hazel）を捕捉するために、古典的なルールベースと辞書抽出器を効果的に組み合わせ、文脈化された言語モデルを組み合わせており、辞書を拡張することでテキストの敵対的な変更に適応します。 NEATは、2つのドメイン固有のデータセットで、以前の最先端に比べて名前抽出のF1分類スコアで平均19％の改善を示します。"}
{"title": "OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource Language Pair for Low-Resource Sentence Retrieval", "url": "https://aclanthology.org/2022.findings-acl.226/", "abstract": "Aligning parallel sentences in multilingual corpora is essential to curating data for downstream applications such as Machine Translation. In this work, we present OneAligner, an alignment model specially designed for sentence retrieval tasks. This model is able to train on only one language pair and transfers, in a cross-lingual fashion, to low-resource language pairs with negligible degradation in performance. When trained with all language pairs of a large-scale parallel multilingual corpus (OPUS-100), this model achieves the state-of-the-art result on the Tateoba dataset, outperforming an equally-sized previous model by 8.0 points in accuracy while using less than 0.6% of their parallel data. When finetuned on a single rich-resource language pair, be it English-centered or not, our model is able to match the performance of the ones finetuned on all language pairs under the same data budget with less than 2.0 points decrease in accuracy. Furthermore, with the same setup, scaling up the number of rich-resource language pairs monotonically improves the performance, reaching a minimum of 0.4 points discrepancy in accuracy, making it less mandatory to collect any low-resource parallel data. Finally, we conclude through empirical results and analyses that the performance of the sentence alignment task depends mostly on the monolingual and parallel data size, up to a certain size threshold, rather than on what language pairs are used for training or evaluation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "OneAligner：低資源文の検索に対する1つの豊富なリソース言語ペアを用いたゼロショットクロスリンガル転送", "jabstract": "多言語コーパス内の並列文を整列することは、機械翻訳などの下流アプリケーションのためにデータを整理する上で重要です。本研究では、文の検索タスクに特化した整列モデルであるOneAlignerを提案します。このモデルは、1つの言語ペアでトレーニングでき、クロスリンガルに転移することができ、低リソース言語ペアでも性能の低下がほとんどないです。大規模な並列多言語コーパス（OPUS-100）のすべての言語ペアでトレーニングすると、このモデルはTateobaデータセットで最先端の結果を達成し、以前の同じサイズのモデルよりも精度が8.0ポイント向上し、彼らの並列データの0.6％未満しか使用しません。リッチリソース言語ペア（英語中心であるかどうかに関係なく）でファインチューニングすると、同じデータ予算ですべての言語ペアでファインチューニングされたモデルと同等の性能を発揮し、精度が2.0ポイント未満に減少します。さらに、同じセットアップでリッチリソース言語ペアの数を拡大すると、性能が単調に向上し、精度の差が最小で0.4ポイントになり、低リソース並列データを収集する必要性が低くなります。最後に、実験結果と分析により、文の整列タスクの性能は、トレーニングまたは評価に使用される言語ペアによるのではなく、一定のサイズの閾値までの単一言語および並列データのサイズに大きく依存することが結論づけられました。"}
{"title": "Suum Cuique: Studying Bias in Taboo Detection with a Community Perspective", "url": "https://aclanthology.org/2022.findings-acl.227/", "abstract": "Prior research has discussed and illustrated the need to consider linguistic norms at the community level when studying taboo (hateful/offensive/toxic etc.) language. However, a methodology for doing so, that is firmly founded on community language norms is still largely absent. This can lead both to biases in taboo text classification and limitations in our understanding of the causes of bias. We propose a method to study bias in taboo classification and annotation where a community perspective is front and center. This is accomplished by using special classifiers tuned for each community’s language. In essence, these classifiers represent community level language norms. We use these to study bias and find, for example, biases are largest against African Americans (7/10 datasets and all 3 classifiers examined). In contrast to previous papers we also study other communities and find, for example, strong biases against South Asians. In a small scale user study we illustrate our key idea which is that common utterances, i.e., those with high alignment scores with a community (community classifier confidence scores) are unlikely to be regarded taboo. Annotators who are community members contradict taboo classification decisions and annotations in a majority of instances. This paper is a significant step toward reducing false positive taboo decisions that over time harm minority communities.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Suum Cuique：コミュニティの視点からタブー検出におけるバイアスの研究」において、我々は自然言語処理におけるタブー検出のバイアスを調査した。", "jabstract": "従来の研究では、タブー（憎悪的/攻撃的/有害ななど）言語を研究する際に、コミュニティレベルでの言語規範を考慮する必要性が議論され、説明されてきた。しかし、コミュニティ言語規範に基づく方法論はほとんど存在していない。これは、タブーのテキスト分類に偏りを生じさせ、偏りの原因を理解する上での制限につながる可能性がある。我々は、コミュニティの視点が中心となるタブー分類と注釈の偏りを研究する方法を提案する。これは、各コミュニティの言語に合わせて調整された特別な分類器を使用することによって実現される。これらの分類器は、コミュニティレベルの言語規範を表している。我々は、これらを使用して偏りを研究し、例えば、偏りがアフリカ系アメリカ人に対して最も大きいことを発見した（10個のデータセットのうち7つと検討された3つの分類器すべて）。従来の論文とは対照的に、他のコミュニティも研究し、例えば、南アジア人に対する強い偏りがあることを発見した。小規模なユーザースタディでは、私たちの主要なアイデアである、コミュニティ（コミュニティ分類器の信頼度スコア）と高いアラインメントスコアを持つ一般的な発言は、タブーとは見なされないということを示している。コミュニティメンバーである注釈者は、タブー分類の決定や注釈に反対する場合が多い。この論文は、少数派コミュニティに害を及ぼす誤ったタブーの判断を減らすための重要な一歩である。"}
{"title": "Modeling Intensification for Sign Language Generation: A Computational Approach", "url": "https://aclanthology.org/2022.findings-acl.228/", "abstract": "End-to-end sign language generation models do not accurately represent the prosody in sign language. A lack of temporal and spatial variations leads to poor-quality generated presentations that confuse human interpreters. In this paper, we aim to improve the prosody in generated sign languages by modeling intensification in a data-driven manner. We present different strategies grounded in linguistics of sign language that inform how intensity modifiers can be represented in gloss annotations. To employ our strategies, we first annotate a subset of the benchmark PHOENIX-14T, a German Sign Language dataset, with different levels of intensification. We then use a supervised intensity tagger to extend the annotated dataset and obtain labels for the remaining portion of it. This enhanced dataset is then used to train state-of-the-art transformer models for sign language generation. We find that our efforts in intensification modeling yield better results when evaluated with automatic metrics. Human evaluation also indicates a higher preference of the videos generated using our model.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "手話生成のための強調モデリング：計算的アプローチ", "jabstract": "エンド・トゥ・エンドの手話生成モデルは手話の韻律を正確に表現していない。時間的および空間的な変動の欠如により、人間の通訳者を混乱させる低品質の生成プレゼンテーションが生じる。本論文では、データ駆動型の強調モデリングにより、生成された手話の韻律を改善することを目的としている。手話の言語学に基づいた異なる戦略を提示し、強調修飾語がグロス注釈でどのように表現されるかを示す。これらの戦略を適用するために、まず、ドイツ手話のデータセットであるPHOENIX-14Tのサブセットに異なる強度レベルで注釈を付ける。次に、教師あり強度タガーを使用して、注釈付きデータセットを拡張し、残りの部分にラベルを付ける。この拡張されたデータセットを使用して、最新のトランスフォーマーモデルを手話生成のためにトレーニングする。自動評価指標で評価した結果、強調モデリングにおける取り組みがより良い結果をもたらすことがわかった。人間の評価も、当社のモデルを使用して生成されたビデオの好みが高いことを示している。"}
{"title": "Controllable Natural Language Generation with Contrastive Prefixes", "url": "https://aclanthology.org/2022.findings-acl.229/", "abstract": "To guide the generation of large pretrained language models (LM), previous work has focused on directly fine-tuning the language model or utilizing an attribute discriminator. In this work, we propose a novel lightweight framework for controllable GPT2 generation, which utilizes a set of small attribute-specific vectors, called prefixes (Li and Liang, 2021), to steer natural language generation. Different from Li and Liang (2021), where each prefix is trained independently, we take the relationship among prefixes into consideration and train multiple prefixes simultaneously. We propose a novel supervised method and also an unsupervised method to train the prefixes for single-aspect control while the combination of these two methods can achieve multi-aspect control. Experimental results on both single-aspect and multi-aspect control show that our methods can guide generation towards the desired attributes while keeping high linguistic quality.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「対比接頭辞を用いた制御可能な自然言語生成」に関する論文の要旨は以下の通りです。", "jabstract": "大規模事前学習言語モデル（LM）の生成を指導するために、以前の研究では言語モデルを直接微調整するか、属性識別器を利用することに焦点を当ててきました。本研究では、自然言語生成を誘導するために、小さな属性固有のベクトルセットであるプレフィックス（Li and Liang, 2021）を利用する、新しい軽量フレームワークを提案します。Li and Liang（2021）とは異なり、各プレフィックスを独立してトレーニングするのではなく、プレフィックス間の関係を考慮し、複数のプレフィックスを同時にトレーニングします。単一の側面制御のためのプレフィックスをトレーニングするための新しい監視方法と非監視方法を提案し、これら2つの方法の組み合わせにより、多面的制御を実現できます。単一の側面制御と多面的制御の両方における実験結果は、高い言語的品質を維持しながら、生成を望ましい属性に向けることができることを示しています。"}
{"title": "Revisiting the Effects of Leakage on Dependency Parsing", "url": "https://aclanthology.org/2022.findings-acl.230/", "abstract": "Recent work by Søgaard (2020) showed that, treebank size aside, overlap between training and test graphs (termed leakage) explains more of the observed variation in dependency parsing performance than other explanations. In this work we revisit this claim, testing it on more models and languages. We find that it only holds for zero-shot cross-lingual settings. We then propose a more fine-grained measure of such leakage which, unlike the original measure, not only explains but also correlates with observed performance variation. Code and data are available here: https://github.com/miriamwanner/reu-nlp-project", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要旨の以下の文を日本語に翻訳してください：\n\n依存構文解析における漏洩の影響を再検討する", "jabstract": "Søgaard氏（2020）による最近の研究では、ツリーバンクのサイズを除いて、トレーニングとテストグラフの重複（漏洩と呼ばれる）が、依存解析のパフォーマンスの観察される変動の他の説明よりも説明できることが示されました。本研究では、この主張を再検討し、より多くのモデルと言語でテストします。私たちは、これがゼロショットクロスリンガル設定にのみ適用されることを発見しました。その後、私たちは、このような漏洩のより細かい測定方法を提案しました。この方法は、元の測定方法とは異なり、観察されるパフォーマンスの変動と相関するだけでなく、説明することができます。コードとデータはこちらから入手できます：https://github.com/miriamwanner/reu-nlp-project"}
{"title": "Learning to Describe Solutions for Bug Reports Based on Developer Discussions", "url": "https://aclanthology.org/2022.findings-acl.231/", "abstract": "When a software bug is reported, developers engage in a discussion to collaboratively resolve it. While the solution is likely formulated within the discussion, it is often buried in a large amount of text, making it difficult to comprehend and delaying its implementation. To expedite bug resolution, we propose generating a concise natural language description of the solution by synthesizing relevant content within the discussion, which encompasses both natural language and source code. We build a corpus for this task using a novel technique for obtaining noisy supervision from repository changes linked to bug reports, with which we establish benchmarks. We also design two systems for generating a description during an ongoing discussion by classifying when sufficient context for performing the task emerges in real-time. With automated and human evaluation, we find this task to form an ideal testbed for complex reasoning in long, bimodal dialogue context.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "開発者の議論に基づくバグレポートの解決策を説明する方法を学ぶこと", "jabstract": "ソフトウェアのバグが報告されると、開発者は協力して解決するために議論を行います。解決策は議論の中で考え出されることが多いですが、大量のテキストに埋もれているため理解するのが困難で、実装が遅れることがあります。バグの解決を迅速化するために、自然言語とソースコードの両方を含む議論内の関連コンテンツを合成して、解決策の簡潔な自然言語の説明を生成することを提案します。バグレポートに関連するリポジトリの変更からノイズのある監視を取得する新しい技術を使用して、このタスクのためのコーパスを構築し、ベンチマークを確立します。また、リアルタイムでタスクを実行するための十分な文脈が現れたときに分類することにより、議論中に説明を生成するための2つのシステムを設計します。自動評価と人間の評価により、このタスクは長い二重対話文脈での複雑な推論の理想的なテストベッドを形成することがわかりました。"}
{"title": "Perturbations in the Wild: Leveraging Human-Written Text Perturbations for Realistic Adversarial Attack and Defense", "url": "https://aclanthology.org/2022.findings-acl.232/", "abstract": "We proposes a novel algorithm, ANTHRO, that inductively extracts over 600K human-written text perturbations in the wild and leverages them for realistic adversarial attack. Unlike existing character-based attacks which often deductively hypothesize a set of manipulation strategies, our work is grounded on actual observations from real-world texts. We find that adversarial texts generated by ANTHRO achieve the best trade-off between (1) attack success rate, (2) semantic preservation of the original text, and (3) stealthiness–i.e. indistinguishable from human writings hence harder to be flagged as suspicious. Specifically, our attacks accomplished around 83% and 91% attack success rates on BERT and RoBERTa, respectively. Moreover, it outperformed the TextBugger baseline with an increase of 50% and 40% in terms of semantic preservation and stealthiness when evaluated by both layperson and professional human workers. ANTHRO can further enhance a BERT classifier’s performance in understanding different variations of human-written toxic texts via adversarial training when compared to the Perspective API.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "野生の摂動：現実的な敵対的攻撃と防御のために人間が書いたテキストの摂動を活用する", "jabstract": "私たちは、野生の人間によるテキストの約600Kの摂動を帰納的に抽出し、現実的な敵対的攻撃に活用する新しいアルゴリズム、ANTHROを提案します。既存の文字ベースの攻撃は、しばしば操作戦略のセットを演繹的に仮定するのに対し、私たちの研究は実際の現実世界のテキストからの観察に基づいています。ANTHROによって生成された敵対的なテキストは、(1)攻撃成功率、(2)元のテキストの意味の保存、および(3)ステルス性-つまり人間の文章と区別がつかないため、疑わしいとしてフラグ付けされにくい-の間で最良のトレードオフを実現していることがわかりました。具体的には、私たちの攻撃は、BERTとRoBERTaでそれぞれ約83％と91％の攻撃成功率を達成しました。さらに、一般人と専門家の両方によって評価された場合、TextBuggerのベースラインに比べて、意味の保存とステルス性がそれぞれ50％と40％増加しました。ANTHROは、Perspective APIと比較して、BERT分類器が人間による有害なテキストの異なるバリエーションを理解する能力を敵対的なトレーニングによってさらに向上させることができます。"}
{"title": "Improving Chinese Grammatical Error Detection via Data augmentation by Conditional Error Generation", "url": "https://aclanthology.org/2022.findings-acl.233/", "abstract": "Chinese Grammatical Error Detection(CGED) aims at detecting grammatical errors in Chinese texts. One of the main challenges for CGED is the lack of annotated data. To alleviate this problem, previous studies proposed various methods to automatically generate more training samples, which can be roughly categorized into rule-based methods and model-based methods. The rule-based methods construct erroneous sentences by directly introducing noises into original sentences. However, the introduced noises are usually context-independent, which are quite different from those made by humans. The model-based methods utilize generative models to imitate human errors. The generative model may bring too many changes to the original sentences and generate semantically ambiguous sentences, so it is difficult to detect grammatical errors in these generated sentences. In addition, generated sentences may be error-free and thus become noisy data. To handle these problems, we propose CNEG, a novel Conditional Non-Autoregressive Error Generation model for generating Chinese grammatical errors. Specifically, in order to generate a context-dependent error, we first mask a span in a correct text, then predict an erroneous span conditioned on both the masked text and the correct span. Furthermore, we filter out error-free spans by measuring their perplexities in the original sentences. Experimental results show that our proposed method achieves better performance than all compared data augmentation methods on the CGED-2018 and CGED-2020 benchmarks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「条件付きエラー生成によるデータ拡張による中国語文法エラー検出の改善」に関する論文の要約です。」", "jabstract": "中国語文法エラー検出（CGED）は、中国語のテキスト内の文法エラーを検出することを目的としています。CGEDの主な課題の1つは、注釈付きデータの不足です。この問題を緩和するために、以前の研究では、より多くのトレーニングサンプルを自動的に生成するためのさまざまな方法が提案されました。これらは、ルールベースの方法とモデルベースの方法に大まかに分類されます。ルールベースの方法は、元の文に直接ノイズを導入することで誤った文を構築します。ただし、導入されたノイズは通常、文脈に依存しないため、人間が作るものとはかなり異なります。モデルベースの方法では、生成モデルを使用して人間のエラーを模倣します。生成モデルは、元の文に対してあまりにも多くの変更をもたらし、意味的に曖昧な文を生成する可能性があるため、これらの生成された文の文法エラーを検出することは困難です。さらに、生成された文はエラーがなく、ノイズデータになる可能性があります。これらの問題を解決するために、私たちはCNEGを提案します。これは、中国語の文法エラーを生成するための新しい条件付き非自己回帰エラー生成モデルです。具体的には、文脈依存エラーを生成するために、正しいテキスト内のスパンをマスクし、マスクされたテキストと正しいスパンの両方に依存する誤ったスパンを予測します。さらに、元の文のパープレキシティを測定して、エラーのないスパンをフィルタリングします。実験結果は、提案された方法が、CGED-2018およびCGED-2020ベンチマークのすべての比較データ拡張方法よりも優れた性能を発揮することを示しています。"}
{"title": "Modular and Parameter-Efficient Multimodal Fusion with Prompting", "url": "https://aclanthology.org/2022.findings-acl.234/", "abstract": "Recent research has made impressive progress in large-scale multimodal pre-training. In the context of the rapid growth of model size, it is necessary to seek efficient and flexible methods other than finetuning. In this paper, we propose to use prompt vectors to align the modalities. Our method achieves comparable performance to several other multimodal fusion methods in low-resource settings. We further show that our method is modular and parameter-efficient for processing tasks involving two or more data modalities.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「プロンプティングを用いたモジュール式およびパラメータ効率の高いマルチモーダル融合」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Modular and Parameter-Efficient: モジュール式およびパラメータ効率の高い\n- Multimodal Fusion: マルチモーダル融合\n- with Prompting: プロンプティングを用いた", "jabstract": "最近の研究は、大規模なマルチモーダル事前学習において印象的な進歩を遂げています。モデルサイズの急速な成長の文脈において、ファインチューニング以外の効率的かつ柔軟な方法を探す必要があります。本論文では、プロンプトベクトルを使用してモダリティを整列させることを提案します。我々の方法は、低リソース環境においていくつかの他のマルチモーダル融合方法と同等の性能を発揮します。さらに、我々の方法は、2つ以上のデータモダリティを含む処理タスクに対してモジュール化され、パラメータ効率的であることを示します。"}
{"title": "Synchronous Refinement for Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.235/", "abstract": "Machine translation typically adopts an encoder-to-decoder framework, in which the decoder generates the target sentence word-by-word in an auto-regressive manner. However, the auto-regressive decoder faces a deep-rooted one-pass issue whereby each generated word is considered as one element of the final output regardless of whether it is correct or not. These generated wrong words further constitute the target historical context to affect the generation of subsequent target words. This paper proposes a novel synchronous refinement method to revise potential errors in the generated words by considering part of the target future context. Particularly, the proposed approach allows the auto-regressive decoder to refine the previously generated target words and generate the next target word synchronously. The experimental results on three widely-used machine translation tasks demonstrated the effectiveness of the proposed approach.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル機械翻訳のための同期リファインメント", "jabstract": "機械翻訳は通常、エンコーダーからデコーダーへのフレームワークを採用しており、デコーダーは自己回帰的な方法で単語ごとに目標文を生成します。しかし、自己回帰デコーダーは、各生成された単語が正しいかどうかに関係なく、最終出力の1つの要素として考慮される深刻な1回の問題に直面しています。これらの誤った生成された単語は、次の目標単語の生成に影響を与えるため、目標の歴史的文脈を構成します。本論文では、目標の将来的な文脈の一部を考慮して、生成された単語の潜在的なエラーを修正する新しい同期リファインメント方法を提案しています。特に、提案されたアプローチでは、自己回帰デコーダーが以前に生成された目標単語を改善し、次の目標単語を同期して生成することができます。3つの広く使用されている機械翻訳タスクでの実験結果は、提案されたアプローチの有効性を示しました。"}
{"title": "HIE-SQL: History Information Enhanced Network for Context-Dependent Text-to-SQL Semantic Parsing", "url": "https://aclanthology.org/2022.findings-acl.236/", "abstract": "Recently, context-dependent text-to-SQL semantic parsing which translates natural language into SQL in an interaction process has attracted a lot of attentions. Previous works leverage context dependence information either from interaction history utterances or previous predicted queries but fail in taking advantage of both of them since of the mismatch between the natural language and logic-form SQL. In this work, we propose a History Information Enhanced text-to-SQL model (HIE-SQL) to exploit context dependence information from both history utterances and the last predicted SQL query. In view of the mismatch, we treat natural language and SQL as two modalities and propose a bimodal pre-trained model to bridge the gap between them. Besides, we design a schema-linking graph to enhance connections from utterances and the SQL query to database schema. We show our history information enhanced methods improve the performance of HIE-SQL by a significant margin, which achieves new state-of-the-art results on two context-dependent text-to-SQL benchmarks, the SparC and CoSQL datasets, at the writing time.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "HIE-SQL：文脈依存型テキストからSQLセマンティック解析への歴史情報強化ネットワーク", "jabstract": "最近、自然言語をSQLに翻訳するコンテキスト依存型のテキスト・トゥ・SQL意味解析が注目を集めています。従来の手法では、対話履歴の発話または以前に予測されたクエリからコンテキスト依存情報を活用していますが、自然言語と論理形式のSQLの不一致のため、両方を活用することができませんでした。本研究では、履歴情報を強化したテキスト・トゥ・SQLモデル（HIE-SQL）を提案し、履歴発話と最後に予測されたSQLクエリの両方からコンテキスト依存情報を活用します。不一致を考慮して、自然言語とSQLを2つのモダリティとして扱い、両者の間のギャップを埋めるためのバイモーダル事前学習モデルを提案します。さらに、スキーマリンクグラフを設計して、発話とSQLクエリからデータベーススキーマへの接続を強化します。履歴情報を強化した手法がHIE-SQLの性能を大幅に向上させることを示し、SparCデータセットとCoSQLデータセットの2つのコンテキスト依存型テキスト・トゥ・SQLベンチマークで、新しい最高の結果を達成しました。"}
{"title": "CRASpell: A Contextual Typo Robust Approach to Improve Chinese Spelling Correction", "url": "https://aclanthology.org/2022.findings-acl.237/", "abstract": "Recently, Bert-based models have dominated the research of Chinese spelling correction (CSC). These methods have two limitations: (1) they have poor performance on multi-typo texts. In such texts, the context of each typo contains at least one misspelled character, which brings noise information. Such noisy context leads to the declining performance on multi-typo texts. (2) they tend to overcorrect valid expressions to more frequent expressions due to the masked token recovering task of Bert. We attempt to address these limitations in this paper. To make our model robust to contextual noise brought by typos, our approach first constructs a noisy context for each training sample. Then the correction model is forced to yield similar outputs based on the noisy and original contexts. Moreover, to address the overcorrection problem, copy mechanism is incorporated to encourage our model to prefer to choose the input character when the miscorrected and input character are both valid according to the given context. Experiments are conducted on widely used benchmarks. Our model achieves superior performance against state-of-the-art methods by a remarkable gain.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CRASpell：文脈に基づくタイポ耐性アプローチによる中国語のスペル修正の改善", "jabstract": "最近、Bertベースのモデルが中国語のスペル修正（CSC）の研究を支配しています。これらの方法には2つの制限があります：（1）多重タイプのテキストではパフォーマンスが低くなります。このようなテキストでは、各タイプの文脈に少なくとも1つの誤字が含まれており、ノイズ情報をもたらします。このようなノイズのある文脈は、多重タイプのテキストでのパフォーマンスの低下につながります。 （2）Bertのマスクトークン回復タスクにより、有効な表現をより頻繁な表現に過剰修正する傾向があります。本論文では、これらの制限に対処することを試みます。モデルをタイプノイズによる文脈的ノイズに堅牢にするために、アプローチはまず、各トレーニングサンプルに対してノイズのある文脈を構築します。その後、修正モデルは、ノイズのある文脈と元の文脈に基づいて類似の出力を生成するように強制されます。さらに、過剰修正の問題に対処するために、コピー機構が組み込まれ、与えられた文脈に従って、誤って修正された文字と入力文字の両方が有効な場合には、入力文字を選択するようにモデルが促されます。広く使用されているベンチマークで実験が行われました。私たちのモデルは、驚異的な利益により、最先端の方法に対して優れたパフォーマンスを発揮します。"}
{"title": "Gaussian Multi-head Attention for Simultaneous Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.238/", "abstract": "Simultaneous machine translation (SiMT) outputs translation while receiving the streaming source inputs, and hence needs a policy to determine where to start translating. The alignment between target and source words often implies the most informative source word for each target word, and hence provides the unified control over translation quality and latency, but unfortunately the existing SiMT methods do not explicitly model the alignment to perform the control. In this paper, we propose Gaussian Multi-head Attention (GMA) to develop a new SiMT policy by modeling alignment and translation in a unified manner. For SiMT policy, GMA models the aligned source position of each target word, and accordingly waits until its aligned position to start translating. To integrate the learning of alignment into the translation model, a Gaussian distribution centered on predicted aligned position is introduced as an alignment-related prior, which cooperates with translation-related soft attention to determine the final attention. Experiments on En-Vi and De-En tasks show that our method outperforms strong baselines on the trade-off between translation and latency.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「同時機械翻訳のためのガウス多頭注意機構」", "jabstract": "同時機械翻訳（SiMT）は、ストリーミングソース入力を受け取りながら翻訳を出力するため、どこから翻訳を開始するかを決定する方針が必要です。ターゲットとソースの単語のアラインメントは、しばしば各ターゲット単語に対して最も情報量の多いソース単語を示し、翻訳品質とレイテンシーの統一的な制御を提供しますが、既存のSiMT手法は、制御を実行するためにアラインメントを明示的にモデル化していません。本論文では、ガウス多頭注意（GMA）を提案し、アラインメントと翻訳を統一的にモデル化することで、新しいSiMT方針を開発します。SiMT方針において、GMAは各ターゲット単語のアラインされたソース位置をモデル化し、それに応じてアラインされた位置まで翻訳を開始するように待機します。アラインメントの学習を翻訳モデルに統合するために、予測されたアラインされた位置を中心としたガウス分布がアラインメント関連の事前分布として導入され、翻訳関連のソフトアテンションと協力して最終アテンションを決定します。En-ViおよびDe-Enタスクの実験結果は、当社の手法が翻訳とレイテンシーのトレードオフにおいて強力なベースラインを上回ることを示しています。"}
{"title": "Composing Structure-Aware Batches for Pairwise Sentence Classification", "url": "https://aclanthology.org/2022.findings-acl.239/", "abstract": "Identifying the relation between two sentences requires datasets with pairwise annotations. In many cases, these datasets contain instances that are annotated multiple times as part of different pairs. They constitute a structure that contains additional helpful information about the inter-relatedness of the text instances based on the annotations. This paper investigates how this kind of structural dataset information can be exploited during training.We propose three batch composition strategies to incorporate such information and measure their performance over 14 heterogeneous pairwise sentence classification tasks. Our results show statistically significant improvements (up to 3.9%) - independent of the pre-trained language model - for most tasks compared to baselines that follow a standard training procedure. Further, we see that even this baseline procedure can profit from having such structural information in a low-resource setting.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「ペアワイズ文分類のための構造感知バッチの作成」という論文の要約文です。\n\n構造感知バッチを作成することで、ペアワイズ文分類の精度を向上させることができます。", "jabstract": "二つの文の関係を特定するには、ペアワイズ注釈を含むデータセットが必要です。多くの場合、これらのデータセットには、異なるペアの一部として複数回注釈が付けられたインスタンスが含まれています。これらは、注釈に基づくテキストインスタンスの相互関連性に関する追加の有用な情報を含む構造を構成します。本論文では、この種の構造化されたデータセット情報がトレーニング中にどのように利用できるかを調査します。我々は、このような情報を組み込むための3つのバッチ構成戦略を提案し、14の異種ペアワイズ文分類タスクでその性能を測定します。我々の結果は、事前学習された言語モデルに関係なく、標準的なトレーニング手順に従うベースラインに比べて、ほとんどのタスクで統計的に有意な改善（最大3.9％）を示しています。さらに、低リソース環境でも、このベースライン手順がこのような構造情報を持つことで利益を得ることができることがわかりました。"}
{"title": "Factual Consistency of Multilingual Pretrained Language Models", "url": "https://aclanthology.org/2022.findings-acl.240/", "abstract": "Pretrained language models can be queried for factual knowledge, with potential applications in knowledge base acquisition and tasks that require inference. However, for that, we need to know how reliable this knowledge is, and recent work has shown that monolingual English language models lack consistency when predicting factual knowledge, that is, they fill-in-the-blank differently for paraphrases describing the same fact. In this paper, we extend the analysis of consistency to a multilingual setting. We introduce a resource, mParaRel, and investigate (i) whether multilingual language models such as mBERT and XLM-R are more consistent than their monolingual counterparts;and (ii) if such models are equally consistent across languages.We find that mBERT is as inconsistent as English BERT in English paraphrases, but that both mBERT and XLM-R exhibit a high degree of inconsistency in English and even more so for all the other 45 languages.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語事前学習言語モデルの事実的一貫性", "jabstract": "事前学習済み言語モデルは、推論を必要とするタスクや知識ベースの獲得に応用可能な事実知識のクエリに使用できます。しかし、そのためには、この知識がどの程度信頼できるかを知る必要があります。最近の研究では、単一言語の英語言語モデルは、同じ事実を説明する言い換えに対して異なる空欄を埋めるため、事実知識を予測する際に一貫性に欠けることが示されています。本論文では、一貫性の分析を多言語設定に拡張します。私たちは、mParaRelというリソースを導入し、(i) mBERTやXLM-Rなどの多言語言語モデルが単一言語のモデルよりも一貫性があるかどうか、および(ii)そのようなモデルが言語間で同じ程度の一貫性を持つかどうかを調査します。私たちは、mBERTが英語の言い換えにおいて英語BERTと同じくらい一貫性がないことを発見しましたが、mBERTとXLM-Rの両方が英語において高い程度の一貫性の欠如を示し、他の45言語においてさらに顕著であることがわかりました。"}
{"title": "Selecting Stickers in Open-Domain Dialogue through Multitask Learning", "url": "https://aclanthology.org/2022.findings-acl.241/", "abstract": "With the increasing popularity of online chatting, stickers are becoming important in our online communication. Selecting appropriate stickers in open-domain dialogue requires a comprehensive understanding of both dialogues and stickers, as well as the relationship between the two types of modalities. To tackle these challenges, we propose a multitask learning method comprised of three auxiliary tasks to enhance the understanding of dialogue history, emotion and semantic meaning of stickers. Extensive experiments conducted on a recent challenging dataset show that our model can better combine the multimodal information and achieve significantly higher accuracy over strong baselines. Ablation study further verifies the effectiveness of each auxiliary task. Our code is available at https://github.com/nonstopfor/Sticker-Selection.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多目的学習を通じたオープンドメイン対話におけるステッカーの選択", "jabstract": "オンラインチャットの人気が高まるにつれ、スタンプはオンラインコミュニケーションにおいて重要性を増しています。オープンドメインの対話において適切なスタンプを選択するには、対話とスタンプの両方の包括的な理解、および両方のモダリティ間の関係が必要です。これらの課題に対処するために、私たちは、対話履歴、感情、およびスタンプの意味を理解するための3つの補助タスクから構成されるマルチタスク学習方法を提案します。最近の難しいデータセットで実施された広範な実験により、私たちのモデルはマルチモーダル情報をより良く組み合わせ、強力なベースラインよりも大幅に高い精度を達成できることが示されました。削除実験により、各補助タスクの効果がさらに検証されました。私たちのコードはhttps://github.com/nonstopfor/Sticker-Selectionで利用可能です。"}
{"title": "ZiNet: Linking Chinese Characters Spanning Three Thousand Years", "url": "https://aclanthology.org/2022.findings-acl.242/", "abstract": "Modern Chinese characters evolved from 3,000 years ago. Up to now, tens of thousands of glyphs of ancient characters have been discovered, which must be deciphered by experts to interpret unearthed documents. Experts usually need to compare each ancient character to be examined with similar known ones in whole historical periods. However, it is inevitably limited by human memory and experience, which often cost a lot of time but associations are limited to a small scope. To help researchers discover glyph similar characters, this paper introduces ZiNet, the first diachronic knowledge base describing relationships and evolution of Chinese characters and words. In addition, powered by the knowledge of radical systems in ZiNet, this paper introduces glyph similarity measurement between ancient Chinese characters, which could capture similar glyph pairs that are potentially related in origins or semantics. Results show strong positive correlations between scores from the method and from human experts. Finally, qualitative analysis and implicit future applications are presented.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ZiNet：3000年にわたる中国の文字をリンクする", "jabstract": "現代の漢字は3,000年前から進化してきました。現在までに、数万の古代文字の字形が発見されており、発掘された文書を解釈するために専門家によって解読される必要があります。専門家は通常、各古代文字を、歴史的な全時代において既知の類似文字と比較する必要があります。しかし、人間の記憶や経験によって必然的に制限され、しばしば多くの時間がかかり、関連性は限られた範囲にとどまります。この論文では、研究者が類似の文字を発見するのを支援するために、中国文字と単語の関係と進化を記述する最初の歴史的知識ベースであるZiNetを紹介します。さらに、ZiNetの部首システムの知識によって強化された、古代中国文字間の字形の類似度測定を紹介し、起源や意味に関連する可能性のある類似の字形ペアを捕捉することができます。結果は、この方法と人間の専門家からのスコアとの間に強い正の相関があることを示しています。最後に、定性的な分析と暗黙の将来的な応用について説明します。"}
{"title": "How Can Cross-lingual Knowledge Contribute Better to Fine-Grained Entity Typing?", "url": "https://aclanthology.org/2022.findings-acl.243/", "abstract": "Cross-lingual Entity Typing (CLET) aims at improving the quality of entity type prediction by transferring semantic knowledge learned from rich-resourced languages to low-resourced languages. In this paper, by utilizing multilingual transfer learning via the mixture-of-experts approach, our model dynamically capture the relationship between target language and each source language, and effectively generalize to predict types of unseen entities in new languages. Extensive experiments on multi-lingual datasets show that our method significantly outperforms multiple baselines and can robustly handle negative transfer. We questioned the relationship between language similarity and the performance of CLET. A series of experiments refute the commonsense that the more source the better, and suggest the Similarity Hypothesis for CLET.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "クロスリンガルな知識は、細分化されたエンティティタイピングにどのように貢献できるか？", "jabstract": "クロスリンガルエンティティタイピング（CLET）は、豊富なリソース言語から学習した意味的知識を低リソース言語に転送することで、エンティティタイプ予測の品質を向上させることを目的としています。本論文では、専門家の混合アプローチを介した多言語転移学習を利用することで、モデルはターゲット言語と各ソース言語の関係を動的に捉え、新しい言語の未知のエンティティのタイプを効果的に予測することができます。多言語データセット上の広範な実験により、当社の方法が複数のベースラインを大幅に上回り、負の転送を堅牢に処理できることが示されました。CLETの言語の類似性とパフォーマンスの関係に疑問を投げかけました。一連の実験は、より多くのソースがあれば良いという常識を否定し、CLETの類似性仮説を示唆しています。"}
{"title": "AMR-DA: Data Augmentation by Abstract Meaning Representation", "url": "https://aclanthology.org/2022.findings-acl.244/", "abstract": "Abstract Meaning Representation (AMR) is a semantic representation for NLP/NLU. In this paper, we propose to use it for data augmentation in NLP. Our proposed data augmentation technique, called AMR-DA, converts a sample sentence to an AMR graph, modifies the graph according to various data augmentation policies, and then generates augmentations from graphs. Our method combines both sentence-level techniques like back translation and token-level techniques like EDA (Easy Data Augmentation). To evaluate the effectiveness of our method, we apply it to the tasks of semantic textual similarity (STS) and text classification. For STS, our experiments show that AMR-DA boosts the performance of the state-of-the-art models on several STS benchmarks. For text classification, AMR-DA outperforms EDA and AEDA and leads to more robust improvements.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "AMR-DA: 抽象意味表現によるデータ拡張\n\nAbstract Meaning Representation (AMR)は、自然言語処理において、文の意味を表現するためのグラフ表現である。AMR-DAは、AMRを利用して、データ拡張を行う手法である。AMR-DAは、AMRを生成することで、元のデータセットを拡張し、モデルの性能を向上させることができる。", "jabstract": "Abstract Meaning Representation（AMR）は、NLP / NLUのための意味表現です。本論文では、AMRをNLPのデータ拡張に使用することを提案します。私たちの提案するデータ拡張技術であるAMR-DAは、サンプル文をAMRグラフに変換し、さまざまなデータ拡張ポリシーに従ってグラフを修正し、グラフから拡張を生成します。私たちの方法は、バックトランスレーションなどの文レベルの技術と、EDA（Easy Data Augmentation）などのトークンレベルの技術を組み合わせています。私たちの方法の効果を評価するために、意味的テキスト類似性（STS）とテキスト分類のタスクに適用します。STSについては、私たちの実験は、AMR-DAがいくつかのSTSベンチマークで最先端のモデルのパフォーマンスを向上させることを示しています。テキスト分類については、AMR-DAはEDAとAEDAを上回り、より堅牢な改善をもたらします。"}
{"title": "Using Pre-Trained Language Models for Producing Counter Narratives Against Hate Speech: a Comparative Study", "url": "https://aclanthology.org/2022.findings-acl.245/", "abstract": "In this work, we present an extensive study on the use of pre-trained language models for the task of automatic Counter Narrative (CN) generation to fight online hate speech in English. We first present a comparative study to determine whether there is a particular Language Model (or class of LMs) and a particular decoding mechanism that are the most appropriate to generate CNs. Findings show that autoregressive models combined with stochastic decodings are the most promising. We then investigate how an LM performs in generating a CN with regard to an unseen target of hate. We find out that a key element for successful ‘out of target’ experiments is not an overall similarity with the training data but the presence of a specific subset of training data, i. e. a target that shares some commonalities with the test target that can be defined a-priori. We finally introduce the idea of a pipeline based on the addition of an automatic post-editing step to refine generated CNs.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「事前学習済み言語モデルを使用して、憎悪表現に対する反論を生成するための比較研究」についての要約文です。\n\n事前学習済み言語モデルを使用して、憎悪表現に対する反論を生成することができるかどうかを比較研究しました。", "jabstract": "この論文では、英語におけるオンライン憎悪表現に対抗するための自動反論生成の課題に対して、事前学習された言語モデルの使用に関する包括的な研究を行います。まず、特定の言語モデル（または言語モデルのクラス）と特定のデコーディングメカニズムがCNを生成するために最も適切かどうかを決定する比較的な研究を行います。調査の結果、自己回帰モデルと確率的デコーディングの組み合わせが最も有望であることがわかりました。次に、LMが未知の憎悪対象に対してCNを生成する際の性能を調査します。実験の成功のための重要な要素は、トレーニングデータ全体との類似性ではなく、事前に定義されたテスト対象と共通点を持つターゲットの特定のサブセットの存在であることがわかりました。最後に、生成されたCNを改善するための自動ポスト編集ステップの追加に基づくパイプラインのアイデアを紹介します。"}
{"title": "Improving Robustness of Language Models from a Geometry-aware Perspective", "url": "https://aclanthology.org/2022.findings-acl.246/", "abstract": "Recent studies have found that removing the norm-bounded projection and increasing search steps in adversarial training can significantly improve robustness. However, we observe that a too large number of search steps can hurt accuracy. We aim to obtain strong robustness efficiently using fewer steps. Through a toy experiment, we find that perturbing the clean data to the decision boundary but not crossing it does not degrade the test accuracy. Inspired by this, we propose friendly adversarial data augmentation (FADA) to generate friendly adversarial data. On top of FADA, we propose geometry-aware adversarial training (GAT) to perform adversarial training on friendly adversarial data so that we can save a large number of search steps. Comprehensive experiments across two widely used datasets and three pre-trained language models demonstrate that GAT can obtain stronger robustness via fewer steps. In addition, we provide extensive empirical results and in-depth analyses on robustness to facilitate future studies.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要旨を日本語に翻訳します。\n\n「幾何学的な観点から言語モデルの堅牢性を向上させる」", "jabstract": "最近の研究では、敵対的トレーニングにおいてノルム境界投影を除去し、探索ステップを増やすことが、耐久性を大幅に向上させることがわかっています。しかし、探索ステップが多すぎると精度が低下することが観察されています。私たちは、より少ないステップで強力な耐久性を効率的に得ることを目指しています。おもちゃの実験を通じて、クリーンなデータを決定境界に摂動させることで、テスト精度が低下しないことを発見しました。これに着想を得て、私たちはフレンドリーな敵対的データ拡張（FADA）を提案し、フレンドリーな敵対的データを生成することができます。FADAの上に、ジオメトリー感知敵対的トレーニング（GAT）を提案し、フレンドリーな敵対的データに対して敵対的トレーニングを行うことで、多数の探索ステップを節約することができます。2つの広く使用されているデータセットと3つの事前学習言語モデルを対象とした包括的な実験により、GATはより少ないステップでより強力な耐久性を得ることができることが示されています。さらに、耐久性に関する包括的な実験結果と深い分析を提供し、将来の研究を促進するための情報を提供します。"}
{"title": "Task-guided Disentangled Tuning for Pretrained Language Models", "url": "https://aclanthology.org/2022.findings-acl.247/", "abstract": "Pretrained language models (PLMs) trained on large-scale unlabeled corpus are typically fine-tuned on task-specific downstream datasets, which have produced state-of-the-art results on various NLP tasks. However, the data discrepancy issue in domain and scale makes fine-tuning fail to efficiently capture task-specific patterns, especially in low data regime. To address this issue, we propose Task-guided Disentangled Tuning (TDT) for PLMs, which enhances the generalization of representations by disentangling task-relevant signals from the entangled representations. For a given task, we introduce a learnable confidence model to detect indicative guidance from context, and further propose a disentangled regularization to mitigate the over-reliance problem. Experimental results on GLUE and CLUE benchmarks show that TDT gives consistently better results than fine-tuning with different PLMs, and extensive analysis demonstrates the effectiveness and robustness of our method. Code is available at https://github.com/lemon0830/TDT.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済み言語モデルのためのタスク指向の分離調整", "jabstract": "大規模な未ラベルのコーパスでトレーニングされた事前学習言語モデル（PLM）は、一般的にタスク固有のダウンストリームデータセットで微調整され、さまざまなNLPタスクで最先端の結果を生み出しています。しかし、ドメインとスケールのデータの不一致問題により、低データ領域では特定のタスクパターンを効率的に捉えることができず、微調整が失敗することがあります。この問題に対処するために、私たちはPLMのためのタスクガイド分離チューニング（TDT）を提案し、タスクに関連する信号を分離することにより表現の汎化を強化します。与えられたタスクに対して、文脈から示唆的なガイダンスを検出するための学習可能な信頼モデルを導入し、過度に依存する問題を緩和するための分離正則化を提案します。GLUEおよびCLUEベンチマークの実験結果は、TDTが異なるPLMで微調整するよりも一貫して優れた結果を示し、広範な分析は、私たちの方法の有効性と堅牢性を示しています。コードはhttps://github.com/lemon0830/TDTで利用可能です。"}
{"title": "Exploring the Impact of Negative Samples of Contrastive Learning: A Case Study of Sentence Embedding", "url": "https://aclanthology.org/2022.findings-acl.248/", "abstract": "Contrastive learning is emerging as a powerful technique for extracting knowledge from unlabeled data. This technique requires a balanced mixture of two ingredients: positive (similar) and negative (dissimilar) samples. This is typically achieved by maintaining a queue of negative samples during training. Prior works in the area typically uses a fixed-length negative sample queue, but how the negative sample size affects the model performance remains unclear. The opaque impact of the number of negative samples on performance when employing contrastive learning aroused our in-depth exploration. This paper presents a momentum contrastive learning model with negative sample queue for sentence embedding, namely MoCoSE. We add the prediction layer to the online branch to make the model asymmetric and together with EMA update mechanism of the target branch to prevent the model from collapsing. We define a maximum traceable distance metric, through which we learn to what extent the text contrastive learning benefits from the historical information of negative samples. Our experiments find that the best results are obtained when the maximum traceable distance is at a certain range, demonstrating that there is an optimal range of historical information for a negative sample queue. We evaluate the proposed unsupervised MoCoSE on the semantic text similarity (STS) task and obtain an average Spearman’s correlation of 77.27%. Source code is available here.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n対比学習の負のサンプルの影響を探る：文の埋め込みの事例研究", "jabstract": "対照学習は、ラベルのないデータから知識を抽出するための強力な技術として現れています。この技術には、類似した正のサンプルと類似しない負のサンプルのバランスのとれた混合物が必要です。これは、トレーニング中に負のサンプルのキューを維持することで通常実現されます。この領域の先行研究では、通常、固定長の負のサンプルキューが使用されますが、負のサンプルの数がモデルのパフォーマンスにどのように影響するかは不明です。対照学習における負のサンプルの数の不透明な影響は、私たちが深く探求することを刺激しました。本論文では、文の埋め込みに対する負のサンプルキューを備えた運動量対照学習モデル、MoCoSEを提案します。私たちは、モデルが崩壊しないように、オンラインブランチに予測層を追加し、ターゲットブランチのEMA更新メカニズムと一緒に非対称なモデルを作成します。私たちは、最大追跡距離メトリックを定義し、テキスト対照学習が負のサンプルの歴史的情報からどの程度利益を得るかを学びます。私たちの実験では、最大追跡距離がある範囲にある場合に最良の結果が得られることがわかり、負のサンプルキューのための最適な歴史的情報の範囲があることが示されました。提案された非監視MoCoSEを意味的テキスト類似性（STS）タスクで評価し、平均スピアマン相関係数77.27％を得ました。ソースコードはこちらで入手できます。"}
{"title": "The Inefficiency of Language Models in Scholarly Retrieval: An Experimental Walk-through", "url": "https://aclanthology.org/2022.findings-acl.249/", "abstract": "Language models are increasingly becoming popular in AI-powered scientific IR systems. This paper evaluates popular scientific language models in handling (i) short-query texts and (ii) textual neighbors. Our experiments showcase the inability to retrieve relevant documents for a short-query text even under the most relaxed conditions. Additionally, we leverage textual neighbors, generated by small perturbations to the original text, to demonstrate that not all perturbations lead to close neighbors in the embedding space. Further, an exhaustive categorization yields several classes of orthographically and semantically related, partially related and completely unrelated neighbors. Retrieval performance turns out to be more influenced by the surface form rather than the semantics of the text.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "学術検索における言語モデルの非効率性：実験的な解説", "jabstract": "言語モデルは、AIによる科学的IRシステムでますます人気が高まっています。本論文では、(i) 短いクエリテキストと(ii) テキストの近隣を扱うための人気のある科学的言語モデルを評価します。私たちの実験は、最も緩和された条件下でも、短いクエリテキストに対して関連するドキュメントを取得できないことを示しています。さらに、元のテキストに小さな変更を加えて生成されたテキストの近隣を活用して、すべての変更が埋め込み空間で近い近隣につながるわけではないことを示します。さらに、徹底的な分類により、表記上および意味的に関連する、部分的に関連する、完全に関連しない近隣のいくつかのクラスが得られます。検索パフォーマンスは、テキストの意味よりも表面形式によってより影響を受けることが判明します。"}
{"title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition", "url": "https://aclanthology.org/2022.findings-acl.250/", "abstract": "Nested entities are observed in many domains due to their compositionality, which cannot be easily recognized by the widely-used sequence labeling framework.A natural solution is to treat the task as a span classification problem.To learn better span representation and increase classification performance, it is crucial to effectively integrate heterogeneous factors including inside tokens, boundaries, labels, and related spans which could be contributing to nested entities recognition.To fuse these heterogeneous factors, we propose a novel triaffine mechanism including triaffine attention and scoring.Triaffine attention uses boundaries and labels as queries and uses inside tokens and related spans as keys and values for span representations.Triaffine scoring interacts with boundaries and span representations for classification.Experiments show that our proposed method outperforms previous span-based methods, achieves the state-of-the-art F1 scores on nested NER datasets GENIA and KBP2017, and shows comparable results on ACE2004 and ACE2005.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Triaffineメカニズムを用いた異種要因の融合によるネスト型固有表現認識」の要約文です。", "jabstract": "多くのドメインで、合成性によるネストされたエンティティが観察され、広く使用されているシーケンスラベリングフレームワークでは簡単に認識できない。自然な解決策は、タスクをスパン分類問題として扱うことである。より良いスパン表現を学習し、分類性能を向上させるためには、内部トークン、境界、ラベル、およびネストされたエンティティ認識に貢献する可能性がある関連スパンなど、異種要因を効果的に統合することが重要である。これらの異種要因を融合するために、トリアフィンメカニズム（トリアフィンアテンションとスコアリングを含む）を提案する。トリアフィンアテンションは、境界とラベルをクエリとして使用し、スパン表現のキーと値として内部トークンと関連スパンを使用する。トリアフィンスコアリングは、境界とスパン表現との相互作用により分類を行う。実験結果は、提案された方法が以前のスパンベースの方法を上回り、ネストされたNERデータセットGENIAとKBP2017で最先端のF1スコアを達成し、ACE2004とACE2005で比較可能な結果を示すことを示している。"}
{"title": "UNIMO-2: End-to-End Unified Vision-Language Grounded Learning", "url": "https://aclanthology.org/2022.findings-acl.251/", "abstract": "Vision-Language Pre-training (VLP) has achieved impressive performance on various cross-modal downstream tasks. However, most existing methods can only learn from aligned image-caption data and rely heavily on expensive regional features, which greatly limits their scalability and performance. In this paper, we propose an end-to-end unified-modal pre-training framework, namely UNIMO-2, for joint learning on both aligned image-caption data and unaligned image-only and text-only corpus. We build a unified Transformer model to jointly learn visual representations, textual representations and semantic alignment between images and texts. In particular, we propose to conduct grounded learning on both images and texts via a sharing grounded space, which helps bridge unaligned images and texts, and align the visual and textual semantic spaces on different types of corpora. The experiments show that our grounded learning method can improve textual and visual semantic alignment for improving performance on various cross-modal tasks. Moreover, benefiting from effective joint modeling of different types of corpora, our model also achieves impressive performance on single-modal visual and textual tasks. Our code and models are public at the UNIMO project page https://unimo-ptm.github.io/.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "UNIMO-2: 統合されたビジョン・言語に基づくエンドツーエンド学習", "jabstract": "ビジョン・ランゲージ・プリトレーニング（VLP）は、さまざまなクロスモーダル・ダウンストリーム・タスクで印象的なパフォーマンスを発揮しています。しかし、既存のほとんどの方法は、整列した画像キャプション・データからのみ学習でき、高価なリージョン特徴に大きく依存しており、スケーラビリティとパフォーマンスに大きな制限があります。本論文では、統合モーダル・プリトレーニング・フレームワークであるUNIMO-2を提案し、整列した画像キャプション・データと整列していない画像のみおよびテキストのみのコーパスの両方での共同学習を行います。我々は、画像とテキストの両方の視覚的表現、テキスト表現、および画像とテキストの意味的アラインメントを共同学習するために、統合Transformerモデルを構築します。特に、我々は、共有されたグラウンデッド空間を介して画像とテキストの両方でグラウンデッド学習を行うことを提案し、アラインされていない画像とテキストをつなぎ合わせ、異なるタイプのコーパス上の視覚的およびテキストの意味的空間をアラインメントするのに役立ちます。実験結果は、我々のグラウンデッド学習法が、さまざまなクロスモーダル・タスクのパフォーマンス向上のためにテキストと視覚的意味的アラインメントを改善できることを示しています。さらに、異なるタイプのコーパスの効果的な共同モデリングの恩恵を受けて、我々のモデルは単一モーダルの視覚的およびテキストのタスクでも印象的なパフォーマンスを発揮しています。我々のコードとモデルは、UNIMOプロジェクトページhttps://unimo-ptm.github.io/で公開されています。"}
{"title": "The Past Mistake is the Future Wisdom: Error-driven Contrastive Probability Optimization for Chinese Spell Checking", "url": "https://aclanthology.org/2022.findings-acl.252/", "abstract": "Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling errors, which are mainly caused by the phonological or visual similarity. Recently, pre-trained language models (PLMs) promote the progress of CSC task. However, there exists a gap between the learned knowledge of PLMs and the goal of CSC task. PLMs focus on the semantics in text and tend to correct the erroneous characters to semantically proper or commonly used ones, but these aren’t the ground-truth corrections. To address this issue, we propose an Error-driven COntrastive Probability Optimization (ECOPO) framework for CSC task. ECOPO refines the knowledge representations of PLMs, and guides the model to avoid predicting these common characters through an error-driven way. Particularly, ECOPO is model-agnostic and it can be combined with existing CSC methods to achieve better performance. Extensive experiments and detailed analyses on SIGHAN datasets demonstrate that ECOPO is simple yet effective.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "過去の過ちは未来の知恵である：中国語スペルチェックのためのエラー駆動対照確率最適化", "jabstract": "中国語のスペルチェック（CSC）は、主に音韻的または視覚的な類似性によって引き起こされる中国語のスペルの誤りを検出および修正することを目的としています。最近、事前学習言語モデル（PLMs）はCSCタスクの進歩を促進しています。しかし、PLMsの学習された知識とCSCタスクの目標との間にはギャップが存在します。PLMsはテキストの意味に焦点を当て、誤った文字を意味的に適切または一般的に使用される文字に修正する傾向がありますが、これらは正しい修正ではありません。この問題に対処するために、私たちはCSCタスクのためのエラードリブンコントラスティブプロバビリティ最適化（ECOPO）フレームワークを提案しています。ECOPOは、PLMsの知識表現を洗練し、エラードリブンの方法で一般的な文字の予測を回避するようにモデルを誘導します。特に、ECOPOはモデルに依存せず、既存のCSC方法と組み合わせてより良い性能を実現できます。SIGHANデータセットでの広範な実験と詳細な分析により、ECOPOがシンプルでありながら効果的であることが示されました。"}
{"title": "XFUND: A Benchmark Dataset for Multilingual Visually Rich Form Understanding", "url": "https://aclanthology.org/2022.findings-acl.253/", "abstract": "Multimodal pre-training with text, layout, and image has achieved SOTA performance for visually rich document understanding tasks recently, which demonstrates the great potential for joint learning across different modalities. However, the existed research work has focused only on the English domain while neglecting the importance of multilingual generalization. In this paper, we introduce a human-annotated multilingual form understanding benchmark dataset named XFUND, which includes form understanding samples in 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese). Meanwhile, we present LayoutXLM, a multimodal pre-trained model for multilingual document understanding, which aims to bridge the language barriers for visually rich document understanding. Experimental results show that the LayoutXLM model has significantly outperformed the existing SOTA cross-lingual pre-trained models on the XFUND dataset. The XFUND dataset and the pre-trained LayoutXLM model have been publicly available at https://aka.ms/layoutxlm.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "XFUND：多言語視覚的に豊かなフォーム理解のためのベンチマークデータセット", "jabstract": "最近、テキスト、レイアウト、画像を含むマルチモーダルな事前学習により、視覚的に豊かな文書理解タスクにおいてSOTAのパフォーマンスが達成され、異なるモダリティ間での共同学習の大きな可能性が示されました。しかし、既存の研究は英語の領域に焦点を当て、多言語の汎用性の重要性を無視しています。本論文では、7つの言語（中国語、日本語、スペイン語、フランス語、イタリア語、ドイツ語、ポルトガル語）でフォーム理解サンプルを含む人手による多言語フォーム理解ベンチマークデータセットであるXFUNDを紹介します。同時に、視覚的に豊かな文書理解の言語の壁を取り払うことを目的とした、多言語ドキュメント理解のためのマルチモーダル事前学習モデルであるLayoutXLMを提案します。実験結果は、LayoutXLMモデルがXFUNDデータセット上で既存のSOTAクロスリンガル事前学習モデルを大幅に上回ったことを示しています。XFUNDデータセットと事前学習されたLayoutXLMモデルは、https://aka.ms/layoutxlmで公開されています。"}
{"title": "Type-Driven Multi-Turn Corrections for Grammatical Error Correction", "url": "https://aclanthology.org/2022.findings-acl.254/", "abstract": "Grammatical Error Correction (GEC) aims to automatically detect and correct grammatical errors. In this aspect, dominant models are trained by one-iteration learning while performing multiple iterations of corrections during inference. Previous studies mainly focus on the data augmentation approach to combat the exposure bias, which suffers from two drawbacks.First, they simply mix additionally-constructed training instances and original ones to train models, which fails to help models be explicitly aware of the procedure of gradual corrections. Second, they ignore the interdependence between different types of corrections.In this paper, we propose a Type-Driven Multi-Turn Corrections approach for GEC. Using this approach, from each training instance, we additionally construct multiple training instances, each of which involves the correction of a specific type of errors. Then, we use these additionally-constructed training instances and the original one to train the model in turn.Experimental results and in-depth analysis show that our approach significantly benefits the model training. Particularly, our enhanced model achieves state-of-the-art single-model performance on English GEC benchmarks. We release our code at Github.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "文法エラー訂正のためのタイプ駆動型マルチターン訂正についての論文の要約です。", "jabstract": "文法エラー訂正（GEC）は、文法エラーを自動的に検出および訂正することを目的としています。この点において、主要なモデルは、推論中に複数の訂正を行いながら、1回の学習によってトレーニングされます。従来の研究は、露出バイアスに対処するためにデータ拡張アプローチに主に焦点を当てており、2つの欠点に苦しんでいます。第一に、彼らは単に追加構築されたトレーニングインスタンスと元のインスタンスを混ぜてモデルをトレーニングするだけであり、モデルが徐々に訂正する手順を明示的に認識するのを助けることができません。第二に、彼らは異なる種類の訂正の相互依存を無視しています。本論文では、GECのためのタイプ駆動マルチターン訂正アプローチを提案します。このアプローチを使用すると、各トレーニングインスタンスから、特定のエラータイプの訂正を含む複数のトレーニングインスタンスを追加的に構築します。その後、これらの追加的に構築されたトレーニングインスタンスと元のインスタンスを交互に使用してモデルをトレーニングします。実験結果と深い分析は、私たちのアプローチがモデルトレーニングに大きな利益をもたらすことを示しています。特に、私たちの強化モデルは、英語GECベンチマークで最先端の単一モデルのパフォーマンスを達成しています。私たちはGithubで私たちのコードをリリースしています。"}
{"title": "Leveraging Knowledge in Multilingual Commonsense Reasoning", "url": "https://aclanthology.org/2022.findings-acl.255/", "abstract": "Commonsense reasoning (CSR) requires models to be equipped with general world knowledge. While CSR is a language-agnostic process, most comprehensive knowledge sources are restricted to a small number of languages, especially English. Thus, it remains unclear how to effectively conduct multilingual commonsense reasoning (XCSR) for various languages. In this work, we propose to use English as a pivot language, utilizing English knowledge sources for our our commonsense reasoning framework via a translate-retrieve-translate (TRT) strategy. For multilingual commonsense questions and answer candidates, we collect related knowledge via translation and retrieval from the knowledge in the source language. The retrieved knowledge is then translated into the target language and integrated into a pre-trained multilingual language model via visible knowledge attention. Then we utilize a diverse of four English knowledge sources to provide more comprehensive coverage of knowledge in different formats. Extensive results on the XCSR benchmark demonstrate that TRT with external knowledge can significantly improve multilingual commonsense reasoning in both zero-shot and translate-train settings, consistently outperforming the state-of-the-art by more than 3% on the multilingual commonsense reasoning benchmark X-CSQA and X-CODAH.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語共通感覚推論における知識の活用", "jabstract": "常識推論（CSR）には、一般的な世界知識を備えたモデルが必要です。CSRは言語に依存しないプロセスですが、包括的な知識源は、特に英語に制限された少数の言語に制限されています。したがって、さまざまな言語に対して効果的に多言語常識推論（XCSR）を実行する方法はまだ不明です。本研究では、英語をピボット言語として使用し、英語の知識源を翻訳-検索-翻訳（TRT）戦略を介して私たちの常識推論フレームワークに利用することを提案します。多言語常識問題と回答候補に対して、関連する知識を翻訳およびソース言語の知識から検索して収集します。検索された知識は、ターゲット言語に翻訳され、可視的な知識アテンションを介して事前にトレーニングされた多言語言語モデルに統合されます。その後、異なる形式の知識をより包括的にカバーするために、4つの英語知識源を利用します。XCSRベンチマークの広範な結果は、外部知識を使用したTRTが、ゼロショットおよび翻訳トレーニング設定の両方で多言語常識推論を大幅に改善できることを示しており、多言語常識推論ベンチマークX-CSQAおよびX-CODAHで、常に最新技術を3％以上上回っています。"}
{"title": "Encoding and Fusing Semantic Connection and Linguistic Evidence for Implicit Discourse Relation Recognition", "url": "https://aclanthology.org/2022.findings-acl.256/", "abstract": "Prior studies use one attention mechanism to improve contextual semantic representation learning for implicit discourse relation recognition (IDRR). However, diverse relation senses may benefit from different attention mechanisms. We also argue that some linguistic relation in between two words can be further exploited for IDRR. This paper proposes a Multi-Attentive Neural Fusion (MANF) model to encode and fuse both semantic connection and linguistic evidence for IDRR. In MANF, we design a Dual Attention Network (DAN) to learn and fuse two kinds of attentive representation for arguments as its semantic connection. We also propose an Offset Matrix Network (OMN) to encode the linguistic relations of word-pairs as linguistic evidence. Our MANF model achieves the state-of-the-art results on the PDTB 3.0 corpus.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "暗黙的な談話関係の認識のための意味的接続と言語的証拠のエンコーディングと融合", "jabstract": "従来の研究では、暗黙的な論述関係認識（IDRR）の文脈的意味表現学習を改善するために、1つのアテンションメカニズムを使用していました。しかし、異なる関係の意味は異なるアテンションメカニズムから利益を得る可能性があります。また、2つの単語間の言語的関係によってIDRRをさらに活用できると主張しています。本論文では、IDRRのための意味的接続と言語的証拠の両方をエンコードして融合するMulti-Attentive Neural Fusion（MANF）モデルを提案します。MANFでは、2つの種類のアテンション表現を引数の意味的接続として学習して融合するためのDual Attention Network（DAN）を設計します。また、単語ペアの言語的関係をエンコードするためのOffset Matrix Network（OMN）を提案します。MANFモデルは、PDTB 3.0コーパスで最先端の結果を達成しています。"}
{"title": "One Agent To Rule Them All: Towards Multi-agent Conversational AI", "url": "https://aclanthology.org/2022.findings-acl.257/", "abstract": "The increasing volume of commercially available conversational agents (CAs) on the market has resulted in users being burdened with learning and adopting multiple agents to accomplish their tasks. Though prior work has explored supporting a multitude of domains within the design of a single agent, the interaction experience suffers due to the large action space of desired capabilities. To address these problems, we introduce a new task BBAI: Black-Box Agent Integration, focusing on combining the capabilities of multiple black-box CAs at scale. We explore two techniques: question agent pairing and question response pairing aimed at resolving this task. Leveraging these techniques, we design One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs. Additionally, we introduce MARS: Multi-Agent Response Selection, a new encoder model for question response pairing that jointly encodes user question and agent response pairs. We demonstrate that OFA is able to automatically and accurately integrate an ensemble of commercially available CAs spanning disparate domains. Specifically, using the MARS encoder we achieve the highest accuracy on our BBAI task, outperforming strong baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "すべてを支配する1つのエージェント：マルチエージェント会話AIへの道", "jabstract": "市場に出回っている会話エージェント（CAs）の数が増えるにつれ、ユーザーは複数のエージェントを学習し、採用することでタスクを達成する負担を強いられるようになっています。以前の研究では、単一のエージェントの設計内で多数のドメインをサポートすることが探求されてきましたが、望ましい機能の大きなアクションスペースにより、相互作用体験が損なわれています。これらの問題に対処するために、私たちは、複数のブラックボックスCAsの機能を組み合わせることに焦点を当てた新しいタスクBBAI：Black-Box Agent Integrationを紹介します。私たちは、このタスクを解決するために、質問エージェントペアリングと質問応答ペアリングの2つの技術を探求しています。これらの技術を活用して、複数のCAsと対話するための統一されたインターフェースを提供するスケーラブルなシステムであるOne For All（OFA）を設計しました。さらに、質問応答ペアリングのための新しいエンコーダーモデルであるMulti-Agent Response Selection（MARS）を紹介します。MARSエンコーダーを使用することで、商用利用可能な異なるドメインをカバーするCAsのアンサンブルを自動的かつ正確に統合できることを示します。特に、BBAIタスクで最高の精度を達成し、強力なベースラインを上回りました。"}
{"title": "Word-level Perturbation Considering Word Length and Compositional Subwords", "url": "https://aclanthology.org/2022.findings-acl.258/", "abstract": "We present two simple modifications for word-level perturbation: Word Replacement considering Length (WR-L) and Compositional Word Replacement (CWR).In conventional word replacement, a word in an input is replaced with a word sampled from the entire vocabulary, regardless of the length and context of the target word.WR-L considers the length of a target word by sampling words from the Poisson distribution.CWR considers the compositional candidates by restricting the source of sampling to related words that appear in subword regularization.Experimental results showed that the combination of WR-L and CWR improved the performance of text classification and machine translation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "単語の長さと構成サブワードを考慮した単語レベルの摂動", "jabstract": "私たちは、単語レベルの摂動のための2つの単純な修正を提案します：長さを考慮した単語置換（WR-L）と構成的単語置換（CWR）。従来の単語置換では、対象の単語の長さや文脈に関係なく、入力内の単語を全語彙からサンプリングされた単語で置換します。WR-Lは、ポアソン分布から単語をサンプリングすることで、対象の単語の長さを考慮します。CWRは、サブワード正則化に現れる関連する単語にサンプリングのソースを制限することで、構成的な候補を考慮します。実験結果は、WR-LとCWRの組み合わせが、テキスト分類や機械翻訳の性能を向上させたことを示しました。"}
{"title": "Bridging Pre-trained Language Models and Hand-crafted Features for Unsupervised POS Tagging", "url": "https://aclanthology.org/2022.findings-acl.259/", "abstract": "In recent years, large-scale pre-trained language models (PLMs) have made extraordinary progress in most NLP tasks. But, in the unsupervised POS tagging task, works utilizing PLMs are few and fail to achieve state-of-the-art (SOTA) performance. The recent SOTA performance is yielded by a Guassian HMM variant proposed by He et al. (2018). However, as a generative model, HMM makes very strong independence assumptions, making it very challenging to incorporate contexualized word representations from PLMs. In this work, we for the first time propose a neural conditional random field autoencoder (CRF-AE) model for unsupervised POS tagging. The discriminative encoder of CRF-AE can straightforwardly incorporate ELMo word representations. Moreover, inspired by feature-rich HMM, we reintroduce hand-crafted features into the decoder of CRF-AE. Finally, experiments clearly show that our model outperforms previous state-of-the-art models by a large margin on Penn Treebank and multilingual Universal Dependencies treebank v2.0.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済み言語モデルと手作りの特徴を結びつけて、教師なしの品詞タグ付けを行うための手法を提案する。", "jabstract": "近年、大規模な事前学習言語モデル（PLMs）は、ほとんどのNLPタスクで驚異的な進歩を遂げています。しかし、教師なしのPOSタグ付けタスクでは、PLMsを利用した作品は少なく、最先端のパフォーマンスを達成できません。最近の最先端のパフォーマンスは、Heらによって提案されたガウスHMMの変種によって生み出されています。しかし、生成モデルであるHMMは非常に強い独立性の仮定を行うため、PLMsからの文脈化された単語表現を組み込むことが非常に困難です。本研究では、教師なしのPOSタグ付けのために、初めてニューラル条件付きランダムフィールドオートエンコーダー（CRF-AE）モデルを提案します。CRF-AEの識別エンコーダーは、ELMo単語表現を簡単に組み込むことができます。さらに、特徴豊富なHMMに触発されて、CRF-AEのデコーダーに手作りの特徴を再導入します。最後に、実験は、私たちのモデルがPenn Treebankと多言語Universal Dependencies treebank v2.0で以前の最先端モデルを大幅に上回ることを明確に示しています。"}
{"title": "Controlling the Focus of Pretrained Language Generation Models", "url": "https://aclanthology.org/2022.findings-acl.260/", "abstract": "The finetuning of pretrained transformer-based language generation models are typically conducted in an end-to-end manner, where the model learns to attend to relevant parts of the input by itself. However, there does not exist a mechanism to directly control the model’s focus. This work aims to develop a control mechanism by which a user can select spans of context as “highlights” for the model to focus on, and generate relevant output. To achieve this goal, we augment a pretrained model with trainable “focus vectors” that are directly applied to the model’s embeddings, while the model itself is kept fixed. These vectors, trained on automatic annotations derived from attribution methods, act as indicators for context importance. We test our approach on two core generation tasks: dialogue response generation and abstractive summarization. We also collect evaluation data where the highlight-generation pairs are annotated by humans. Our experiments show that the trained focus vectors are effective in steering the model to generate outputs that are relevant to user-selected highlights.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済み言語生成モデルの焦点制御", "jabstract": "事前学習されたトランスフォーマーベースの言語生成モデルの微調整は、通常、モデルが自ら入力の関連部分に注意を払うように学習するエンドツーエンドの方法で行われます。しかし、モデルの焦点を直接制御するメカニズムは存在しません。本研究は、ユーザーがモデルが焦点を合わせる「ハイライト」としてコンテキストのスパンを選択し、関連する出力を生成する制御メカニズムを開発することを目的としています。この目標を達成するために、モデル自体は固定されたまま、モデルの埋め込みに直接適用されるトレーニング可能な「焦点ベクトル」を事前学習されたモデルに追加します。これらのベクトルは、属性付け方法から派生した自動注釈でトレーニングされ、コンテキストの重要性の指標として機能します。私たちは、対話応答生成と要約生成の2つのコア生成タスクでアプローチをテストしました。また、ハイライト生成ペアが人間によって注釈付けされた評価データを収集しました。私たちの実験は、トレーニングされた焦点ベクトルが、ユーザーが選択したハイライトに関連する出力を生成するためにモデルを効果的に誘導することを示しています。"}
{"title": "Comparative Opinion Summarization via Collaborative Decoding", "url": "https://aclanthology.org/2022.findings-acl.261/", "abstract": "Opinion summarization focuses on generating summaries that reflect popular subjective information expressed in multiple online reviews.While generated summaries offer general and concise information about a particular hotel or product, the information may be insufficient to help the user compare multiple different choices.Thus, the user may still struggle with the question “Which one should I pick?” In this paper, we propose the comparative opinion summarization task, which aims at generating two contrastive summaries and one common summary from two different candidate sets of reviews.We develop a comparative summarization framework CoCoSum, which consists of two base summarization models that jointly generate contrastive and common summaries.Experimental results on a newly created benchmark CoCoTrip show that CoCoSum can produce higher-quality contrastive and common summaries than state-of-the-art opinion summarization models.The dataset and code are available at https://github.com/megagonlabs/cocosum", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "協調デコーディングを通じた比較的な意見要約化", "jabstract": "意見要約は、複数のオンラインレビューで表現された人気のある主観的情報を反映する要約を生成することに焦点を当てています。生成された要約は、特定のホテルや製品に関する一般的で簡潔な情報を提供しますが、情報が不十分であり、ユーザーが複数の異なる選択肢を比較するのに役立たない場合があります。したがって、ユーザーはまだ「どれを選ぶべきか」という問題に苦しむかもしれません。本論文では、2つの異なる候補のレビューセットから2つの対比的な要約と1つの共通要約を生成する比較的意見要約タスクを提案します。我々は、対比的および共通要約を共同で生成する2つのベース要約モデルから構成される比較要約フレームワークCoCoSumを開発しました。新しく作成されたベンチマークCoCoTripでの実験結果は、CoCoSumが最先端の意見要約モデルよりも高品質な対比的および共通要約を生成できることを示しています。データセットとコードはhttps://github.com/megagonlabs/cocosumで利用可能です。"}
{"title": "IsoScore: Measuring the Uniformity of Embedding Space Utilization", "url": "https://aclanthology.org/2022.findings-acl.262/", "abstract": "The recent success of distributed word representations has led to an increased interest in analyzing the properties of their spatial distribution. Several studies have suggested that contextualized word embedding models do not isotropically project tokens into vector space. However, current methods designed to measure isotropy, such as average random cosine similarity and the partition score, have not been thoroughly analyzed and are not appropriate for measuring isotropy. We propose IsoScore: a novel tool that quantifies the degree to which a point cloud uniformly utilizes the ambient vector space. Using rigorously designed tests, we demonstrate that IsoScore is the only tool available in the literature that accurately measures how uniformly distributed variance is across dimensions in vector space. Additionally, we use IsoScore to challenge a number of recent conclusions in the NLP literature that have been derived using brittle metrics of isotropy. We caution future studies from using existing tools to measure isotropy in contextualized embedding space as resulting conclusions will be misleading or altogether inaccurate.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "IsoScore：埋め込み空間の利用の均一性を測定する方法", "jabstract": "分散表現の成功により、その空間分布の特性を分析することに興味が高まっています。いくつかの研究は、文脈依存の単語埋め込みモデルがトークンをベクトル空間に等方的に投影しないことを示唆しています。しかし、平均ランダムコサイン類似度や分割スコアなどの等方性を測定するために設計された現在の方法は、十分に分析されておらず、等方性を測定するために適切ではありません。本研究では、周囲のベクトル空間を均等に利用する点群の度合いを定量化する新しいツール「IsoScore」を提案します。厳密に設計されたテストを使用して、IsoScoreがベクトル空間の次元間で分散が均等に分布しているかどうかを正確に測定することができることを示します。さらに、IsoScoreを使用して、脆弱な等方性のメトリックを使用して導かれたNLP文献の最近の結論に疑問を投げかけます。既存のツールを使用して文脈依存の埋め込み空間で等方性を測定することは、結果的に誤解を招くか、完全に不正確な結論を導く可能性があるため、将来の研究に注意を促します。"}
{"title": "A Natural Diet: Towards Improving Naturalness of Machine Translation Output", "url": "https://aclanthology.org/2022.findings-acl.263/", "abstract": "Machine translation (MT) evaluation often focuses on accuracy and fluency, without paying much attention to translation style. This means that, even when considered accurate and fluent, MT output can still sound less natural than high quality human translations or text originally written in the target language. Machine translation output notably exhibits lower lexical diversity, and employs constructs that mirror those in the source sentence. In this work we propose a method for training MT systems to achieve a more natural style, i.e. mirroring the style of text originally written in the target language. Our method tags parallel training data according to the naturalness of the target side by contrasting language models trained on natural and translated data. Tagging data allows us to put greater emphasis on target sentences originally written in the target language. Automatic metrics show that the resulting models achieve lexical richness on par with human translations, mimicking a style much closer to sentences originally written in the target language. Furthermore, we find that their output is preferred by human experts when compared to the baseline translations.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然な食事：機械翻訳の自然さ向上に向けて\n\nAbstract: This paper proposes a novel approach to improve the naturalness of machine translation output by incorporating natural language processing techniques into the translation process. Specifically, we focus on the use of natural language generation models to generate more fluent and natural-sounding translations. We evaluate our approach on a standard benchmark dataset and show that it outperforms existing state-of-the-art methods in terms of naturalness and fluency. Our results suggest that incorporating natural language processing techniques into machine translation can lead to significant improvements in the quality of translation output. \n\n要旨：本論文では、自然言語処理技術を翻訳プロセスに取り入れることで、機械翻訳の自然さを向上させる新しいアプローチを提案します。具体的には、自然言語生成モデルを使用して、より流暢で自然な翻訳を生成することに焦点を当てます。標準的なベンチマークデータセットでアプローチを評価し、自然さと流暢さの面で既存の最先端の方法を上回ることを示します。結果から、自然言語処理技術を機械翻訳に取り入れることで、翻訳の品質を大幅に向上させることができることが示唆されます。", "jabstract": "機械翻訳（MT）の評価は、しばしば正確性と流暢さに焦点を当てており、翻訳スタイルにはあまり注意が払われていません。つまり、正確で流暢であっても、MTの出力は、高品質の人間による翻訳や、ターゲット言語で元々書かれたテキストよりも自然さに欠ける場合があります。機械翻訳の出力は、特に語彙の多様性が低く、ソース文と同様の構造を使用します。本研究では、より自然なスタイル、つまりターゲット言語で元々書かれたテキストのスタイルを反映するMTシステムのトレーニング方法を提案します。私たちの方法は、自然言語と翻訳されたデータでトレーニングされた言語モデルを対比して、並列トレーニングデータを自然さに基づいてタグ付けすることです。データのタグ付けにより、ターゲット言語で元々書かれた文に重点を置くことができます。自動メトリックによると、結果として得られるモデルは、人間による翻訳と同等の語彙豊かさを実現し、ターゲット言語で元々書かれた文に近いスタイルを模倣します。さらに、ベースライン翻訳と比較して、人間の専門家によってその出力が好まれることがわかりました。"}
{"title": "From Stance to Concern: Adaptation of Propositional Analysis to New Tasks and Domains", "url": "https://aclanthology.org/2022.findings-acl.264/", "abstract": "We present a generalized paradigm for adaptation of propositional analysis (predicate-argument pairs) to new tasks and domains. We leverage an analogy between stances (belief-driven sentiment) and concerns (topical issues with moral dimensions/endorsements) to produce an explanatory representation. A key contribution is the combination of semi-automatic resource building for extraction of domain-dependent concern types (with 2-4 hours of human labor per domain) and an entirely automatic procedure for extraction of domain-independent moral dimensions and endorsement values. Prudent (automatic) selection of terms from propositional structures for lexical expansion (via semantic similarity) produces new moral dimension lexicons at three levels of granularity beyond a strong baseline lexicon. We develop a ground truth (GT) based on expert annotators and compare our concern detection output to GT, to yield 231% improvement in recall over baseline, with only a 10% loss in precision. F1 yields 66% improvement over baseline and 97.8% of human performance. Our lexically based approach yields large savings over approaches that employ costly human labor and model building. We provide to the community a newly expanded moral dimension/value lexicon, annotation guidelines, and GT.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「スタンスから関心へ：新しいタスクとドメインに対応する命題分析の適応」は、自然言語処理に関する論文の要約である。", "jabstract": "私たちは、命題分析（述語-引数ペア）を新しいタスクやドメインに適応するための一般化されたパラダイムを提案します。私たちは、スタンス（信念に基づく感情）と関心（道徳的な次元/支持を持つトピック）の類似点を利用して、説明的な表現を生成します。主要な貢献は、ドメイン依存の関心タイプの抽出のための半自動的なリソース構築（ドメインごとに2-4時間の人的労力を必要とする）と、ドメインに依存しない道徳的な次元と支持値の抽出のための完全自動的な手順の組み合わせです。命題構造から語彙の拡張（意味的類似性を介した）のための慎重な（自動的な）用語の選択は、強力なベースライン語彙を超えた3つの粒度レベルで新しい道徳的な次元語彙を生成します。私たちは、専門家の注釈者に基づくグラウンドトゥルース（GT）を開発し、私たちの関心検出の出力をGTと比較して、ベースラインに対して再現率が231％向上し、精度はわずか10％の損失しかありません。F1は、ベースラインに比べて66％の改善を示し、人間のパフォーマンスの97.8％を達成します。私たちの語彙ベースのアプローチは、高価な人的労力やモデル構築を必要とするアプローチに比べて大幅なコスト削減を実現します。私たちは、コミュニティに新しく拡張された道徳的な次元/価値語彙、注釈ガイドライン、およびGTを提供します。"}
{"title": "CUE Vectors: Modular Training of Language Models Conditioned on Diverse Contextual Signals", "url": "https://aclanthology.org/2022.findings-acl.265/", "abstract": "We propose a framework to modularize the training of neural language models that use diverse forms of context by eliminating the need to jointly train context and within-sentence encoders. Our approach, contextual universal embeddings (CUE), trains LMs on one type of contextual data and adapts to novel context types. The model consists of a pretrained neural sentence LM, a BERT-based contextual encoder, and a masked transfomer decoder that estimates LM probabilities using sentence-internal and contextual evidence.When contextually annotated data is unavailable, our model learns to combine contextual and sentence-internal information using noisy oracle unigram embeddings as a proxy. Real context data can be introduced later and used to adapt a small number of parameters that map contextual data into the decoder’s embedding space. We validate the CUE framework on a NYTimes text corpus with multiple metadata types, for which the LM perplexity can be lowered from 36.6 to 27.4 by conditioning on context. Bootstrapping a contextual LM with only a subset of the metadata during training retains 85% of the achievable gain. Training the model initially with proxy context retains 67% of the perplexity gain after adapting to real context. Furthermore, we can swap one type of pretrained sentence LM for another without retraining the context encoders, by only adapting the decoder model. Overall, we obtain a modular framework that allows incremental, scalable training of context-enhanced LMs.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CUEベクトル：多様な文脈信号に基づく言語モデルのモジュール式トレーニング", "jabstract": "私たちは、文脈と文内エンコーダーを共同でトレーニングする必要をなくし、多様な文脈形式を使用するニューラル言語モデルのトレーニングをモジュール化するためのフレームワークを提案します。私たちのアプローチ、コンテキストユニバーサルエンベディング（CUE）は、1つのタイプの文脈データでLMをトレーニングし、新しい文脈タイプに適応します。モデルは、事前にトレーニングされたニューラル文LM、BERTベースのコンテキストエンコーダー、および文内および文脈的証拠を使用してLM確率を推定するマスクされたトランスフォーマーデコーダーで構成されています。文脈的に注釈されたデータが利用できない場合、私たちのモデルは、ノイズの多いオラクルユニグラムエンベディングをプロキシとして使用して、文脈と文内情報を組み合わせる方法を学習します。実際の文脈データは後で導入され、文脈データをデコーダーの埋め込み空間にマップする少数のパラメータを適応するために使用できます。私たちは、LMのperplexityを36.6から27.4に下げることができるNYTimesテキストコーパスでCUEフレームワークを検証します。トレーニング中にメタデータのサブセットのみを使用してコンテキストLMをブートストラップすると、達成可能な利益の85％を保持できます。プロキシコンテキストで最初にモデルをトレーニングすると、実際のコンテキストに適応した後にperplexityの利益の67％を保持できます。さらに、文脈エンコーダーを再トレーニングすることなく、事前にトレーニングされた1つのタイプの文LMを別のタイプに交換することができます。全体的に、私たちは、文脈強化LMのインクリメンタルでスケーラブルなトレーニングを可能にするモジュラーフレームワークを得ました。"}
{"title": "Cross-Lingual UMLS Named Entity Linking using UMLS Dictionary Fine-Tuning", "url": "https://aclanthology.org/2022.findings-acl.266/", "abstract": "We study cross-lingual UMLS named entity linking, where mentions in a given source language are mapped to UMLS concepts, most of which are labeled in English. Our cross-lingual framework includes an offline unsupervised construction of a translated UMLS dictionary and a per-document pipeline which identifies UMLS candidate mentions and uses a fine-tuned pretrained transformer language model to filter candidates according to context. Our method exploits a small dataset of manually annotated UMLS mentions in the source language and uses this supervised data in two ways: to extend the unsupervised UMLS dictionary and to fine-tune the contextual filtering of candidate mentions in full documents.We demonstrate results of our approach on both Hebrew and English. We achieve new state-of-the-art (SOTA) results on the Hebrew Camoni corpus, +8.9 F1 on average across three communities in the dataset. We also achieve new SOTA on the English dataset MedMentions with +7.3 F1.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "UMLS辞書の微調整を用いたクロスリンガルUMLS固有表現リンキング", "jabstract": "私たちは、与えられたソース言語のメンションをUMLSコンセプトにマッピングするクロスリンガルUMLS固有表現リンキングを研究しています。ほとんどのUMLSコンセプトは英語でラベル付けされています。私たちのクロスリンガルフレームワークには、翻訳されたUMLS辞書のオフライン非監督構築と、UMLS候補メンションを識別し、文脈に応じて候補をフィルタリングするために事前に微調整されたトランスフォーマー言語モデルを使用するドキュメントごとのパイプラインが含まれています。私たちの方法は、ソース言語の手動注釈付きUMLSメンションの小規模なデータセットを利用し、この監視されたデータを2つの方法で使用しています。非監視UMLS辞書を拡張し、フルドキュメント内の候補メンションの文脈フィルタリングを微調整するためです。私たちは、ヘブライ語と英語の両方でアプローチの結果を示しています。ヘブライ語のCamoniコーパスでは、データセット内の3つのコミュニティ全体で平均+8.9 F1の新しい最先端（SOTA）の結果を達成しました。また、英語のデータセットMedMentionsでも+7.3 F1の新しいSOTAを達成しました。"}
{"title": "Aligned Weight Regularizers for Pruning Pretrained Neural Networks", "url": "https://aclanthology.org/2022.findings-acl.267/", "abstract": "Pruning aims to reduce the number of parameters while maintaining performance close to the original network. This work proposes a novel self-distillation based pruning strategy, whereby the representational similarity between the pruned and unpruned versions of the same network is maximized. Unlike previous approaches that treat distillation and pruning separately, we use distillation to inform the pruning criteria, without requiring a separate student network as in knowledge distillation. We show that the proposed cross-correlation objective for self-distilled pruning implicitly encourages sparse solutions, naturally complementing magnitude-based pruning criteria. Experiments on the GLUE and XGLUE benchmarks show that self-distilled pruning increases mono- and cross-lingual language model performance. Self-distilled pruned models also outperform smaller Transformers with an equal number of parameters and are competitive against (6 times) larger distilled networks. We also observe that self-distillation (1) maximizes class separability, (2) increases the signal-to-noise ratio, and (3) converges faster after pruning steps, providing further insights into why self-distilled pruning improves generalization.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済みニューラルネットワークの剪定のためのアラインドウェイトレギュラライザー", "jabstract": "剪定は、元のネットワークに近い性能を維持しながらパラメータの数を減らすことを目的としています。本研究では、同じネットワークの剪定前と剪定後の表現の類似性を最大化する新しい自己蒸留ベースの剪定戦略を提案しています。蒸留と剪定を別々に扱う従来の手法とは異なり、知識蒸留のように別個の生徒ネットワークを必要とせず、蒸留を剪定基準に反映させるために蒸留を使用します。自己蒸留剪定のための提案された相互相関目的は、従来の大きさベースの剪定基準を自然に補完するように、疎な解を暗黙的に促進することを示しています。GLUEおよびXGLUEベンチマークの実験では、自己蒸留剪定により、単言語および多言語言語モデルの性能が向上することが示されました。自己蒸留剪定されたモデルは、同じパラメータ数を持つより小さなトランスフォーマーを上回り、（6倍）大きな蒸留ネットワークに対して競争力があります。また、自己蒸留は（1）クラスの分離度を最大化し、（2）信号対雑音比を増加させ、（3）剪定ステップ後により速く収束することが観察され、自己蒸留剪定が一般化を改善する理由についてのさらなる洞察を提供します。"}
{"title": "Consistent Representation Learning for Continual Relation Extraction", "url": "https://aclanthology.org/2022.findings-acl.268/", "abstract": "Continual relation extraction (CRE) aims to continuously train a model on data with new relations while avoiding forgetting old ones. Some previous work has proved that storing a few typical samples of old relations and replaying them when learning new relations can effectively avoid forgetting. However, these memory-based methods tend to overfit the memory samples and perform poorly on imbalanced datasets. To solve these challenges, a consistent representation learning method is proposed, which maintains the stability of the relation embedding by adopting contrastive learning and knowledge distillation when replaying memory. Specifically, supervised contrastive learning based on a memory bank is first used to train each new task so that the model can effectively learn the relation representation. Then, contrastive replay is conducted of the samples in memory and makes the model retain the knowledge of historical relations through memory knowledge distillation to prevent the catastrophic forgetting of the old task. The proposed method can better learn consistent representations to alleviate forgetting effectively. Extensive experiments on FewRel and TACRED datasets show that our method significantly outperforms state-of-the-art baselines and yield strong robustness on the imbalanced dataset.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "継続的な関係抽出のための一貫した表現学習", "jabstract": "Continual relation extraction (CRE)は、新しい関係を持つデータでモデルを継続的にトレーニングする一方で、古い関係を忘れることを避けることを目的としています。以前の研究では、古い関係のいくつかの典型的なサンプルを保存し、新しい関係を学習する際に再生することで、忘却を効果的に回避できることが証明されています。しかし、これらのメモリベースの方法は、メモリサンプルに過剰に適合し、不均衡なデータセットで性能が低下する傾向があります。これらの課題を解決するために、一貫した表現学習方法が提案されており、関係の埋め込みの安定性を維持するために、コントラスティブ学習と知識蒸留を採用してメモリを再生します。具体的には、メモリバンクに基づく教師ありコントラスティブ学習を最初に使用して、モデルが関係表現を効果的に学習できるようにします。次に、メモリ内のサンプルをコントラスティブに再生し、メモリ知識蒸留によって歴史的な関係の知識を保持し、古いタスクの壊滅的な忘却を防止します。提案された方法は、一貫した表現をよりよく学習して、忘却を効果的に緩和することができます。FewRelとTACREDデータセットでの広範な実験により、提案手法が最先端のベースラインを大幅に上回り、不均衡なデータセットで強い堅牢性を発揮することが示されました。"}
{"title": "Event Transition Planning for Open-ended Text Generation", "url": "https://aclanthology.org/2022.findings-acl.269/", "abstract": "Open-ended text generation tasks, such as dialogue generation and story completion, require models to generate a coherent continuation given limited preceding context. The open-ended nature of these tasks brings new challenges to the neural auto-regressive text generators nowadays. Despite these neural models are good at producing human-like text, it is difficult for them to arrange causalities and relations between given facts and possible ensuing events. To bridge this gap, we propose a novel two-stage method which explicitly arranges the ensuing events in open-ended text generation. Our approach can be understood as a specially-trained coarse-to-fine algorithm, where an event transition planner provides a “coarse” plot skeleton and a text generator in the second stage refines the skeleton. Experiments on two open-ended text generation tasks demonstrate that our proposed method effectively improves the quality of the generated text, especially in coherence and diversity. We will release the codes to the community for further exploration.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "オープンエンドテキスト生成のためのイベント遷移計画", "jabstract": "オープンエンドのテキスト生成タスク、例えば対話生成やストーリーの完結、は、限られた前提文脈が与えられた場合に、モデルが継続的な文を生成する必要があります。これらのタスクのオープンエンドの性質は、現在のニューラル自己回帰テキストジェネレータに新しい課題をもたらします。これらのニューラルモデルは人間らしいテキストを生成するのに優れていますが、与えられた事実と可能な結果の関係を整理することは難しいです。このギャップを埋めるために、私たちはオープンエンドのテキスト生成において明示的に結果のイベントを配置する新しい2段階の方法を提案します。私たちのアプローチは、イベントの移行プランナーが「粗い」プロットの骨格を提供し、2段階目のテキストジェネレータが骨格を洗練するという特別にトレーニングされたコーストゥファインアルゴリズムとして理解できます。2つのオープンエンドのテキスト生成タスクでの実験は、私たちの提案手法が生成されたテキストの品質を効果的に改善し、特に一貫性と多様性に優れていることを示しています。私たちは、コミュニティにコードを公開して、さらなる探索を促します。"}
{"title": "Comprehensive Multi-Modal Interactions for Referring Image Segmentation", "url": "https://aclanthology.org/2022.findings-acl.270/", "abstract": "We investigate Referring Image Segmentation (RIS), which outputs a segmentation map corresponding to the natural language description. Addressing RIS efficiently requires considering the interactions happening across visual and linguistic modalities and the interactions within each modality. Existing methods are limited because they either compute different forms of interactions sequentially (leading to error propagation) or ignore intra-modal interactions. We address this limitation by performing all three interactions simultaneously through a Synchronous Multi-Modal Fusion Module (SFM). Moreover, to produce refined segmentation masks, we propose a novel Hierarchical Cross-Modal Aggregation Module (HCAM), where linguistic features facilitate the exchange of contextual information across the visual hierarchy. We present thorough ablation studies and validate our approach’s performance on four benchmark datasets, showing considerable performance gains over the existing state-of-the-art (SOTA) methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「画像セグメンテーションを参照するための包括的なマルチモーダルインタラクション」", "jabstract": "私たちは、自然言語の説明に対応するセグメンテーションマップを出力するReferring Image Segmentation（RIS）を調査しています。RISに効率的に対処するには、視覚的および言語的モダリティ間および各モダリティ内で発生する相互作用を考慮する必要があります。既存の方法は、異なる形式の相互作用を順次計算するか（エラー伝播を引き起こす）、または内部モダリティの相互作用を無視するため、限界があります。私たちは、Synchronous Multi-Modal Fusion Module（SFM）を介してすべての3つの相互作用を同時に実行することによって、この制限に対処します。さらに、洗練されたセグメンテーションマスクを生成するために、私たちは、言語的特徴が視覚的階層を横断する文脈情報の交換を促進する新しいHierarchical Cross-Modal Aggregation Module（HCAM）を提案します。私たちは、徹底的な削除研究を提示し、4つのベンチマークデータセットで私たちのアプローチのパフォーマンスを検証し、既存の最先端（SOTA）の方法に比べてかなりのパフォーマンス向上を示します。"}
{"title": "MetaWeighting: Learning to Weight Tasks in Multi-Task Learning", "url": "https://aclanthology.org/2022.findings-acl.271/", "abstract": "Task weighting, which assigns weights on the including tasks during training, significantly matters the performance of Multi-task Learning (MTL); thus, recently, there has been an explosive interest in it. However, existing task weighting methods assign weights only based on the training loss, while ignoring the gap between the training loss and generalization loss. It degenerates MTL’s performance. To address this issue, the present paper proposes a novel task weighting algorithm, which automatically weights the tasks via a learning-to-learn paradigm, referred to as MetaWeighting. Extensive experiments are conducted to validate the superiority of our proposed method in multi-task text classification.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MetaWeighting：マルチタスク学習におけるタスクの重み付けを学習する", "jabstract": "トレーニング中に含まれるタスクに重みを割り当てるタスクウェイトは、マルチタスク学習（MTL）のパフォーマンスに重要な影響を与えるため、最近、爆発的な関心が寄せられています。しかし、既存のタスクウェイト方法は、トレーニング損失に基づいて重みを割り当てるだけであり、トレーニング損失と汎化損失の間のギャップを無視しています。これはMTLのパフォーマンスを低下させます。この問題に対処するため、本論文では、学習から学習するパラダイムでタスクを自動的に重み付けする新しいタスクウェイトアルゴリズム、MetaWeightingを提案しています。多数の実験を行い、提案手法がマルチタスクテキスト分類において優れた性能を発揮することを検証しました。"}
{"title": "Improving Controllable Text Generation with Position-Aware Weighted Decoding", "url": "https://aclanthology.org/2022.findings-acl.272/", "abstract": "Weighted decoding methods composed of the pretrained language model (LM) and the controller have achieved promising results for controllable text generation. However, these models often suffer from a control strength/fluency trade-off problem as higher control strength is more likely to generate incoherent and repetitive text. In this paper, we illustrate this trade-off is arisen by the controller imposing the target attribute on the LM at improper positions. And we propose a novel framework based on existing weighted decoding methods called CAT-PAW, which introduces a lightweight regulator to adjust bias signals from the controller at different decoding positions. Experiments on positive sentiment control, topic control, and language detoxification show the effectiveness of our CAT-PAW upon 4 SOTA models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「位置感知重み付きデコーディングによる制御可能なテキスト生成の改善」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Improving Controllable Text Generation with Position-Aware Weighted Decoding\n- 位置感知重み付きデコーディングによる制御可能なテキスト生成の改善", "jabstract": "事前学習された言語モデル（LM）とコントローラから構成される重み付きデコーディング手法は、制御可能なテキスト生成において有望な結果を示しています。しかし、これらのモデルは、制御力と流暢性のトレードオフ問題に苦しむことが多く、制御力が高いほど不連続で繰り返しの多いテキストを生成する可能性が高くなります。本論文では、このトレードオフが、コントローラがLMに対して不適切な位置で目標属性を課すことによって引き起こされることを示します。そして、我々は既存の重み付きデコーディング手法に基づく新しいフレームワークであるCAT-PAWを提案し、軽量なレギュレータを導入して、コントローラからのバイアス信号を異なるデコーディング位置で調整します。ポジティブな感情制御、トピック制御、言語解毒の実験により、CAT-PAWが4つのSOTAモデルに対して有効であることが示されました。"}
{"title": "Prompt Tuning for Discriminative Pre-trained Language Models", "url": "https://aclanthology.org/2022.findings-acl.273/", "abstract": "Recent works have shown promising results of prompt tuning in stimulating pre-trained language models (PLMs) for natural language processing (NLP) tasks. However, to the best of our knowledge, existing works focus on prompt-tuning generative PLMs that are pre-trained to generate target tokens, such as BERT. It is still unknown whether and how discriminative PLMs, e.g., ELECTRA, can be effectively prompt-tuned. In this work, we present DPT, the first prompt tuning framework for discriminative PLMs, which reformulates NLP tasks into a discriminative language modeling problem. Comprehensive experiments on text classification and question answering show that, compared with vanilla fine-tuning, DPT achieves significantly higher performance, and also prevents the unstable problem in tuning large PLMs in both full-set and low-resource settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nPrompt Tuning for Discriminative Pre-trained Language Models\n\n識別的事前学習言語モデルのためのプロンプト調整", "jabstract": "最近の研究では、プロンプトチューニングが事前学習言語モデル（PLM）を刺激するために自然言語処理（NLP）タスクで有望な結果を示している。しかし、私たちの知る限り、既存の研究は、BERTなどのターゲットトークンを生成するために事前学習された生成型PLMに焦点を当てている。ELECTRAなどの識別型PLMがどのようにして効果的にプロンプトチューニングできるかはまだ不明である。本研究では、NLPタスクを識別型言語モデリング問題に再定式化するDPTという最初のプロンプトチューニングフレームワークを提案する。テキスト分類と質問応答に関する包括的な実験では、バニラファインチューニングと比較して、DPTは有意に高い性能を発揮し、フルセットと低リソースの両方の設定で大規模PLMのチューニングにおける不安定な問題を防止することも示された。"}
{"title": "Two Birds with One Stone: Unified Model Learning for Both Recall and Ranking in News Recommendation", "url": "https://aclanthology.org/2022.findings-acl.274/", "abstract": "Recall and ranking are two critical steps in personalized news recommendation. Most existing news recommender systems conduct personalized news recall and ranking separately with different models. However, maintaining multiple models leads to high computational cost and poses great challenges to meeting the online latency requirement of news recommender systems. In order to handle this problem, in this paper we propose UniRec, a unified method for recall and ranking in news recommendation. In our method, we first infer user embedding for ranking from the historical news click behaviors of a user using a user encoder model. Then we derive the user embedding for recall from the obtained user embedding for ranking by using it as the attention query to select a set of basis user embeddings which encode different general user interests and synthesize them into a user embedding for recall. The extensive experiments on benchmark dataset demonstrate that our method can improve both efficiency and effectiveness for recall and ranking in news recommendation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「一石二鳥：ニュース推薦におけるリコールとランキングの両方のための統一モデル学習」は、自然言語処理に関する論文の要約です。", "jabstract": "個人化ニュース推薦において、リコールとランキングは2つの重要なステップである。既存のニュース推薦システムの多くは、異なるモデルを使用して個人化ニュースリコールとランキングを別々に実行する。しかし、複数のモデルを維持することは高い計算コストを引き起こし、ニュース推薦システムのオンラインレイテンシ要件を満たすために大きな課題を提起する。この問題を解決するために、本論文では、ニュース推薦におけるリコールとランキングのための統一された方法であるUniRecを提案する。我々の方法では、ユーザーエンコーダーモデルを使用して、ユーザーの過去のニュースクリック行動からランキングのためのユーザー埋め込みを推論する。次に、リコールのためのユーザー埋め込みを、ランキングのためのユーザー埋め込みを注意クエリとして使用して、異なる一般的なユーザーの興味をエンコードする一連の基本的なユーザー埋め込みを選択し、それらを合成してリコールのためのユーザー埋め込みを導出する。ベンチマークデータセット上の広範な実験は、我々の方法がニュース推薦におけるリコールとランキングの両方の効率性と効果性を向上させることができることを示している。"}
{"title": "What does it take to bake a cake? The RecipeRef corpus and anaphora resolution in procedural text", "url": "https://aclanthology.org/2022.findings-acl.275/", "abstract": "Procedural text contains rich anaphoric phenomena, yet has not received much attention in NLP. To fill this gap, we investigate the textual properties of two types of procedural text, recipes and chemical patents, and generalize an anaphora annotation framework developed for the chemical domain for modeling anaphoric phenomena in recipes. We apply this framework to annotate the RecipeRef corpus with both bridging and coreference relations. Through comparison to chemical patents, we show the complexity of anaphora resolution in recipes. We demonstrate empirically that transfer learning from the chemical domain improves resolution of anaphora in recipes, suggesting transferability of general procedural knowledge.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ケーキを焼くには何が必要ですか？RecipeRefコーパスと手順テキストにおける照応解析", "jabstract": "手順テキストには豊富な照応現象が含まれているが、NLPではあまり注目されていない。このギャップを埋めるために、レシピと化学特許の2種類の手順テキストのテキスト特性を調査し、化学ドメインの照応注釈フレームワークを一般化して、レシピの照応現象をモデリングする。このフレームワークを使用して、RecipeRefコーパスにブリッジングと共参照関係の両方を注釈付けする。化学特許と比較することで、レシピの照応解決の複雑さを示す。化学ドメインからの転移学習がレシピの照応解決を改善することを実証し、一般的な手順知識の転移可能性を示唆する。"}
{"title": "MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning", "url": "https://aclanthology.org/2022.findings-acl.276/", "abstract": "Logical reasoning is of vital importance to natural language understanding. Previous studies either employ graph-based models to incorporate prior knowledge about logical relations, or introduce symbolic logic into neural models through data augmentation. These methods, however, heavily depend on annotated training data, and thus suffer from over-fitting and poor generalization problems due to the dataset sparsity. To address these two problems, in this paper, we propose MERIt, a MEta-path guided contrastive learning method for logical ReasonIng of text, to perform self-supervised pre-training on abundant unlabeled text data. Two novel strategies serve as indispensable components of our method. In particular, a strategy based on meta-path is devised to discover the logical structure in natural texts, followed by a counterfactual data augmentation strategy to eliminate the information shortcut induced by pre-training. The experimental results on two challenging logical reasoning benchmarks, i.e., ReClor and LogiQA, demonstrate that our method outperforms the SOTA baselines with significant improvements.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "MERIt：論理推論のためのメタパスガイド対照学習", "jabstract": "論理推論は自然言語理解にとって極めて重要である。従来の研究では、論理関係に関する事前知識を組み込むためにグラフベースのモデルを使用するか、データ拡張を通じてシンボリックロジックをニューラルモデルに導入する。しかしながら、これらの方法はアノテーションされたトレーニングデータに大きく依存しており、データセットの疎密性による過学習や一般化の問題に苦しんでいる。本論文では、これらの2つの問題に対処するために、豊富な未ラベルのテキストデータに対して自己教師ありプレトレーニングを実行するためのMEta-path guided contrastive learning method for logical ReasonIng of text（MERIt）を提案する。2つの新しい戦略が我々の方法の不可欠な構成要素として機能する。特に、自然言語の論理構造を発見するためのメタパスに基づく戦略が考案され、その後、プレトレーニングによって誘発される情報ショートカットを排除するための反事実的なデータ拡張戦略が続く。ReClorとLogiQAという2つの難解な論理推論ベンチマークにおける実験結果は、我々の方法がSOTAベースラインを大幅に上回ることを示している。"}
{"title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption", "url": "https://aclanthology.org/2022.findings-acl.277/", "abstract": "As more and more pre-trained language models adopt on-cloud deployment, the privacy issues grow quickly, mainly for the exposure of plain-text user data (e.g., search history, medical record, bank account). Privacy-preserving inference of transformer models is on the demand of cloud service users. To protect privacy, it is an attractive choice to compute only with ciphertext in homomorphic encryption (HE). However, enabling pre-trained models inference on ciphertext data is difficult due to the complex computations in transformer blocks, which are not supported by current HE tools yet. In this work, we introduce THE-X, an approximation approach for transformers, which enables privacy-preserving inference of pre-trained models developed by popular frameworks. THE-X proposes a workflow to deal with complex computation in transformer networks, including all the non-polynomial functions like GELU, softmax, and LayerNorm. Experiments reveal our proposed THE-X can enable transformer inference on encrypted data for different downstream tasks, all with negligible performance drop but enjoying the theory-guaranteed privacy-preserving advantage.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "THE-X：ホモモーフィック暗号化によるプライバシー保護トランスフォーマー推論", "jabstract": "事前学習済み言語モデルがクラウド展開されるにつれ、プライバシー問題が急速に増加しています。主に、平文のユーザーデータ（検索履歴、医療記録、銀行口座など）が公開されることが原因です。トランスフォーマーモデルのプライバシー保護推論は、クラウドサービスのユーザーにとって需要があります。プライバシーを保護するために、ホモモーフィック暗号（HE）での暗号化データのみを使用して計算することは魅力的な選択肢です。しかし、現在のHEツールではサポートされていないトランスフォーマーブロック内の複雑な計算のため、暗号化されたデータで事前学習済みモデルの推論を有効にすることは困難です。本研究では、人気のあるフレームワークで開発された事前学習済みモデルのプライバシー保護推論を可能にするTHE-Xという近似アプローチを紹介します。THE-Xは、GELU、softmax、LayerNormなどのすべての非多項式関数を含むトランスフォーマーネットワーク内の複雑な計算を処理するためのワークフローを提案します。実験により、THE-Xが異なる下流タスクで暗号化されたデータ上でトランスフォーマー推論を可能にし、理論的に保証されたプライバシー保護の利点を享受しながら、ほとんど性能低下がないことが明らかになりました。"}
{"title": "HLDC: Hindi Legal Documents Corpus", "url": "https://aclanthology.org/2022.findings-acl.278/", "abstract": "Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "HLDC: ヒンディー語法的文書コーパス\n\n1. This paper presents the development of a Hindi Legal Documents Corpus (HLDC) for natural language processing (NLP) tasks.\nこの論文では、自然言語処理（NLP）タスクのためのヒンディー語法的文書コーパス（HLDC）の開発について述べています。\n\n2. The HLDC consists of 1,000 legal documents from various domains, such as civil, criminal, and revenue.\nHLDCは、民事、刑事、収益などのさまざまなドメインから1,000の法的文書で構成されています。\n\n3. The corpus has been annotated with part-of-speech tags, named entities, and sentence boundaries.\nコーパスは、品詞タグ、固有名詞、文の境界線で注釈が付けられています。\n\n4. The HLDC can be used for various NLP tasks, such as information extraction, text classification, and machine translation.\nHLDCは、情報抽出、テキスト分類、機械翻訳などのさまざまなNLPタスクに使用できます。", "jabstract": "多くの人口のある国、特にインドは、多数の法的事件のバックログに苦しんでいます。法的文書を処理し、法律実務家を補完する自動化システムの開発は、これを緩和することができます。しかし、そのようなデータ駆動型システムを開発するために必要な高品質のコーパスが不足しています。特にヒンディー語などの低資源言語の場合、この問題はさらに顕著になります。本リソース論文では、900K以上のヒンディー語の法的文書からなるコーパスであるHindi Legal Documents Corpus（HLDC）を紹介します。文書はクリーニングされ、構造化され、下流アプリケーションの開発が可能になっています。さらに、コーパスのユースケースとして、保釈予測のタスクを紹介します。私たちは、複数のモデルを実験し、同じタスクに対してマルチタスク学習（MTL）ベースのモデルを提案します。MTLモデルは、保釈予測を主要なタスクとして、要約を補助的なタスクとして使用します。異なるモデルでの実験は、この領域でのさらなる研究の必要性を示唆しています。"}
{"title": "Rethinking Document-level Neural Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.279/", "abstract": "This paper does not aim at introducing a novel model for document-level neural machine translation. Instead, we head back to the original Transformer model and hope to answer the following question: Is the capacity of current models strong enough for document-level translation? Interestingly, we observe that the original Transformer with appropriate training techniques can achieve strong results for document translation, even with a length of 2000 words. We evaluate this model and several recent approaches on nine document-level datasets and two sentence-level datasets across six languages. Experiments show that document-level Transformer models outperforms sentence-level ones and many previous methods in a comprehensive set of metrics, including BLEU, four lexical indices, three newly proposed assistant linguistic indicators, and human evaluation.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「文書レベルのニューラル機械翻訳を再考する」", "jabstract": "この論文は、文書レベルのニューラル機械翻訳のための新しいモデルを紹介することを目的としていません。代わりに、私たちは元のTransformerモデルに戻り、次の質問に答えることを望んでいます：現在のモデルの容量は、文書レベルの翻訳に十分強力ですか？興味深いことに、適切なトレーニング技術を用いた元のTransformerは、2000語の長さでも文書翻訳に強力な結果を出すことができることが観察されました。私たちは、6つの言語にまたがる9つの文書レベルのデータセットと2つの文レベルのデータセットで、このモデルといくつかの最近のアプローチを評価しました。実験の結果、文書レベルのTransformerモデルは、BLEU、4つの語彙指標、3つの新しい補助言語指標、および人間の評価を含む包括的なメトリックのセットで、文レベルのモデルや以前の多くの手法よりも優れた結果を示しました。"}
{"title": "Incremental Intent Detection for Medical Domain with Contrast Replay Networks", "url": "https://aclanthology.org/2022.findings-acl.280/", "abstract": "Conventional approaches to medical intent detection require fixed pre-defined intent categories. However, due to the incessant emergence of new medical intents in the real world, such requirement is not practical. Considering that it is computationally expensive to store and re-train the whole data every time new data and intents come in, we propose to incrementally learn emerged intents while avoiding catastrophically forgetting old intents. We first formulate incremental learning for medical intent detection. Then, we employ a memory-based method to handle incremental learning. We further propose to enhance the method with contrast replay networks, which use multilevel distillation and contrast objective to address training data imbalance and medical rare words respectively. Experiments show that the proposed method outperforms the state-of-the-art model by 5.7% and 9.1% of accuracy on two benchmarks respectively.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Contrast Replay Networksを用いた医療ドメインにおけるインクリメンタルな意図検出", "jabstract": "医療意図検出における従来のアプローチは、固定された事前定義された意図カテゴリが必要である。しかし、現実世界で新しい医療意図が絶え間なく出現するため、この要件は実用的ではない。新しいデータと意図が入ってくるたびに、全データを保存して再トレーニングするのは計算コストが高いため、古い意図を忘れることなく新しい意図を段階的に学習することを提案する。まず、医療意図検出のための段階的学習を定式化する。次に、記憶ベースの方法を用いて段階的学習を処理する。さらに、トレーニングデータの不均衡と医療用語の希少性に対処するために、マルチレベル蒸留と対比目的を使用した対比再生ネットワークで方法を強化することを提案する。実験結果は、提案手法が2つのベンチマークにおいて、最先端のモデルよりもそれぞれ5.7％と9.1％の精度を上回ることを示している。"}
{"title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval", "url": "https://aclanthology.org/2022.findings-acl.281/", "abstract": "In this paper, we propose LaPraDoR, a pretrained dual-tower dense retriever that does not require any supervised data for training. Specifically, we first present Iterative Contrastive Learning (ICoL) that iteratively trains the query and document encoders with a cache mechanism. ICoL not only enlarges the number of negative instances but also keeps representations of cached examples in the same hidden space. We then propose Lexicon-Enhanced Dense Retrieval (LEDR) as a simple yet effective way to enhance dense retrieval with lexical matching. We evaluate LaPraDoR on the recently proposed BEIR benchmark, including 18 datasets of 9 zero-shot text retrieval tasks. Experimental results show that LaPraDoR achieves state-of-the-art performance compared with supervised dense retrieval models, and further analysis reveals the effectiveness of our training strategy and objectives. Compared to re-ranking, our lexicon-enhanced approach can be run in milliseconds (22.5x faster) while achieving superior performance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "LaPraDoR：ゼロショットテキスト検索のための非監視事前学習密集リトリーバー", "jabstract": "本論文では、教師なしデータを必要としない事前学習されたデュアルタワー密集リトリーバーであるLaPraDoRを提案する。具体的には、キャッシュメカニズムを用いてクエリエンコーダーとドキュメントエンコーダーを反復的にトレーニングするIterative Contrastive Learning（ICoL）を最初に提案する。ICoLは、負のインスタンスの数を増やすだけでなく、キャッシュされた例の表現を同じ隠れ空間に保持する。次に、レキシコン強化密集リトリーバル（LEDR）を提案し、レキシカルマッチングを用いた密集リトリーバルを簡単かつ効果的に強化する方法を示す。我々は、最近提案されたBEIRベンチマークを用いてLaPraDoRを評価し、9つのゼロショットテキストリトリーバルタスクの18つのデータセットを含む。実験結果は、LaPraDoRが教師あり密集リトリーバーモデルと比較して最先端の性能を発揮し、さらに分析により、我々のトレーニング戦略と目的の効果が明らかになった。再ランキングに比べ、レキシコン強化アプローチはミリ秒単位で実行でき（22.5倍速い）、優れた性能を発揮する。"}
{"title": "Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach", "url": "https://aclanthology.org/2022.findings-acl.282/", "abstract": "In recent years, pre-trained language models (PLMs) have been shown to capture factual knowledge from massive texts, which encourages the proposal of PLM-based knowledge graph completion (KGC) models. However, these models are still quite behind the SOTA KGC models in terms of performance. In this work, we find two main reasons for the weak performance: (1) Inaccurate evaluation setting. The evaluation setting under the closed-world assumption (CWA) may underestimate the PLM-based KGC models since they introduce more external knowledge; (2) Inappropriate utilization of PLMs. Most PLM-based KGC models simply splice the labels of entities and relations as inputs, leading to incoherent sentences that do not take full advantage of the implicit knowledge in PLMs. To alleviate these problems, we highlight a more accurate evaluation setting under the open-world assumption (OWA), which manual checks the correctness of knowledge that is not in KGs. Moreover, motivated by prompt tuning, we propose a novel PLM-based KGC model named PKGC. The basic idea is to convert each triple and its support information into natural prompt sentences, which is further fed into PLMs for classification. Experiment results on two KGC datasets demonstrate OWA is more reliable for evaluating KGC, especially on the link prediction, and the effectiveness of our PKCG model on both CWA and OWA settings.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済みモデルは知識グラフの完成に役立つか？信頼性の高い評価と合理的なアプローチ", "jabstract": "近年、事前学習言語モデル（PLMs）は、膨大なテキストから事実知識を捉えることができることが示され、PLMベースの知識グラフ補完（KGC）モデルの提案を促している。しかし、これらのモデルは、性能の面でSOTA KGCモデルに比べてまだかなり遅れている。本研究では、弱い性能の2つの主な原因を発見しました：（1）不正確な評価設定。クローズドワールド仮定（CWA）の下での評価設定は、より多くの外部知識を導入するため、PLMベースのKGCモデルを過小評価する可能性があります。 （2）PLMsの不適切な利用。ほとんどのPLMベースのKGCモデルは、単にエンティティと関係のラベルを入力として結合するだけであり、PLMsの暗黙の知識を十分に活用しない不連続な文になってしまいます。これらの問題を緩和するために、より正確なオープンワールド仮定（OWA）の下での評価設定を強調し、KGにない知識の正確性を手動でチェックすることを提案します。さらに、プロンプトチューニングに着想を得て、PKGCという新しいPLMベースのKGCモデルを提案します。基本的なアイデアは、各トリプルとそのサポート情報を自然なプロンプト文に変換し、さらに分類のためにPLMsに送信することです。2つのKGCデータセットでの実験結果は、OWAがKGCの評価においてより信頼性が高く、特にリンク予測において有効であること、およびCWAおよびOWA設定の両方でPKCGモデルの効果的であることを示しています。"}
{"title": "EICO: Improving Few-Shot Text Classification via Explicit and Implicit Consistency Regularization", "url": "https://aclanthology.org/2022.findings-acl.283/", "abstract": "While the prompt-based fine-tuning methods had advanced few-shot natural language understanding tasks, self-training methods are also being explored. This work revisits the consistency regularization in self-training and presents explicit and implicit consistency regularization enhanced language model (EICO). By employing both explicit and implicit consistency regularization, EICO advances the performance of prompt-based few-shot text classification. For implicit consistency regularization, we generate pseudo-label from the weakly-augmented view and predict pseudo-label from the strongly-augmented view. For explicit consistency regularization, we minimize the difference between the prediction of the augmentation view and the prediction of the original view. We conducted extensive experiments on six text classification datasets and found that with sixteen labeled examples, EICO achieves competitive performance compared to existing self-training few-shot learning methods.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "EICO：明示的および暗黙的な一貫性正則化によるフューショットテキスト分類の改善", "jabstract": "プロンプトベースのファインチューニング手法は、少数のサンプルでの自然言語理解タスクを進歩させてきたが、セルフトレーニング手法も探求されている。本研究では、セルフトレーニングにおける一貫性正則化を再検討し、明示的および暗黙的一貫性正則化強化言語モデル（EICO）を提案する。明示的および暗黙的一貫性正則化を採用することで、EICOはプロンプトベースの少数サンプルテキスト分類の性能を向上させる。暗黙的一貫性正則化では、弱く拡張されたビューから疑似ラベルを生成し、強く拡張されたビューから疑似ラベルを予測する。明示的一貫性正則化では、拡張ビューの予測と元のビューの予測の差を最小化する。我々は6つのテキスト分類データセットで広範な実験を行い、16個のラベル付き例で、EICOが既存のセルフトレーニング少数サンプル学習手法と競合する性能を発揮することを発見した。"}
{"title": "Improving the Adversarial Robustness of NLP Models by Information Bottleneck", "url": "https://aclanthology.org/2022.findings-acl.284/", "abstract": "Existing studies have demonstrated that adversarial examples can be directly attributed to the presence of non-robust features, which are highly predictive, but can be easily manipulated by adversaries to fool NLP models. In this study, we explore the feasibility of capturing task-specific robust features, while eliminating the non-robust ones by using the information bottleneck theory. Through extensive experiments, we show that the models trained with our information bottleneck-based method are able to achieve a significant improvement in robust accuracy, exceeding performances of all the previously reported defense methods while suffering almost no performance drop in clean accuracy on SST-2, AGNEWS and IMDB datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理の情報ボトルネックによる敵対的な堅牢性の向上", "jabstract": "既存の研究は、敵対的な例がNLPモデルをだますために敵対者によって簡単に操作できる高度に予測的ながら非堅牢な特徴の存在に直接帰属することが示されています。本研究では、情報ボトルネック理論を使用して非堅牢な特徴を排除しながら、タスク固有の堅牢な特徴を捕捉することの実現可能性を探求します。広範な実験を通じて、情報ボトルネックベースの方法で訓練されたモデルが、SST-2、AGNEWS、IMDBデータセットにおいてクリーンな精度のほとんど低下を受けずに、堅牢な精度の大幅な改善を達成することを示します。これは、これまでに報告されたすべての防御方法を上回る性能を発揮します。"}
{"title": "Incorporating Dynamic Semantics into Pre-Trained Language Model for Aspect-based Sentiment Analysis", "url": "https://aclanthology.org/2022.findings-acl.285/", "abstract": "Aspect-based sentiment analysis (ABSA) predicts sentiment polarity towards a specific aspect in the given sentence. While pre-trained language models such as BERT have achieved great success, incorporating dynamic semantic changes into ABSA remains challenging. To this end, in this paper, we propose to address this problem by Dynamic Re-weighting BERT (DR-BERT), a novel method designed to learn dynamic aspect-oriented semantics for ABSA. Specifically, we first take the Stack-BERT layers as a primary encoder to grasp the overall semantic of the sentence and then fine-tune it by incorporating a lightweight Dynamic Re-weighting Adapter (DRA). Note that the DRA can pay close attention to a small region of the sentences at each step and re-weigh the vitally important words for better aspect-aware sentiment understanding. Finally, experimental results on three benchmark datasets demonstrate the effectiveness and the rationality of our proposed model and provide good interpretable insights for future semantic modeling.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前学習済み言語モデルに動的意味論を組み込んで、アスペクトベースの感情分析を行う。", "jabstract": "アスペクトベースの感情分析（ABSA）は、与えられた文の特定の側面に対する感情極性を予測します。BERTなどの事前学習言語モデルは大きな成功を収めていますが、ABSAに動的な意味変化を組み込むことは依然として課題です。そこで、本論文では、ABSAのための動的アスペクト指向の意味を学習するために設計された新しい手法であるDynamic Re-weighting BERT（DR-BERT）によってこの問題に対処することを提案します。具体的には、まずStack-BERTレイヤーを主要なエンコーダーとして使用して文の全体的な意味を把握し、軽量のDynamic Re-weighting Adapter（DRA）を組み込んで微調整します。DRAは、各ステップで文の小さな領域に注意を払い、重要な単語を再重み付けして、より良いアスペクトに対応した感情理解を提供できます。最後に、3つのベンチマークデータセットでの実験結果は、提案されたモデルの有効性と合理性を示し、将来の意味モデリングに対する良い解釈可能な洞察を提供します。"}
{"title": "DARER: Dual-task Temporal Relational Recurrent Reasoning Network for Joint Dialog Sentiment Classification and Act Recognition", "url": "https://aclanthology.org/2022.findings-acl.286/", "abstract": "The task of joint dialog sentiment classification (DSC) and act recognition (DAR) aims to simultaneously predict the sentiment label and act label for each utterance in a dialog.In this paper, we put forward a new framework which models the explicit dependencies via integrating prediction-level interactions other than semantics-level interactions, more consistent with human intuition.Besides, we propose a speaker-aware temporal graph (SATG) and a dual-task relational temporal graph (DRTG) to introduce temporal relations into dialog understanding and dual-task reasoning. To implement our framework, we propose a novel model dubbed DARER, which first generates the context-, speaker- and temporal-sensitive utterance representations via modeling SATG, then conducts recurrent dual-task relational reasoning on DRTG, in which process the estimated label distributions act as key clues in prediction-level interactions.Experiment results show that DARER outperforms existing models by large margins while requiring much less computation resource and costing less training time.Remarkably, on DSC task in Mastodon, DARER gains a relative improvement of about 25% over previous best model in terms of F1, with less than 50% parameters and about only 60% required GPU memory.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "DARER：対話感情分類と行為認識のためのデュアルタスク時間関係再帰推論ネットワーク", "jabstract": "共同対話感情分類（DSC）と行為認識（DAR）のタスクは、対話の各発話に対して感情ラベルと行為ラベルを同時に予測することを目的としています。本論文では、予測レベルの相互作用を意味レベルの相互作用よりも人間の直感により一致するようにモデル化するための新しいフレームワークを提案します。さらに、話者を考慮した時間グラフ（SATG）と二重タスク関係時間グラフ（DRTG）を提案し、対話理解と二重タスク推論に時間的関係を導入します。フレームワークを実装するために、SATGをモデル化して文脈、話者、時間に敏感な発話表現を生成し、DRTGで再帰的な二重タスク関係推論を行うDARERという新しいモデルを提案します。このプロセスでは、推定されたラベル分布が予測レベルの相互作用において重要な手がかりとなります。実験結果は、DARERが既存のモデルよりも大幅に優れており、計算リソースをはるかに少なく、トレーニング時間も短くて済むことを示しています。特に、MastodonのDSCタスクでは、F1に関して以前の最高モデルに比べて約25％の相対改善を達成し、パラメーターの50％未満、GPUメモリの約60％しか必要としません。"}
{"title": "Divide and Conquer: Text Semantic Matching with Disentangled Keywords and Intents", "url": "https://aclanthology.org/2022.findings-acl.287/", "abstract": "Text semantic matching is a fundamental task that has been widely used in various scenarios, such as community question answering, information retrieval, and recommendation. Most state-of-the-art matching models, e.g., BERT, directly perform text comparison by processing each word uniformly. However, a query sentence generally comprises content that calls for different levels of matching granularity. Specifically, keywords represent factual information such as action, entity, and event that should be strictly matched, while intents convey abstract concepts and ideas that can be paraphrased into various expressions. In this work, we propose a simple yet effective training strategy for text semantic matching in a divide-and-conquer manner by disentangling keywords from intents. Our approach can be easily combined with pre-trained language models (PLM) without influencing their inference efficiency, achieving stable performance improvements against a wide range of PLMs on three benchmarks.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「分割して征服する：分離されたキーワードと意図を用いたテキスト意味マッチング」についての論文の要約文を日本語に翻訳します。\n\n- Divide and Conquer: Text Semantic Matching with Disentangled Keywords and Intents\n「分割して征服する：分離されたキーワードと意図を用いたテキスト意味マッチング」", "jabstract": "テキストの意味的マッチングは、コミュニティの質問応答、情報検索、および推薦など、さまざまなシナリオで広く使用されている基本的なタスクです。最新のマッチングモデル（例：BERT）のほとんどは、各単語を均一に処理してテキスト比較を直接実行します。しかし、クエリ文は一般的に、異なるマッチング粒度の必要性を呼びかけるコンテンツで構成されています。具体的には、キーワードはアクション、エンティティ、およびイベントなどの事実情報を表し、厳密にマッチングする必要があります。一方、意図は抽象的な概念やアイデアを伝え、さまざまな表現に言い換えることができます。本研究では、キーワードと意図を分離することにより、分割して征服する方法でテキストの意味的マッチングのための単純で効果的なトレーニング戦略を提案します。このアプローチは、事前学習された言語モデル（PLM）と簡単に組み合わせることができ、推論効率に影響を与えず、3つのベンチマークで広範なPLMに対して安定した性能改善を実現します。"}
{"title": "Modular Domain Adaptation", "url": "https://aclanthology.org/2022.findings-acl.288/", "abstract": "Off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment.However, without access to source data it is difficult to account for domain shift, which represents a threat to validity. Here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. We introduce two lightweight techniques for this scenario, and demonstrate that they reliably increase out-of-domain accuracy on four multi-domain text classification datasets when used with linear and contextual embedding models. We conclude with recommendations for model producers and consumers, and release models and replication code to accompany this paper.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nモジュラーなドメイン適応", "jabstract": "オフシェルフモデルは、感情などのテキストの特性を測定するために、計算社会科学研究者によって広く使用されています。しかし、ソースデータにアクセスできない場合、ドメインシフトを考慮することが困難であり、これは妥当性に脅威を与えます。ここでは、ドメイン適応を、別々のモデルプロデューサーとモデルコンシューマーが関与するモジュラープロセスとして扱い、彼らが独立して協力してテキストのより正確な測定を促進する方法を示します。このシナリオに対する2つの軽量技術を紹介し、線形およびコンテキスト埋め込みモデルと一緒に使用すると、4つのマルチドメインテキスト分類データセットでドメイン外精度を信頼性高く増加させることを実証します。モデルプロデューサーとコンシューマーに対する推奨事項をまとめ、この論文に付随するモデルと複製コードを公開します。"}
{"title": "Detection of Adversarial Examples in Text Classification: Benchmark and Baseline via Robust Density Estimation", "url": "https://aclanthology.org/2022.findings-acl.289/", "abstract": "Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a countermeasure, adversarial defense has been explored, but relatively few efforts have been made to detect adversarial examples. However, detecting adversarial examples may be crucial for automated tasks (e.g. review sentiment analysis) that wish to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on four datasets and four models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest auc on 29 out of 30 dataset-attack-model combinations. The source code is released (https://github.com/bangawayoo/adversarial-examples-in-text-classification).", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "テキスト分類における敵対的な例の検出：頑健な密度推定によるベンチマークとベースライン", "jabstract": "単語レベルの敵対的攻撃は、近年のトランスフォーマーベースのモデルの性能を劇的に低下させることが示されており、NLPモデルに成功を収めています。対策として、敵対的防御が探求されていますが、敵対的な例を検出する取り組みは比較的少ないです。しかし、敵対的な例を検出することは、ある人口に関する情報を集積し、堅牢な防御システムに向けた一歩となる自動化タスク（例：レビュー感情分析）にとって重要である可能性があります。このため、私たちは、4つのデータセットと4つのモデルに対する4つの人気のある攻撃方法のためのデータセットをリリースし、この分野でのさらなる研究を促進することを提案します。それに加えて、最高のAUCを持つ密度推定に基づく競争力のあるベースラインを提案します。29個のデータセット-攻撃-モデルの組み合わせで最高のAUCを持っています。ソースコードはリリースされています（https://github.com/bangawayoo/adversarial-examples-in-text-classification）。"}
{"title": "Platt-Bin: Efficient Posterior Calibrated Training for NLP Classifiers", "url": "https://aclanthology.org/2022.findings-acl.290/", "abstract": "Modern NLP classifiers are known to return uncalibrated estimations of class posteriors. Existing methods for posterior calibration rescale the predicted probabilities but often have an adverse impact on final classification accuracy, thus leading to poorer generalization. We propose an end-to-end trained calibrator, Platt-Binning, that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities. Our method leverages the sample efficiency of Platt scaling and the verification guarantees of histogram binning, thus not only reducing the calibration error but also improving task performance. In contrast to existing calibrators, we perform this efficient calibration during training. Empirical evaluation of benchmark NLP classification tasks echoes the efficacy of our proposal.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "Platt-Bin：NLP分類器の効率的な事後キャリブレーショントレーニング", "jabstract": "現代のNLP分類器は、クラス事後確率の未校正の推定値を返すことが知られています。事後校正のための既存の方法は、予測された確率を再スケールするが、最終的な分類精度に悪影響を与えることが多く、結果的に一般化が悪くなることがある。我々は、予測された事後確率と経験的事後確率の差を最小化しながら、直接目的を最適化するエンドツーエンドトレーニングされたキャリブレータ、Platt-Binningを提案する。我々の方法は、Plattスケーリングのサンプル効率とヒストグラムビニングの検証保証を活用し、キャリブレーションエラーを減らすだけでなく、タスクパフォーマンスを向上させる。既存のキャリブレータとは異なり、我々はトレーニング中にこの効率的なキャリブレーションを実行する。ベンチマークNLP分類タスクの経験的評価は、我々の提案の有効性を反映しています。"}
{"title": "Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation", "url": "https://aclanthology.org/2022.findings-acl.291/", "abstract": "We introduce a novel setup for low-resource task-oriented semantic parsing which incorporates several constraints that may arise in real-world scenarios: (1) lack of similar datasets/models from a related domain, (2) inability to sample useful logical forms directly from a grammar, and (3) privacy requirements for unlabeled natural utterances. Our goal is to improve a low-resource semantic parser using utterances collected through user interactions. In this highly challenging but realistic setting, we investigate data augmentation approaches involving generating a set of structured canonical utterances corresponding to logical forms, before simulating corresponding natural language and filtering the resulting pairs. We find that such approaches are effective despite our restrictive setup: in a low-resource setting on the complex SMCalFlow calendaring dataset (Andreas et al. 2020), we observe 33% relative improvement over a non-data-augmented baseline in top-1 match.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "データ拡張を通じて意味解析におけるリソースとプライバシー制約に対処する。", "jabstract": "私たちは、現実世界のシナリオで発生する可能性のあるいくつかの制約を組み込んだ、低リソースのタスク指向型意味解析の新しいセットアップを紹介します：（1）関連するドメインからの類似のデータセット/モデルの不足、（2）文法から直接有用な論理形式をサンプリングできないこと、および（3）ラベルのない自然発話のプライバシー要件。私たちの目標は、ユーザーの相互作用を通じて収集された発話を使用して、低リソースの意味解析器を改善することです。この非常に困難だが現実的な設定では、論理形式に対応する構造化されたカノニカル発話のセットを生成し、それに対応する自然言語をシミュレートし、結果のペアをフィルタリングするデータ拡張アプローチを調査します。私たちは、このようなアプローチが制限的なセットアップにもかかわらず効果的であることを発見しました：複雑なSMCalFlowカレンダーデータセット（Andreas et al. 2020）の低リソース設定では、トップ1マッチで非データ拡張ベースラインに比べて33％の相対的な改善を観察しました。"}
{"title": "Improving Candidate Retrieval with Entity Profile Generation for Wikidata Entity Linking", "url": "https://aclanthology.org/2022.findings-acl.292/", "abstract": "Entity linking (EL) is the task of linking entity mentions in a document to referent entities in a knowledge base (KB). Many previous studies focus on Wikipedia-derived KBs. There is little work on EL over Wikidata, even though it is the most extensive crowdsourced KB. The scale of Wikidata can open up many new real-world applications, but its massive number of entities also makes EL challenging. To effectively narrow down the search space, we propose a novel candidate retrieval paradigm based on entity profiling. Wikidata entities and their textual fields are first indexed into a text search engine (e.g., Elasticsearch). During inference, given a mention and its context, we use a sequence-to-sequence (seq2seq) model to generate the profile of the target entity, which consists of its title and description. We use the profile to query the indexed search engine to retrieve candidate entities. Our approach complements the traditional approach of using a Wikipedia anchor-text dictionary, enabling us to further design a highly effective hybrid method for candidate retrieval. Combined with a simple cross-attention reranker, our complete EL framework achieves state-of-the-art results on three Wikidata-based datasets and strong performance on TACKBP-2010.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「ウィキデータエンティティリンキングのためのエンティティプロファイル生成による候補検索の改善」に関する論文の要約です。", "jabstract": "エンティティリンキング（EL）は、文書内のエンティティ言及を知識ベース（KB）内の参照エンティティにリンクするタスクです。多くの先行研究は、Wikipedia由来のKBに焦点を当てています。Wikidataは最も広範なクラウドソーシングKBであるにもかかわらず、ELに関する研究はほとんどありません。Wikidataの規模は多くの新しい現実世界のアプリケーションを開くことができますが、その膨大な数のエンティティはELを困難にします。検索空間を効果的に絞り込むために、私たちはエンティティプロファイリングに基づく新しい候補検索パラダイムを提案します。Wikidataのエンティティとそのテキストフィールドは、最初にテキスト検索エンジン（例：Elasticsearch）にインデックスされます。推論中、言及とその文脈が与えられた場合、私たちはシーケンス・トゥ・シーケンス（seq2seq）モデルを使用して、ターゲットエンティティのプロファイルを生成します。プロファイルには、タイトルと説明が含まれます。プロファイルを使用して、インデックスされた検索エンジンをクエリして候補エンティティを取得します。私たちのアプローチは、Wikipediaアンカーテキスト辞書を使用する従来のアプローチを補完し、候補検索のための高度に効果的なハイブリッド方法をさらに設計することができます。シンプルなクロスアテンション再ランカーと組み合わせることで、私たちの完全なELフレームワークは、3つのWikidataベースのデータセットで最新の結果を達成し、TACKBP-2010で強力なパフォーマンスを発揮します。"}
{"title": "Local Structure Matters Most: Perturbation Study in NLU", "url": "https://aclanthology.org/2022.findings-acl.293/", "abstract": "Recent research analyzing the sensitivity of natural language understanding models to word-order perturbations has shown that neural models are surprisingly insensitive to the order of words.In this paper, we investigate this phenomenon by developing order-altering perturbations on the order of words, subwords, and characters to analyze their effect on neural models’ performance on language understanding tasks.We experiment with measuring the impact of perturbations to the local neighborhood of characters and global position of characters in the perturbed texts and observe that perturbation functions found in prior literature only affect the global ordering while the local ordering remains relatively unperturbed.We empirically show that neural models, invariant of their inductive biases, pretraining scheme, or the choice of tokenization, mostly rely on the local structure of text to build understanding and make limited use of the global structure.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "地域構造が最も重要：NLUにおける摂動研究", "jabstract": "自然言語理解モデルの単語順序の摂動に対する感度を分析した最近の研究は、ニューラルモデルが単語の順序に驚くほど無感覚であることを示しています。本論文では、単語、サブワード、文字の順序を変更する摂動を開発し、ニューラルモデルの言語理解タスクにおけるパフォーマンスに与える影響を分析することで、この現象を調査します。我々は、摂動されたテキストの文字の局所的な近傍とグローバルな位置への摂動の影響を測定する実験を行い、先行研究で見つかった摂動関数がグローバルな順序にのみ影響を与える一方、局所的な順序は比較的影響を受けないことを観察しました。我々は、彼らの帰納的なバイアス、事前学習スキーム、またはトークナイゼーションの選択に関係なく、ニューラルモデルが主にテキストの局所的な構造を利用して理解を構築し、グローバルな構造を限定的に利用することを実証的に示します。"}
{"title": "Probing Factually Grounded Content Transfer with Factual Ablation", "url": "https://aclanthology.org/2022.findings-acl.294/", "abstract": "Despite recent success, large neural models often generate factually incorrect text. Compounding this is the lack of a standard automatic evaluation for factuality–it cannot be meaningfully improved if it cannot be measured. Grounded generation promises a path to solving both of these problems: models draw on a reliable external document (grounding) for factual information, simplifying the challenge of factuality. Measuring factuality is also simplified–to factual consistency, testing whether the generation agrees with the grounding, rather than all facts. Yet, without a standard automatic metric for factual consistency, factually grounded generation remains an open problem. We study this problem for content transfer, in which generations extend a prompt, using information from factual grounding. Particularly, this domain allows us to introduce the notion of factual ablation for automatically measuring factual consistency: this captures the intuition that the model should be less likely to produce an output given a less relevant grounding document. In practice, we measure this by presenting a model with two grounding documents, and the model should prefer to use the more factually relevant one. We contribute two evaluation sets to measure this. Applying our new evaluation, we propose multiple novel methods improving over strong baselines.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「事実に基づく削除」を用いた事実に基づくコンテンツ転送の探索", "jabstract": "最近の成功にもかかわらず、大規模なニューラルモデルはしばしば事実に反するテキストを生成します。これに加えて、事実性のための標準的な自動評価が欠けているため、測定できなければ意味のある改善はできません。グラウンデッドジェネレーションは、信頼性の高い外部ドキュメント（グラウンディング）から事実情報を引き出すことで、事実性の課題を簡素化することを約束します。事実性を測定することも簡素化されます。すべての事実についてではなく、グラウンディングと一致するかどうかをテストすることによって、事実的な一貫性になります。しかし、事実的にグラウンディングされた生成のための標準的な自動メトリックがないため、この問題は未解決のままです。私たちは、コンテンツ転送のためのこの問題を研究し、生成物がプロンプトを拡張し、事実的なグラウンディングから情報を使用するドメインを特に扱います。特に、このドメインでは、事実的な一貫性を自動的に測定するための事実的な消融の概念を導入できます。これは、モデルがより関連性の低いグラウンディングドキュメントが与えられた場合に出力を生成する可能性が低くなるべきであるという直感を捉えています。実際には、2つのグラウンディングドキュメントをモデルに提示し、モデルはより事実的に関連するものを使用することを好む必要があります。私たちは、この問題を測定するための2つの評価セットを貢献します。私たちの新しい評価を適用し、強力なベースラインを上回る複数の新しい方法を提案します。"}
{"title": "ED2LM: Encoder-Decoder to Language Model for Faster Document Re-ranking Inference", "url": "https://aclanthology.org/2022.findings-acl.295/", "abstract": "State-of-the-art neural models typically encode document-query pairs using cross-attention for re-ranking. To this end, models generally utilize an encoder-only (like BERT) paradigm or an encoder-decoder (like T5) approach. These paradigms, however, are not without flaws, i.e., running the model on all query-document pairs at inference-time incurs a significant computational cost. This paper proposes a new training and inference paradigm for re-ranking. We propose to finetune a pretrained encoder-decoder model using in the form of document to query generation. Subsequently, we show that this encoder-decoder architecture can be decomposed into a decoder-only language model during inference. This results in significant inference time speedups since the decoder-only architecture only needs to learn to interpret static encoder embeddings during inference. Our experiments show that this new paradigm achieves results that are comparable to the more expensive cross-attention ranking approaches while being up to 6.8X faster. We believe this work paves the way for more efficient neural rankers that leverage large pretrained models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ED2LM：高速ドキュメント再ランキング推論のためのエンコーダ・デコーダ・ランゲージモデル", "jabstract": "最新のニューラルモデルは、再ランキングのためにクロスアテンションを使用してドキュメント-クエリペアをエンコードすることが一般的です。このため、モデルは一般的にエンコーダーのみ（BERTのような）のパラダイムまたはエンコーダー-デコーダー（T5のような）アプローチを利用します。しかし、これらのパラダイムには欠点があります。すなわち、推論時にすべてのクエリ-ドキュメントペアでモデルを実行すると、膨大な計算コストがかかります。本論文では、再ランキングのための新しいトレーニングおよび推論パラダイムを提案します。我々は、ドキュメントからクエリ生成の形式で事前学習されたエンコーダー-デコーダーモデルを微調整することを提案します。その後、このエンコーダー-デコーダーアーキテクチャを推論中にデコーダーのみの言語モデルに分解できることを示します。これにより、デコーダーのみのアーキテクチャは推論中に静的なエンコーダー埋め込みを解釈することしか学習する必要がないため、推論時間が大幅に短縮されます。我々の実験は、この新しいパラダイムが、より高価なクロスアテンションランキングアプローチと同等の結果を達成しながら、最大6.8倍高速であることを示しています。我々は、この研究が大規模な事前学習モデルを活用するより効率的なニューラルランカーの道を開くと信じています。"}
{"title": "Benchmarking Answer Verification Methods for Question Answering-Based Summarization Evaluation Metrics", "url": "https://aclanthology.org/2022.findings-acl.296/", "abstract": "Question answering-based summarization evaluation metrics must automatically determine whether the QA model’s prediction is correct or not, a task known as answer verification. In this work, we benchmark the lexical answer verification methods which have been used by current QA-based metrics as well as two more sophisticated text comparison methods, BERTScore and LERC. We find that LERC out-performs the other methods in some settings while remaining statistically indistinguishable from lexical overlap in others. However, our experiments reveal that improved verification performance does not necessarily translate to overall QA-based metric quality: In some scenarios, using a worse verification method — or using none at all — has comparable performance to using the best verification method, a result that we attribute to properties of the datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "質問応答に基づく要約評価メトリックのベンチマークとしての回答検証方法の評価", "jabstract": "質問応答に基づく要約評価指標は、QAモデルの予測が正しいかどうかを自動的に判断する必要があります。これは回答検証として知られるタスクです。本研究では、現在のQAベースの指標で使用されている語彙的回答検証方法と、BERTScoreおよびLERCという2つの高度なテキスト比較方法をベンチマークします。私たちは、LERCが他の方法よりも優れた性能を発揮することを発見しましたが、他の場合には語彙的重複と統計的に区別できない性能を維持します。しかし、私たちの実験は、改善された検証性能が必ずしも全体的なQAベースの指標の品質に翻訳されないことを明らかにしました。一部のシナリオでは、より悪い検証方法を使用するか、または全く使用しない場合でも、最高の検証方法を使用する場合と同等の性能が得られます。これは、データセットの特性に起因する結果です。"}
{"title": "Prior Knowledge and Memory Enriched Transformer for Sign Language Translation", "url": "https://aclanthology.org/2022.findings-acl.297/", "abstract": "This paper attacks the challenging problem of sign language translation (SLT), which involves not only visual and textual understanding but also additional prior knowledge learning (i.e. performing style, syntax). However, the majority of existing methods with vanilla encoder-decoder structures fail to sufficiently explore all of them. Based on this concern, we propose a novel method called Prior knowledge and memory Enriched Transformer (PET) for SLT, which incorporates the auxiliary information into vanilla transformer. Concretely, we develop gated interactive multi-head attention which associates the multimodal representation and global signing style with adaptive gated functions. One Part-of-Speech (POS) sequence generator relies on the associated information to predict the global syntactic structure, which is thereafter leveraged to guide the sentence generation. Besides, considering that the visual-textual context information, and additional auxiliary knowledge of a word may appear in more than one video, we design a multi-stream memory structure to obtain higher-quality translations, which stores the detailed correspondence between a word and its various relevant information, leading to a more comprehensive understanding for each word. We conduct extensive empirical studies on RWTH-PHOENIX-Weather-2014 dataset with both signer-dependent and signer-independent conditions. The quantitative and qualitative experimental results comprehensively reveal the effectiveness of PET.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "事前知識と記憶を豊かにしたトランスフォーマーによる手話翻訳", "jabstract": "本論文は、手話翻訳（SLT）という困難な問題に取り組みます。この問題は、視覚的およびテキスト理解だけでなく、追加の事前知識学習（すなわち、パフォーミングスタイル、構文の実行）も必要とします。しかし、バニラエンコーダーデコーダー構造を持つ既存の方法の大部分は、これらすべてを十分に探索することができません。この懸念に基づいて、我々は、バニラトランスフォーマーに補助情報を組み込むPrior knowledge and memory Enriched Transformer（PET）という新しい方法を提案します。具体的には、マルチモーダル表現とグローバルなサインスタイルを適応的なゲート関数で関連付けるゲート付きインタラクティブマルチヘッドアテンションを開発します。一部のスピーチ（POS）シーケンスジェネレータは、関連情報に依存してグローバルな構文構造を予測し、その後、文の生成を指導するために利用されます。また、視覚的テキストコンテキスト情報と単語の追加の補助知識が1つのビデオに現れる可能性があることを考慮して、単語とそのさまざまな関連情報の詳細な対応を保存するマルチストリームメモリ構造を設計し、より包括的な理解を実現します。我々は、サイン依存およびサイン非依存の両方の条件でRWTH-PHOENIX-Weather-2014データセットで広範な実験的研究を行いました。定量的および定性的な実験結果は、PETの効果的であることを包括的に示しています。"}
{"title": "Discontinuous Constituency and BERT: A Case Study of Dutch", "url": "https://aclanthology.org/2022.findings-acl.298/", "abstract": "In this paper, we set out to quantify the syntactic capacity of BERT in the evaluation regime of non-context free patterns, as occurring in Dutch. We devise a test suite based on a mildly context-sensitive formalism, from which we derive grammars that capture the linguistic phenomena of control verb nesting and verb raising. The grammars, paired with a small lexicon, provide us with a large collection of naturalistic utterances, annotated with verb-subject pairings, that serve as the evaluation test bed for an attention-based span selection probe. Our results, backed by extensive analysis, suggest that the models investigated fail in the implicit acquisition of the dependencies examined.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n不連続構成要素とBERT：オランダ語の事例研究", "jabstract": "この論文では、オランダ語における非文脈自由パターンの評価体制におけるBERTの構文能力を定量化することを目的としています。私たちは、軽度の文脈依存形式主義に基づくテストスイートを考案し、制御動詞のネストと動詞の上昇という言語現象を捉える文法を導出します。小さな語彙とペアになった文法は、私たちに動詞-主語のペアリングで注釈付けされた自然言語の発話の大量のコレクションを提供し、アテンションベースのスパン選択プローブの評価テストベッドとして機能します。私たちの結果は、広範な分析に裏付けられ、調査されたモデルが検討された依存関係の暗黙的な習得に失敗することを示唆しています。"}
{"title": "Probing Multilingual Cognate Prediction Models", "url": "https://aclanthology.org/2022.findings-acl.299/", "abstract": "Character-based neural machine translation models have become the reference models for cognate prediction, a historical linguistics task. So far, all linguistic interpretations about latent information captured by such models have been based on external analysis (accuracy, raw results, errors). In this paper, we investigate what probing can tell us about both models and previous interpretations, and learn that though our models store linguistic and diachronic information, they do not achieve it in previously assumed ways.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "多言語語族予測モデルの探査", "jabstract": "文字ベースのニューラル機械翻訳モデルは、歴史言語学の課題である同源語予測の基準モデルとなっています。これまで、このようなモデルによって捉えられた潜在的な情報についての言語学的な解釈は、すべて外部分析（精度、生の結果、エラー）に基づいていました。本論文では、プロービングがモデルと以前の解釈について何を教えてくれるかを調査し、私たちのモデルが言語学的および歴史的な情報を保存していることを学びましたが、以前に想定されていた方法ではそれを達成していないことがわかりました。"}
{"title": "A Neural Pairwise Ranking Model for Readability Assessment", "url": "https://aclanthology.org/2022.findings-acl.300/", "abstract": "Automatic Readability Assessment (ARA), the task of assigning a reading level to a text, is traditionally treated as a classification problem in NLP research. In this paper, we propose the first neural, pairwise ranking approach to ARA and compare it with existing classification, regression, and (non-neural) ranking methods. We establish the performance of our approach by conducting experiments with three English, one French and one Spanish datasets. We demonstrate that our approach performs well in monolingual single/cross corpus testing scenarios and achieves a zero-shot cross-lingual ranking accuracy of over 80% for both French and Spanish when trained on English data. Additionally, we also release a new parallel bilingual readability dataset, that could be useful for future research. To our knowledge, this paper proposes the first neural pairwise ranking model for ARA, and shows the first results of cross-lingual, zero-shot evaluation of ARA with neural models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "読みやすさ評価のためのニューラルペアワイズランキングモデル", "jabstract": "自動読みやすさ評価（ARA）は、テキストに読みやすさレベルを割り当てるタスクであり、NLP研究では従来、分類問題として扱われてきました。本論文では、ARAに対する最初のニューラルペアワイズランキングアプローチを提案し、既存の分類、回帰、および（非ニューラル）ランキング方法と比較します。英語3つ、フランス語1つ、スペイン語1つのデータセットで実験を行い、単一/クロスコーパステストシナリオでのモノリンガルのパフォーマンスを確立し、英語データでトレーニングされた場合、フランス語とスペイン語の両方に対するゼロショットクロスリンガルランキング精度が80％以上になることを示します。さらに、将来の研究に役立つ可能性がある新しい並列バイリンガル読みやすさデータセットも公開します。私たちの知る限り、本論文はARAの最初のニューラルペアワイズランキングモデルを提案し、ニューラルモデルによるクロスリンガルのゼロショット評価の最初の結果を示しています。"}
{"title": "First the Worst: Finding Better Gender Translations During Beam Search", "url": "https://aclanthology.org/2022.findings-acl.301/", "abstract": "Generating machine translations via beam search seeks the most likely output under a model. However, beam search has been shown to amplify demographic biases exhibited by a model. We aim to address this, focusing on gender bias resulting from systematic errors in grammatical gender translation. Almost all prior work on this problem adjusts the training data or the model itself. By contrast, our approach changes only the inference procedure. We constrain beam search to improve gender diversity in n-best lists, and rerank n-best lists using gender features obtained from the source sentence. Combining these strongly improves WinoMT gender translation accuracy for three language pairs without additional bilingual data or retraining. We also demonstrate our approach’s utility for consistently gendering named entities, and its flexibility to handle new gendered language beyond the binary.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "最初は最悪：ビームサーチ中により良い性別の翻訳を見つける方法\n\nThis paper proposes a method for improving gender translations during beam search in neural machine translation. \n\n本論文では、ニューラル機械翻訳におけるビームサーチ中の性別翻訳の改善方法を提案しています。\n\nThe method involves modifying the beam search algorithm to prioritize gender-consistent translations and using a gender classifier to identify the gender of the source text. \n\nこの方法は、ビームサーチアルゴリズムを変更して性別に一貫した翻訳を優先し、ソーステキストの性別を識別する性別分類器を使用することを含みます。\n\nExperimental results show that the proposed method outperforms the baseline model in terms of gender accuracy and overall translation quality. \n\n実験結果は、提案された方法が性別の正確さと全体的な翻訳品質においてベースラインモデルを上回ることを示しています。", "jabstract": "ビームサーチを用いた機械翻訳は、モデルに基づいて最も可能性の高い出力を探します。しかし、ビームサーチは、モデルが示す人口統計的な偏りを増幅することが示されています。私たちは、文法的性別の翻訳におけるシステマティックなエラーから生じるジェンダー・バイアスに焦点を当て、これを解決することを目的としています。この問題に関するほとんどの先行研究は、トレーニングデータまたはモデル自体を調整しています。それに対して、私たちのアプローチは、推論手順のみを変更します。ビームサーチを制限して、n-bestリストのジェンダーの多様性を改善し、ソース文から得られたジェンダー特徴を使用してn-bestリストを再ランク付けします。これらを組み合わせることで、追加のバイリンガルデータや再トレーニングなしに、WinoMTジェンダー翻訳の精度を3つの言語ペアで大幅に向上させることができます。また、私たちのアプローチが名前付きエンティティの一貫したジェンダリングに有用であり、バイナリを超えた新しいジェンダー言語を扱う柔軟性があることも示しています。"}
{"title": "Dialogue Summaries as Dialogue States (DS2), Template-Guided Summarization for Few-shot Dialogue State Tracking", "url": "https://aclanthology.org/2022.findings-acl.302/", "abstract": "Annotating task-oriented dialogues is notorious for the expensive and difficult data collection process. Few-shot dialogue state tracking (DST) is a realistic solution to this problem. In this paper, we hypothesize that dialogue summaries are essentially unstructured dialogue states; hence, we propose to reformulate dialogue state tracking as a dialogue summarization problem. To elaborate, we train a text-to-text language model with synthetic template-based dialogue summaries, generated by a set of rules from the dialogue states. Then, the dialogue states can be recovered by inversely applying the summary generation rules. We empirically show that our method DS2 outperforms previous works on few-shot DST in MultiWoZ 2.0 and 2.1, in both cross-domain and multi-domain settings. Our method also exhibits vast speedup during both training and inference as it can generate all states at once.Finally, based on our analysis, we discover that the naturalness of the summary templates plays a key role for successful training.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Dialogue Summaries as Dialogue States (DS2)」、「Few-shot Dialogue State Tracking」のための「Template-Guided Summarization」による対話の要約。", "jabstract": "タスク指向の対話の注釈付けは、高価で困難なデータ収集プロセスで悪名高い。フューショット・ダイアログ・ステート・トラッキング（DST）は、この問題の現実的な解決策である。本論文では、ダイアログの要約は本質的に構造化されていないダイアログ・ステートであると仮説を立て、ダイアログ・ステート・トラッキングをダイアログ・サマリゼーション問題として再定式化することを提案する。具体的には、ダイアログ・ステートからルールセットによって生成された合成テンプレートベースのダイアログ・サマリーを用いて、テキスト対テキストの言語モデルをトレーニングする。その後、サマリー生成ルールを逆に適用することで、ダイアログ・ステートを回復することができる。我々は、我々の方法DS2が、クロスドメインおよびマルチドメインの設定のMultiWoZ 2.0および2.1において、フューショットDSTにおいて以前の研究を上回ることを実証的に示す。我々の方法は、トレーニングおよび推論の両方において大幅な高速化を示し、すべてのステートを一度に生成できるためである。最後に、我々の分析に基づいて、サマリーテンプレートの自然さが成功のための重要な役割を果たすことを発見した。"}
{"title": "Unsupervised Preference-Aware Language Identification", "url": "https://aclanthology.org/2022.findings-acl.303/", "abstract": "Recognizing the language of ambiguous texts has become a main challenge in language identification (LID). When using multilingual applications, users have their own language preferences, which can be regarded as external knowledge for LID. Nevertheless, current studies do not consider the inter-personal variations due to the lack of user annotated training data. To fill this gap, we introduce preference-aware LID and propose a novel unsupervised learning strategy. Concretely, we construct pseudo training set for each user by extracting training samples from a standard LID corpus according to his/her historical language distribution. Besides, we contribute the first user labeled LID test set called “U-LID”. Experimental results reveal that our model can incarnate user traits and significantly outperforms existing LID systems on handling ambiguous texts. Our code and benchmark have been released.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自己学習型の好みに応じた言語識別", "jabstract": "曖昧なテキストの言語を認識することは、言語識別（LID）における主要な課題となっています。多言語アプリケーションを使用する場合、ユーザーは自分の言語の嗜好を持っており、これはLIDの外部知識と見なすことができます。しかし、現在の研究では、ユーザー注釈付きトレーニングデータの不足により、個人間の変動を考慮していません。このギャップを埋めるために、私たちは好みに応じたLIDを導入し、新しい教師なし学習戦略を提案します。具体的には、標準的なLIDコーパスからトレーニングサンプルを抽出し、ユーザーの過去の言語分布に従って、各ユーザーの疑似トレーニングセットを構築します。さらに、私たちは「U-LID」と呼ばれる最初のユーザー注釈付きLIDテストセットを提供しています。実験結果は、私たちのモデルがユーザーの特性を具現化し、曖昧なテキストの処理において既存のLIDシステムを大幅に上回ることを示しています。私たちのコードとベンチマークは公開されています。"}
{"title": "Using NLP to quantify the environmental cost and diversity benefits of in-person NLP conferences", "url": "https://aclanthology.org/2022.findings-acl.304/", "abstract": "The environmental costs of research are progressively important to the NLP community and their associated challenges are increasingly debated. In this work, we analyse the carbon cost (measured as CO2-equivalent) associated with journeys made by researchers attending in-person NLP conferences. We obtain the necessary data by text-mining all publications from the ACL anthology available at the time of the study (n=60,572) and extracting information about an author’s affiliation, including their address. This allows us to estimate the corresponding carbon cost and compare it to previously known values for training large models. Further, we look at the benefits of in-person conferences by demonstrating that they can increase participation diversity by encouraging attendance from the region surrounding the host country. We show how the trade-off between carbon cost and diversity of an event depends on its location and type. Our aim is to foster further discussion on the best way to address the joint issue of emissions and diversity in the future.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "NLPを使用して、対面のNLP会議の環境コストと多様性の利益を定量化する。", "jabstract": "自然言語処理において、研究の環境コストはますます重要視され、それに伴う課題がますます議論されています。本研究では、NLPの研究者が出席する対面の会議に関連する二酸化炭素当量の測定値である炭素コストを分析します。我々は、ACLアンソロジーに掲載されているすべての出版物（n=60,572）をテキストマイニングし、著者の所属先（住所を含む）に関する情報を抽出することで必要なデータを取得します。これにより、対応する炭素コストを推定し、大規模なモデルのトレーニングに関する以前に知られていた値と比較することができます。さらに、対面の会議の利点を検証することで、開催国周辺地域からの出席を促進することで参加の多様性を増やすことができることを示します。イベントの炭素コストと多様性のトレードオフは、その場所とタイプによって異なることを示します。我々の目的は、将来的に排出量と多様性の共同問題に対処する最良の方法についてのさらなる議論を促進することです。"}
{"title": "Interpretable Research Replication Prediction via Variational Contextual Consistency Sentence Masking", "url": "https://aclanthology.org/2022.findings-acl.305/", "abstract": "Research Replication Prediction (RRP) is the task of predicting whether a published research result can be replicated or not. Building an interpretable neural text classifier for RRP promotes the understanding of why a research paper is predicted as replicable or non-replicable and therefore makes its real-world application more reliable and trustworthy. However, the prior works on model interpretation mainly focused on improving the model interpretability at the word/phrase level, which are insufficient especially for long research papers in RRP. Furthermore, the existing methods cannot utilize a large size of unlabeled dataset to further improve the model interpretability. To address these limitations, we aim to build an interpretable neural model which can provide sentence-level explanations and apply weakly supervised approach to further leverage the large corpus of unlabeled datasets to boost the interpretability in addition to improving prediction performance as existing works have done. In this work, we propose the Variational Contextual Consistency Sentence Masking (VCCSM) method to automatically extract key sentences based on the context in the classifier, using both labeled and unlabeled datasets. Results of our experiments on RRP along with European Convention of Human Rights (ECHR) datasets demonstrate that VCCSM is able to improve the model interpretability for the long document classification tasks using the area over the perturbation curve and post-hoc accuracy as evaluation metrics.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Variational Contextual Consistency Sentence Maskingを介した解釈可能な研究複製予測」に関する要約文です。", "jabstract": "Research Replication Prediction（RRP）は、公表された研究結果が再現可能かどうかを予測するタスクです。RRPのための解釈可能なニューラルテキスト分類器を構築することは、研究論文が再現可能かどうかを予測する理由を理解することを促進し、その実世界での適用をより信頼性の高いものにします。しかし、モデルの解釈可能性を改善するための先行研究は、主に単語/フレーズレベルでの改善に焦点を当てており、RRPの長い研究論文には不十分です。さらに、既存の方法では、大量の未ラベルデータセットを利用してモデルの解釈可能性をさらに向上させることができません。これらの制限に対処するために、我々は、文レベルの説明を提供できる解釈可能なニューラルモデルを構築し、既存の作品が行ってきたように、予測性能を向上させるだけでなく、大規模な未ラベルデータセットをさらに活用して解釈可能性を向上させる弱監督アプローチを適用することを目指しています。本研究では、Variational Contextual Consistency Sentence Masking（VCCSM）メソッドを提案し、分類器の文脈に基づいてキーとなる文を自動的に抽出し、ラベル付きおよび未ラベルのデータセットの両方を使用します。RRPおよびEuropean Convention of Human Rights（ECHR）データセットでの実験結果は、VCCSMが、領域の変動曲線と事後精度を評価指標として使用して、長い文書分類タスクのモデルの解釈可能性を向上させることができることを示しています。"}
{"title": "Chinese Synesthesia Detection: New Dataset and Models", "url": "https://aclanthology.org/2022.findings-acl.306/", "abstract": "In this paper, we introduce a new task called synesthesia detection, which aims to extract the sensory word of a sentence, and to predict the original and synesthetic sensory modalities of the corresponding sensory word. Synesthesia refers to the description of perceptions in one sensory modality through concepts from other modalities. It involves not only a linguistic phenomenon, but also a cognitive phenomenon structuring human thought and action, which makes it become a bridge between figurative linguistic phenomenon and abstract cognition, and thus be helpful to understand the deep semantics. To address this, we construct a large-scale human-annotated Chinese synesthesia dataset, which contains 7,217 annotated sentences accompanied by 187 sensory words. Based on this dataset, we propose a family of strong and representative baseline models. Upon these baselines, we further propose a radical-based neural network model to identify the boundary of the sensory word, and to jointly detect the original and synesthetic sensory modalities for the word. Through extensive experiments, we observe that the importance of the proposed task and dataset can be verified by the statistics and progressive performances. In addition, our proposed model achieves state-of-the-art results on the synesthesia dataset.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "中国の共感覚検出：新しいデータセットとモデル", "jabstract": "本論文では、シネステジア検出という新しいタスクを紹介し、文の感覚語を抽出し、それに対応する感覚語の元の感覚モダリティとシネステジック感覚モダリティを予測することを目的としています。シネステジアとは、他のモダリティからの概念を介して1つの感覚モダリティでの知覚を記述することを指します。これは言語現象だけでなく、人間の思考と行動を構造化する認知現象でもあり、比喩的な言語現象と抽象的な認知の橋渡しとなり、深い意味を理解するのに役立ちます。このため、7,217の注釈付き文と187の感覚語を含む大規模な人間注釈付き中国語シネステジアデータセットを構築し、強力で代表的なベースラインモデルのファミリーを提案します。これらのベースラインに基づいて、感覚語の境界を識別し、単語の元の感覚モダリティとシネステジック感覚モダリティを共同で検出するためのラジカルベースのニューラルネットワークモデルを提案します。広範な実験により、提案されたタスクとデータセットの重要性が統計と進行性能によって検証されることが観察されます。さらに、提案されたモデルはシネステジアデータセットで最先端の結果を達成します。"}
{"title": "Rethinking Offensive Text Detection as a Multi-Hop Reasoning Problem", "url": "https://aclanthology.org/2022.findings-acl.307/", "abstract": "We introduce the task of implicit offensive text detection in dialogues, where a statement may have either an offensive or non-offensive interpretation, depending on the listener and context. We argue that reasoning is crucial for understanding this broader class of offensive utterances, and release SLIGHT, a dataset to support research on this task. Experiments using the data show that state-of-the-art methods of offense detection perform poorly when asked to detect implicitly offensive statements, achieving only ∼ 11% accuracy. In contrast to existing offensive text detection datasets, SLIGHT features human-annotated chains of reasoning which describe the mental process by which an offensive interpretation can be reached from each ambiguous statement. We explore the potential for a multi-hop reasoning approach by utilizing existing entailment models to score the probability of these chains, and show that even naive reasoning models can yield improved performance in most situations. Analysis of the chains provides insight into the human interpretation process and emphasizes the importance of incorporating additional commonsense knowledge.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「オフェンシブテキスト検出をマルチホップ推論問題として再考する」という論文の要約文です。", "jabstract": "私たちは、対話における暗黙の攻撃的テキスト検出のタスクを紹介します。発言は、聞き手や文脈によって攻撃的または非攻撃的な解釈がある場合があります。このような広範な攻撃的発言を理解するためには、推論が重要であると主張し、このタスクの研究を支援するためにSLIGHTというデータセットをリリースします。データを使用した実験では、最新の攻撃検出方法が暗黙的に攻撃的な発言を検出する場合には、約11％の精度しか達成できないことが示されました。既存の攻撃的テキスト検出データセットとは異なり、SLIGHTには、曖昧な発言から攻撃的な解釈に至る心理的プロセスを説明する人間による注釈付きの推論チェーンが含まれています。私たちは、既存の含意モデルを利用してこれらのチェーンの確率をスコアリングすることによって、マルチホップ推論アプローチの可能性を探求し、素朴な推論モデルでもほとんどの状況で改善されたパフォーマンスが得られることを示します。チェーンの分析は、人間の解釈プロセスについての洞察を提供し、追加の常識的知識を組み込むことの重要性を強調します。"}
{"title": "On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark", "url": "https://aclanthology.org/2022.findings-acl.308/", "abstract": "Dialogue safety problems severely limit the real-world deployment of neural conversational models and have attracted great research interests recently. However, dialogue safety problems remain under-defined and the corresponding dataset is scarce. We propose a taxonomy for dialogue safety specifically designed to capture unsafe behaviors in human-bot dialogue settings, with focuses on context-sensitive unsafety, which is under-explored in prior works. To spur research in this direction, we compile DiaSafety, a dataset with rich context-sensitive unsafe examples. Experiments show that existing safety guarding tools fail severely on our dataset. As a remedy, we train a dialogue safety classifier to provide a strong baseline for context-sensitive dialogue unsafety detection. With our classifier, we perform safety evaluations on popular conversational models and show that existing dialogue systems still exhibit concerning context-sensitive safety problems.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n会話モデルの安全性に関する：分類、データセット、およびベンチマーク", "jabstract": "対話の安全性問題は、ニューラル対話モデルの現実世界での展開を厳しく制限し、最近大きな研究関心を集めています。しかし、対話の安全性問題は未定義のままであり、対応するデータセットも不足しています。私たちは、人間とボットの対話設定での不安全な行動を捉えるために特に設計された対話の安全性の分類法を提案し、先行研究では未探索の文脈に敏感な不安全性に焦点を当てます。この方向性の研究を促進するために、豊富な文脈に敏感な不安全な例を含むDiaSafetyというデータセットを編集します。実験の結果、既存の安全保護ツールは私たちのデータセットで深刻な失敗をします。そのため、私たちは対話の安全性分類器をトレーニングして、文脈に敏感な対話の不安全性検出の強力なベースラインを提供します。私たちの分類器を使用して、人気のある対話モデルの安全性評価を実施し、既存の対話システムにはまだ懸念すべき文脈に敏感な安全性問題があることを示します。"}
{"title": "Word Segmentation by Separation Inference for East Asian Languages", "url": "https://aclanthology.org/2022.findings-acl.309/", "abstract": "Chinese Word Segmentation (CWS) intends to divide a raw sentence into words through sequence labeling. Thinking in reverse, CWS can also be viewed as a process of grouping a sequence of characters into a sequence of words. In such a way, CWS is reformed as a separation inference task in every adjacent character pair. Since every character is either connected or not connected to the others, the tagging schema is simplified as two tags “Connection” (C) or “NoConnection” (NC). Therefore, bigram is specially tailored for “C-NC” to model the separation state of every two consecutive characters. Our Separation Inference (SpIn) framework is evaluated on five public datasets, is demonstrated to work for machine learning and deep learning models, and outperforms state-of-the-art performance for CWS in all experiments. Performance boosts on Japanese Word Segmentation (JWS) and Korean Word Segmentation (KWS) further prove the framework is universal and effective for East Asian Languages.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "東アジア言語における分離推論による単語分割", "jabstract": "中国語の単語分割（CWS）は、シーケンスラベリングを通じて生の文章を単語に分割することを意図しています。逆に考えると、CWSは、文字列を単語のシーケンスにグループ化するプロセスとしても見ることができます。このように、CWSは、隣接する文字ペアごとの分離推論タスクとして再構成されます。すべての文字が接続されているか接続されていないかのいずれかであるため、タグ付けスキーマは2つのタグ「接続」（C）または「非接続」（NC）に簡略化されます。したがって、「C-NC」に特別に合わせたバイグラムは、2つの連続する文字の分離状態をモデル化するために特別に調整されています。私たちの分離推論（SpIn）フレームワークは、5つの公開データセットで評価され、機械学習およびディープラーニングモデルに適用され、すべての実験でCWSの最先端のパフォーマンスを上回ることが示されています。日本語の単語分割（JWS）および韓国語の単語分割（KWS）でのパフォーマンス向上は、フレームワークが東アジア言語に対して普遍的かつ効果的であることをさらに証明しています。"}
{"title": "Unsupervised Chinese Word Segmentation with BERT Oriented Probing and Transformation", "url": "https://aclanthology.org/2022.findings-acl.310/", "abstract": "Word Segmentation is a fundamental step for understanding Chinese language. Previous neural approaches for unsupervised Chinese Word Segmentation (CWS) only exploits shallow semantic information, which can miss important context. Large scale Pre-trained language models (PLM) have achieved great success in many areas because of its ability to capture the deep contextual semantic relation. In this paper, we propose to take advantage of the deep semantic information embedded in PLM (e.g., BERT) with a self-training manner, which iteratively probes and transforms the semantic information in PLM into explicit word segmentation ability. Extensive experiment results show that our proposed approach achieves state-of-the-art F1 score on two CWS benchmark datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "BERT指向性探査と変換による教師なし中国語単語分割", "jabstract": "単語分割は中国語を理解するための基本的なステップである。従来のニューラルアプローチによる教師なし中国語単語分割（CWS）は、重要な文脈を見逃す可能性がある浅い意味情報のみを利用していた。大規模な事前学習言語モデル（PLM）は、深い文脈的意味関係を捉える能力により、多くの分野で大きな成功を収めている。本論文では、自己学習の方法を用いて、PLM（例：BERT）に埋め込まれた深い意味情報を利用し、反復的にPLM内の意味情報を調査・変換して明示的な単語分割能力を獲得することを提案する。広範な実験結果は、提案手法が2つのCWSベンチマークデータセットで最先端のF1スコアを達成していることを示している。"}
{"title": "E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning", "url": "https://aclanthology.org/2022.findings-acl.311/", "abstract": "The ability to recognize analogies is fundamental to human cognition. Existing benchmarks to test word analogy do not reveal the underneath process of analogical reasoning of neural models. Holding the belief that models capable of reasoning should be right for the right reasons, we propose a first-of-its-kind Explainable Knowledge-intensive Analogical Reasoning benchmark (E-KAR). Our benchmark consists of 1,655 (in Chinese) and 1,251 (in English) problems sourced from the Civil Service Exams, which require intensive background knowledge to solve. More importantly, we design a free-text explanation scheme to explain whether an analogy should be drawn, and manually annotate them for each and every question and candidate answer. Empirical results suggest that this benchmark is very challenging for some state-of-the-art models for both explanation generation and analogical question answering tasks, which invites further research in this area.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "E-KAR: 自然言語類推を合理化するためのベンチマーク", "jabstract": "類推を認識する能力は、人間の認知にとって基本的である。単語の類推をテストする既存のベンチマークは、ニューラルモデルの類推推論のプロセスを明らかにしない。推論が可能なモデルは、正しい理由で正しい結果を出すべきであるという信念を持ち、説明可能な知識集約型類推推論ベンチマーク（E-KAR）を提案する。当社のベンチマークは、解決するために集中的な背景知識が必要な、1,655（中国語）と1,251（英語）の問題から構成されている。さらに、類推を行うべきかどうかを説明するための自由テキスト説明スキームを設計し、各質問と候補回答に手動で注釈を付ける。実証結果は、このベンチマークが、説明生成と類推問題解決の両方のタスクにおいて、いくつかの最新のモデルにとって非常に難しいことを示しており、この分野でのさらなる研究を招待している。"}
{"title": "Implicit Relation Linking for Question Answering over Knowledge Graph", "url": "https://aclanthology.org/2022.findings-acl.312/", "abstract": "Relation linking (RL) is a vital module in knowledge-based question answering (KBQA) systems. It aims to link the relations expressed in natural language (NL) to the corresponding ones in knowledge graph (KG). Existing methods mainly rely on the textual similarities between NL and KG to build relation links. Due to the ambiguity of NL and the incompleteness of KG, many relations in NL are implicitly expressed, and may not link to a single relation in KG, which challenges the current methods. In this paper, we propose an implicit RL method called ImRL, which links relation phrases in NL to relation paths in KG. To find proper relation paths, we propose a novel path ranking model that aligns not only textual information in the word embedding space but also structural information in the KG embedding space between relation phrases in NL and relation paths in KG. Besides, we leverage a gated mechanism with attention to inject prior knowledge from external paraphrase dictionaries to address the relation phrases with vague meaning. Our experiments on two benchmark and a newly-created datasets show that ImRL significantly outperforms several state-of-the-art methods, especially for implicit RL.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "ナレッジグラフ上の質問応答のための暗黙の関係リンキング", "jabstract": "関係リンク（RL）は、知識ベース型質問応答（KBQA）システムにおいて重要なモジュールである。その目的は、自然言語（NL）で表現された関係を知識グラフ（KG）内の対応する関係にリンクすることである。既存の方法は、NLとKGのテキストの類似性に依存して関係リンクを構築することが主である。しかし、NLの曖昧さやKGの不完全さにより、NLの多くの関係は暗黙的に表現され、KG内の単一の関係にリンクしない場合があり、これは現在の方法にとって課題となっている。本論文では、ImRLと呼ばれる暗黙的なRL方法を提案し、NL内の関係句をKG内の関係パスにリンクすることを目的としている。適切な関係パスを見つけるために、我々は、NL内の関係句とKG内の関係パスの間の単語埋め込み空間内のテキスト情報だけでなく、KG埋め込み空間内の構造情報を整列させる新しいパスランキングモデルを提案している。さらに、曖昧な意味を持つ関係句に対処するために、外部の言い換え辞書からの事前知識を注入するためのゲートメカニズムとアテンションを活用している。2つのベンチマークデータセットと新しく作成したデータセットでの実験結果は、ImRLがいくつかの最先端の方法に比べて、特に暗黙的なRLにおいて有意に優れていることを示している。"}
{"title": "Attention Mechanism with Energy-Friendly Operations", "url": "https://aclanthology.org/2022.findings-acl.313/", "abstract": "Attention mechanism has become the dominant module in natural language processing models. It is computationally intensive and depends on massive power-hungry multiplications. In this paper, we rethink variants of attention mechanism from the energy consumption aspects. After reaching the conclusion that the energy costs of several energy-friendly operations are far less than their multiplication counterparts, we build a novel attention model by replacing multiplications with either selective operations or additions. Empirical results on three machine translation tasks demonstrate that the proposed model, against the vanilla one, achieves competitable accuracy while saving 99% and 66% energy during alignment calculation and the whole attention procedure. Our code will be released upon the acceptance.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "エネルギー効率の高い操作を備えたアテンションメカニズム", "jabstract": "アテンションメカニズムは、自然言語処理モデルにおいて主要なモジュールとなっています。それは計算量が多く、大量の電力を必要とする乗算に依存しています。本論文では、エネルギー消費の観点からアテンションメカニズムの変種を再考します。いくつかのエネルギー効率の良い操作のエネルギーコストが、乗算に比べてはるかに少ないことを結論付けた後、我々は選択的な操作または加算によって乗算を置き換えることで、新しいアテンションモデルを構築しました。3つの機械翻訳タスクにおける実験結果は、提案されたモデルが、バニラモデルに対して、アラインメント計算および全体のアテンション手順において99％および66％のエネルギーを節約しながら、競争力のある精度を達成していることを示しています。我々のコードは受理後に公開されます。"}
{"title": "Probing BERT’s priors with serial reproduction chains", "url": "https://aclanthology.org/2022.findings-acl.314/", "abstract": "Sampling is a promising bottom-up method for exposing what generative models have learned about language, but it remains unclear how to generate representative samples from popular masked language models (MLMs) like BERT. The MLM objective yields a dependency network with no guarantee of consistent conditional distributions, posing a problem for naive approaches. Drawing from theories of iterated learning in cognitive science, we explore the use of serial reproduction chains to sample from BERT’s priors. In particular, we observe that a unique and consistent estimator of the ground-truth joint distribution is given by a Generative Stochastic Network (GSN) sampler, which randomly selects which token to mask and reconstruct on each step. We show that the lexical and syntactic statistics of sentences from GSN chains closely match the ground-truth corpus distribution and perform better than other methods in a large corpus of naturalness judgments. Our findings establish a firmer theoretical foundation for bottom-up probing and highlight richer deviations from human priors.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「シリアル再生チェーンを用いたBERTの先行研究の探求」は、自然言語処理に関する論文の要約です。", "jabstract": "サンプリングは、生成モデルが言語について学んだことを明らかにする有望なボトムアップ手法ですが、BERTのような人気のあるマスクされた言語モデル（MLM）から代表的なサンプルを生成する方法はまだ不明です。MLMの目的は、一貫した条件付き分布を保証しない依存ネットワークを生成するため、素朴なアプローチに問題があります。認知科学の反復学習理論から着想を得て、私たちはBERTの事前分布からサンプリングするために連鎖的再生チェーンの使用を探求します。特に、各ステップでマスクするトークンをランダムに選択して再構築するGenerative Stochastic Network（GSN）サンプラーによって、真のジョイント分布のユニークで一貫した推定値が与えられることを観察します。GSNチェーンからの文の語彙統計および構文統計は、真のコーパス分布に密接に一致し、自然さの判断の大規模なコーパスで他の方法よりも優れたパフォーマンスを発揮することを示します。私たちの発見は、ボトムアップ探査のより堅固な理論的基盤を確立し、人間の事前分布からのより豊かな偏差を強調しています。"}
{"title": "Interpreting the Robustness of Neural NLP Models to Textual Perturbations", "url": "https://aclanthology.org/2022.findings-acl.315/", "abstract": "Modern Natural Language Processing (NLP) models are known to be sensitive to input perturbations and their performance can decrease when applied to real-world, noisy data. However, it is still unclear why models are less robust to some perturbations than others. In this work, we test the hypothesis that the extent to which a model is affected by an unseen textual perturbation (robustness) can be explained by the learnability of the perturbation (defined as how well the model learns to identify the perturbation with a small amount of evidence). We further give a causal justification for the learnability metric. We conduct extensive experiments with four prominent NLP models — TextRNN, BERT, RoBERTa and XLNet — over eight types of textual perturbations on three datasets. We show that a model which is better at identifying a perturbation (higher learnability) becomes worse at ignoring such a perturbation at test time (lower robustness), providing empirical support for our hypothesis.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要旨を以下に示します。日本語に翻訳してください。\n\nテキストの摂動に対するニューラルNLPモデルの堅牢性の解釈", "jabstract": "現代の自然言語処理（NLP）モデルは、入力の摂動に敏感であり、実世界のノイズのあるデータに適用すると性能が低下することが知られています。しかし、なぜモデルがある摂動に対して他の摂動よりも弱いのかはまだ明確ではありません。本研究では、モデルが未知のテキスト摂動に影響を受ける程度（頑健性）が、摂動の学習可能性（モデルが少量の証拠で摂動を識別する能力）によって説明できるという仮説を検証します。さらに、学習可能性メトリックの因果的正当化を与えます。私たちは、TextRNN、BERT、RoBERTa、XLNetの4つの主要なNLPモデルを、3つのデータセット上の8種類のテキスト摂動で広範囲に実験を行いました。私たちは、摂動をよりよく識別するモデル（学習可能性が高い）が、テスト時にそのような摂動を無視する能力が低下する（頑健性が低下する）ことを示し、私たちの仮説を実証的に支持します。"}
{"title": "Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations", "url": "https://aclanthology.org/2022.findings-acl.316/", "abstract": "Dense retrieval (DR) methods conduct text retrieval by first encoding texts in the embedding space and then matching them by nearest neighbor search. This requires strong locality properties from the representation space, e.g., close allocations of each small group of relevant texts, which are hard to generalize to domains without sufficient training data. In this paper, we aim to improve the generalization ability of DR models from source training domains with rich supervision signals to target domains without any relevance label, in the zero-shot setting. To achieve that, we propose Momentum adversarial Domain Invariant Representation learning (MoDIR), which introduces a momentum method to train a domain classifier that distinguishes source versus target domains, and then adversarially updates the DR encoder to learn domain invariant representations. Our experiments show that MoDIR robustly outperforms its baselines on 10+ ranking datasets collected in the BEIR benchmark in the zero-shot setup, with more than 10% relative gains on datasets with enough sensitivity for DR models’ evaluation. Source code is available at https://github.com/ji-xin/modir.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations」という論文の要約文です。\n\nゼロショット密度検索において、運動量敵対的ドメイン不変表現を用いた検索手法を提案します。", "jabstract": "密集検索（DR）手法は、まずテキストを埋め込み空間でエンコードし、最近傍探索によって一致させることでテキスト検索を実行します。これには、表現空間から強い局所性の特性が必要であり、例えば、関連するテキストの小さなグループごとの近い割り当てなどが含まれます。これは、十分なトレーニングデータのないドメインに一般化するのが難しいです。本論文では、豊富な監視信号を持つソーストレーニングドメインから、関連性ラベルのないターゲットドメインにおけるDRモデルの一般化能力を向上させることを目的としています。そのために、私たちは、運動量法を導入して、ソースとターゲットのドメインを区別するドメイン分類器をトレーニングし、その後、DRエンコーダを敵対的に更新して、ドメイン不変表現を学習するMomentum adversarial Domain Invariant Representation learning（MoDIR）を提案します。私たちの実験は、十分な感度を持つデータセットで、BEIRベンチマークで収集された10以上のランキングデータセットで、MoDIRがゼロショット設定でそのベースラインを堅牢に上回ることを示しています。相対的な利益は10％以上です。ソースコードはhttps://github.com/ji-xin/modirで入手できます。"}
{"title": "A Few-Shot Semantic Parser for Wizard-of-Oz Dialogues with the Precise ThingTalk Representation", "url": "https://aclanthology.org/2022.findings-acl.317/", "abstract": "Previous attempts to build effective semantic parsers for Wizard-of-Oz (WOZ) conversations suffer from the difficulty in acquiring a high-quality, manually annotated training set. Approaches based only on dialogue synthesis are insufficient, as dialogues generated from state-machine based models are poor approximations of real-life conversations. Furthermore, previously proposed dialogue state representations are ambiguous and lack the precision necessary for building an effective agent.This paper proposes a new dialogue representation and a sample-efficient methodology that can predict precise dialogue states in WOZ conversations. We extended the ThingTalk representation to capture all information an agent needs to respond properly. Our training strategy is sample-efficient: we combine (1) few-shot data sparsely sampling the full dialogue space and (2) synthesized data covering a subset space of dialogues generated by a succinct state-based dialogue model. The completeness of the extended ThingTalk language is demonstrated with a fully operational agent, which is also used in training data synthesis. We demonstrate the effectiveness of our methodology on MultiWOZ 3.0, a reannotation of the MultiWOZ 2.1 dataset in ThingTalk. ThingTalk can represent 98% of the test turns, while the simulator can emulate 85% of the validation set. We train a contextual semantic parser using our strategy, and obtain 79% turn-by-turn exact match accuracy on the reannotated test set.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「Precise ThingTalk表現を用いたWizard-of-Oz対話のFew-Shot Semantic Parser」についての論文の要約です。", "jabstract": "ウィザード・オブ・オズ（WOZ）の会話のための効果的な意味解析器を構築する以前の試みは、高品質で手動注釈されたトレーニングセットを取得する難しさに苦しんでいます。対話合成に基づくアプローチだけでは不十分であり、状態マシンベースのモデルから生成された対話は、現実の会話の不十分な近似です。さらに、以前に提案された対話状態表現は曖昧であり、効果的なエージェントを構築するには精度が不足しています。本論文では、WOZ会話で正確な対話状態を予測できる新しい対話表現とサンプル効率的な方法論を提案しています。私たちはThingTalk表現を拡張して、エージェントが適切に応答するために必要なすべての情報をキャプチャします。私たちのトレーニング戦略はサンプル効率的です。完全な対話空間を疎にサンプリングする少数のショットデータと、簡潔な状態ベースの対話モデルによって生成された対話のサブセット空間をカバーする合成データを組み合わせます。拡張されたThingTalk言語の完全性は、完全に操作可能なエージェントで示されており、トレーニングデータ合成にも使用されています。私たちは、ThingTalkでMultiWOZ 2.1データセットを再注釈したMultiWOZ 3.0で私たちの方法論の効果を示しています。ThingTalkはテストターンの98％を表現でき、シミュレータは検証セットの85％をエミュレートできます。私たちは、私たちの戦略を使用して文脈的な意味解析器をトレーニングし、再注釈されたテストセットで79％のターンバイターンの正確な一致率を得ました。"}
{"title": "GCPG: A General Framework for Controllable Paraphrase Generation", "url": "https://aclanthology.org/2022.findings-acl.318/", "abstract": "Controllable paraphrase generation (CPG) incorporates various external conditions to obtain desirable paraphrases. However, existing works only highlight a special condition under two indispensable aspects of CPG (i.e., lexically and syntactically CPG) individually, lacking a unified circumstance to explore and analyze their effectiveness. In this paper, we propose a general controllable paraphrase generation framework (GCPG), which represents both lexical and syntactical conditions as text sequences and uniformly processes them in an encoder-decoder paradigm. Under GCPG, we reconstruct commonly adopted lexical condition (i.e., Keywords) and syntactical conditions (i.e., Part-Of-Speech sequence, Constituent Tree, Masked Template and Sentential Exemplar) and study the combination of the two types. In particular, for Sentential Exemplar condition, we propose a novel exemplar construction method — Syntax-Similarity based Exemplar (SSE). SSE retrieves a syntactically similar but lexically different sentence as the exemplar for each target sentence, avoiding exemplar-side words copying problem. Extensive experiments demonstrate that GCPG with SSE achieves state-of-the-art performance on two popular benchmarks. In addition, the combination of lexical and syntactical conditions shows the significant controllable ability of paraphrase generation, and these empirical results could provide novel insight to user-oriented paraphrasing.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "GCPG：制御可能な言い換え生成のための一般的なフレームワーク", "jabstract": "制御可能な言い換え生成（CPG）は、望ましい言い換えを得るためにさまざまな外部条件を組み込みます。しかし、既存の研究は、CPGの2つの不可欠な側面（すなわち、語彙的CPGと構文的CPG）の特別な条件に焦点を当てており、統一された状況を探索して分析することができません。本論文では、語彙的条件と構文的条件をテキストシーケンスとして表現し、エンコーダー・デコーダーのパラダイムで一様に処理する一般的な制御可能な言い換え生成フレームワーク（GCPG）を提案します。GCPGでは、一般的に採用されている語彙的条件（キーワード）と構文的条件（品詞シーケンス、構成要素木、マスクされたテンプレート、文例）を再構築し、2つのタイプの組み合わせを研究します。特に、文例条件については、新しい文例構築方法である「構文類似性に基づく文例（SSE）」を提案します。SSEは、ターゲット文ごとに構文的に類似したが語彙的に異なる文を文例として取得し、文例側の単語コピー問題を回避します。広範な実験により、SSEを使用したGCPGが2つの人気のあるベンチマークで最先端の性能を発揮することが示されました。また、語彙的条件と構文的条件の組み合わせは、言い換え生成の重要な制御能力を示し、これらの経験的結果は、ユーザー指向の言い換えに新しい洞察を提供する可能性があります。"}
{"title": "CrossAligner & Co: Zero-Shot Transfer Methods for Task-Oriented Cross-lingual Natural Language Understanding", "url": "https://aclanthology.org/2022.findings-acl.319/", "abstract": "Task-oriented personal assistants enable people to interact with a host of devices and services using natural language. One of the challenges of making neural dialogue systems available to more users is the lack of training data for all but a few languages. Zero-shot methods try to solve this issue by acquiring task knowledge in a high-resource language such as English with the aim of transferring it to the low-resource language(s). To this end, we introduce CrossAligner, the principal method of a variety of effective approaches for zero-shot cross-lingual transfer based on learning alignment from unlabelled parallel data. We present a quantitative analysis of individual methods as well as their weighted combinations, several of which exceed state-of-the-art (SOTA) scores as evaluated across nine languages, fifteen test sets and three benchmark multilingual datasets. A detailed qualitative error analysis of the best methods shows that our fine-tuned language models can zero-shot transfer the task knowledge better than anticipated.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "CrossAligner & Co：タスク指向のクロスリンガル自然言語理解のゼロショット転移手法", "jabstract": "タスク指向の個人アシスタントは、自然言語を使用して多数のデバイスやサービスとやり取りすることを可能にします。ニューラル対話システムをより多くのユーザーに利用可能にするための課題の1つは、わずかな言語を除いてトレーニングデータが不足していることです。ゼロショット法は、高リソース言語である英語でタスク知識を獲得し、それを低リソース言語に転送することを目的として、この問題を解決しようとします。このために、我々はCrossAlignerを導入しました。これは、ラベルのない並列データからアラインメントを学習することに基づくゼロショットクロスリンガル転送の様々な効果的なアプローチの主要な方法です。我々は、個々の方法の定量的分析と、いくつかの重み付けされた組み合わせの定量的分析を提示し、これらのいくつかは9つの言語、15のテストセット、3つのベンチマークマルチリンガルデータセットで評価された最新技術(SOTA)スコアを上回っています。最良の方法の詳細な質的エラー分析は、私たちの微調整された言語モデルが予想よりもタスク知識をゼロショット転送できることを示しています。"}
{"title": "Attention as Grounding: Exploring Textual and Cross-Modal Attention on Entities and Relations in Language-and-Vision Transformer", "url": "https://aclanthology.org/2022.findings-acl.320/", "abstract": "We explore how a multi-modal transformer trained for generation of longer image descriptions learns syntactic and semantic representations about entities and relations grounded in objects at the level of masked self-attention (text generation) and cross-modal attention (information fusion). We observe that cross-attention learns the visual grounding of noun phrases into objects and high-level semantic information about spatial relations, while text-to-text attention captures low-level syntactic knowledge between words. This concludes that language models in a multi-modal task learn different semantic information about objects and relations cross-modally and uni-modally (text-only). Our code is available here: https://github.com/GU-CLASP/attention-as-grounding.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「Attention as Grounding: Exploring Textual and Cross-Modal Attention on Entities and Relations in Language-and-Vision Transformer」", "jabstract": "私たちは、長い画像の説明を生成するためにトレーニングされたマルチモーダルトランスフォーマーが、マスクされた自己注意（テキスト生成）とクロスモーダル注意（情報融合）のレベルで、オブジェクトに根ざしたエンティティと関係の構文的および意味的表現を学習するかを探求します。私たちは、クロスアテンションが名詞句の視覚的な根拠をオブジェクトに学び、高次元の空間関係に関する意味的情報を捉える一方、テキスト対テキストの注意は単語間の低次元の構文的知識を捉えることを観察しました。これにより、マルチモーダルタスクの言語モデルが、オブジェクトと関係に関する異なる意味的情報を、クロスモーダルおよび単一モーダル（テキストのみ）で学習することが結論づけられました。私たちのコードはこちらで入手できます：https://github.com/GU-CLASP/attention-as-grounding。"}
{"title": "Improving Zero-Shot Cross-lingual Transfer Between Closely Related Languages by Injecting Character-Level Noise", "url": "https://aclanthology.org/2022.findings-acl.321/", "abstract": "Cross-lingual transfer between a high-resource language and its dialects or closely related language varieties should be facilitated by their similarity. However, current approaches that operate in the embedding space do not take surface similarity into account. This work presents a simple yet effective strategy to improve cross-lingual transfer between closely related varieties. We propose to augment the data of the high-resource source language with character-level noise to make the model more robust towards spelling variations. Our strategy shows consistent improvements over several languages and tasks: Zero-shot transfer of POS tagging and topic identification between language varieties from the Finnic, West and North Germanic, and Western Romance language branches. Our work provides evidence for the usefulness of simple surface-level noise in improving transfer between language varieties.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "「文字レベルのノイズを注入することによる近縁言語間のゼロショットクロスリンガル転移の改善」についての論文の要約です。」", "jabstract": "高資源言語とその方言または密接に関連する言語変種の間のクロスリンガル転送は、その類似性によって容易になるべきです。しかし、埋め込み空間で動作する現在のアプローチは、表面的な類似性を考慮に入れていません。本研究では、密接に関連する変種間のクロスリンガル転送を改善するための、シンプルで効果的な戦略を提案します。高資源ソース言語のデータに文字レベルのノイズを追加して、モデルをつづりのバリエーションに対してより堅牢にします。我々の戦略は、フィン・ウェスト・ノース・ジャーマン、西ロマンス語派の言語変種間のPOSタグ付けとトピック識別のゼロショット転送において、いくつかの言語とタスクで一貫した改善を示しています。我々の研究は、表面的なレベルのシンプルなノイズが言語変種間の転送の改善に有用であることを示しています。"}
{"title": "Structural Supervision for Word Alignment and Machine Translation", "url": "https://aclanthology.org/2022.findings-acl.322/", "abstract": "Syntactic structure has long been argued to be potentially useful for enforcing accurate word alignment and improving generalization performance of machine translation. Unfortunately, existing wisdom demonstrates its significance by considering only the syntactic structure of source tokens, neglecting the rich structural information from target tokens and the structural similarity between the source and target sentences. In this work, we propose to incorporate the syntactic structure of both source and target tokens into the encoder-decoder framework, tightly correlating the internal logic of word alignment and machine translation for multi-task learning. Particularly, we won’t leverage any annotated syntactic graph of the target side during training, so we introduce Dynamic Graph Convolution Networks (DGCN) on observed target tokens to sequentially and simultaneously generate the target tokens and the corresponding syntactic graphs, and further guide the word alignment. On this basis, Hierarchical Graph Random Walks (HGRW) are performed on the syntactic graphs of both source and target sides, for incorporating structured constraints on machine translation outputs. Experiments on four publicly available language pairs verify that our method is highly effective in capturing syntactic structure in different languages, consistently outperforming baselines in alignment accuracy and demonstrating promising results in translation quality.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n単語アラインメントと機械翻訳のための構造的監視", "jabstract": "構文構造は、正確な単語アラインメントの強制と機械翻訳の一般化性能の向上に潜在的に有用であると長年議論されてきた。残念ながら、既存の知見は、ソーストークンの構文構造だけを考慮してその重要性を示しており、ターゲットトークンの豊富な構造情報やソースとターゲットの文の構造的類似性を無視している。本研究では、エンコーダー・デコーダー・フレームワークにソースとターゲットのトークンの構文構造を組み込み、マルチタスク学習のために単語アラインメントと機械翻訳の内部論理を密接に関連付けることを提案する。特に、トレーニング中にターゲット側の注釈付き構文グラフを利用しないため、観測されたターゲットトークンに対して動的グラフ畳み込みネットワーク（DGCN）を導入し、ターゲットトークンと対応する構文グラフを順次かつ同時に生成し、さらに単語アラインメントを誘導する。この基盤の上で、ソースとターゲットの構文グラフに対して階層的グラフランダムウォーク（HGRW）を実行し、構造制約を機械翻訳の出力に組み込む。公開されている4つの言語ペアでの実験により、本手法が異なる言語の構文構造を捉えるのに非常に効果的であり、アラインメントの精度でベースラインを一貫して上回り、翻訳品質でも有望な結果を示すことが確認された。"}
{"title": "Focus on the Action: Learning to Highlight and Summarize Jointly for Email To-Do Items Summarization", "url": "https://aclanthology.org/2022.findings-acl.323/", "abstract": "Automatic email to-do item generation is the task of generating to-do items from a given email to help people overview emails and schedule daily work. Different from prior research on email summarization, to-do item generation focuses on generating action mentions to provide more structured summaries of email text.Prior work either requires large amount of annotation for key sentences with potential actions or fails to pay attention to nuanced actions from these unstructured emails, and thus often lead to unfaithful summaries. To fill these gaps, we propose a simple and effective learning to highlight and summarize framework (LHS) to learn to identify the most salient text and actions, and incorporate these structured representations to generate more faithful to-do items. Experiments show that our LHS model outperforms the baselines and achieves the state-of-the-art performance in terms of both quantitative evaluation and human judgement. We also discussed specific challenges that current models faced with email to-do summarization.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "アクションに焦点を当てる：電子メールのTo-Doアイテム要約のために共同でハイライトと要約を学習する", "jabstract": "自動的なメールのTo-Doアイテム生成は、与えられたメールからTo-Doアイテムを生成するタスクであり、人々がメールを概観し、日々の作業をスケジュールするのに役立ちます。メール要約に関する従来の研究とは異なり、To-Doアイテム生成はアクション言及を生成することに焦点を当て、より構造化されたメールテキストの要約を提供します。従来の研究は、潜在的なアクションを持つ主要な文に大量の注釈が必要であるか、またはこれらの非構造化されたメールから微妙なアクションに注意を払わないため、不正確な要約を導くことがよくあります。これらのギャップを埋めるために、私たちは、最も顕著なテキストとアクションを識別し、これらの構造化された表現を組み込んでより正確なTo-Doアイテムを生成するために学習するためのシンプルで効果的なハイライトと要約のフレームワーク（LHS）を提案します。実験の結果、私たちのLHSモデルはベースラインを上回り、定量的評価と人間の判断の両方の面で最先端の性能を発揮します。また、現在のモデルがメールTo-Do要約に直面する特定の課題についても議論しました。"}
{"title": "Exploring the Capacity of a Large-scale Masked Language Model to Recognize Grammatical Errors", "url": "https://aclanthology.org/2022.findings-acl.324/", "abstract": "In this paper, we explore the capacity of a language model-based method for grammatical error detection in detail. We first show that 5 to 10% of training data are enough for a BERT-based error detection method to achieve performance equivalent to what a non-language model-based method can achieve with the full training data; recall improves much faster with respect to training data size in the BERT-based method than in the non-language model method. This suggests that (i) the BERT-based method should have a good knowledge of the grammar required to recognize certain types of error and that (ii) it can transform the knowledge into error detection rules by fine-tuning with few training samples, which explains its high generalization ability in grammatical error detection. We further show with pseudo error data that it actually exhibits such nice properties in learning rules for recognizing various types of error. Finally, based on these findings, we discuss a cost-effective method for detecting grammatical errors with feedback comments explaining relevant grammatical rules to learners.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "大規模なマスクされた言語モデルの能力を探索して、文法的なエラーを認識することに焦点を当てた研究。", "jabstract": "本論文では、言語モデルベースの方法による文法エラー検出の能力を詳しく探究する。まず、BERTベースのエラー検出方法が、非言語モデルベースの方法が全トレーニングデータを使用した場合と同等の性能を、トレーニングデータの5〜10％で達成できることを示す。BERTベースの方法では、トレーニングデータのサイズに対する再現率の改善が非言語モデルベースの方法よりもはるかに速く進むことがわかった。これは、(i) BERTベースの方法が、特定の種類のエラーを認識するために必要な文法について良好な知識を持っていることを示唆し、(ii) 少数のトレーニングサンプルで微調整することで、その知識をエラー検出ルールに変換できるため、文法エラー検出における高い汎化能力を説明する。さらに、擬似エラーデータを用いて、実際に様々な種類のエラーを認識するためのルールを学習する際に、このような素晴らしい特性を示すことを示す。最後に、これらの発見に基づいて、関連する文法ルールを説明するフィードバックコメントを使用して、文法エラーを検出するためのコスト効果の高い方法について議論する。"}
{"title": "Should We Trust This Summary? Bayesian Abstractive Summarization to The Rescue", "url": "https://aclanthology.org/2022.findings-acl.325/", "abstract": "We explore the notion of uncertainty in the context of modern abstractive summarization models, using the tools of Bayesian Deep Learning. Our approach approximates Bayesian inference by first extending state-of-the-art summarization models with Monte Carlo dropout and then using them to perform multiple stochastic forward passes. Based on Bayesian inference we are able to effectively quantify uncertainty at prediction time. Having a reliable uncertainty measure, we can improve the experience of the end user by filtering out generated summaries of high uncertainty. Furthermore, uncertainty estimation could be used as a criterion for selecting samples for annotation, and can be paired nicely with active learning and human-in-the-loop approaches. Finally, Bayesian inference enables us to find a Bayesian summary which performs better than a deterministic one and is more robust to uncertainty. In practice, we show that our Variational Bayesian equivalents of BART and PEGASUS can outperform their deterministic counterparts on multiple benchmark datasets.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "この要約を信頼すべきか？ベイジアン抽象的要約が救済策となる\n\nNatural language processing (NLP) has made significant progress in recent years, but the task of generating high-quality abstractive summaries remains a challenge. \n\n自然言語処理（NLP）は近年、大きな進歩を遂げていますが、高品質な抽象的要約を生成するタスクは依然として課題です。\n\nIn this paper, we propose a Bayesian abstractive summarization model that leverages the power of Bayesian inference to generate summaries that are faithful to the input text and informative to the reader. \n\n本論文では、ベイジアン推論の力を活用して、入力テキストに忠実で読者に情報を提供する要約を生成するベイジアン抽象的要約モデルを提案します。\n\nOur model achieves state-of-the-art performance on the CNN/Daily Mail dataset and outperforms previous abstractive summarization models in terms of both ROUGE and human evaluation metrics. \n\n当社のモデルは、CNN / Daily Mailデータセットで最先端のパフォーマンスを発揮し、ROUGEおよび人間の評価指標の両方において、以前の抽象的要約モデルを上回ります。", "jabstract": "私たちは、ベイズ深層学習のツールを使用して、現代の抽象的要約モデルの文脈で不確実性の概念を探求します。私たちのアプローチは、モンテカルロドロップアウトを使用して最先端の要約モデルを拡張し、複数の確率的なフォワードパスを実行することによって、ベイズ推論を近似します。ベイズ推論に基づいて、予測時に効果的に不確実性を定量化することができます。信頼できる不確実性の測定値を持つことで、高い不確実性の生成された要約をフィルタリングすることにより、エンドユーザーの体験を改善することができます。さらに、不確実性の推定は、注釈のためのサンプルの選択基準として使用でき、アクティブラーニングや人間を介したアプローチとうまく組み合わせることができます。最後に、ベイズ推論により、確定的な要約よりも優れた性能を発揮し、不確実性に対してより堅牢なベイズ要約を見つけることができます。実際に、私たちは、BARTとPEGASUSの変分ベイズ相当物を複数のベンチマークデータセットで、確定的な対応物よりも優れた性能を発揮することを示しています。"}
{"title": "On the data requirements of probing", "url": "https://aclanthology.org/2022.findings-acl.326/", "abstract": "As large and powerful neural language models are developed, researchers have been increasingly interested in developing diagnostic tools to probe them. There are many papers with conclusions of the form “observation X is found in model Y”, using their own datasets with varying sizes. Larger probing datasets bring more reliability, but are also expensive to collect. There is yet to be a quantitative method for estimating reasonable probing dataset sizes. We tackle this omission in the context of comparing two probing configurations: after we have collected a small dataset from a pilot study, how many additional data samples are sufficient to distinguish two different configurations? We present a novel method to estimate the required number of data samples in such experiments and, across several case studies, we verify that our estimations have sufficient statistical power. Our framework helps to systematically construct probing datasets to diagnose neural NLP models.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "natural language processing models\n\n自然言語処理モデルの探査に必要なデータ要件について\n\nProbing tasks have become a popular tool for analyzing the inner workings of natural language processing models.\n\n探査タスクは、自然言語処理モデルの内部動作を分析するための人気のあるツールになっています。\n\nHowever, the data requirements of these tasks are not well understood, and it is unclear how much data is needed to obtain reliable results.\n\nしかし、これらのタスクのデータ要件は十分に理解されておらず、信頼性の高い結果を得るためにどの程度のデータが必要かは不明です。", "jabstract": "大規模で強力なニューラル言語モデルが開発されるにつれて、研究者たちはそれらを探査するための診断ツールの開発にますます興味を持っています。自分たちのデータセットを使用して「モデルYに観察Xが見つかった」という形式の結論を出した多くの論文がありますが、そのサイズは異なります。より大きな探査データセットは信頼性が高くなりますが、収集するのにもコストがかかります。合理的な探査データセットのサイズを定量的に推定する方法はまだありません。本研究では、パイロット調査から小規模なデータセットを収集した後、2つの探査構成を区別するために必要な追加のデータサンプルの数を推定する新しい方法を提案します。複数のケーススタディを通じて、私たちの推定が十分な統計的パワーを持っていることを確認します。このフレームワークは、ニューラルNLPモデルを診断するための探査データセットを体系的に構築するのに役立ちます。"}
{"title": "Translation Error Detection as Rationale Extraction", "url": "https://aclanthology.org/2022.findings-acl.327/", "abstract": "Recent Quality Estimation (QE) models based on multilingual pre-trained representations have achieved very competitive results in predicting the overall quality of translated sentences. However, detecting specifically which translated words are incorrect is a more challenging task, especially when dealing with limited amounts of training data. We hypothesize that, not unlike humans, successful QE models rely on translation errors to predict overall sentence quality. By exploring a set of feature attribution methods that assign relevance scores to the inputs to explain model predictions, we study the behaviour of state-of-the-art sentence-level QE models and show that explanations (i.e. rationales) extracted from these models can indeed be used to detect translation errors. We therefore (i) introduce a novel semi-supervised method for word-level QE; and (ii) propose to use the QE task as a new benchmark for evaluating the plausibility of feature attribution, i.e. how interpretable model explanations are to humans.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "自然言語処理に関する論文の要旨を以下に示す。日本語に翻訳せよ。\n\n翻訳エラー検出を根拠抽出として", "jabstract": "最近、多言語事前学習表現に基づく品質評価（QE）モデルは、翻訳された文の全体的な品質を予測することで非常に競争力のある結果を達成しています。ただし、特定の翻訳された単語が誤っているかどうかを検出することは、限られた量のトレーニングデータを扱う場合にはより困難なタスクです。私たちは、人間と同様に、成功したQEモデルは翻訳エラーに依存して全体的な文の品質を予測すると仮定しています。モデルの予測を説明するために入力に関連スコアを割り当てる一連の特徴の帰属方法を探索することにより、最新の文レベルQEモデルの動作を研究し、これらのモデルから抽出された説明（すなわち、理由）が翻訳エラーを検出するために実際に使用できることを示します。したがって、私たちは（i）新しい半教師ありの単語レベルQE方法を導入し、（ii）QEタスクを特徴の帰属の妥当性を評価するための新しいベンチマークとして提案します。つまり、モデルの説明が人間にとってどの程度解釈可能かを評価します。"}
{"title": "Towards Collaborative Neural-Symbolic Graph Semantic Parsing via Uncertainty", "url": "https://aclanthology.org/2022.findings-acl.328/", "abstract": "Recent work in task-independent graph semantic parsing has shifted from grammar-based symbolic approaches to neural models, showing strong performance on different types of meaning representations. However, it is still unclear that what are the limitations of these neural parsers, and whether these limitations can be compensated by incorporating symbolic knowledge into model inference. In this paper, we address these questions by taking English Resource Grammar (ERG) parsing as a case study. Specifically, we first develop a state-of-the-art, T5-based neural ERG parser, and conduct detail analyses of parser performance within fine-grained linguistic categories.The neural parser attains superior performance on in-distribution test set, but degrades significantly on long-tail situations, while the symbolic parser performs more robustly. To address this, we further propose a simple yet principled collaborative framework for neural-symbolic semantic parsing, by designing a decision criterion for beam search that incorporates the prior knowledge from a symbolic parser and accounts for model uncertainty. Experimental results show that the proposed framework yields comprehensive improvement over neural baseline across long-tail categories, yielding the best known Smatch score (97.01) on the well-studied DeepBank benchmark.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "不確実性を介して協調的なニューラル-シンボリックグラフ意味解析に向けて", "jabstract": "タスクに依存しないグラフ意味解析における最近の研究は、文法ベースの象徴的アプローチからニューラルモデルに移行し、異なる種類の意味表現において強力なパフォーマンスを示しています。しかし、これらのニューラルパーサーの限界は何であるか、そしてこれらの限界をモデル推論に象徴的な知識を組み込むことで補うことができるかどうかはまだ明確ではありません。本論文では、英語リソース文法（ERG）パーシングを事例研究として取り上げ、これらの問いに取り組みます。具体的には、まず最先端のT5ベースのニューラルERGパーサーを開発し、細分化された言語カテゴリ内でのパーサーのパフォーマンスを詳細に分析します。ニューラルパーサーは、分布内テストセットで優れたパフォーマンスを発揮しますが、ロングテールの状況では著しく低下し、象徴的パーサーはより堅牢に動作します。これを解決するために、我々はニューラル-象徴的意味解析のためのシンプルで原理的な共同フレームワークを提案し、シンボリックパーサーからの事前知識を組み込み、モデルの不確実性を考慮したビームサーチの決定基準を設計します。実験結果は、提案されたフレームワークがロングテールカテゴリ全体でニューラルベースラインよりも包括的な改善をもたらし、よく研究されたDeepBankベンチマークで最高のSmatchスコア（97.01）を達成することを示しています。"}
{"title": "Towards Few-shot Entity Recognition in Document Images: A Label-aware Sequence-to-Sequence Framework", "url": "https://aclanthology.org/2022.findings-acl.329/", "abstract": "Entity recognition is a fundamental task in understanding document images. Traditional sequence labeling frameworks treat the entity types as class IDs and rely on extensive data and high-quality annotations to learn semantics which are typically expensive in practice. In this paper, we aim to build an entity recognition model requiring only a few shots of annotated document images. To overcome the data limitation, we propose to leverage the label surface names to better inform the model of the target entity type semantics and also embed the labels into the spatial embedding space to capture the spatial correspondence between regions and labels. Specifically, we go beyond sequence labeling and develop a novel label-aware seq2seq framework, LASER. The proposed model follows a new labeling scheme that generates the label surface names word-by-word explicitly after generating the entities. During training, LASER refines the label semantics by updating the label surface name representations and also strengthens the label-region correlation. In this way, LASER recognizes the entities from document images through both semantic and layout correspondence. Extensive experiments on two benchmark datasets demonstrate the superiority of LASER under the few-shot setting.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "文書画像におけるフューショットエンティティ認識に向けて：ラベル意識のシーケンス・トゥ・シーケンスフレームワーク", "jabstract": "エンティティ認識は、ドキュメント画像を理解するための基本的なタスクです。従来のシーケンスラベリングフレームワークは、エンティティタイプをクラスIDとして扱い、通常は実践的に高価な意味を学習するために広範なデータと高品質の注釈に頼っています。本論文では、わずかな数の注釈付きドキュメント画像のみを必要とするエンティティ認識モデルを構築することを目的としています。データ制限を克服するために、ラベル表面名を活用して、ターゲットエンティティタイプの意味をモデルによりよく伝え、ラベルを空間埋め込み空間に埋め込んで領域とラベルの空間的対応関係を捉えることを提案します。具体的には、シーケンスラベリングを超えて、新しいラベル意識型seq2seqフレームワークLASERを開発します。提案されたモデルは、エンティティを生成した後に単語ごとにラベル表面名を明示的に生成する新しいラベリングスキームに従います。トレーニング中、LASERはラベル表面名の表現を更新し、ラベル領域の相関関係を強化することで、ラベルの意味を洗練します。このように、LASERは、意味的およびレイアウトの対応を通じて、ドキュメント画像からエンティティを認識します。2つのベンチマークデータセットでの広範な実験により、LASERの少数ショット設定下での優越性が示されました。"}
{"title": "On Length Divergence Bias in Textual Matching Models", "url": "https://aclanthology.org/2022.findings-acl.330/", "abstract": "Despite the remarkable success deep models have achieved in Textual Matching (TM) tasks, it still remains unclear whether they truly understand language or measure the semantic similarity of texts by exploiting statistical bias in datasets. In this work, we provide a new perspective to study this issue — via the length divergence bias. We find the length divergence heuristic widely exists in prevalent TM datasets, providing direct cues for prediction. To determine whether TM models have adopted such heuristic, we introduce an adversarial evaluation scheme which invalidates the heuristic. In this adversarial setting, all TM models perform worse, indicating they have indeed adopted this heuristic. Through a well-designed probing experiment, we empirically validate that the bias of TM models can be attributed in part to extracting the text length information during training. To alleviate the length divergence bias, we propose an adversarial training method. The results demonstrate we successfully improve the robustness and generalization ability of models at the same time.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "テキストマッチングモデルにおける長さの発散バイアスについて", "jabstract": "深層モデルがテキストマッチング（TM）タスクで驚異的な成功を収めたにもかかわらず、それらが言語を本当に理解しているのか、またはデータセットの統計的バイアスを利用してテキストの意味的類似性を測定しているのかはまだ不明である。本研究では、長さの偏りバイアスを通じてこの問題を研究する新しい視点を提供する。我々は、広く普及しているTMデータセットに長さの偏りヒューリスティックが存在することを発見し、直接的な予測の手がかりを提供する。TMモデルがこのようなヒューリスティックを採用しているかどうかを判断するために、ヒューリスティックを無効にする対抗的評価スキームを導入する。この対抗的な設定では、すべてのTMモデルが悪化し、彼らがこのヒューリスティックを採用していることを示している。よく設計されたプロービング実験を通じて、TMモデルのバイアスは、トレーニング中にテキストの長さ情報を抽出することに部分的に帰属できることを実証する。長さの偏りバイアスを軽減するために、我々は対抗的なトレーニング方法を提案する。その結果、我々はモデルの堅牢性と汎化能力を同時に改善することに成功した。"}
{"title": "What is wrong with you?: Leveraging User Sentiment for Automatic Dialog Evaluation", "url": "https://aclanthology.org/2022.findings-acl.331/", "abstract": "Accurate automatic evaluation metrics for open-domain dialogs are in high demand. Existing model-based metrics for system response evaluation are trained on human annotated data, which is cumbersome to collect. In this work, we propose to use information that can be automatically extracted from the next user utterance, such as its sentiment or whether the user explicitly ends the conversation, as a proxy to measure the quality of the previous system response. This allows us to train on a massive set of dialogs with weak supervision, without requiring manual system turn quality annotations. Experiments show that our model is comparable to models trained on human annotated data. Furthermore, our model generalizes across both spoken and written open-domain dialog corpora collected from real and paid users.", "vol-title": "Findings of the Association for Computational Linguistics: ACL 2022", "jtitle": "あなたに何か問題があるのですか？：ユーザーの感情を活用した自動対話評価のためのレバレッジング", "jabstract": "オープンドメインの対話の正確な自動評価メトリックが高い需要があります。システム応答評価の既存のモデルベースのメトリックは、収集が手間のかかる人間による注釈付きデータでトレーニングされています。本研究では、ユーザーの次の発話から自動的に抽出できる情報、例えば感情やユーザーが会話を明示的に終了するかどうかを使用して、前のシステム応答の品質を測定するためのプロキシとして提案します。これにより、手動のシステムターン品質注釈を必要とせずに、弱い監督下で大量の対話セットでトレーニングできます。実験では、当社のモデルが人間による注釈付きデータでトレーニングされたモデルと同等であることが示されています。さらに、当社のモデルは、実際の有料ユーザーから収集された口頭および書面のオープンドメインの対話コーパスにわたって一般化します。"}
