{"title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "url": "https://aclanthology.org/2022.acl-srw.0/", "abstract": "acl-2022-association", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要旨です。以下の文章を日本語に翻訳してください。\n\n「第60回計算言語学協会年次大会：学生研究ワークショップの論文集」", "jabstract": "以下の文章は自然言語処理に関する論文の要約です。日本語に翻訳してください。\n\nacl-2022-association"}
{"title": "Evaluating zero-shot transfers and multilingual models for dependency parsing and POS tagging within the low-resource language family Tupían", "url": "https://aclanthology.org/2022.acl-srw.1/", "abstract": "This work presents two experiments with the goal of replicating the transferability of dependency parsers and POS taggers trained on closely related languages within the low-resource language family Tupían. The experiments include both zero-shot settings as well as multilingual models. Previous studies have found that even a comparably small treebank from a closely related language will improve sequence labelling considerably in such cases. Results from both POS tagging and dependency parsing confirm previous evidence that the closer the phylogenetic relation between two languages, the better the predictions for sequence labelling tasks get. In many cases, the results are improved if multiple languages from the same family are combined. This suggests that in addition to leveraging similarity between two related languages, the incorporation of multiple languages of the same family might lead to better results in transfer learning for NLP applications.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "低資源言語ファミリーTupíanにおける依存構文解析とPOSタグ付けのゼロショット転送と多言語モデルの評価", "jabstract": "この論文では、Tupíanという低リソース言語ファミリー内で、密接に関連する言語でトレーニングされた依存構文解析器とPOSタガーの転移性を再現することを目的とした2つの実験を紹介する。実験には、ゼロショット設定とマルチリンガルモデルの両方が含まれる。以前の研究では、密接に関連する言語からの比較的小さなツリーバンクでも、シーケンスラベリングをかなり改善することがわかっている。POSタギングと依存構文解析の両方からの結果は、2つの言語間の系統関係が近いほど、シーケンスラベリングタスクの予測がよくなることを確認している。多くの場合、同じファミリーの複数の言語を組み合わせると結果が改善される。これは、関連する2つの言語の類似性を活用するだけでなく、同じファミリーの複数の言語を組み合わせることで、NLPアプリケーションの転移学習においてより良い結果が得られる可能性があることを示唆している。"}
{"title": "RFBFN: A Relation-First Blank Filling Network for Joint Relational Triple Extraction", "url": "https://aclanthology.org/2022.acl-srw.2/", "abstract": "Joint relational triple extraction from unstructured text is an important task in information extraction. However, most existing works either ignore the semantic information of relations or predict subjects and objects sequentially. To address the issues, we introduce a new blank filling paradigm for the task, and propose a relation-first blank filling network (RFBFN). Specifically, we first detect potential relations maintained in the text to aid the following entity pair extraction. Then, we transform relations into relation templates with blanks which contain the fine-grained semantic representation of the relations. Finally, corresponding subjects and objects are extracted simultaneously by filling the blanks. We evaluate the proposed model on public benchmark datasets. Experimental results show our model outperforms current state-of-the-art methods. The source code of our work is available at: https://github.com/lizhe2016/RFBFN.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "RFBFN: 関係トリプル抽出のための関係優先ブランク埋め込みネットワーク\n\nAbstract:\nIn this paper, we propose a novel relation-first blank filling network (RFBFN) for joint relational triple extraction, which aims to extract subject-relation-object triples from natural language text. The proposed RFBFN consists of two main components: a relation-first encoder and a blank filling decoder. The relation-first encoder encodes the input sentence by focusing on the relation between the entities, while the blank filling decoder generates the missing entity in the triple. Experimental results on two benchmark datasets demonstrate that our proposed RFBFN outperforms state-of-the-art methods in terms of both accuracy and F1 score.", "jabstract": "非構造化テキストからの共同関係トリプル抽出は、情報抽出における重要なタスクです。しかし、既存の多くの研究は、関係の意味情報を無視するか、主語と目的語を順次予測します。これらの問題に対処するために、私たちは新しい空欄埋めパラダイムを導入し、関係優先空欄埋めネットワーク（RFBFN）を提案します。具体的には、まず、テキストに保持されている潜在的な関係を検出して、次のエンティティペア抽出を支援します。次に、関係を空欄を含む関係テンプレートに変換し、関係の細かい意味表現を含みます。最後に、対応する主語と目的語を空欄に入れて同時に抽出します。提案されたモデルを公開ベンチマークデータセットで評価しました。実験結果は、当社のモデルが現在の最先端の方法を上回っていることを示しています。当社の作品のソースコードは、https://github.com/lizhe2016/RFBFNで入手できます。"}
{"title": "Building a Dialogue Corpus Annotated with Expressed and Experienced Emotions", "url": "https://aclanthology.org/2022.acl-srw.3/", "abstract": "In communication, a human would recognize the emotion of an interlocutor and respond with an appropriate emotion, such as empathy and comfort. Toward developing a dialogue system with such a human-like ability, we propose a method to build a dialogue corpus annotated with two kinds of emotions. We collect dialogues from Twitter and annotate each utterance with the emotion that a speaker put into the utterance (expressed emotion) and the emotion that a listener felt after listening to the utterance (experienced emotion). We built a dialogue corpus in Japanese using this method, and its statistical analysis revealed the differences between expressed and experienced emotions. We conducted experiments on recognition of the two kinds of emotions. The experimental results indicated the difficulty in recognizing experienced emotions and the effectiveness of multi-task learning of the two kinds of emotions. We hope that the constructed corpus will facilitate the study on emotion recognition in a dialogue and emotion-aware dialogue response generation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「表現された感情と経験された感情に注釈が付けられた対話コーパスの構築」", "jabstract": "コミュニケーションにおいて、人間は相手の感情を認識し、共感や慰めなど適切な感情で応答する。このような人間らしい能力を持つ対話システムの開発に向けて、本論文では2種類の感情で注釈付けされた対話コーパスの構築方法を提案する。Twitterから対話を収集し、発話者が発話に込めた感情（表現された感情）と、聞き手が聞いた後に感じた感情（経験された感情）を注釈付けする。この方法を用いて日本語の対話コーパスを構築し、統計分析により表現された感情と経験された感情の違いが明らかになった。2種類の感情の認識実験を行った結果、経験された感情の認識が困難であること、2種類の感情のマルチタスク学習の有効性が示された。構築されたコーパスが対話における感情認識や感情を考慮した対話応答生成の研究を促進することを期待する。"}
{"title": "Darkness can not drive out darkness: Investigating Bias in Hate SpeechDetection Models", "url": "https://aclanthology.org/2022.acl-srw.4/", "abstract": "It has become crucial to develop tools for automated hate speech and abuse detection. These tools would help to stop the bullies and the haters and provide a safer environment for individuals especially from marginalized groups to freely express themselves. However, recent research shows that machine learning models are biased and they might make the right decisions for the wrong reasons. In this thesis, I set out to understand the performance of hate speech and abuse detection models and the different biases that could influence them. I show that hate speech and abuse detection models are not only subject to social bias but also to other types of bias that have not been explored before. Finally, I investigate the causal effect of the social and intersectional bias on the performance and unfairness of hate speech detection models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "暗闇は暗闇を追い払うことはできない：憎悪スピーチ検出モデルにおけるバイアスの調査", "jabstract": "自動的な憎悪表現や虐待の検出ツールの開発が重要になってきています。これらのツールは、いじめや憎悪表現を止め、特にマージナライズドグループからの個人が自由に表現できるように、より安全な環境を提供するのに役立ちます。しかし、最近の研究によると、機械学習モデルには偏りがあり、正しい決定を誤った理由で行う可能性があります。本論文では、憎悪表現や虐待の検出モデルの性能と影響を理解し、それらに影響を与えるさまざまなバイアスを調査します。憎悪表現や虐待の検出モデルは、社会的なバイアスだけでなく、これまで探究されていなかった他の種類のバイアスにも影響を受けることを示します。最後に、社会的および交差的バイアスの因果効果を調査し、憎悪表現の検出モデルの性能と不公平性に与える影響を調べます。"}
{"title": "Ethical Considerations for Low-resourced Machine Translation", "url": "https://aclanthology.org/2022.acl-srw.5/", "abstract": "This paper considers some ethical implications of machine translation for low-resourced languages. I use Armenian as a case study and investigate specific needs for and concerns arising from the creation and deployment of improved machine translation between English and Armenian. To do this, I conduct stakeholder interviews and construct Value Scenarios (Nathan et al., 2007) from the themes that emerge. These scenarios illustrate some of the potential harms that low-resourced language communities may face due to the deployment of improved machine translation systems. Based on these scenarios, I recommend 1) collaborating with stakeholders in order to create more useful and reliable machine translation tools, and 2) determining which other forms of language technology should be developed alongside efforts to improve machine translation in order to mitigate harms rendered to vulnerable language communities. Both of these goals require treating low-resourced machine translation as a language-specific, rather than language-agnostic, task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要旨の以下の文を日本語に翻訳してください：\n\n低資源機械翻訳の倫理的考慮事項", "jabstract": "この論文では、低資源言語に対する機械翻訳の倫理的な問題について考察する。アルメニア語を事例とし、英語とアルメニア語の改善された機械翻訳の作成と展開に伴う特定のニーズと懸念を調査する。そのために、ステークホルダーへのインタビューを行い、Nathanら(2007)のバリューシナリオを構築する。これらのシナリオは、低資源言語コミュニティが改善された機械翻訳システムの展開によって直面する可能性のある損害を示している。これらのシナリオに基づき、1)ステークホルダーと協力してより有用で信頼性の高い機械翻訳ツールを作成し、2)脆弱な言語コミュニティに与える損害を軽減するために、機械翻訳の改善に取り組む際に開発すべき他の言語技術を決定することを推奨する。これらの両方の目標は、低資源言語の機械翻訳を言語特有のタスクとして扱うことを必要とする。"}
{"title": "Integrating Question Rewrites in Conversational Question Answering: A Reinforcement Learning Approach", "url": "https://aclanthology.org/2022.acl-srw.6/", "abstract": "Resolving dependencies among dialogue history is one of the main obstacles in the research on conversational question answering (QA). The conversational question rewrites (QR) task has been shown to be effective to solve this problem by reformulating questions in a self-contained form. However, QR datasets are limited and existing methods tend to depend on the assumption of the existence of corresponding QR datasets for every CQA dataset.This paper proposes a reinforcement learning approach that integrates QR and CQA tasks without corresponding labeled QR datasets. We train a QR model based on the reward signal obtained from the CQA, and the experimental results show that our approach can bring improvement over the pipeline approaches.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "会話型質問応答における質問の書き換えの統合：強化学習アプローチ", "jabstract": "会話型質問応答（QA）の研究において、対話履歴の依存関係を解決することは主要な障害の一つである。会話型質問書き換え（QR）タスクは、自己完結形式の質問を再構築することによってこの問題を解決するために効果的であることが示されている。しかし、QRデータセットは限られており、既存の方法は、すべてのCQAデータセットに対応するQRデータセットの存在を前提とする傾向がある。本論文では、対応するラベル付きQRデータセットがなくてもQRとCQAタスクを統合する強化学習アプローチを提案する。CQAから得られた報酬信号に基づいてQRモデルをトレーニングし、実験結果は、パイプラインアプローチよりも改善をもたらすことが示されている。"}
{"title": "What Do You Mean by Relation Extraction? A Survey on Datasets and Study on Scientific Relation Classification", "url": "https://aclanthology.org/2022.acl-srw.7/", "abstract": "Over the last five years, research on Relation Extraction (RE) witnessed extensive progress with many new dataset releases. At the same time, setup clarity has decreased, contributing to increased difficulty of reliable empirical evaluation (Taillé et al., 2020). In this paper, we provide a comprehensive survey of RE datasets, and revisit the task definition and its adoption by the community. We find that cross-dataset and cross-domain setups are particularly lacking. We present an empirical study on scientific Relation Classification across two datasets. Despite large data overlap, our analysis reveals substantial discrepancies in annotation. Annotation discrepancies strongly impact Relation Classification performance, explaining large drops in cross-dataset evaluations. Variation within further sub-domains exists but impacts Relation Classification only to limited degrees. Overall, our study calls for more rigour in reporting setups in RE and evaluation across multiple test sets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「Relation Extraction」とは何を意味するのか？データセットに関する調査と科学的関係分類に関する研究についての調査書", "jabstract": "過去5年間、関係抽出（RE）に関する研究は多くの新しいデータセットのリリースとともに大きな進歩を遂げてきました。同時に、セットアップの明確さが減少し、信頼性の高い経験的評価の困難さが増加しています（Taillé et al.、2020）。本論文では、REデータセットの包括的な調査を提供し、タスク定義とそのコミュニティによる採用を再検討します。クロスデータセットおよびクロスドメインのセットアップが特に不足していることがわかりました。2つのデータセットを対象とした科学的関係分類の経験的研究を行いました。大きなデータの重複があるにもかかわらず、私たちの分析は注釈に重大な不一致があることを明らかにしました。注釈の不一致は、クロスデータセットの評価で大幅な性能低下を説明し、関係分類に強く影響を与えます。さらに、サブドメイン内の変動は存在しますが、関係分類には限定的な影響しか与えません。全体的に、私たちの研究は、REにおけるセットアップの報告と複数のテストセットでの評価により厳密さが必要であることを示唆しています。"}
{"title": "Logical Inference for Counting on Semi-structured Tables", "url": "https://aclanthology.org/2022.acl-srw.8/", "abstract": "Recently, the Natural Language Inference (NLI) task has been studied for semi-structured tables that do not have a strict format. Although neural approaches have achieved high performance in various types of NLI, including NLI between semi-structured tables and texts, they still have difficulty in performing a numerical type of inference, such as counting. To handle a numerical type of inference, we propose a logical inference system for reasoning between semi-structured tables and texts. We use logical representations as meaning representations for tables and texts and use model checking to handle a numerical type of inference between texts and tables. To evaluate the extent to which our system can perform inference with numerical comparatives, we make an evaluation protocol that focuses on numerical understanding between semi-structured tables and texts in English. We show that our system can more robustly perform inference between tables and texts that requires numerical understanding compared with current neural approaches.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "半構造化テーブルにおける数え上げのための論理推論", "jabstract": "最近、厳密なフォーマットを持たない半構造化テーブルに対する自然言語推論（NLI）タスクが研究されています。ニューラルアプローチは、半構造化テーブルとテキストのNLIを含む様々なタイプのNLIで高い性能を発揮していますが、数値的な推論（例えば、カウント）を行うことにはまだ苦労しています。数値的な推論を扱うために、我々は半構造化テーブルとテキストの間の推論のための論理推論システムを提案します。我々は、テーブルとテキストの意味表現として論理表現を使用し、テキストとテーブルの間の数値的な推論を扱うためにモデルチェックを使用します。半構造化テーブルとテキストの間の数値的な理解に焦点を当てた評価プロトコルを作成し、我々のシステムが数値的な比較を含むテーブルとテキストの間の推論をより堅牢に実行できることを示します。現在のニューラルアプローチと比較して、我々のシステムはより高い性能を発揮します。"}
{"title": "GNNer: Reducing Overlapping in Span-based NER Using Graph Neural Networks", "url": "https://aclanthology.org/2022.acl-srw.9/", "abstract": "There are two main paradigms for Named Entity Recognition (NER): sequence labelling and span classification. Sequence labelling aims to assign a label to each word in an input text using, for example, BIO (Begin, Inside and Outside) tagging, while span classification involves enumerating all possible spans in a text and classifying them into their labels. In contrast to sequence labelling, unconstrained span-based methods tend to assign entity labels to overlapping spans, which is generally undesirable, especially for NER tasks without nested entities. Accordingly, we propose GNNer, a framework that uses Graph Neural Networks to enrich the span representation to reduce the number of overlapping spans during prediction. Our approach reduces the number of overlapping spans compared to strong baseline while maintaining competitive metric performance. Code is available at https://github.com/urchade/GNNer.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "GNNer：グラフニューラルネットワークを使用して、スパンベースのNERにおける重複を減らす\n\n※NER：Named Entity Recognition（固有表現抽出）", "jabstract": "Named Entity Recognition（NER）には、シーケンスラベリングとスパン分類の2つの主要なパラダイムがあります。シーケンスラベリングは、BIO（Begin、Inside、Outside）タグ付けなどを使用して、入力テキストの各単語にラベルを割り当てることを目的としています。一方、スパン分類は、テキスト内のすべての可能なスパンを列挙し、それらをラベルに分類することを含みます。シーケンスラベリングとは対照的に、制約のないスパンベースの方法は、重複するスパンにエンティティラベルを割り当てる傾向があり、これは一般的に望ましくないです。特に、ネストされたエンティティがないNERタスクの場合はそうです。そのため、私たちはGNNerを提案します。これは、グラフニューラルネットワークを使用してスパン表現を豊かにし、予測中の重複するスパンの数を減らすためのフレームワークです。私たちのアプローチは、強力なベースラインと比較して、重複するスパンの数を減らしながら競争力のあるメトリックパフォーマンスを維持します。コードはhttps://github.com/urchade/GNNerで利用可能です。"}
{"title": "Compositional Semantics and Inference System for Temporal Order based on Japanese CCG", "url": "https://aclanthology.org/2022.acl-srw.10/", "abstract": "Natural Language Inference (NLI) is the task of determining whether a premise entails a hypothesis. NLI with temporal order is a challenging task because tense and aspect are complex linguistic phenomena involving interactions with temporal adverbs and temporal connectives. To tackle this, temporal and aspectual inference has been analyzed in various ways in the field of formal semantics. However, a Japanese NLI system for temporal order based on the analysis of formal semantics has not been sufficiently developed. We present a logic-based NLI system that considers temporal order in Japanese based on compositional semantics via Combinatory Categorial Grammar (CCG) syntactic analysis. Our system performs inference involving temporal order by using axioms for temporal relations and automated theorem provers. We evaluate our system by experimenting with Japanese NLI datasets that involve temporal order. We show that our system outperforms previous logic-based systems as well as current deep learning-based models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "日本語CCGに基づく時間順序のための構成的意味論と推論システム", "jabstract": "自然言語推論（NLI）は、前提が仮説を含意するかどうかを決定するタスクである。時間的順序を考慮したNLIは、時制と相が時間副詞や時間接続詞との相互作用を含む複雑な言語現象であるため、課題がある。この問題に対処するために、形式意味論の分野で、時間的および相関推論が様々な方法で分析されてきた。しかし、形式意味論に基づく日本語の時間的順序に関するNLIシステムは、十分に開発されていない。本論文では、組み合わせカテゴリー文法（CCG）構文解析を介した合成意味論に基づく日本語の時間的順序を考慮した論理ベースのNLIシステムを提案する。本システムは、時間関係の公理と自動定理証明器を使用して、時間的順序を含む推論を実行する。我々は、時間的順序を含む日本語NLIデータセットを用いて、本システムを評価する。その結果、本システムは、以前の論理ベースのシステムや現在の深層学習ベースのモデルよりも優れた性能を示すことを示す。"}
{"title": "Combine to Describe: Evaluating Compositional Generalization in Image Captioning", "url": "https://aclanthology.org/2022.acl-srw.11/", "abstract": "Compositionality – the ability to combine simpler concepts to understand & generate arbitrarily more complex conceptual structures – has long been thought to be the cornerstone of human language capacity. With the recent, notable success of neural models in various NLP tasks, attention has now naturally turned to the compositional capacity of these models. In this paper, we study the compositional generalization properties of image captioning models. We perform a set experiments under controlled conditions using model and data ablations, each designed to benchmark a particular facet of compositional generalization: systematicity is the ability of a model to create novel combinations of concepts out of those observed during training, productivity is here operationalised as the capacity of a model to extend its predictions beyond the length distribution it has observed during training, and substitutivity is concerned with the robustness of the model against synonym substitutions. While previous work has focused primarily on systematicity, here we provide a more in-depth analysis of the strengths and weaknesses of state of the art captioning models. Our findings demonstrate that the models we study here do not compositionally generalize in terms of systematicity and productivity, however, they are robust to some degree to synonym substitutions", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「結合して説明する：画像キャプショニングにおける合成的一般化の評価」は、自然言語処理に関する論文の要約です。", "jabstract": "合成性 - より単純な概念を組み合わせて任意に複雑な概念構造を理解・生成する能力 - は、長年にわたり人間の言語能力の基盤と考えられてきました。最近、ニューラルモデルがさまざまなNLPタスクで注目すべき成功を収めたことから、これらのモデルの合成能力に注目が集まっています。本論文では、画像キャプションモデルの合成一般化特性を研究します。我々は、モデルとデータの欠落を使用した一連の実験を制御された条件下で実行し、合成一般化の特定の側面をベンチマークするためにそれぞれ設計されました。体系性は、モデルがトレーニング中に観察された概念の新しい組み合わせを作成する能力です。生産性は、モデルがトレーニング中に観察された長さ分布を超えて予測を拡張する能力です。置換性は、モデルが同義語の置換に対してどの程度堅牢であるかに関するものです。以前の研究は主に体系性に焦点を当てていましたが、ここでは最新のキャプションモデルの強みと弱みについてより詳細な分析を提供します。私たちの調査結果は、ここで研究されたモデルが体系性と生産性の点で合成的に一般化しないことを示していますが、同義語の置換に対してある程度堅牢であることを示しています。"}
{"title": "Towards Unification of Discourse Annotation Frameworks", "url": "https://aclanthology.org/2022.acl-srw.12/", "abstract": "Discourse information is difficult to represent and annotate. Among the major frameworks for annotating discourse information, RST, PDTB and SDRT are widely discussed and used, each having its own theoretical foundation and focus. Corpora annotated under different frameworks vary considerably. To make better use of the existing discourse corpora and achieve the possible synergy of different frameworks, it is worthwhile to investigate the systematic relations between different frameworks and devise methods of unifying the frameworks. Although the issue of framework unification has been a topic of discussion for a long time, there is currently no comprehensive approach which considers unifying both discourse structure and discourse relations and evaluates the unified framework intrinsically and extrinsically. We plan to use automatic means for the unification task and evaluate the result with structural complexity and downstream tasks. We will also explore the application of the unified framework in multi-task learning and graphical models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「談話注釈フレームワークの統一に向けて」", "jabstract": "談話情報は表現や注釈が困難である。談話情報を注釈する主要なフレームワークには、RST、PDTB、SDRTがあり、それぞれ独自の理論的基盤と焦点を持って広く議論され、使用されている。異なるフレームワークで注釈されたコーパスはかなり異なる。既存の談話コーパスをより良く活用し、異なるフレームワークの可能なシナジーを実現するために、異なるフレームワーク間の体系的な関係を調査し、フレームワークを統一する方法を考案することは価値がある。フレームワークの統一に関する問題は長年議論されてきたが、談話構造と談話関係の両方を統一し、統一されたフレームワークを内的および外的に評価する包括的なアプローチは現在存在していない。我々は自動手段を使用して統一タスクを行い、構造的複雑さと下流タスクで結果を評価する予定である。また、マルチタスク学習とグラフィカルモデルで統一されたフレームワークの応用を探求する予定である。"}
{"title": "AMR Alignment for Morphologically-rich and Pro-drop Languages", "url": "https://aclanthology.org/2022.acl-srw.13/", "abstract": "Alignment between concepts in an abstract meaning representation (AMR) graph and the words within a sentence is one of the important stages of AMR parsing. Although there exist high performing AMR aligners for English, unfortunately, these are not well suited for many languages where many concepts appear from morpho-semantic elements.For the first time in the literature, this paper presents an AMR aligner tailored for morphologically-rich and pro-drop languages by experimenting on the Turkish language being a prominent example of this language group.Our aligner focuses on the meaning considering the rich Turkish morphology and aligns AMR concepts that emerge from morphemes using a tree traversal approach without additional resources or rules. We evaluate our aligner over a manually annotated gold data set in terms of precision, recall and F1 score. Our aligner outperforms the Turkish adaptations of the previously proposed aligners for English and Portuguese by an F1 score of 0.87 and provides a relative error reduction of up to 76%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n形態豊かでプロドロップ言語のためのAMRアラインメント", "jabstract": "抽象的な意味表現（AMR）グラフ内の概念と文内の単語の整合性は、AMR解析の重要な段階の1つです。英語に対して高い性能を発揮するAMRアライナーが存在する一方で、多くの概念が形態意味要素から出現する多くの言語には適していません。本論文では、この言語グループの代表的な例であるトルコ語を実験対象として、形態豊かでプロドロップ言語に適したAMRアライナーを初めて提案します。私たちのアライナーは、豊かなトルコ語の形態を考慮して意味に焦点を当て、追加のリソースやルールなしに形態素から出現するAMR概念を木のトラバースアプローチを用いて整列します。私たちは、手動で注釈付けされたゴールドデータセットを用いて、精度、再現率、F1スコアについて私たちのアライナーを評価しました。私たちのアライナーは、英語やポルトガル語に対するトルコ語の適応版のアライナーをF1スコア0.87で上回り、相対誤差削減率は最大で76％を提供します。"}
{"title": "Sketching a Linguistically-Driven Reasoning Dialog Model for Social Talk", "url": "https://aclanthology.org/2022.acl-srw.14/", "abstract": "The capability of holding social talk (or casual conversation) and making sense of conversational content requires context-sensitive natural language understanding and reasoning, which cannot be handled efficiently by the current popular open-domain dialog systems and chatbots. Heavily relying on corpus-based machine learning techniques to encode and decode context-sensitive meanings, these systems focus on fitting a particular training dataset, but not tracking what is actually happening in a conversation, and therefore easily derail in a new context. This work sketches out a more linguistically-informed architecture to handle social talk in English, in which corpus-based methods form the backbone of the relatively context-insensitive components (e.g. part-of-speech tagging, approximation of lexical meaning and constituent chunking), while symbolic modeling is used for reasoning out the context-sensitive components, which do not have any consistent mapping to linguistic forms. All components are fitted into a Bayesian game-theoretic model to address the interactive and rational aspects of conversation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "社会的な会話のための言語学に基づく推論的な対話モデルのスケッチ", "jabstract": "社交的な会話を行い、会話内容を理解する能力には、文脈に敏感な自然言語理解と推論が必要であり、現在の一般的なオープンドメインの対話システムやチャットボットでは効率的に処理できない。これらのシステムは、文脈に敏感な意味をエンコードおよびデコードするためにコーパスベースの機械学習技術に大きく依存しており、特定のトレーニングデータセットに適合することに焦点を当てていますが、会話で実際に起こっていることを追跡することはできず、新しい文脈で容易に脱線します。本研究では、比較的文脈に敏感でないコンポーネント（品詞タグ付け、語彙的意味の近似、構成要素のチャンキングなど）のバックボーンとしてコーパスベースの手法を使用し、文脈に一貫したマッピングを持たない文脈に敏感なコンポーネントを推論するためにシンボリックモデリングを使用する、英語の社交的な会話を処理するためのより言語学的に基づいたアーキテクチャを概説しています。すべてのコンポーネントは、会話の相互作用的かつ合理的な側面に対処するためにベイジアンゲーム理論モデルに適合されます。"}
{"title": "Scoping natural language processing in Indonesian and Malay for education applications", "url": "https://aclanthology.org/2022.acl-srw.15/", "abstract": "Indonesian and Malay are underrepresented in the development of natural language processing (NLP) technologies and available resources are difficult to find. A clear picture of existing work can invigorate and inform how researchers conceptualise worthwhile projects. Using an education sector project to motivate the study, we conducted a wide-ranging overview of Indonesian and Malay human language technologies and corpus work. We charted 657 included studies according to Hirschberg and Manning’s 2015 description of NLP, concluding that the field was dominated by exploratory corpus work, machine reading of text gathered from the Internet, and sentiment analysis. In this paper, we identify most published authors and research hubs, and make a number of recommendations to encourage future collaboration and efficiency within NLP in Indonesian and Malay.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "インドネシア語とマレー語における教育アプリケーションに向けた自然言語処理の範囲を明確化する。", "jabstract": "インドネシア語とマレー語は、自然言語処理（NLP）技術の開発において十分に扱われておらず、利用可能なリソースを見つけることが困難です。既存の研究の明確な概要は、研究者が有益なプロジェクトを構想する上で活力を与え、情報を提供することができます。教育セクターのプロジェクトを動機として、私たちはインドネシア語とマレー語の人間言語技術とコーパス作業について広範な概要を行いました。私たちは657の研究をHirschbergとManningの2015年のNLPの説明に従って分類し、探索的なコーパス作業、インターネットから収集されたテキストの機械読み取り、感情分析が支配的であることを結論づけました。本論文では、最も多くの著者や研究拠点を特定し、インドネシア語とマレー語のNLP内での将来の協力と効率を促進するためのいくつかの提言を行います。"}
{"title": "English-Malay Cross-Lingual Embedding Alignment using Bilingual Lexicon Augmentation", "url": "https://aclanthology.org/2022.acl-srw.16/", "abstract": "As high-quality Malay language resources are still a scarcity, cross lingual word embeddings make it possible for richer English resources to be leveraged for downstream Malay text classification tasks. This paper focuses on creating an English-Malay cross-lingual word embeddings using embedding alignment by exploiting existing language resources. We augmented the training bilingual lexicons using machine translation with the goal to improve the alignment precision of our cross-lingual word embeddings. We investigated the quality of the current state-of-the-art English-Malay bilingual lexicon and worked on improving its quality using Google Translate. We also examined the effect of Malay word coverage on the quality of cross-lingual word embeddings. Experimental results with a precision up till 28.17% show that the alignment precision of the cross-lingual word embeddings would inevitably degrade after 1-NN but a better seed lexicon and cleaner nearest neighbours can reduce the number of word pairs required to achieve satisfactory performance. As the English and Malay monolingual embeddings are pre-trained on informal language corpora, our proposed English-Malay embeddings alignment approach is also able to map non-standard Malay translations in the English nearest neighbours.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "バイリンガルレキシコン拡張を使用した英語-マレー語クロスリンガル埋め込みアラインメント", "jabstract": "高品質のマレー語リソースがまだ不足しているため、クロスリンガルワードエンベッディングを使用することで、豊富な英語リソースを下流のマレー語テキスト分類タスクに活用することが可能になります。本論文では、既存の言語リソースを利用して埋め込みの整合性を利用した英語-マレー語クロスリンガルワードエンベッディングの作成に焦点を当てています。機械翻訳を使用してトレーニングバイリンガル辞書を拡張し、クロスリンガルワードエンベッディングの整合性精度を向上させることを目的としています。現在の最先端の英語-マレー語バイリンガル辞書の品質を調査し、Google翻訳を使用してその品質を改善することを検討しました。また、マレー語の単語カバレッジがクロスリンガルワードエンベッディングの品質に与える影響も調べました。28.17％までの精度を持つ実験結果は、クロスリンガルワードエンベッディングの整合性精度が1-NN後に必然的に低下することを示していますが、より良いシード辞書とよりクリーンな最近傍は、満足のいくパフォーマンスを達成するために必要な単語ペアの数を減らすことができます。英語とマレー語の単一言語エンベッディングが非公式の言語コーパスで事前にトレーニングされているため、提案された英語-マレー語エンベッディングの整合アプローチは、英語の最近傍に非標準的なマレー語の翻訳をマッピングすることもできます。"}
{"title": "Towards Detecting Political Bias in Hindi News Articles", "url": "https://aclanthology.org/2022.acl-srw.17/", "abstract": "Political propaganda in recent times has been amplified by media news portals through biased reporting, creating untruthful narratives on serious issues causing misinformed public opinions with interests of siding and helping a particular political party. This issue proposes a challenging NLP task of detecting political bias in news articles.We propose a transformer-based transfer learning method to fine-tune the pre-trained network on our data for this bias detection. As the required dataset for this particular task was not available, we created our dataset comprising 1388 Hindi news articles and their headlines from various Hindi news media outlets. We marked them on whether they are biased towards, against, or neutral to BJP, a political party, and the current ruling party at the centre in India.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "ヒンディー語ニュース記事における政治的偏見の検出に向けて", "jabstract": "近年の政治プロパガンダは、偏向報道を通じてメディアニュースポータルによって増幅され、深刻な問題について不正確な物語を作り出し、特定の政党を支持し、助けるために誤った公衆意見を引き起こしています。この問題は、ニュース記事の政治的偏見を検出する難しいNLPタスクを提案しています。私たちは、この偏見検出のために、事前学習されたネットワークを私たちのデータに微調整するトランスフォーマーベースの転移学習方法を提案しています。この特定のタスクに必要なデータセットがなかったため、私たちは、さまざまなヒンディー語ニュースメディアから1388のヒンディー語ニュース記事とその見出しを含むデータセットを作成しました。私たちは、それらがインドの中央政府の現在の与党である政党であるBJPに対して、反対しているか、または中立であるかをマークしました。"}
{"title": "Restricted or Not: A General Training Framework for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-srw.18/", "abstract": "Restricted machine translation incorporates human prior knowledge into translation. It restricts the flexibility of the translation to satisfy the demands of translation in specific scenarios. Existing work typically imposes constraints on beam search decoding. Although this can satisfy the requirements overall, it usually requires a larger beam size and far longer decoding time than unrestricted translation, which limits the concurrent processing ability of the translation model in deployment, and thus its practicality. In this paper, we propose a general training framework that allows a model to simultaneously support both unrestricted and restricted translation by adopting an additional auxiliary training process without constraining the decoding process. This maintains the benefits of restricted translation but greatly reduces the extra time overhead of constrained decoding, thus improving its practicality. The effectiveness of our proposed training framework is demonstrated by experiments on both original (WAT21 En↔Ja) and simulated (WMT14 En→De and En→Fr) restricted translation benchmarks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "制限されたか否か：ニューラル機械翻訳の一般的なトレーニングフレームワーク", "jabstract": "制限付き機械翻訳は、翻訳の特定のシナリオにおける要求を満たすために、人間の先行知識を翻訳に取り入れます。これにより、翻訳の柔軟性が制限されます。既存の研究では、ビームサーチデコーディングに制約を課すことが一般的です。これは全体的に要件を満たすことができますが、通常、制限のない翻訳よりも大きなビームサイズとはるかに長いデコーディング時間が必要であり、展開時の翻訳モデルの並列処理能力を制限し、その実用性を制限します。本論文では、デコーディングプロセスを制限することなく、追加の補助トレーニングプロセスを採用することで、モデルが制限のない翻訳と制限付き翻訳の両方を同時にサポートできる一般的なトレーニングフレームワークを提案します。これにより、制限付き翻訳の利点を維持しながら、制限付きデコーディングの余分な時間オーバーヘッドを大幅に削減し、実用性を向上させます。提案されたトレーニングフレームワークの効果は、オリジナル（WAT21 En↔Ja）およびシミュレートされた（WMT14 En→DeおよびEn→Fr）制限付き翻訳ベンチマークの両方での実験によって示されています。"}
{"title": "What do Models Learn From Training on More Than Text? Measuring Visual Commonsense Knowledge", "url": "https://aclanthology.org/2022.acl-srw.19/", "abstract": "There are limitations in learning language from text alone. Therefore, recent focus has been on developing multimodal models. However, few benchmarks exist that can measure what language models learn about language from multimodal training. We hypothesize that training on a visual modality should improve on the visual commonsense knowledge in language models. Therefore, we introduce two evaluation tasks for measuring visual commonsense knowledge in language models (code publicly available at: github.com/lovhag/measure-visual-commonsense-knowledge) and use them to evaluate different multimodal models and unimodal baselines. Primarily, we find that the visual commonsense knowledge is not significantly different between the multimodal models and unimodal baseline models trained on visual text data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「テキスト以上のトレーニングからモデルが学ぶものは何か？視覚的な常識的知識の測定」", "jabstract": "テキストだけから言語を学ぶには限界があるため、最近はマルチモーダルモデルの開発に注力されています。しかし、マルチモーダルトレーニングから言語モデルがどのように言語を学ぶかを測定できるベンチマークはほとんど存在しません。我々は、視覚モダリティでのトレーニングが言語モデルの視覚的な常識知識を向上させると仮説を立てました。そのため、言語モデルの視覚的な常識知識を測定するための2つの評価タスクを導入し（コードはgithub.com/lovhag/measure-visual-commonsense-knowledgeで公開されています）、異なるマルチモーダルモデルと単一モダルのベースラインを評価しました。主に、視覚テキストデータでトレーニングされたマルチモーダルモデルと単一モダルのベースラインモデルの視覚的な常識知識には有意な違いがないことがわかりました。"}
{"title": "TeluguNER: Leveraging Multi-Domain Named Entity Recognition with Deep Transformers", "url": "https://aclanthology.org/2022.acl-srw.20/", "abstract": "Named Entity Recognition (NER) is a successful and well-researched problem in English due to the availability of resources. The transformer models, specifically the masked-language models (MLM), have shown remarkable performance in NER during recent times. With growing data in different online platforms, there is a need for NER in other languages too. NER remains to be underexplored in Indian languages due to the lack of resources and tools. Our contributions in this paper include (i) Two annotated NER datasets for the Telugu language in multiple domains: Newswire Dataset (ND) and Medical Dataset (MD), and we combined ND and MD to form Combined Dataset (CD) (ii) Comparison of the finetuned Telugu pretrained transformer models (BERT-Te, RoBERTa-Te, and ELECTRA-Te) with other baseline models (CRF, LSTM-CRF, and BiLSTM-CRF) (iii) Further investigation of the performance of Telugu pretrained transformer models against the multilingual models mBERT, XLM-R, and IndicBERT. We find that pretrained Telugu language models (BERT-Te and RoBERTa) outperform the existing pretrained multilingual and baseline models in NER. On a large dataset (CD) of 38,363 sentences, the BERT-Te achieves a high F1-score of 0.80 (entity-level) and 0.75 (token-level). Further, these pretrained Telugu models have shown state-of-the-art performance on various existing Telugu NER datasets. We open-source our dataset, pretrained models, and code.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「TeluguNER：深層トランスフォーマーを用いたマルチドメイン固有表現認識の活用」に関する論文の要約です。", "jabstract": "Named Entity Recognition（NER）は、リソースの利用可能性により、英語で成功し、よく研究された問題です。トランスフォーマーモデル、特にマスク言語モデル（MLM）は、最近のNERで驚異的なパフォーマンスを示しています。さまざまなオンラインプラットフォームで成長するデータに対応するため、他の言語でもNERが必要です。リソースとツールの不足により、NERはインドの言語で未開拓のままです。本論文の貢献は、（i）複数のドメインでテルグ語の2つの注釈付きNERデータセット：ニュースワイヤーデータセット（ND）と医療データセット（MD）を組み合わせて、結合データセット（CD）を形成したこと、（ii）ファインチューニングされたテルグ語の事前学習済みトランスフォーマーモデル（BERT-Te、RoBERTa-Te、ELECTRA-Te）と他のベースラインモデル（CRF、LSTM-CRF、BiLSTM-CRF）の比較、（iii）テルグ語の事前学習済みトランスフォーマーモデルと多言語モデルmBERT、XLM-R、IndicBERTのパフォーマンスのさらなる調査です。事前学習済みのテルグ語モデル（BERT-Te、RoBERTa）は、NERで既存の事前学習済みの多言語およびベースラインモデルを上回るパフォーマンスを発揮しています。 38,363の文の大規模なデータセット（CD）では、BERT-Teは高いF1スコア（エンティティレベル）0.80および（トークンレベル）0.75を達成しています。さらに、これらの事前学習済みのテルグ語モデルは、さまざまな既存のテルグ語NERデータセットで最先端のパフォーマンスを発揮しています。私たちは、データセット、事前学習済みモデル、およびコードをオープンソース化しています。"}
{"title": "Using Neural Machine Translation Methods for Sign Language Translation", "url": "https://aclanthology.org/2022.acl-srw.21/", "abstract": "We examine methods and techniques, proven to be helpful for the text-to-text translation of spoken languages in the context of gloss-to-text translation systems, where the glosses are the written representation of the signs. We present one of the first works that include experiments on both parallel corpora of the German Sign Language (PHOENIX14T and the Public DGS Corpus). We experiment with two NMT architectures with optimization of their hyperparameters, several tokenization methods and two data augmentation techniques (back-translation and paraphrasing). Through our investigation we achieve a substantial improvement of 5.0 and 2.2 BLEU scores for the models trained on the two corpora respectively. Our RNN models outperform our Transformer models, and the segmentation method we achieve best results with is BPE, whereas back-translation and paraphrasing lead to minor but not significant improvements.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要旨を日本語に翻訳します。\n\n神経機械翻訳法を使用した手話翻訳について", "jabstract": "私たちは、手話の書き言葉であるグロスをテキストに翻訳するシステムの文脈で、話される言語のテキストからテキストへの翻訳に役立つと証明された方法や技術を検討します。私たちは、ドイツ手話の並列コーパス（PHOENIX14TとPublic DGS Corpus）の両方で実験を行った最初の研究の1つを紹介します。私たちは、ハイパーパラメータの最適化を行った2つのNMTアーキテクチャ、いくつかのトークナイズ方法、および2つのデータ拡張技術（逆翻訳と言い換え）を用いて実験を行いました。調査の結果、私たちは、それぞれのコーパスでトレーニングされたモデルのBLEUスコアを5.0と2.2改善しました。私たちのRNNモデルはTransformerモデルよりも優れており、最も良い結果を得られたセグメンテーション方法はBPEであり、逆翻訳と言い換えはわずかながら有意な改善をもたらしませんでした。"}
{"title": "Flexible Visual Grounding", "url": "https://aclanthology.org/2022.acl-srw.22/", "abstract": "Existing visual grounding datasets are artificially made, where every query regarding an entity must be able to be grounded to a corresponding image region, i.e., answerable. However, in real-world multimedia data such as news articles and social media, many entities in the text cannot be grounded to the image, i.e., unanswerable, due to the fact that the text is unnecessarily directly describing the accompanying image. A robust visual grounding model should be able to flexibly deal with both answerable and unanswerable visual grounding. To study this flexible visual grounding problem, we construct a pseudo dataset and a social media dataset including both answerable and unanswerable queries. In order to handle unanswerable visual grounding, we propose a novel method by adding a pseudo image region corresponding to a query that cannot be grounded. The model is then trained to ground to ground-truth regions for answerable queries and pseudo regions for unanswerable queries. In our experiments, we show that our model can flexibly process both answerable and unanswerable queries with high accuracy on our datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n柔軟な視覚的基盤", "jabstract": "既存の視覚的グラウンディングデータセットは人工的に作成されており、すべてのエンティティに関するクエリは、対応する画像領域にグラウンディングできる必要があります。つまり、回答可能である必要があります。しかし、ニュース記事やソーシャルメディアなどの現実世界のマルチメディアデータでは、テキスト内の多くのエンティティは画像にグラウンディングできないため、回答不可能です。これは、テキストが不必要に直接付随する画像を説明しているためです。堅牢な視覚的グラウンディングモデルは、回答可能な視覚的グラウンディングと回答不可能な視覚的グラウンディングの両方を柔軟に扱える必要があります。この柔軟な視覚的グラウンディング問題を研究するために、回答可能なクエリと回答不可能なクエリの両方を含む疑似データセットとソーシャルメディアデータセットを構築します。回答不可能な視覚的グラウンディングを処理するために、クエリにグラウンディングできない疑似画像領域を追加する新しい方法を提案します。その後、モデルは、回答可能なクエリのグラウンド・トゥルース領域と回答不可能なクエリの疑似領域にグラウンディングするようにトレーニングされます。実験では、モデルがデータセットで高い精度で回答可能なクエリと回答不可能なクエリの両方を柔軟に処理できることを示します。"}
{"title": "A large-scale computational study of content preservation measures for text style transfer and paraphrase generation", "url": "https://aclanthology.org/2022.acl-srw.23/", "abstract": "Text style transfer and paraphrasing of texts are actively growing areas of NLP, dozens of methods for solving these tasks have been recently introduced. In both tasks, the system is supposed to generate a text which should be semantically similar to the input text. Therefore, these tasks are dependent on methods of measuring textual semantic similarity. However, it is still unclear which measures are the best to automatically evaluate content preservation between original and generated text. According to our observations, many researchers still use BLEU-like measures, while there exist more advanced measures including neural-based that significantly outperform classic approaches. The current problem is the lack of a thorough evaluation of the available measures. We close this gap by conducting a large-scale computational study by comparing 57 measures based on different principles on 19 annotated datasets. We show that measures based on cross-encoder models outperform alternative approaches in almost all cases.We also introduce the Mutual Implication Score (MIS), a measure that uses the idea of paraphrasing as a bidirectional entailment and outperforms all other measures on the paraphrase detection task and performs on par with the best measures in the text style transfer task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "テキストスタイルの変換と言い換え生成のためのコンテンツ保存措置の大規模な計算的研究", "jabstract": "テキストスタイルの変換とテキストの言い換えは、NLPの活発な成長分野であり、これらのタスクを解決するための数十の方法が最近導入されています。両方のタスクでは、システムは入力テキストに意味的に類似したテキストを生成することが期待されています。したがって、これらのタスクは、テキストの意味的類似性を測定する方法に依存しています。しかし、オリジナルと生成されたテキストの内容の保存を自動的に評価するための最適な手法はまだ明確ではありません。私たちの観察によると、多くの研究者はまだBLEUのような手法を使用していますが、より高度なニューラルベースの手法が存在し、古典的な手法を大幅に上回っています。現在の問題は、利用可能な手法の徹底的な評価の欠如です。私たちは、19の注釈付きデータセットで異なる原則に基づく57の手法を比較することにより、大規模な計算的研究を行うことで、このギャップを埋めます。クロスエンコーダーモデルに基づく手法がほとんどの場合で代替手法を上回ることを示します。また、相互含意スコア（MIS）を紹介し、言い換え検出タスクで他のすべての手法を上回り、テキストスタイル変換タスクで最高の手法と同等の性能を発揮します。"}
{"title": "Explicit Object Relation Alignment for Vision and Language Navigation", "url": "https://aclanthology.org/2022.acl-srw.24/", "abstract": "In this paper, we investigate the problem of vision and language navigation. To solve this problem, grounding the landmarks and spatial relations in the textual instructions into visual modality is important. We propose a neural agent named Explicit Object Relation Alignment Agent (EXOR),to explicitly align the spatial information in both instruction and the visual environment, including landmarks and spatial relationships between the agent and landmarks.Empirically, our proposed method surpasses the baseline by a large margin on the R2R dataset. We provide a comprehensive analysis to show our model’s spatial reasoning ability and explainability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「視覚と言語ナビゲーションのための明示的なオブジェクト関係の整列」", "jabstract": "本論文では、ビジョンと言語ナビゲーションの問題を調査します。この問題を解決するために、テキスト指示のランドマークと空間関係を視覚的な形式に落とし込むことが重要です。私たちは、明示的なオブジェクト関係アラインメントエージェント（EXOR）というニューラルエージェントを提案し、指示と視覚環境、ランドマークとエージェントとの空間関係を明示的に整列させます。実験的に、私たちの提案手法はR2Rデータセットでベースラインを大幅に上回ります。私たちは、モデルの空間推論能力と説明可能性を示す包括的な分析を提供します。"}
{"title": "Mining Logical Event Schemas From Pre-Trained Language Models", "url": "https://aclanthology.org/2022.acl-srw.25/", "abstract": "We present NESL (the Neuro-Episodic Schema Learner), an event schema learning system that combines large language models, FrameNet parsing, a powerful logical representation of language, and a set of simple behavioral schemas meant to bootstrap the learning process. In lieu of a pre-made corpus of stories, our dataset is a continuous feed of “situation samples” from a pre-trained language model, which are then parsed into FrameNet frames, mapped into simple behavioral schemas, and combined and generalized into complex, hierarchical schemas for a variety of everyday scenarios. We show that careful sampling from the language model can help emphasize stereotypical properties of situations and de-emphasize irrelevant details, and that the resulting schemas specify situations more comprehensively than those learned by other systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "事前学習された言語モデルから論理的なイベントスキーマを探索する", "jabstract": "私たちは、大規模な言語モデル、FrameNet解析、言語の強力な論理的表現、および学習プロセスをブートストラップするための一連の単純な行動スキーマを組み合わせたイベントスキーマ学習システムであるNESL（Neuro-Episodic Schema Learner）を提供します。私たちのデータセットは、事前にトレーニングされた言語モデルからの「状況サンプル」の連続的なフィードであり、これらはFrameNetフレームに解析され、単純な行動スキーマにマップされ、複雑な階層スキーマに結合および一般化されます。私たちは、言語モデルからの慎重なサンプリングが、状況の定型的な特性を強調し、関係のない詳細を軽減するのに役立つことを示し、その結果得られるスキーマが、他のシステムによって学習されたものよりも状況を包括的に指定することを示します。"}
{"title": "Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.", "url": "https://aclanthology.org/2022.acl-srw.26/", "abstract": "Detoxification is a task of generating text in polite style while preserving meaning and fluency of the original toxic text. Existing detoxification methods are monolingual i.e. designed to work in one exact language. This work investigates multilingual and cross-lingual detoxification and the behavior of large multilingual models in this setting. Unlike previous works we aim to make large language models able to perform detoxification without direct fine-tuning in a given language. Experiments show that multilingual models are capable of performing multilingual style transfer. However, tested state-of-the-art models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is currently inevitable and motivating the need of further research in this direction.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "大規模多言語言語モデルを用いたクロスリンガルテキストデトックスの探索。", "jabstract": "解毒は、元の有害なテキストの意味と流暢さを保ちつつ、丁寧なスタイルでテキストを生成するタスクである。既存の解毒方法は、1つの正確な言語で動作するように設計された単一言語である。この研究では、多言語およびクロスリンガルの解毒と、この設定での大規模な多言語モデルの振る舞いを調査する。以前の研究とは異なり、私たちは大規模な言語モデルが、特定の言語での直接の微調整なしで解毒を実行できるようにすることを目的としています。実験の結果、多言語モデルは多言語スタイルの転送を実行できることが示されました。しかし、テストされた最新のモデルはクロスリンガルの解毒を実行できず、正確な言語での直接の微調整が不可欠であり、この方向性でのさらなる研究の必要性を促しています。"}
{"title": "MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering", "url": "https://aclanthology.org/2022.acl-srw.27/", "abstract": "Knowledge Graphs (KGs) are symbolically structured storages of facts. The KG embedding contains concise data used in NLP tasks requiring implicit information about the real world. Furthermore, the size of KGs that may be useful in actual NLP assignments is enormous, and creating embedding over it has memory cost issues. We represent KG as a 3rd-order binary tensor and move beyond the standard CP decomposition (CITATION) by using a data-specific generalized version of it (CITATION). The generalization of the standard CP-ALS algorithm allows obtaining optimization gradients without a backpropagation mechanism. It reduces the memory needed in training while providing computational benefits. We propose a MEKER, a memory-efficient KG embedding model, which yields SOTA-comparable performance on link prediction tasks and KG-based Question Answering.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "MEKER：リンク予測と質問応答のためのメモリ効率の高い知識埋め込み表現", "jabstract": "知識グラフ（KG）は、事実を象徴的に構造化されたストレージに格納するものです。KG埋め込みには、現実世界に関する暗黙の情報が必要なNLPタスクで使用される簡潔なデータが含まれます。さらに、実際のNLP課題で有用なKGのサイズは膨大であり、その上に埋め込みを作成することにはメモリコストの問題があります。我々は、KGを第3オーダーのバイナリテンソルとして表現し、それを標準的なCP分解を超えたデータ固有の一般化バージョンを使用しています。標準的なCP-ALSアルゴリズムの一般化により、バックプロパゲーションメカニズムなしで最適化勾配を取得できます。これにより、トレーニングに必要なメモリが削減され、計算上の利点が提供されます。我々は、メモリ効率の良いKG埋め込みモデルであるMEKERを提案し、リンク予測タスクとKGベースの質問応答でSOTAに匹敵するパフォーマンスを発揮します。"}
{"title": "Discourse on ASR Measurement: Introducing the ARPOCA Assessment Tool", "url": "https://aclanthology.org/2022.acl-srw.28/", "abstract": "Automatic speech recognition (ASR) has evolved from a pipeline architecture with pronunciation dictionaries, phonetic features and language models to the end-to-end systems performing a direct translation from a raw waveform into a word sequence. With the increase in accuracy and the availability of pre-trained models, the ASR systems are now omnipresent in our daily applications. On the other hand, the models’ interpretability and their computational cost have become more challenging, particularly when dealing with less-common languages or identifying regional variations of speakers. This research proposal will follow a four-stage process: 1) Proving an overview of acoustic features and feature extraction algorithms; 2) Exploring current ASR models, tools, and performance assessment techniques; 3) Aligning features with interpretable phonetic transcripts; and 4) Designing a prototype ARPOCA to increase awareness of regional language variation and improve models feedback by developing a semi-automatic acoustic features extraction using PRAAT in conjunction with phonetic transcription.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "ASR測定に関する論文：ARPOCA評価ツールの紹介", "jabstract": "自動音声認識（ASR）は、発音辞書、音声特徴、言語モデルを備えたパイプラインアーキテクチャから、生の波形から単語シーケンスに直接翻訳を行うエンドツーエンドシステムに進化しました。精度の向上と事前学習モデルの利用可能性により、ASRシステムは現在、私たちの日常的なアプリケーションに普及しています。一方、モデルの解釈可能性と計算コストは、特に一般的でない言語や話者の地域的な変化を特定する場合に、より困難になっています。この研究提案は、4段階のプロセスに従います：1）音響特徴と特徴抽出アルゴリズムの概要を証明すること。2）現在のASRモデル、ツール、および性能評価技術を探索すること。3）解釈可能な音声転写と特徴を整列させること。4）PRAATを使用した半自動音響特徴抽出を開発し、音声転写と組み合わせて地域言語変化の認識を高め、モデルのフィードバックを改善するARPOCAのプロトタイプを設計すること。"}
{"title": "Pretrained Knowledge Base Embeddings for improved Sentential Relation Extraction", "url": "https://aclanthology.org/2022.acl-srw.29/", "abstract": "In this work we put forward to combine pretrained knowledge base graph embeddings with transformer based language models to improve performance on the sentential Relation Extraction task in natural language processing. Our proposed model is based on a simple variation of existing models to incorporate off-task pretrained graph embeddings with an on-task finetuned BERT encoder. We perform a detailed statistical evaluation of the model on standard datasets. We provide evidence that the added graph embeddings improve the performance, making such a simple approach competitive with the state-of-the-art models that perform explicit on-task training of the graph embeddings. Furthermore, we ob- serve for the underlying BERT model an interesting power-law scaling behavior between the variance of the F1 score obtained for a relation class and its support in terms of training examples.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "事前学習済みの知識ベース埋め込みを用いた文間関係抽出の改善", "jabstract": "この論文では、事前学習された知識ベースグラフ埋め込みをトランスフォーマーベースの言語モデルと組み合わせて、自然言語処理における文の関係抽出タスクの性能を向上させることを提案します。提案されたモデルは、既存のモデルを単純に変更して、オフタスクの事前学習されたグラフ埋め込みをオンタスクのファインチューニングされたBERTエンコーダーに組み込むものです。標準的なデータセットでモデルの詳細な統計的評価を行います。追加されたグラフ埋め込みが性能を向上させることを示し、明示的なオンタスクトレーニングを行う最新のモデルと競合するほど簡単なアプローチになることを証明します。さらに、関係クラスのF1スコアの分散とトレーニング例のサポートの間に興味深いべき乗則のスケーリング動作がBERTモデルの基礎にあることを観察します。"}
{"title": "Improving Cross-domain, Cross-lingual and Multi-modal Deception Detection", "url": "https://aclanthology.org/2022.acl-srw.30/", "abstract": "With the increase of deception and misinformation especially in social media, it has become crucial to be able to develop machine learning methods to automatically identify deceptive language. In this proposal, we identify key challenges underlying deception detection in cross-domain, cross-lingual and multi-modal settings. To improve cross-domain deception classification, we propose to use inter-domain distance to identify a suitable source domain for a given target domain. We propose to study the efficacy of multilingual classification models vs translation for cross-lingual deception classification. Finally, we propose to better understand multi-modal deception detection and explore methods to weight and combine information from multiple modalities to improve multi-modal deception classification.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nドメイン間、言語間、および多様なモードにおける欺瞞検出の改善", "jabstract": "社会メディアを含めた欺瞞や誤情報の増加に伴い、自動的に欺瞞的な言語を識別する機械学習手法を開発することが重要になってきています。本提案では、異なるドメイン、言語、モーダル設定における欺瞞検出の課題を特定します。クロスドメインの欺瞞分類を改善するために、対象ドメインに適したソースドメインを特定するために、ドメイン間距離を使用することを提案します。クロスリンガルの欺瞞分類において、多言語分類モデルと翻訳の有効性を研究することを提案します。最後に、マルチモーダルの欺瞞検出をより理解し、複数のモダリティからの情報を重み付けて組み合わせる方法を探索して、マルチモーダルの欺瞞分類を改善することを提案します。"}
{"title": "Automatic Generation of Distractors for Fill-in-the-Blank Exercises with Round-Trip Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-srw.31/", "abstract": "In a fill-in-the-blank exercise, a student is presented with a carrier sentence with one word hidden, and a multiple-choice list that includes the correct answer and several inappropriate options, called distractors. We propose to automatically generate distractors using round-trip neural machine translation: the carrier sentence is translated from English into another (pivot) language and back, and distractors are produced by aligning the original sentence and its round-trip translation. We show that using hundreds of translations for a given sentence allows us to generate a rich set of challenging distractors. Further, using multiple pivot languages produces a diverse set of candidates. The distractors are evaluated against a real corpus of cloze exercises and checked manually for validity. We demonstrate that the proposed method significantly outperforms two strong baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自動生成された誤答選択肢を用いた穴埋め問題の作成において、往復ニューラル機械翻訳を用いた手法を提案する。この手法は、対訳コーパスを用いて、入力文の意味を保持しつつ、誤答選択肢を生成する。提案手法は、英語を対象とした実験において、従来手法と比較して高い精度を示した。", "jabstract": "本論文では、空欄補充問題において、学生には一つの単語が隠されたキャリア文が提示され、正解といくつかの不適切な選択肢であるディストラクターが含まれる複数選択肢リストが与えられます。我々は、ラウンドトリップニューラルマシン翻訳を使用して、自動的にディストラクターを生成することを提案します。キャリア文は英語から別の（ピボット）言語に翻訳され、再度英語に戻され、元の文とそのラウンドトリップ翻訳を整列させることでディストラクターが生成されます。我々は、与えられた文の数百の翻訳を使用することで、多様な難解なディストラクターの豊富なセットを生成できることを示します。さらに、複数のピボット言語を使用することで、多様な候補が生成されます。ディストラクターは、クローズ演習の実際のコーパスに対して評価され、手動で妥当性が確認されます。提案された方法が2つの強力なベースラインを大幅に上回ることを示します。"}
{"title": "On the Locality of Attention in Direct Speech Translation", "url": "https://aclanthology.org/2022.acl-srw.32/", "abstract": "Transformers have achieved state-of-the-art results across multiple NLP tasks. However, the self-attention mechanism complexity scales quadratically with the sequence length, creating an obstacle for tasks involving long sequences, like in the speech domain. In this paper, we discuss the usefulness of self-attention for Direct Speech Translation. First, we analyze the layer-wise token contributions in the self-attention of the encoder, unveiling local diagonal patterns. To prove that some attention weights are avoidable, we propose to substitute the standard self-attention with a local efficient one, setting the amount of context used based on the results of the analysis. With this approach, our model matches the baseline performance, and improves the efficiency by skipping the computation of those weights that standard attention discards.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "直接音声翻訳における注意の局所性について", "jabstract": "トランスフォーマーは、複数のNLPタスクで最先端の結果を達成しています。しかし、自己注意機構の複雑さは、音声ドメインのような長いシーケンスを含むタスクにとって障害となります。本論文では、直接音声翻訳における自己注意の有用性について議論します。まず、エンコーダーの自己注意におけるレイヤーごとのトークンの貢献を分析し、ローカルな対角線パターンを明らかにします。一部の注意重みが回避可能であることを証明するために、標準の自己注意をローカルな効率的なものに置き換え、分析結果に基づいて使用するコンテキストの量を設定することを提案します。このアプローチにより、モデルはベースラインの性能に合致し、標準の注意が破棄する重みの計算をスキップすることで効率が向上します。"}
{"title": "Extraction of Diagnostic Reasoning Relations for Clinical Knowledge Graphs", "url": "https://aclanthology.org/2022.acl-srw.33/", "abstract": "Clinical knowledge graphs lack meaningful diagnostic relations (e.g. comorbidities, sign/symptoms), limiting their ability to represent real-world diagnostic processes. Previous methods in biomedical relation extraction have focused on concept relations, such as gene-disease and disease-drug, and largely ignored clinical processes. In this thesis, we leverage a clinical reasoning ontology and propose methods to extract such relations from a physician-facing point-of-care reference wiki and consumer health resource texts. Given the lack of data labeled with diagnostic relations, we also propose new methods of evaluating the correctness of extracted triples in the zero-shot setting. We describe a process for the intrinsic evaluation of new facts by triple confidence filtering and clinician manual review, as well extrinsic evaluation in the form of a differential diagnosis prediction task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "臨床知識グラフの診断推論関係の抽出", "jabstract": "臨床知識グラフには意味のある診断関係（例：共存症、兆候/症状）が欠けており、現実世界の診断プロセスを表現する能力が制限されています。従来のバイオメディカル関係抽出方法は、遺伝子-疾患や疾患-薬剤などの概念関係に焦点を当て、臨床プロセスをほとんど無視してきました。本論文では、臨床推論オントロジーを活用し、医師向けのポイントオブケアリファレンスウィキと消費者向けの健康リソーステキストからこのような関係を抽出する方法を提案します。診断関係にラベル付けされたデータが不足しているため、ゼロショット設定で抽出されたトリプルの正確性を評価する新しい方法も提案します。トリプル信頼フィルタリングとクリニシャンマニュアルレビューによる新しい事実の固有評価プロセス、および差異診断予測タスクの形式での外的評価について説明します。"}
{"title": "Scene-Text Aware Image and Text Retrieval with Dual-Encoder", "url": "https://aclanthology.org/2022.acl-srw.34/", "abstract": "We tackle the tasks of image and text retrieval using a dual-encoder model in which images and text are encoded independently. This model has attracted attention as an approach that enables efficient offline inferences by connecting both vision and language in the same semantic space; however, whether an image encoder as part of a dual-encoder model can interpret scene-text (i.e., the textual information in images) is unclear.We propose pre-training methods that encourage a joint understanding of the scene-text and surrounding visual information.The experimental results demonstrate that our methods improve the retrieval performances of the dual-encoder models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nデュアルエンコーダを用いたシーンテキストに対応した画像とテキストの検索。", "jabstract": "私たちは、画像とテキストの検索課題に対して、画像とテキストを独立にエンコードするデュアルエンコーダーモデルを使用しています。このモデルは、ビジョンと言語を同じ意味空間に接続することで、効率的なオフライン推論を可能にするアプローチとして注目されていますが、デュアルエンコーダーモデルの画像エンコーダーがシーンテキスト（つまり、画像内のテキスト情報）を解釈できるかどうかは不明です。私たちは、シーンテキストと周囲の視覚情報の共通理解を促進する事前トレーニング方法を提案しています。実験結果は、私たちの方法がデュアルエンコーダーモデルの検索性能を向上させることを示しています。"}
{"title": "Towards Fine-grained Classification of Climate Change related Social Media Text", "url": "https://aclanthology.org/2022.acl-srw.35/", "abstract": "With climate change becoming a cause of concern worldwide, it becomes essential to gauge people’s reactions. This can help educate and spread awareness about it and help leaders improve decision-making. This work explores the fine-grained classification and Stance detection of climate change-related social media text. Firstly, we create two datasets, ClimateStance and ClimateEng, consisting of 3777 tweets each, posted during the 2019 United Nations Framework Convention on Climate Change and comprehensively outline the dataset collection, annotation methodology, and dataset composition. Secondly, we propose the task of Climate Change stance detection based on our proposed ClimateStance dataset. Thirdly, we propose a fine-grained classification based on the ClimateEng dataset, classifying social media text into five categories: Disaster, Ocean/Water, Agriculture/Forestry, Politics, and General. We benchmark both the datasets for climate change stance detection and fine-grained classification using state-of-the-art methods in text classification. We also create a Reddit-based dataset for both the tasks, ClimateReddit, consisting of 6262 pseudo-labeled comments along with 329 manually annotated comments for the label. We then perform semi-supervised experiments for both the tasks and benchmark their results using the best-performing model for the supervised experiments. Lastly, we provide insights into the ClimateStance and ClimateReddit using part-of-speech tagging and named-entity recognition.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "気候変動に関連するソーシャルメディアテキストの細かい分類に向けて", "jabstract": "気候変動が世界的な懸念事項となる中、人々の反応を測定することは重要になってきています。これにより、気候変動に関する教育や啓発を行い、指導者が意思決定を改善するのに役立ちます。本研究では、気候変動に関連するソーシャルメディアテキストの細かい分類とスタンス検出を探求しています。まず、2019年の国連気候変動枠組条約中に投稿された3777件のツイートからなるClimateStanceとClimateEngの2つのデータセットを作成し、データセットの収集、注釈方法、およびデータセットの構成を包括的に説明します。次に、提案されたClimateStanceデータセットに基づく気候変動スタンス検出のタスクを提案します。第三に、ClimateEngデータセットに基づく細かい分類を提案し、ソーシャルメディアテキストを5つのカテゴリに分類します：災害、海洋/水、農業/林業、政治、一般。両方のデータセットをテキスト分類の最新の方法でベンチマークし、気候変動スタンス検出と細かい分類の両方のタスクについてRedditベースのデータセットであるClimateRedditを作成し、擬似ラベル付きコメント6262件と手動注釈コメント329件を含めます。その後、両方のタスクについて半教師あり実験を実施し、教師あり実験の最も優れたモデルを使用してその結果をベンチマークします。最後に、品詞タグ付けと固有表現認識を使用してClimateStanceとClimateRedditについての洞察を提供します。"}
{"title": "Deep Neural Representations for Multiword Expressions Detection", "url": "https://aclanthology.org/2022.acl-srw.36/", "abstract": "Effective methods for multiword expressions detection are important for many technologies related to Natural Language Processing. Most contemporary methods are based on the sequence labeling scheme applied to an annotated corpus, while traditional methods use statistical measures. In our approach, we want to integrate the concepts of those two approaches. We present a novel weakly supervised multiword expressions extraction method which focuses on their behaviour in various contexts. Our method uses a lexicon of English multiword lexical units acquired from The Oxford Dictionary of English as a reference knowledge base and leverages neural language modelling with deep learning architectures. In our approach, we do not need a corpus annotated specifically for the task. The only required components are: a lexicon of multiword units, a large corpus, and a general contextual embeddings model. We propose a method for building a silver dataset by spotting multiword expression occurrences and acquiring statistical collocations as negative samples. Sample representation has been inspired by representations used in Natural Language Inference and relation recognition. Very good results (F1=0.8) were obtained with CNN network applied to individual occurrences followed by weighted voting used to combine results from the whole corpus.The proposed method can be quite easily applied to other languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "「Deep Neural Representations for Multiword Expressions Detection」という論文の要約文を日本語に翻訳してください。\n\n多語表現検出のための深層ニューラル表現", "jabstract": "自然言語処理に関連する多くの技術にとって、多語表現の効果的な検出方法は重要です。現代の多くの方法は、注釈付きコーパスに適用されるシーケンスラベリングスキームに基づいていますが、従来の方法は統計的な手法を使用しています。私たちのアプローチでは、これら2つのアプローチの概念を統合したいと考えています。私たちは、様々な文脈での振る舞いに焦点を当てた新しい弱く監視された多語表現抽出方法を提案します。私たちの方法は、英語の多語表現を含む語彙をオックスフォード英語辞典から獲得し、深層学習アーキテクチャを用いたニューラル言語モデリングを活用します。私たちのアプローチでは、特定のタスクのために注釈付きコーパスは必要ありません。必要なのは、多語表現の語彙、大規模なコーパス、一般的な文脈埋め込みモデルだけです。私たちは、多語表現の出現をスポットし、統計的な共起を負のサンプルとして獲得することで、シルバーデータセットを構築する方法を提案しています。サンプル表現は、自然言語推論や関係認識で使用される表現に着想を得ています。個々の出現に適用されたCNNネットワークに続いて、全コーパスからの結果を組み合わせるために重み付け投票を使用した結果、非常に良好な結果（F1=0.8）が得られました。提案された方法は、他の言語にも比較的簡単に適用できます。"}
{"title": "A Checkpoint on Multilingual Misogyny Identification", "url": "https://aclanthology.org/2022.acl-srw.37/", "abstract": "We address the problem of identifying misogyny in tweets in mono and multilingual settings in three languages: English, Italian, and Spanish. We explore model variations considering single and multiple languages both in the pre-training of the transformer and in the training of the downstream taskto explore the feasibility of detecting misogyny through a transfer learning approach across multiple languages. That is, we train monolingual transformers with monolingual data, and multilingual transformers with both monolingual and multilingual data.Our models reach state-of-the-art performance on all three languages. The single-language BERT models perform the best, closely followed by different configurations of multilingual BERT models. The performance drops in zero-shot classification across languages. Our error analysis shows that multilingual and monolingual models tend to make the same mistakes.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "多言語の女性蔑視の特定に関するチェックポイント", "jabstract": "私たちは、英語、イタリア語、スペイン語の3つの言語で、ツイート内の女性嫌悪を単一言語および多言語の設定で特定する問題に取り組んでいます。私たちは、トランスフォーマーの事前学習およびダウンストリームタスクのトレーニングの両方において、単一言語および複数言語を考慮したモデルの変化を探索し、複数言語間の転移学習アプローチによる女性嫌悪の検出の実現可能性を探求します。つまり、単一言語のデータで単一言語のトランスフォーマーをトレーニングし、単一言語および多言語のデータで多言語のトランスフォーマーをトレーニングします。私たちのモデルは、すべての3つの言語で最新のパフォーマンスを発揮します。単一言語のBERTモデルが最も優れており、複数のBERTモデルの異なる構成が続きます。言語間のゼロショット分類ではパフォーマンスが低下します。私たちのエラー分析は、多言語および単一言語のモデルが同じ間違いをする傾向があることを示しています。"}
{"title": "Using dependency parsing for few-shot learning in distributional semantics", "url": "https://aclanthology.org/2022.acl-srw.38/", "abstract": "In this work, we explore the novel idea of employing dependency parsing information in the context of few-shot learning, the task of learning the meaning of a rare word based on a limited amount of context sentences. Firstly, we use dependency-based word embedding models as background spaces for few-shot learning. Secondly, we introduce two few-shot learning methods which enhance the additive baseline model by using dependencies.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "分布意味論におけるfew-shot学習に依存構文解析を使用する。", "jabstract": "この論文では、依存構造解析情報を少数派学習の文脈で利用するという新しいアイデアを探求する。少数派学習とは、限られた文脈文に基づいて稀な単語の意味を学習するタスクである。まず、依存構造ベースの単語埋め込みモデルを少数派学習の背景空間として使用する。次に、依存関係を利用した2つの少数派学習手法を導入し、加算ベースラインモデルを強化する。"}
{"title": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on Turkish Texts", "url": "https://aclanthology.org/2022.acl-srw.39/", "abstract": "Targeted Sentiment Analysis aims to extract sentiment towards a particular target from a given text. It is a field that is attracting attention due to the increasing accessibility of the Internet, which leads people to generate an enormous amount of data. Sentiment analysis, which in general requires annotated data for training, is a well-researched area for widely studied languages such as English. For low-resource languages such as Turkish, there is a lack of such annotated data. We present an annotated Turkish dataset suitable for targeted sentiment analysis. We also propose BERT-based models with different architectures to accomplish the task of targeted sentiment analysis. The results demonstrate that the proposed models outperform the traditional sentiment analysis models for the targeted sentiment analysis task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop", "jtitle": "トルコ語テキストに対するターゲット感情分析のためのデータセットとBERTベースのモデル", "jabstract": "ターゲットセンチメント分析は、与えられたテキストから特定の対象に対する感情を抽出することを目的としています。インターネットの利用が増加し、人々が膨大な量のデータを生成することが増えているため、注目されている分野です。一般的にトレーニングに注釈付きデータが必要な感情分析は、英語など広く研究されている言語に対してはよく研究された分野です。トルコ語などの低資源言語には、そのような注釈付きデータが不足しています。本論文では、ターゲットセンチメント分析に適した注釈付きトルコ語データセットを提供します。また、BERTベースの異なるアーキテクチャを提案し、ターゲットセンチメント分析のタスクを達成するために使用します。結果は、提案されたモデルがターゲットセンチメント分析タスクにおいて従来の感情分析モデルよりも優れていることを示しています。"}
