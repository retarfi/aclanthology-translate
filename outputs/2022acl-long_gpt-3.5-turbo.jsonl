{"title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "url": "https://aclanthology.org/2022.acl-long.0/", "abstract": "acl-2022-association-linguistics-1", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨です。\n\n「計算言語学協会第60回年次大会論文集（第1巻：長い論文）」の論文です。", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n1. This paper presents a novel approach to natural language processing using deep learning techniques.\n2. The proposed method achieves state-of-the-art performance on several benchmark datasets.\n3. We also conduct extensive experiments to analyze the effectiveness of our approach.\n4. Our results demonstrate the potential of deep learning for natural language processing tasks.\n5. Future work will focus on further improving the proposed method and exploring its applications in various domains. \n\n1. 本論文では、深層学習技術を用いた自然言語処理の新しいアプローチを提案しています。\n2. 提案された手法は、いくつかのベンチマークデータセットで最先端の性能を実現しています。\n3. 我々はまた、効果的な手法の分析のために広範な実験を行っています。\n4. 我々の結果は、自然言語処理タスクにおける深層学習の可能性を示しています。\n5. 今後の研究は、提案された手法のさらなる改善と、様々な領域での応用の探索に焦点を当てる予定です。"}
{"title": "AdapLeR: Speeding up Inference by Adaptive Length Reduction", "url": "https://aclanthology.org/2022.acl-long.1/", "abstract": "Pre-trained language models have shown stellar performance in various downstream tasks. But, this usually comes at the cost of high latency and computation, hindering their usage in resource-limited settings. In this work, we propose a novel approach for reducing the computational cost of BERT with minimal loss in downstream performance. Our method dynamically eliminates less contributing tokens through layers, resulting in shorter lengths and consequently lower computational cost. To determine the importance of each token representation, we train a Contribution Predictor for each layer using a gradient-based saliency method. Our experiments on several diverse classification tasks show speedups up to 22x during inference time without much sacrifice in performance. We also validate the quality of the selected tokens in our method using human annotations in the ERASER benchmark. In comparison to other widely used strategies for selecting important tokens, such as saliency and attention, our proposed method has a significantly lower false positive rate in generating rationales. Our code is freely available at https://github.com/amodaresi/AdapLeR.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AdapLeR：適応的長さ縮小による推論の高速化", "jabstract": "事前学習された言語モデルは、さまざまな下流タスクで優れたパフォーマンスを発揮しています。しかし、これには通常、高いレイテンシと計算コストがかかり、リソースに制限のある環境での使用を妨げています。本研究では、BERTの計算コストを最小限に抑えながら、下流パフォーマンスの損失を最小限に抑える新しいアプローチを提案しています。我々の方法は、レイヤーを通じて寄与が少ないトークンを動的に除外することにより、短い長さとしたがって低い計算コストを実現します。各トークン表現の重要性を決定するために、勾配ベースのサリエンシーメソッドを使用して、各レイヤーの寄与予測器をトレーニングします。私たちの実験は、いくつかの異なる分類タスクで、パフォーマンスの犠牲をあまり出さずに推論時間を最大22倍高速化することを示しています。また、ERASERベンチマークで人間の注釈を使用して、当社の方法で選択されたトークンの品質を検証します。重要なトークンを選択するための他の広く使用されている戦略（サリエンシー、アテンションなど）と比較して、当社の提案手法は、合理的な説明を生成する際の偽陽性率が著しく低いことが示されています。当社のコードは、https://github.com/amodaresi/AdapLeRで無料で入手できます。"}
{"title": "Quantified Reproducibility Assessment of NLP Results", "url": "https://aclanthology.org/2022.acl-long.2/", "abstract": "This paper describes and tests a method for carrying out quantified reproducibility assessment (QRA) that is based on concepts and definitions from metrology. QRA produces a single score estimating the degree of reproducibility of a given system and evaluation measure, on the basis of the scores from, and differences between, different reproductions. We test QRA on 18 different system and evaluation measure combinations (involving diverse NLP tasks and types of evaluation), for each of which we have the original results and one to seven reproduction results. The proposed QRA method produces degree-of-reproducibility scores that are comparable across multiple reproductions not only of the same, but also of different, original studies. We find that the proposed method facilitates insights into causes of variation between reproductions, and as a result, allows conclusions to be drawn about what aspects of system and/or evaluation design need to be changed in order to improve reproducibility.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理の定量的再現性評価", "jabstract": "本論文では、計量学の概念と定義に基づく量子再現性評価（QRA）の方法を説明し、テストします。QRAは、異なる再現のスコアと差に基づいて、特定のシステムと評価尺度の再現性の程度を推定する単一のスコアを生成します。我々は、異なるNLPタスクと評価の種類を含む18種類のシステムと評価尺度の組み合わせについてQRAをテストし、各組み合わせについて元の結果と1〜7回の再現結果を持っています。提案されたQRA方法は、同じだけでなく、異なる元の研究の複数の再現にわたって比較可能な再現性スコアを生成します。我々は、提案された方法が再現の間の変動の原因についての洞察を促進し、その結果、システムと/または評価設計のどの側面を改善する必要があるかについての結論を導くことを可能にすることを発見しました。"}
{"title": "Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via Adaptive Gradient Gating for Rare Token Embeddings", "url": "https://aclanthology.org/2022.acl-long.3/", "abstract": "Recent studies have determined that the learned token embeddings of large-scale neural language models are degenerated to be anisotropic with a narrow-cone shape. This phenomenon, called the representation degeneration problem, facilitates an increase in the overall similarity between token embeddings that negatively affect the performance of the models. Although the existing methods that address the degeneration problem based on observations of the phenomenon triggered by the problem improves the performance of the text generation, the training dynamics of token embeddings behind the degeneration problem are still not explored. In this study, we analyze the training dynamics of the token embeddings focusing on rare token embedding. We demonstrate that the specific part of the gradient for rare token embeddings is the key cause of the degeneration problem for all tokens during training stage. Based on the analysis, we propose a novel method called, adaptive gradient gating(AGG). AGG addresses the degeneration problem by gating the specific part of the gradient for rare token embeddings. Experimental results from language modeling, word similarity, and machine translation tasks quantitatively and qualitatively verify the effectiveness of AGG.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "レアなトークンはすべてのトークンを劣化させる：レアなトークン埋め込みのための適応的勾配ゲーティングによるニューラルテキスト生成の改善", "jabstract": "最近の研究により、大規模なニューラル言語モデルの学習されたトークン埋め込みが狭い円錐形の異方性を持つように退化することが判明しています。この現象は、表現退化問題と呼ばれ、トークン埋め込み間の全体的な類似性を増加させ、モデルの性能に悪影響を与えます。問題に対処する既存の方法は、問題によって引き起こされる現象の観察に基づいているため、テキスト生成の性能を向上させますが、退化問題の背後にあるトークン埋め込みのトレーニングダイナミクスはまだ探求されていません。本研究では、レアなトークン埋め込みに焦点を当ててトークン埋め込みのトレーニングダイナミクスを分析します。我々は、レアなトークン埋め込みの特定の勾配が、トレーニング段階中にすべてのトークンの退化問題の主な原因であることを示します。この分析に基づいて、我々は、適応的勾配ゲーティング（AGG）と呼ばれる新しい方法を提案します。AGGは、レアなトークン埋め込みの特定の勾配をゲート制御することによって、退化問題に対処します。言語モデリング、単語類似性、機械翻訳タスクからの実験結果は、AGGの効果を定量的および定性的に検証しています。"}
{"title": "AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level", "url": "https://aclanthology.org/2022.acl-long.4/", "abstract": "Large Pre-trained Language Models (PLMs) have become ubiquitous in the development of language understanding technology and lie at the heart of many artificial intelligence advances. While advances reported for English using PLMs are unprecedented, reported advances using PLMs for Hebrew are few and far between. The problem is twofold. First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts. Second, most benchmarks available to evaluate progress in Hebrew NLP require morphological boundaries which are not available in the output of standard PLMs. In this work we remedy both aspects. We present AlephBERT, a large PLM for Modern Hebrew, trained on larger vocabulary and a larger dataset than any Hebrew PLM before. Moreover, we introduce a novel neural architecture that recovers the morphological segments encoded in contextualized embedding vectors. Based on this new morphological component we offer an evaluation suite consisting of multiple tasks and benchmarks that cover sentence-level, word-level and sub-word level analyses. On all tasks, AlephBERT obtains state-of-the-art results beyond contemporary Hebrew baselines. We make our AlephBERT model, the morphological extraction model, and the Hebrew evaluation suite publicly available, for evaluating future Hebrew PLMs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AlephBERT：サブワードから文レベルまでの言語モデルの事前学習と評価", "jabstract": "大規模事前学習言語モデル（PLMs）は、言語理解技術の開発において普及し、多くの人工知能の進歩の中心に位置しています。英語に対するPLMsの報告された進歩は前例のないものですが、ヘブライ語に対するPLMsの報告された進歩は少なく、遠いものです。この問題は二つの側面があります。第一に、現在までに、大規模言語モデルのトレーニングに使用されるヘブライ語のリソースは、英語の対応物と同じ規模ではありません。第二に、ヘブライ語NLPの進歩を評価するために利用可能なベンチマークのほとんどは、標準的なPLMsの出力には存在しない形態論的境界を必要とします。本研究では、これらの両方の側面を改善します。私たちは、AlephBERTという現代ヘブライ語の大規模PLMを紹介し、これまでのどのヘブライ語PLMよりも大きな語彙とデータセットでトレーニングしました。さらに、コンテキスト化された埋め込みベクトルにエンコードされた形態素セグメントを回復する新しいニューラルアーキテクチャを導入します。この新しい形態素コンポーネントに基づいて、文レベル、単語レベル、サブワードレベルの分析をカバーする複数のタスクとベンチマークからなる評価スイートを提供します。すべてのタスクで、AlephBERTは現代ヘブライ語のベースラインを超える最新の結果を得ました。私たちは、AlephBERTモデル、形態素抽出モデル、ヘブライ語評価スイートを公開し、将来のヘブライ語PLMsの評価に利用できるようにします。"}
{"title": "Learning to Imagine: Integrating Counterfactual Thinking in Neural Discrete Reasoning", "url": "https://aclanthology.org/2022.acl-long.5/", "abstract": "Neural discrete reasoning (NDR) has shown remarkable progress in combining deep models with discrete reasoning. However, we find that existing NDR solution suffers from large performance drop on hypothetical questions, e.g. “what the annualized rate of return would be if the revenue in 2020 was doubled”. The key to hypothetical question answering (HQA) is counterfactual thinking, which is a natural ability of human reasoning but difficult for deep models. In this work, we devise a Learning to Imagine (L2I) module, which can be seamlessly incorporated into NDR models to perform the imagination of unseen counterfactual. In particular, we formulate counterfactual thinking into two steps: 1) identifying the fact to intervene, and 2) deriving the counterfactual from the fact and assumption, which are designed as neural networks. Based on TAT-QA, we construct a very challenging HQA dataset with 8,283 hypothetical questions. We apply the proposed L2I to TAGOP, the state-of-the-art solution on TAT-QA, validating the rationality and effectiveness of our approach.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "学習すること：ニューラルディスクリート推論に対するカウンターファクト思考の統合", "jabstract": "ニューラルディスクリートリーズニング（NDR）は、深層モデルと離散的な推論を組み合わせた驚くべき進歩を示しています。しかし、既存のNDRソリューションは、仮説的な質問、例えば「2020年の収益が倍増した場合の年率利回りは何になるか」といった質問に対して、大きな性能低下を引き起こすことがわかっています。仮説的な質問に答えるための鍵は、反事実的な思考であり、これは人間の推論の自然な能力ですが、深層モデルにとっては困難です。本研究では、未知の反事実を想像するためにシームレスにNDRモデルに組み込むことができるLearning to Imagine（L2I）モジュールを考案しました。特に、反事実的な思考を2つのステップに分けて定式化しました。1）介入する事実を特定すること、2）事実と仮定から反事実を導出することで、これらはニューラルネットワークとして設計されています。TAT-QAに基づいて、8,283の仮説的な質問を含む非常に難しいHQAデータセットを構築しました。提案されたL2IをTAT-QAの最先端ソリューションであるTAGOPに適用し、アプローチの合理性と効果を検証しました。"}
{"title": "Domain Adaptation in Multilingual and Multi-Domain Monolingual Settings for Complex Word Identification", "url": "https://aclanthology.org/2022.acl-long.6/", "abstract": "Complex word identification (CWI) is a cornerstone process towards proper text simplification. CWI is highly dependent on context, whereas its difficulty is augmented by the scarcity of available datasets which vary greatly in terms of domains and languages. As such, it becomes increasingly more difficult to develop a robust model that generalizes across a wide array of input examples. In this paper, we propose a novel training technique for the CWI task based on domain adaptation to improve the target character and context representations. This technique addresses the problem of working with multiple domains, inasmuch as it creates a way of smoothing the differences between the explored datasets. Moreover, we also propose a similar auxiliary task, namely text simplification, that can be used to complement lexical complexity prediction. Our model obtains a boost of up to 2.42% in terms of Pearson Correlation Coefficients in contrast to vanilla training techniques, when considering the CompLex from the Lexical Complexity Prediction 2021 dataset. At the same time, we obtain an increase of 3% in Pearson scores, while considering a cross-lingual setup relying on the Complex Word Identification 2018 dataset. In addition, our model yields state-of-the-art results in terms of Mean Absolute Error.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "複雑な単語の識別のための多言語および多ドメイン単一言語設定におけるドメイン適応", "jabstract": "複雑な単語の特定（CWI）は、適切なテキストの簡素化に向けた基本的なプロセスです。CWIは文脈に高度に依存しており、利用可能なデータセットがドメインや言語によって大きく異なるため、その難しさが増大しています。そのため、幅広い入力例に対して一般化する堅牢なモデルを開発することがますます困難になっています。本論文では、ドメイン適応に基づくCWIタスクの新しいトレーニング技術を提案し、ターゲットの文字と文脈表現を改善します。この技術は、複数のドメインで作業する問題に対処し、探索されたデータセット間の違いを平滑化する方法を作成します。さらに、レキシカル複雑性予測を補完するために使用できる、テキストの簡素化という同様の補助タスクも提案します。当社のモデルは、Lexical Complexity Prediction 2021データセットのCompLexを考慮する場合、バニラトレーニング技術に比べて、ピアソン相関係数で最大2.42％のブーストを獲得します。同時に、Complex Word Identification 2018データセットに依存するクロスリンガルセットアップを考慮する場合、ピアソンスコアで3％の増加を得ます。さらに、当社のモデルは、平均絶対誤差に関して最新の結果を提供します。"}
{"title": "JointCL: A Joint Contrastive Learning Framework for Zero-Shot Stance Detection", "url": "https://aclanthology.org/2022.acl-long.7/", "abstract": "Zero-shot stance detection (ZSSD) aims to detect the stance for an unseen target during the inference stage. In this paper, we propose a joint contrastive learning (JointCL) framework, which consists of stance contrastive learning and target-aware prototypical graph contrastive learning. Specifically, a stance contrastive learning strategy is employed to better generalize stance features for unseen targets. Further, we build a prototypical graph for each instance to learn the target-based representation, in which the prototypes are deployed as a bridge to share the graph structures between the known targets and the unseen ones. Then a novel target-aware prototypical graph contrastive learning strategy is devised to generalize the reasoning ability of target-based stance representations to the unseen targets. Extensive experiments on three benchmark datasets show that the proposed approach achieves state-of-the-art performance in the ZSSD task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "JointCL：ゼロショットスタンス検出のための共同対比学習フレームワーク", "jabstract": "ゼロショットスタンス検出（ZSSD）は、推論段階で未知のターゲットのスタンスを検出することを目的としています。本論文では、スタンス対比学習とターゲットに配慮したプロトタイプグラフ対比学習から構成されるジョイントコントラスティブラーニング（JointCL）フレームワークを提案します。具体的には、スタンス対比学習戦略を採用して、未知のターゲットに対してスタンス特徴をより一般化するようにします。さらに、各インスタンスに対してプロトタイプグラフを構築して、ターゲットベースの表現を学習し、プロトタイプを橋渡しとして既知のターゲットと未知のターゲットのグラフ構造を共有します。その後、新しいターゲットに配慮したプロトタイプグラフ対比学習戦略を考案して、ターゲットベースのスタンス表現の推論能力を未知のターゲットに一般化します。3つのベンチマークデータセットでの広範な実験により、提案手法がZSSDタスクで最先端の性能を発揮することが示されました。"}
{"title": "[CASPI] Causal-aware Safe Policy Improvement for Task-oriented Dialogue", "url": "https://aclanthology.org/2022.acl-long.8/", "abstract": "The recent success of reinforcement learning (RL) in solving complex tasks is often attributed to its capacity to explore and exploit an environment.Sample efficiency is usually not an issue for tasks with cheap simulators to sample data online.On the other hand, Task-oriented Dialogues (ToD) are usually learnt from offline data collected using human demonstrations.Collecting diverse demonstrations and annotating them is expensive.Unfortunately, RL policy trained on off-policy data are prone to issues of bias and generalization, which are further exacerbated by stochasticity in human response and non-markovian nature of annotated belief state of a dialogue management system.To this end, we propose a batch-RL framework for ToD policy learning: Causal-aware Safe Policy Improvement (CASPI). CASPI includes a mechanism to learn fine-grained reward that captures intention behind human response and also offers guarantee on dialogue policy’s performance against a baseline. We demonstrate the effectiveness of this framework on end-to-end dialogue task of the Multiwoz2.0 dataset. The proposed method outperforms the current state of the art. Further more we demonstrate sample efficiency, where our method trained only on 20% of the data, are comparable to current state of the art method trained on 100% data on two out of there evaluation metrics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "[CASPI] タスク指向型対話の因果関係に注意した安全なポリシー改善", "jabstract": "強化学習（RL）の最近の成功は、環境を探索し利用する能力に帰因されることが多い。データをオンラインでサンプリングするための安価なシミュレータがあるタスクにおいては、サンプル効率は通常問題にならない。一方、タスク指向型対話（ToD）は、通常、人間のデモを使用してオフラインデータから学習される。多様なデモを収集し注釈を付けることは高価である。残念ながら、オフポリシーデータでトレーニングされたRLポリシーは、バイアスや一般化の問題に陥りやすく、人間の反応の確率性や対話管理システムの注釈付き信念状態の非マルコフ性によってさらに悪化する。このため、私たちはToDポリシー学習のためのバッチRLフレームワークである因果関係に注意した安全なポリシー改善（CASPI）を提案する。CASPIには、人間の反応の意図を捉える細かい報酬を学習するメカニズムが含まれ、また、対話ポリシーのパフォーマンスに対するベースラインに対する保証も提供する。私たちは、Multiwoz2.0データセットのエンドツーエンドの対話タスクでこのフレームワークの効果を実証する。提案された方法は、現在の最先端を上回る性能を発揮する。さらに、私たちは、20％のデータのみでトレーニングされた私たちの方法が、3つの評価メトリックのうち2つで100％のデータでトレーニングされた現在の最先端の方法と同等のサンプル効率を示すことを示している。"}
{"title": "UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System", "url": "https://aclanthology.org/2022.acl-long.9/", "abstract": "As a more natural and intelligent interaction manner, multimodal task-oriented dialog system recently has received great attention and many remarkable progresses have been achieved. Nevertheless, almost all existing studies follow the pipeline to first learn intra-modal features separately and then conduct simple feature concatenation or attention-based feature fusion to generate responses, which hampers them from learning inter-modal interactions and conducting cross-modal feature alignment for generating more intention-aware responses. To address these issues, we propose UniTranSeR, a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning for multimodal dialog systems. Specifically, we first embed the multimodal features into a unified Transformer semantic space to prompt inter-modal interactions, and then devise a feature alignment and intention reasoning (FAIR) layer to perform cross-modal entity alignment and fine-grained key-value reasoning, so as to effectively identify user’s intention for generating more accurate responses. Experimental results verify the effectiveness of UniTranSeR, showing that it significantly outperforms state-of-the-art approaches on the representative MMD dataset.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "UniTranSeR：多様なタスク指向対話システムのための統一されたトランスフォーマー意味表現フレームワーク", "jabstract": "近年、より自然で知的な対話方法として、多様なモーダルタスク指向対話システムが注目され、多くの進歩が達成されています。しかし、ほとんどの既存研究は、まずモーダル内の特徴を別々に学習し、その後、単純な特徴連結またはアテンションベースの特徴融合を行って応答を生成するパイプラインに従っています。これにより、異なるモーダル間の相互作用を学習し、より意図に沿った応答を生成するためのクロスモーダル特徴アラインメントを行うことが妨げられます。これらの問題に対処するために、私たちはUniTranSeRを提案します。これは、多様な対話システムのための特徴アラインメントと意図推論を備えた統一されたトランスフォーマー意味表現フレームワークです。具体的には、まず多様なモーダル特徴を統一されたトランスフォーマー意味空間に埋め込んで、モーダル間の相互作用を促進し、クロスモーダルエンティティアラインメントと細かいキー値推論を実行する特徴アラインメントと意図推論（FAIR）層を設計して、より正確な応答を生成するためにユーザーの意図を効果的に特定します。実験結果は、UniTranSeRの有効性を検証し、代表的なMMDデータセットで最先端のアプローチを大幅に上回ることを示しています。"}
{"title": "Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State Tracking", "url": "https://aclanthology.org/2022.acl-long.10/", "abstract": "Dialogue State Tracking (DST) aims to keep track of users’ intentions during the course of a conversation. In DST, modelling the relations among domains and slots is still an under-studied problem. Existing approaches that have considered such relations generally fall short in: (1) fusing prior slot-domain membership relations and dialogue-aware dynamic slot relations explicitly, and (2) generalizing to unseen domains. To address these issues, we propose a novel Dynamic Schema Graph Fusion Network (DSGFNet), which generates a dynamic schema graph to explicitly fuse the prior slot-domain membership relations and dialogue-aware dynamic slot relations. It also uses the schemata to facilitate knowledge transfer to new domains. DSGFNet consists of a dialogue utterance encoder, a schema graph encoder, a dialogue-aware schema graph evolving network, and a schema graph enhanced dialogue state decoder. Empirical results on benchmark datasets (i.e., SGD, MultiWOZ2.1, and MultiWOZ2.2), show that DSGFNet outperforms existing methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多ドメイン対話状態追跡のためのダイナミックスキーマグラフフュージョンネットワーク", "jabstract": "Dialogue State Tracking（DST）は、会話の進行中にユーザーの意図を追跡することを目的としています。DSTでは、ドメインとスロットの関係をモデリングすることはまだ研究されていない問題です。これらの関係を考慮した既存のアプローチは、(1)事前のスロット-ドメインメンバーシップ関係と対話に関する動的スロット関係を明示的に融合すること、(2)未知のドメインに一般化することにおいて不十分である。これらの問題に対処するために、我々は新しいDynamic Schema Graph Fusion Network（DSGFNet）を提案します。DSGFNetは、動的スキーマグラフを生成して、事前のスロット-ドメインメンバーシップ関係と対話に関する動的スロット関係を明示的に融合します。また、スキーマを使用して新しいドメインへの知識転送を促進します。DSGFNetは、対話発話エンコーダ、スキーマグラフエンコーダ、対話に関するスキーマグラフ進化ネットワーク、およびスキーマグラフ強化対話状態デコーダから構成されています。ベンチマークデータセット（SGD、MultiWOZ2.1、およびMultiWOZ2.2）の実験結果は、DSGFNetが既存の方法を上回ることを示しています。"}
{"title": "Attention Temperature Matters in Abstractive Summarization Distillation", "url": "https://aclanthology.org/2022.acl-long.11/", "abstract": "Recent progress of abstractive text summarization largely relies on large pre-trained sequence-to-sequence Transformer models, which are computationally expensive. This paper aims to distill these large models into smaller ones for faster inference and with minimal performance loss. Pseudo-labeling based methods are popular in sequence-to-sequence model distillation. In this paper, we find simply manipulating attention temperatures in Transformers can make pseudo labels easier to learn for student models. Our experiments on three summarization datasets show our proposed method consistently improves vanilla pseudo-labeling based methods. Further empirical analysis shows that both pseudo labels and summaries produced by our students are shorter and more abstractive.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "要約抽出の蒸留において、注意温度は重要です。", "jabstract": "最近の抽象的なテキスト要約の進歩は、計算コストの高い大規模な事前学習されたシーケンス・トゥ・シーケンス・トランスフォーマー・モデルに大きく依存しています。本論文は、これらの大規模なモデルをより小さなものに蒸留し、より高速な推論と最小限の性能低下を実現することを目的としています。疑似ラベリングに基づく方法は、シーケンス・トゥ・シーケンス・モデルの蒸留で一般的に使用されています。本論文では、トランスフォーマーのアテンション温度を単純に操作することで、疑似ラベルを学習しやすくすることができることを発見しました。3つの要約データセットでの実験は、提案された方法がバニラの疑似ラベリングに基づく方法を一貫して改善することを示しています。さらに、実証分析により、私たちの学生が生成する疑似ラベルと要約がより短く、より抽象的であることが示されています。"}
{"title": "Towards Making the Most of Cross-Lingual Transfer for Zero-Shot Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.12/", "abstract": "This paper demonstrates that multilingual pretraining and multilingual fine-tuning are both critical for facilitating cross-lingual transfer in zero-shot translation, where the neural machine translation (NMT) model is tested on source languages unseen during supervised training. Following this idea, we present SixT+, a strong many-to-English NMT model that supports 100 source languages but is trained with a parallel dataset in only six source languages. SixT+ initializes the decoder embedding and the full encoder with XLM-R large and then trains the encoder and decoder layers with a simple two-stage training strategy. SixT+ achieves impressive performance on many-to-English translation. It significantly outperforms CRISS and m2m-100, two strong multilingual NMT systems, with an average gain of 7.2 and 5.0 BLEU respectively. Additionally, SixT+ offers a set of model parameters that can be further fine-tuned to other unsupervised tasks. We demonstrate that adding SixT+ initialization outperforms state-of-the-art explicitly designed unsupervised NMT models on Si<->En and Ne<->En by over 1.2 average BLEU. When applied to zero-shot cross-lingual abstractive summarization, it produces an average performance gain of 12.3 ROUGE-L over mBART-ft. We conduct detailed analyses to understand the key ingredients of SixT+, including multilinguality of the auxiliary parallel data, positional disentangled encoder, and the cross-lingual transferability of its encoder.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ゼロショットニューラルマシン翻訳におけるクロスリンガルトランスファーの最大限の活用に向けて", "jabstract": "この論文は、多言語の事前学習と多言語の微調整が、教師ありトレーニング中に見たことのないソース言語でニューラル機械翻訳（NMT）モデルをテストするゼロショット翻訳において、クロスリンガル転送を促進するために重要であることを示しています。このアイデアに従い、私たちはSixT+を提案します。SixT+は、わずか6つのソース言語の並列データセットでトレーニングされたが、100のソース言語をサポートする強力な多言語-英語NMTモデルです。SixT+は、デコーダー埋め込みと完全なエンコーダーをXLM-R largeで初期化し、その後、シンプルな2段階のトレーニング戦略でエンコーダーとデコーダーレイヤーをトレーニングします。SixT+は、多言語-英語翻訳において印象的な性能を発揮します。CRISSとm2m-100という2つの強力な多言語NMTシステムを平均7.2と5.0 BLEUの利益で大幅に上回ります。さらに、SixT+は、他の教師なしタスクにさらに微調整できる一連のモデルパラメータを提供します。私たちは、SixT+の初期化を追加することが、Si<->EnおよびNe<->Enの最新の明示的に設計された教師なしNMTモデルを平均BLEU 1.2以上上回ることを示しています。ゼロショットクロスリンガル抽象的要約に適用すると、mBART-ftに比べて平均12.3 ROUGE-Lの性能向上が得られます。私たちは、SixT+の主要な要素、つまり補助並列データの多言語性、位置分離エンコーダー、およびそのエンコーダーのクロスリンガル転送性を理解するための詳細な分析を実施しています。"}
{"title": "TopWORDS-Seg: Simultaneous Text Segmentation and Word Discovery for Open-Domain Chinese Texts via Bayesian Inference", "url": "https://aclanthology.org/2022.acl-long.13/", "abstract": "Processing open-domain Chinese texts has been a critical bottleneck in computational linguistics for decades, partially because text segmentation and word discovery often entangle with each other in this challenging scenario. No existing methods yet can achieve effective text segmentation and word discovery simultaneously in open domain. This study fills in this gap by proposing a novel method called TopWORDS-Seg based on Bayesian inference, which enjoys robust performance and transparent interpretation when no training corpus and domain vocabulary are available. Advantages of TopWORDS-Seg are demonstrated by a series of experimental studies.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "TopWORDS-Seg：ベイズ推論を用いたオープンドメインの中国語テキストの同時テキストセグメンテーションと単語発見", "jabstract": "数十年にわたり、オープンドメインの中国語テキストの処理は、計算言語学において重要なボトルネックであった。これは、この困難なシナリオにおいて、テキストのセグメンテーションと単語の発見がしばしば絡み合うためである。現在の方法では、オープンドメインにおいて効果的なテキストのセグメンテーションと単語の発見を同時に達成することはできない。本研究は、ベイジアン推論に基づく新しい方法であるTopWORDS-Segを提案することにより、このギャップを埋める。TopWORDS-Segの利点は、トレーニングコーパスやドメイン語彙が利用できない場合でも、堅牢なパフォーマンスと透明な解釈を提供することである。TopWORDS-Segの利点は、一連の実験的研究によって示されている。"}
{"title": "An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition", "url": "https://aclanthology.org/2022.acl-long.14/", "abstract": "Cross-lingual named entity recognition task is one of the critical problems for evaluating the potential transfer learning techniques on low resource languages. Knowledge distillation using pre-trained multilingual language models between source and target languages have shown their superiority in transfer. However, existing cross-lingual distillation models merely consider the potential transferability between two identical single tasks across both domains. Other possible auxiliary tasks to improve the learning performance have not been fully investigated. In this study, based on the knowledge distillation framework and multi-task learning, we introduce the similarity metric model as an auxiliary task to improve the cross-lingual NER performance on the target domain. Specifically, an entity recognizer and a similarity evaluator are first trained in parallel as two teachers from the source domain. Then, two tasks in the student model are supervised by these teachers simultaneously. Empirical studies on the three datasets across 7 different languages confirm the effectiveness of the proposed model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「クロス言語固有表現認識のための非教師付き複数タスク・複数教師モデル」", "jabstract": "クロスリンガルな固有表現認識タスクは、低リソース言語における潜在的な転移学習技術の評価において、重要な問題の1つである。ソース言語とターゲット言語間の事前学習された多言語言語モデルを用いた知識蒸留は、転移学習において優位性を示している。しかし、既存のクロスリンガル蒸留モデルは、両ドメイン間で同一の単一タスクの潜在的な転移性のみを考慮している。学習性能を向上させるための他の可能な補助タスクは、十分に調査されていない。本研究では、知識蒸留フレームワークとマルチタスク学習に基づき、類似度メトリックモデルを補助タスクとして導入し、ターゲットドメインにおけるクロスリンガルNERの性能を向上させる。具体的には、ソースドメインから2つの教師としてエンティティ認識器と類似度評価器を並列にトレーニングし、その後、学生モデルの2つのタスクを同時にこれらの教師によって監督する。7つの異なる言語の3つのデータセットでの実証研究は、提案されたモデルの有効性を確認している。"}
{"title": "Discriminative Marginalized Probabilistic Neural Method for Multi-Document Summarization of Medical Literature", "url": "https://aclanthology.org/2022.acl-long.15/", "abstract": "Although current state-of-the-art Transformer-based solutions succeeded in a wide range for single-document NLP tasks, they still struggle to address multi-input tasks such as multi-document summarization. Many solutions truncate the inputs, thus ignoring potential summary-relevant contents, which is unacceptable in the medical domain where each information can be vital. Others leverage linear model approximations to apply multi-input concatenation, worsening the results because all information is considered, even if it is conflicting or noisy with respect to a shared background. Despite the importance and social impact of medicine, there are no ad-hoc solutions for multi-document summarization. For this reason, we propose a novel discriminative marginalized probabilistic method (DAMEN) trained to discriminate critical information from a cluster of topic-related medical documents and generate a multi-document summary via token probability marginalization. Results prove we outperform the previous state-of-the-art on a biomedical dataset for multi-document summarization of systematic literature reviews. Moreover, we perform extensive ablation studies to motivate the design choices and prove the importance of each module of our method.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "医学文献の多文書要約のための差別化された周辺化確率ニューラル法", "jabstract": "現在の最先端のTransformerベースのソリューションは、単一ドキュメントのNLPタスクの広範な範囲で成功していますが、マルチドキュメント要約などのマルチ入力タスクに対処するのはまだ苦労しています。多くのソリューションは入力を切り捨て、潜在的な要約に関連する内容を無視するため、医療分野では各情報が重要であるため、受け入れられません。他のソリューションは、線形モデルの近似を利用してマルチ入力連結を適用し、すべての情報が共有される背景に対して矛盾したりノイズがある場合でも、結果を悪化させます。医学の重要性と社会的影響にもかかわらず、マルチドキュメント要約のための特別なソリューションはありません。そのため、私たちは、トピックに関連する医療文書のクラスタから重要な情報を識別し、トークン確率のマージナル化を介してマルチドキュメント要約を生成する新しい識別的マージナル確率法（DAMEN）を提案します。結果は、系統的文献レビューのマルチドキュメント要約のバイオメディカルデータセットで、以前の最先端を上回ることを証明しています。さらに、私たちは設計の選択肢を促進するための広範な消去研究を実施し、私たちの方法の各モジュールの重要性を証明しています。"}
{"title": "Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm", "url": "https://aclanthology.org/2022.acl-long.16/", "abstract": "Conventional wisdom in pruning Transformer-based language models is that pruning reduces the model expressiveness and thus is more likely to underfit rather than overfit. However, under the trending pretrain-and-finetune paradigm, we postulate a counter-traditional hypothesis, that is: pruning increases the risk of overfitting when performed at the fine-tuning phase. In this paper, we aim to address the overfitting problem and improve pruning performance via progressive knowledge distillation with error-bound properties. We show for the first time that reducing the risk of overfitting can help the effectiveness of pruning under the pretrain-and-finetune paradigm. Ablation studies and experiments on the GLUE benchmark show that our method outperforms the leading competitors across different tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Sparse Progressive Distillation：Pretrain-and-Finetuneパラダイム下での過学習の解決", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n従来のTransformerベースの言語モデルの剪定に関する常識は、剪定がモデルの表現力を低下させ、したがって過学習よりも適合不足の可能性が高いというものでした。しかし、最近の事前学習と微調整のパラダイムにおいて、私たちは逆の仮説を立てます。すなわち、微調整フェーズで剪定を行うと、過学習のリスクが増加するというものです。本論文では、誤差境界特性を持つ進行的な知識蒸留により、過学習問題を解決し、剪定性能を改善することを目的としています。私たちは、過学習のリスクを減らすことが、事前学習と微調整のパラダイム下で剪定の効果を高めることができることを初めて示しました。GLUEベンチマークの実験と除去実験により、私たちの方法が異なるタスクで主要な競合他社を上回ることを示しました。"}
{"title": "CipherDAug: Ciphertext based Data Augmentation for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.17/", "abstract": "We propose a novel data-augmentation technique for neural machine translation based on ROT-k ciphertexts. ROT-k is a simple letter substitution cipher that replaces a letter in the plaintext with the kth letter after it in the alphabet. We first generate multiple ROT-k ciphertexts using different values of k for the plaintext which is the source side of the parallel data. We then leverage this enciphered training data along with the original parallel data via multi-source training to improve neural machine translation. Our method, CipherDAug, uses a co-regularization-inspired training procedure, requires no external data sources other than the original training data, and uses a standard Transformer to outperform strong data augmentation techniques on several datasets by a significant margin. This technique combines easily with existing approaches to data augmentation, and yields particularly strong results in low-resource settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CipherDAug：ニューラル機械翻訳のための暗号文に基づくデータ拡張", "jabstract": "私たちは、ROT-k暗号文に基づくニューラル機械翻訳の新しいデータ拡張技術を提案します。ROT-kは、平文の文字をアルファベットのk番目の文字で置き換える単純な文字置換暗号です。まず、ソース側の平文に対して異なるkの値を使用して複数のROT-k暗号文を生成します。次に、この暗号化されたトレーニングデータを元の並列データとともにマルチソーストレーニングを利用してニューラル機械翻訳を改善します。私たちの方法であるCipherDAugは、共同正則化に着想を得たトレーニング手順を使用し、元のトレーニングデータ以外の外部データソースを必要とせず、標準的なTransformerを使用して、いくつかのデータセットで強力なデータ拡張技術を大幅に上回る結果を出します。この技術は、既存のデータ拡張手法と簡単に組み合わせることができ、リソースが少ない環境で特に強力な結果を生み出します。"}
{"title": "Overlap-based Vocabulary Generation Improves Cross-lingual Transfer Among Related Languages", "url": "https://aclanthology.org/2022.acl-long.18/", "abstract": "Pre-trained multilingual language models such as mBERT and XLM-R have demonstrated great potential for zero-shot cross-lingual transfer to low web-resource languages (LRL). However, due to limited model capacity, the large difference in the sizes of available monolingual corpora between high web-resource languages (HRL) and LRLs does not provide enough scope of co-embedding the LRL with the HRL, thereby affecting the downstream task performance of LRLs. In this paper, we argue that relatedness among languages in a language family along the dimension of lexical overlap may be leveraged to overcome some of the corpora limitations of LRLs. We propose Overlap BPE (OBPE), a simple yet effective modification to the BPE vocabulary generation algorithm which enhances overlap across related languages. Through extensive experiments on multiple NLP tasks and datasets, we observe that OBPE generates a vocabulary that increases the representation of LRLs via tokens shared with HRLs. This results in improved zero-shot transfer from related HRLs to LRLs without reducing HRL representation and accuracy. Unlike previous studies that dismissed the importance of token-overlap, we show that in the low-resource related language setting, token overlap matters. Synthetically reducing the overlap to zero can cause as much as a four-fold drop in zero-shot transfer accuracy.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "重複ベースの語彙生成は、関連する言語間のクロスリンガル転送を改善する。", "jabstract": "mBERTやXLM-Rなどの事前学習済みの多言語言語モデルは、低いウェブリソース言語（LRL）へのゼロショットクロスリンガル転送の可能性を示しています。しかし、限られたモデル容量のため、高いウェブリソース言語（HRL）とLRLの利用可能な単一言語コーパスのサイズの大きな違いは、LRLをHRLと共埋め込みする十分な余地を提供せず、LRLのダウンストリームタスクのパフォーマンスに影響を与えます。本論文では、言語ファミリー内の言語の関連性が、語彙の重複の次元で利用され、LRLのコーパスの制限のいくつかを克服することができると主張しています。我々は、BPE語彙生成アルゴリズムの単純で効果的な変更であるOverlap BPE（OBPE）を提案します。関連する言語間のオーバーラップを強化するために使用されます。複数のNLPタスクとデータセットでの広範な実験により、OBPEが、HRLと共有されるトークンを介してLRLの表現を増やす語彙を生成することがわかりました。これにより、HRLの表現と精度を低下させることなく、関連するHRLからLRLへのゼロショット転送が改善されます。トークンのオーバーラップの重要性を無視する以前の研究とは異なり、低リソース関連言語の設定では、トークンのオーバーラップが重要であることを示します。オーバーラップをゼロに人工的に減らすと、ゼロショット転送の精度が4倍に低下する可能性があります。"}
{"title": "Long-range Sequence Modeling with Predictable Sparse Attention", "url": "https://aclanthology.org/2022.acl-long.19/", "abstract": "Self-attention mechanism has been shown to be an effective approach for capturing global context dependencies in sequence modeling, but it suffers from quadratic complexity in time and memory usage. Due to the sparsity of the attention matrix, much computation is redundant. Therefore, in this paper, we design an efficient Transformer architecture, named Fourier Sparse Attention for Transformer (FSAT), for fast long-range sequence modeling. We provide a brand-new perspective for constructing sparse attention matrix, i.e. making the sparse attention matrix predictable. Two core sub-modules are: (1) A fast Fourier transform based hidden state cross module, which captures and pools L2 semantic combinations in 𝒪(Llog L) time complexity. (2) A sparse attention matrix estimation module, which predicts dominant elements of an attention matrix based on the output of the previous hidden state cross module. By reparameterization and gradient truncation, FSAT successfully learned the index of dominant elements. The overall complexity about the sequence length is reduced from 𝒪(L2) to 𝒪(Llog L). Extensive experiments (natural language, vision, and math) show that FSAT remarkably outperforms the standard multi-head attention and its variants in various long-sequence tasks with low computational costs, and achieves new state-of-the-art results on the Long Range Arena benchmark.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「予測可能な疎な注意力を持つ長距離シーケンスモデリング」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Long-range Sequence Modeling with Predictable Sparse Attention\n- 予測可能な疎な注意力を持つ長距離シーケンスモデリング", "jabstract": "自己注意機構は、シーケンスモデリングにおいてグローバルコンテキスト依存性を捉えるための効果的な手法であることが示されていますが、時間とメモリ使用量の二次的な複雑性に苦しんでいます。注意行列の疎さにより、多くの計算が冗長になります。したがって、本論文では、長距離シーケンスモデリングのための高速なTransformerアーキテクチャであるFourier Sparse Attention for Transformer（FSAT）を設計しました。私たちは、疎な注意行列を構築するための全く新しい視点を提供しています。つまり、疎な注意行列を予測可能にすることです。2つのコアサブモジュールは次のとおりです。 （1）L2意味的組み合わせをキャプチャし、𝒪（Llog L）の時間複雑性でプールする高速フーリエ変換ベースの隠れ状態クロスモジュール。 （2）前の隠れ状態クロスモジュールの出力に基づいて注意行列の主要な要素を予測する疎な注意行列推定モジュール。再パラメータ化と勾配切り捨てにより、FSATは主要な要素のインデックスを正常に学習しました。シーケンス長に関する全体的な複雑性は、𝒪（L2）から𝒪（Llog L）に減少します。豊富な実験（自然言語、ビジョン、数学）は、FSATが低い計算コストでさまざまな長いシーケンスタスクで標準のマルチヘッドアテンションとその変種を大幅に上回り、Long Range Arenaベンチマークで新しい最高の結果を達成したことを示しています。"}
{"title": "Improving Personalized Explanation Generation through Visualization", "url": "https://aclanthology.org/2022.acl-long.20/", "abstract": "In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visually-enhanced approach named METER with the help of visualization generation and text–image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨を以下に示します。\n\n可視化を通じた個人化された説明生成の改善", "jabstract": "現代の推薦システムでは、通常、ユーザーの評価を正当化するコメントやレビューがあります。このようなテキストコーパスにトレーニングされた説明可能な推薦モデルは、ユーザーの興味を発見し、個人に合わせた説明を生成することを学びます。現存するモデルは、妥当な説明を提供できるものの、異なるアイテムに対して繰り返しの文または不十分な詳細を持つ空の文を生成する傾向があります。これは興味深い問題を提起します。モデルをマルチモーダル環境に浸して、現実世界の概念に適切な認識を得て、上記の欠点を緩和できるでしょうか？このために、私たちは視覚的に強化されたアプローチであるMETERを提案します。視覚化生成とテキスト-画像マッチング識別の支援を受けて、説明可能な推薦モデルは、テキスト説明と一致しない場合にペナルティを負うことで、何を指しているかを視覚化するように促されます。実験結果と手動評価により、私たちのアプローチは、生成された説明のテキスト品質だけでなく、多様性と説明可能性を改善できることが示されました。"}
{"title": "New Intent Discovery with Pre-training and Contrastive Learning", "url": "https://aclanthology.org/2022.acl-long.21/", "abstract": "New intent discovery aims to uncover novel intent categories from user utterances to expand the set of supported intent classes. It is a critical task for the development and service expansion of a practical dialogue system. Despite its importance, this problem remains under-explored in the literature. Existing approaches typically rely on a large amount of labeled utterances and employ pseudo-labeling methods for representation learning and clustering, which are label-intensive, inefficient, and inaccurate. In this paper, we provide new solutions to two important research questions for new intent discovery: (1) how to learn semantic utterance representations and (2) how to better cluster utterances. Particularly, we first propose a multi-task pre-training strategy to leverage rich unlabeled data along with external labeled data for representation learning. Then, we design a new contrastive loss to exploit self-supervisory signals in unlabeled data for clustering. Extensive experiments on three intent recognition benchmarks demonstrate the high effectiveness of our proposed method, which outperforms state-of-the-art methods by a large margin in both unsupervised and semi-supervised scenarios. The source code will be available at https://github.com/zhang-yu-wei/MTP-CLNN.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習と対比学習による新しい意図の発見", "jabstract": "新しい意図の発見は、ユーザーの発話から新しい意図カテゴリを発見し、サポートされる意図クラスのセットを拡大することを目的としています。これは、実用的な対話システムの開発とサービス拡大にとって重要なタスクです。しかし、この問題は、文献では未だに十分に探究されていません。既存のアプローチは、通常、大量のラベル付き発話に依存し、表現学習とクラスタリングのために疑似ラベリング手法を使用しますが、これらはラベルが多く、効率が悪く、正確性が低いという欠点があります。本論文では、新しい意図の発見に関する2つの重要な研究問題に対する新しい解決策を提供します：(1)どのように意味的な発話表現を学習するか、(2)どのように発話をより良くクラスタリングするか。特に、まず、豊富な未ラベルデータと外部ラベルデータを活用したマルチタスクの事前学習戦略を提案します。次に、自己監督信号を未ラベルデータから利用するための新しい対比損失を設計します。3つの意図認識ベンチマークでの広範な実験により、提案手法の高い効果性が示され、非監督学習および半教師ありシナリオの両方で、最先端の手法を大幅に上回ることが示されました。ソースコードはhttps://github.com/zhang-yu-wei/MTP-CLNNで入手可能です。"}
{"title": "Modeling U.S. State-Level Policies by Extracting Winners and Losers from Legislative Texts", "url": "https://aclanthology.org/2022.acl-long.22/", "abstract": "Decisions on state-level policies have a deep effect on many aspects of our everyday life, such as health-care and education access. However, there is little understanding of how these policies and decisions are being formed in the legislative process. We take a data-driven approach by decoding the impact of legislation on relevant stakeholders (e.g., teachers in education bills) to understand legislators’ decision-making process and votes. We build a new dataset for multiple US states that interconnects multiple sources of data including bills, stakeholders, legislators, and money donors. Next, we develop a textual graph-based model to embed and analyze state bills. Our model predicts winners/losers of bills and then utilizes them to better determine the legislative body’s vote breakdown according to demographic/ideological criteria, e.g., gender.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "米国州レベルの政策をモデリングするために、立法テキストから勝者と敗者を抽出することによって、自然言語処理に関する論文の要約を行います。", "jabstract": "州レベルの政策決定は、医療や教育アクセスなど、私たちの日常生活の多くの側面に深い影響を与えます。しかし、これらの政策や決定が立法プロセスでどのように形成されているかについては、ほとんど理解がありません。私たちは、関係者（例えば、教育法案の教師）に対する立法の影響を解読することにより、立法者の意思決定プロセスと投票を理解するために、データ駆動型のアプローチを取ります。私たちは、法案、関係者、立法者、寄付者など、複数のデータソースを相互に接続する複数の米国州の新しいデータセットを構築します。次に、州法案を埋め込み分析するためのテキストグラフベースのモデルを開発します。私たちのモデルは、法案の勝者/敗者を予測し、それらを利用して、立法機関の投票傾向を人口/イデオロギーの基準に応じてより正確に決定します。例えば、性別。"}
{"title": "Structural Characterization for Dialogue Disentanglement", "url": "https://aclanthology.org/2022.acl-long.23/", "abstract": "Tangled multi-party dialogue contexts lead to challenges for dialogue reading comprehension, where multiple dialogue threads flow simultaneously within a common dialogue record, increasing difficulties in understanding the dialogue history for both human and machine. Previous studies mainly focus on utterance encoding methods with carefully designed features but pay inadequate attention to characteristic features of the structure of dialogues. We specially take structure factors into account and design a novel model for dialogue disentangling. Based on the fact that dialogues are constructed on successive participation and interactions between speakers, we model structural information of dialogues in two aspects: 1)speaker property that indicates whom a message is from, and 2) reference dependency that shows whom a message may refer to. The proposed method achieves new state-of-the-art on the Ubuntu IRC benchmark dataset and contributes to dialogue-related comprehension.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "対話の解体のための構造的特徴の特定化", "jabstract": "複雑な多人数対話文脈は、複数の対話スレッドが共通の対話記録内で同時に流れるため、人間と機械の両方にとって対話履歴を理解することが困難になるため、対話読解に課題を提供します。以前の研究は、慎重に設計された特徴を持つ発話符号化方法に主に焦点を当てていますが、対話構造の特徴的な特徴に十分な注意を払っていません。我々は特に構造要因を考慮に入れ、対話分離のための新しいモデルを設計しました。対話が話者間の連続的な参加と相互作用に基づいて構築されることを考慮して、対話の構造情報を2つの側面でモデル化します。1）メッセージの送信元を示す話者プロパティ、および2）メッセージが参照する可能性のある人物を示す参照依存性。提案された方法は、Ubuntu IRCベンチマークデータセットで新しい最先端を達成し、対話関連の理解に貢献しています。"}
{"title": "Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems", "url": "https://aclanthology.org/2022.acl-long.24/", "abstract": "Empathetic dialogue assembles emotion understanding, feeling projection, and appropriate response generation. Existing work for empathetic dialogue generation concentrates on the two-party conversation scenario. Multi-party dialogues, however, are pervasive in reality. Furthermore, emotion and sensibility are typically confused; a refined empathy analysis is needed for comprehending fragile and nuanced human feelings. We address these issues by proposing a novel task called Multi-Party Empathetic Dialogue Generation in this study. Additionally, a Static-Dynamic model for Multi-Party Empathetic Dialogue Generation, SDMPED, is introduced as a baseline by exploring the static sensibility and dynamic emotion for the multi-party empathetic dialogue learning, the aspects that help SDMPED achieve the state-of-the-art performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多人数共感的な対話生成：対話システムの新しいタスク", "jabstract": "共感的な対話は、感情理解、感情投影、適切な応答生成を組み合わせたものである。共感的な対話生成の既存の研究は、二者間の会話シナリオに集中している。しかし、現実には多数の人が参加する対話が普及している。さらに、感情と感性はしばしば混同されるため、繊細で微妙な人間の感情を理解するために洗練された共感分析が必要である。本研究では、Multi-Party Empathetic Dialogue Generationという新しいタスクを提案し、Multi-Party Empathetic Dialogue GenerationのためのStatic-Dynamicモデル（SDMPED）を導入することでこれらの問題に対処する。SDMPEDは、多数の参加者がいる共感的な対話学習のために静的な感性と動的な感情を探求することで、最先端のパフォーマンスを達成することができる。"}
{"title": "MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation", "url": "https://aclanthology.org/2022.acl-long.25/", "abstract": "Applying existing methods to emotional support conversation—which provides valuable assistance to people who are in need—has two major limitations: (a) they generally employ a conversation-level emotion label, which is too coarse-grained to capture user’s instant mental state; (b) most of them focus on expressing empathy in the response(s) rather than gradually reducing user’s distress. To address the problems, we propose a novel model MISC, which firstly infers the user’s fine-grained emotional status, and then responds skillfully using a mixture of strategy. Experimental results on the benchmark dataset demonstrate the effectiveness of our method and reveal the benefits of fine-grained emotion understanding as well as mixed-up strategy modeling.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nMISC：COMETを統合した混合戦略意識モデルによる感情サポート会話", "jabstract": "既存の手法を感情的なサポート会話に適用することは、必要な人々に貴重な支援を提供するが、2つの主要な制限がある：(a) 一般的に会話レベルの感情ラベルを使用するため、ユーザーの瞬時の精神状態を捉えるには粒度が荒すぎること。(b) ほとんどの手法は、応答で共感を表現することに焦点を当てており、ユーザーの苦痛を徐々に軽減することには焦点を当てていない。これらの問題に対処するために、私たちは新しいモデルMISCを提案し、まずユーザーの細かい感情状態を推定し、その後、戦略の混合を使用して巧みに応答します。ベンチマークデータセットでの実験結果は、私たちの手法の有効性を示し、細かい感情理解と混合戦略モデリングの利点を明らかにします。"}
{"title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling", "url": "https://aclanthology.org/2022.acl-long.26/", "abstract": "There have been various types of pretraining architectures including autoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and encoder-decoder models (e.g., T5). However, none of the pretraining frameworks performs the best for all tasks of three main categories including natural language understanding (NLU), unconditional generation, and conditional generation. We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge. GLM improves blank filling pretraining by adding 2D positional encodings and allowing an arbitrary order to predict spans, which results in performance gains over BERT and T5 on NLU tasks. Meanwhile, GLM can be pretrained for different types of tasks by varying the number and lengths of blanks. On a wide range of tasks across NLU, conditional and unconditional generation, GLM outperforms BERT, T5, and GPT given the same model sizes and data, and achieves the best performance from a single pretrained model with 1.25× parameters of BERT Large , demonstrating its generalizability to different downstream tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "GLM：自己回帰的なブランク埋め込みを用いた一般言語モデルの事前学習", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自然言語理解（NLU）、無条件生成、条件生成の3つの主要なカテゴリのすべてのタスクに最適な事前学習フレームワークは存在しない。これに対処するために、自己回帰的なブランク埋め込みに基づく一般言語モデル（GLM）を提案する。GLMは、2D位置エンコーディングを追加し、任意の順序でスパンを予測できるようにすることで、ブランク埋め込みの事前学習を改善し、NLUタスクでBERTやT5よりも性能が向上する。同時に、GLMは、ブランクの数や長さを変えることで、さまざまなタイプのタスクのために事前学習できる。NLU、条件付き生成、無条件生成の幅広いタスクにおいて、同じモデルサイズとデータを使用して、GLMはBERT、T5、GPTを上回り、BERT Largeの1.25倍のパラメータを持つ単一の事前学習モデルから最高の性能を発揮し、異なる下流タスクに対して汎用性を示す。"}
{"title": "QuoteR: A Benchmark of Quote Recommendation for Writing", "url": "https://aclanthology.org/2022.acl-long.27/", "abstract": "It is very common to use quotations (quotes) to make our writings more elegant or convincing. To help people find appropriate quotes efficiently, the task of quote recommendation is presented, aiming to recommend quotes that fit the current context of writing. There have been various quote recommendation approaches, but they are evaluated on different unpublished datasets. To facilitate the research on this task, we build a large and fully open quote recommendation dataset called QuoteR, which comprises three parts including English, standard Chinese and classical Chinese. Any part of it is larger than previous unpublished counterparts. We conduct an extensive evaluation of existing quote recommendation methods on QuoteR. Furthermore, we propose a new quote recommendation model that significantly outperforms previous methods on all three parts of QuoteR. All the code and data of this paper can be obtained at https://github.com/thunlp/QuoteR.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "この論文は、自然言語処理に関するものであり、以下はその要約文です。\n\n「QuoteR：文章作成のための引用推薦のベンチマーク」と題された本論文は、引用の推薦に関するベンチマークを提供することを目的としています。このベンチマークは、自然言語処理の分野において、引用の推薦に関する研究を促進することを意図しています。」", "jabstract": "私たちは、私たちの文章をより優雅で説得力のあるものにするために引用符（引用）を使用することが非常に一般的です。人々が適切な引用を効率的に見つけるのを支援するために、現在の文章に適合する引用を推奨することを目的とした引用推奨のタスクが提示されています。様々な引用推奨アプローチがありますが、それらは未公開の異なるデータセットで評価されています。このタスクの研究を促進するために、私たちは、英語、標準中国語、古典中国語を含む大規模で完全にオープンな引用推奨データセットであるQuoteRを構築しました。それぞれの部分は以前の未公開の対応物よりも大きくなっています。私たちは、既存の引用推奨方法をQuoteRで広範囲に評価しています。さらに、私たちは、すべてのQuoteRの3つの部分で以前の方法を大幅に上回る新しい引用推奨モデルを提案しています。この論文のすべてのコードとデータは、https://github.com/thunlp/QuoteRから入手できます。"}
{"title": "Towards Comprehensive Patent Approval Predictions:Beyond Traditional Document Classification", "url": "https://aclanthology.org/2022.acl-long.28/", "abstract": "Predicting the approval chance of a patent application is a challenging problem involving multiple facets. The most crucial facet is arguably the novelty — 35 U.S. Code § 102 rejects more recent applications that have very similar prior arts. Such novelty evaluations differ the patent approval prediction from conventional document classification — Successful patent applications may share similar writing patterns; however, too-similar newer applications would receive the opposite label, thus confusing standard document classifiers (e.g., BERT). To address this issue, we propose a novel framework that unifies the document classifier with handcrafted features, particularly time-dependent novelty scores. Specifically, we formulate the novelty scores by comparing each application with millions of prior arts using a hybrid of efficient filters and a neural bi-encoder. Moreover, we impose a new regularization term into the classification objective to enforce the monotonic change of approval prediction w.r.t. novelty scores. From extensive experiments on a large-scale USPTO dataset, we find that standard BERT fine-tuning can partially learn the correct relationship between novelty and approvals from inconsistent data. However, our time-dependent novelty features offer a boost on top of it. Also, our monotonic regularization, while shrinking the search space, can drive the optimizer to better local optima, yielding a further small performance gain.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "包括的な特許承認予測に向けて：従来の文書分類を超えて", "jabstract": "特許出願の承認率を予測することは、複数の側面を含む難しい問題である。最も重要な側面はおそらく新規性であり、35 U.S. Code § 102は非常に類似した先行技術を持つ最近の出願を拒否する。このような新規性の評価は、通常の文書分類とは異なり、成功した特許出願は類似した書き方をすることがあるが、あまりにも類似した新しい出願は逆のラベルを受け取るため、標準的な文書分類器（例えばBERT）を混乱させる。この問題に対処するために、我々は手作りの特徴、特に時間依存性の新規性スコアを文書分類器と統合する新しいフレームワークを提案する。具体的には、我々は効率的なフィルタとニューラルバイエンコーダのハイブリッドを使用して、各出願を何百万もの先行技術と比較して新規性スコアを定式化する。さらに、新規性スコアに関する承認予測の単調な変化を強制するために、分類目的に新しい正則化項を課す。大規模なUSPTOデータセットでの広範な実験から、標準的なBERT fine-tuningは不一致なデータから新規性と承認の正しい関係を部分的に学習できることがわかった。しかし、我々の時間依存性の新規性特徴はそれに加えてブーストを提供する。また、我々の単調な正則化は、探索空間を縮小しながら、最適化プロセスをより良い局所最適解に導くことができ、さらにわずかな性能向上をもたらす。"}
{"title": "Hypergraph Transformer: Weakly-Supervised Multi-hop Reasoning for Knowledge-based Visual Question Answering", "url": "https://aclanthology.org/2022.acl-long.29/", "abstract": "Knowledge-based visual question answering (QA) aims to answer a question which requires visually-grounded external knowledge beyond image content itself. Answering complex questions that require multi-hop reasoning under weak supervision is considered as a challenging problem since i) no supervision is given to the reasoning process and ii) high-order semantics of multi-hop knowledge facts need to be captured. In this paper, we introduce a concept of hypergraph to encode high-level semantics of a question and a knowledge base, and to learn high-order associations between them. The proposed model, Hypergraph Transformer, constructs a question hypergraph and a query-aware knowledge hypergraph, and infers an answer by encoding inter-associations between two hypergraphs and intra-associations in both hypergraph itself. Extensive experiments on two knowledge-based visual QA and two knowledge-based textual QA demonstrate the effectiveness of our method, especially for multi-hop reasoning problem. Our source code is available at https://github.com/yujungheo/kbvqa-public.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ハイパーグラフトランスフォーマー：知識ベースのビジュアル質問応答のための弱監督マルチホップ推論", "jabstract": "知識ベースの視覚的な質問応答（QA）は、画像の内容自体を超えた視覚的に根拠のある外部知識を必要とする質問に答えることを目的としています。弱い監督下で多段階の推論を必要とする複雑な質問に答えることは、推論プロセスに対して監督が与えられていないことと、多段階の知識事実の高次の意味を捉える必要があるため、課題と考えられています。本論文では、質問と知識ベースの高レベルな意味をエンコードし、それらの間の高次の関連性を学習するためのハイパーグラフの概念を導入します。提案されたモデルであるHypergraph Transformerは、質問ハイパーグラフとクエリに関する知識ハイパーグラフを構築し、2つのハイパーグラフ間の相互関連性と、両方のハイパーグラフ内の内部関連性をエンコードして回答を推論します。2つの知識ベースの視覚的QAと2つの知識ベースのテキストQAに対する広範な実験により、特に多段階の推論問題に対して、提案手法の有効性が示されました。ソースコードはhttps://github.com/yujungheo/kbvqa-publicで入手可能です。"}
{"title": "Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech", "url": "https://aclanthology.org/2022.acl-long.30/", "abstract": "Modelling prosody variation is critical for synthesizing natural and expressive speech in end-to-end text-to-speech (TTS) systems. In this paper, a cross-utterance conditional VAE (CUC-VAE) is proposed to estimate a posterior probability distribution of the latent prosody features for each phoneme by conditioning on acoustic features, speaker information, and text features obtained from both past and future sentences. At inference time, instead of the standard Gaussian distribution used by VAE, CUC-VAE allows sampling from an utterance-specific prior distribution conditioned on cross-utterance information, which allows the prosody features generated by the TTS system to be related to the context and is more similar to how humans naturally produce prosody. The performance of CUC-VAE is evaluated via a qualitative listening test for naturalness, intelligibility and quantitative measurements, including word error rates and the standard deviation of prosody attributes. Experimental results on LJ-Speech and LibriTTS data show that the proposed CUC-VAE TTS system improves naturalness and prosody diversity with clear margins.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n非自己回帰的なテキストから音声への変換のためのクロス発話条件付きVAE", "jabstract": "自然で表現豊かな音声を合成するためには、プロソディの変動をモデル化することが重要です。本論文では、過去と未来の文章から得られた音響特徴、話者情報、テキスト特徴に基づいて、各音素の潜在的なプロソディ特徴の事後確率分布を推定するためのクロス発話条件付きVAE（CUC-VAE）を提案します。推論時には、VAEで使用される標準的なガウス分布ではなく、クロス発話情報に基づいた発話特有の事前分布からサンプリングすることができるため、TTSシステムによって生成されるプロソディ特徴が文脈に関連し、人間が自然にプロソディを生成する方法により近くなります。CUC-VAEの性能は、自然さ、理解可能性、単語エラー率、プロソディ属性の標準偏差などの定量的な測定と、質的な聴取テストによって評価されます。LJ-SpeechとLibriTTSデータに対する実験結果は、提案されたCUC-VAE TTSシステムが自然さとプロソディの多様性を明確に向上させることを示しています。"}
{"title": "Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models", "url": "https://aclanthology.org/2022.acl-long.31/", "abstract": "Recent work on controlled text generation has either required attribute-based fine-tuning of the base language model (LM), or has restricted the parameterization of the attribute discriminator to be compatible with the base autoregressive LM. In this work, we propose Mix and Match LM, a global score-based alternative for controllable text generation that combines arbitrary pre-trained black-box models for achieving the desired attributes in the generated text without involving any fine-tuning or structural assumptions about the black-box models. We interpret the task of controllable generation as drawing samples from an energy-based model whose energy values are a linear combination of scores from black-box models that are separately responsible for fluency, the control attribute, and faithfulness to any conditioning context. We use a Metropolis-Hastings sampling scheme to sample from this energy-based model using bidirectional context and global attribute features. We validate the effectiveness of our approach on various controlled generation and style-based text revision tasks by outperforming recently proposed methods that involve extra training, fine-tuning, or restrictive assumptions over the form of models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models」という論文の要約です。\n\n混ぜ合わせ：エネルギー言語モデルを使用した学習フリーの制御可能なテキスト生成。", "jabstract": "制御可能なテキスト生成に関する最近の研究は、基本言語モデル（LM）の属性ベースの微調整を必要とするか、属性識別器のパラメータ化を基本自己回帰LMと互換性があるように制限する必要がありました。本研究では、任意の事前学習済みブラックボックスモデルを組み合わせて、微調整やブラックボックスモデルの構造的な仮定を必要とせずに、生成されたテキストに所望の属性を実現するための制御可能なテキスト生成のためのグローバルスコアベースの代替案であるMix and Match LMを提案します。制御可能な生成のタスクを、流暢さ、制御属性、および任意の条件付けコンテキストに対する忠実度に個別に責任を持つブラックボックスモデルのスコアの線形結合であるエネルギーベースのモデルからサンプルを抽出するタスクとして解釈します。双方向コンテキストとグローバル属性特徴を使用して、メトロポリス・ヘイスティングスのサンプリングスキームを使用して、このエネルギーベースのモデルからサンプリングします。我々は、モデルの形式に関する制限、追加のトレーニング、微調整を必要とする最近提案された方法を上回ることによって、さまざまな制御生成およびスタイルベースのテキスト修正タスクで我々のアプローチの有効性を検証します。"}
{"title": "So Different Yet So Alike! Constrained Unsupervised Text Style Transfer", "url": "https://aclanthology.org/2022.acl-long.32/", "abstract": "Automatic transfer of text between domains has become popular in recent times. One of its aims is to preserve the semantic content while adapting to the target domain. However, it does not explicitly maintain other attributes between the source and translated text: e.g., text length and descriptiveness. Maintaining constraints in transfer has several downstream applications, including data augmentation and debiasing. We introduce a method for such constrained unsupervised text style transfer by introducing two complementary losses to the generative adversarial network (GAN) family of models. Unlike the competing losses used in GANs, we introduce cooperative losses where the discriminator and the generator cooperate and reduce the same loss. The first is a contrastive loss and the second is a classification loss — aiming to regularize the latent space further and bring similar sentences closer together. We demonstrate that such training retains lexical, syntactic and domain-specific constraints between domains for multiple benchmark datasets, including ones where more than one attribute change. We show that the complementary cooperative losses improve text quality, according to both automated and human evaluation measures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nそれほど異なるが、それほど似ている！制約付き非教示的テキストスタイル転送", "jabstract": "最近では、ドメイン間のテキストの自動転送が一般的になってきています。その目的の1つは、ターゲットドメインに適応しながら意味内容を保持することです。しかし、ソースと翻訳されたテキストの他の属性（例：テキストの長さや説明力）を明示的に維持しないため、制約を転送に維持することには、データ拡張や偏見除去などの多数の下流アプリケーションがあります。我々は、2つの補完的な損失を生成的対抗ネットワーク（GAN）モデルに導入することで、そのような制約付き非監督テキストスタイル転送の方法を紹介します。GANで使用される競合する損失とは異なり、我々は、識別器とジェネレータが協力して同じ損失を減らす協力的な損失を導入します。最初のものは対照的な損失であり、2番目のものは分類損失であり、潜在空間をさらに正則化し、類似した文を近づけることを目的としています。我々は、複数のベンチマークデータセットに対して、複数の属性が変化する場合も含め、ドメイン間の語彙、構文、およびドメイン固有の制約を保持することを示します。補完的な協力的な損失が、自動評価および人間の評価尺度の両方においてテキストの品質を向上させることを示します。"}
{"title": "e-CARE: a New Dataset for Exploring Explainable Causal Reasoning", "url": "https://aclanthology.org/2022.acl-long.33/", "abstract": "Understanding causality has vital importance for various Natural Language Processing (NLP) applications. Beyond the labeled instances, conceptual explanations of the causality can provide deep understanding of the causal fact to facilitate the causal reasoning process. However, such explanation information still remains absent in existing causal reasoning resources. In this paper, we fill this gap by presenting a human-annotated explainable CAusal REasoning dataset (e-CARE), which contains over 20K causal reasoning questions, together with natural language formed explanations of the causal questions. Experimental results show that generating valid explanations for causal facts still remains especially challenging for the state-of-the-art models, and the explanation information can be helpful for promoting the accuracy and stability of causal reasoning models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "e-CARE：説明可能な因果推論を探索するための新しいデータセット", "jabstract": "因果関係を理解することは、様々な自然言語処理（NLP）アプリケーションにとって極めて重要です。ラベル付きのインスタンスを超えて、因果関係の概念的な説明は、因果推論プロセスを促進するために因果事実の深い理解を提供することができます。しかし、このような説明情報は、既存の因果推論リソースにまだ存在していません。本論文では、人間による説明可能な因果推論データセット（e-CARE）を紹介し、20,000以上の因果推論の質問と、自然言語で形成された因果的な質問の説明を含んでいます。実験結果は、因果事実の有効な説明を生成することは、最先端のモデルにとって依然として特に困難であり、説明情報は因果推論モデルの精度と安定性を促進するのに役立つことが示されています。"}
{"title": "Fantastic Questions and Where to Find Them: FairytaleQA – An Authentic Dataset for Narrative Comprehension", "url": "https://aclanthology.org/2022.acl-long.34/", "abstract": "Question answering (QA) is a fundamental means to facilitate assessment and training of narrative comprehension skills for both machines and young children, yet there is scarcity of high-quality QA datasets carefully designed to serve this purpose. In particular, existing datasets rarely distinguish fine-grained reading skills, such as the understanding of varying narrative elements. Drawing on the reading education research, we introduce FairytaleQA, a dataset focusing on narrative comprehension of kindergarten to eighth-grade students. Generated by educational experts based on an evidence-based theoretical framework, FairytaleQA consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements or relations. Our dataset is valuable in two folds: First, we ran existing QA models on our dataset and confirmed that this annotation helps assess models’ fine-grained learning skills. Second, the dataset supports question generation (QG) task in the education domain. Through benchmarking with QG models, we show that the QG model trained on FairytaleQA is capable of asking high-quality and more diverse questions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ファンタスティック・クエスチョンズ・アンド・ウェア・トゥ・ファインド・ゼム：フェアリーテイルQA - 物語理解のための本物のデータセット」は、自然言語処理に関する論文の要約です。", "jabstract": "質問応答（QA）は、機械と幼児の物語理解能力の評価とトレーニングを促進するための基本的な手段であるが、この目的に適した高品質のQAデータセットが不足している。特に、既存のデータセットは、異なる物語要素の理解などの細かい読解力を区別することがほとんどない。読み書き教育研究に基づいて、私たちはFairytaleQAというデータセットを紹介する。FairytaleQAは、幼稚園から8年生の学生の物語理解に焦点を当てたデータセットであり、証拠に基づく理論的枠組みに基づいて教育専門家によって生成され、7種類の物語要素または関係をカバーする278の子供向けストーリーから派生した10,580の明示的および暗黙的な質問から構成されている。私たちのデータセットは2つの価値がある。第一に、既存のQAモデルを私たちのデータセットで実行し、この注釈がモデルの細かい学習能力を評価するのに役立つことを確認した。第二に、データセットは教育領域の質問生成（QG）タスクをサポートする。QGモデルとのベンチマークを通じて、FairytaleQAでトレーニングされたQGモデルが高品質でより多様な質問をすることができることを示した。"}
{"title": "KaFSP: Knowledge-Aware Fuzzy Semantic Parsing for Conversational Question Answering over a Large-Scale Knowledge Base", "url": "https://aclanthology.org/2022.acl-long.35/", "abstract": "In this paper, we study two issues of semantic parsing approaches to conversational question answering over a large-scale knowledge base: (1) The actions defined in grammar are not sufficient to handle uncertain reasoning common in real-world scenarios. (2) Knowledge base information is not well exploited and incorporated into semantic parsing. To mitigate the two issues, we propose a knowledge-aware fuzzy semantic parsing framework (KaFSP). It defines fuzzy comparison operations in the grammar system for uncertain reasoning based on the fuzzy set theory. In order to enhance the interaction between semantic parsing and knowledge base, we incorporate entity triples from the knowledge base into a knowledge-aware entity disambiguation module. Additionally, we propose a multi-label classification framework to not only capture correlations between entity types and relations but also detect knowledge base information relevant to the current utterance. Both enhancements are based on pre-trained language models. Experiments on a large-scale conversational question answering benchmark demonstrate that the proposed KaFSP achieves significant improvements over previous state-of-the-art models, setting new SOTA results on 8 out of 10 question types, gaining improvements of over 10% F1 or accuracy on 3 question types, and improving overall F1 from 83.01% to 85.33%. The source code of KaFSP is available at https://github.com/tjunlp-lab/KaFSP.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KaFSP：大規模な知識ベース上での会話型質問応答のための知識に基づくファジィ意味解析", "jabstract": "本論文では、大規模な知識ベースを対象とした会話型質問応答の意味解析アプローチにおける2つの問題を研究する：(1)文法で定義されたアクションは、現実世界のシナリオで一般的な不確実な推論を扱うのに十分ではない。(2)知識ベース情報が十分に活用され、意味解析に組み込まれていない。これらの問題を緩和するために、知識に基づくファジー意味解析フレームワーク(KaFSP)を提案する。これは、ファジー集合論に基づく不確実な推論のための文法システム内のファジー比較演算を定義するものである。意味解析と知識ベースの相互作用を強化するために、知識ベースからのエンティティトリプルを知識に基づくエンティティの曖昧さ解消モジュールに組み込む。さらに、エンティティタイプと関係の相関関係を捕捉し、現在の発話に関連する知識ベース情報を検出するためのマルチラベル分類フレームワークを提案する。両方の強化は、事前学習された言語モデルに基づいている。大規模な会話型質問応答ベンチマークでの実験結果は、提案されたKaFSPが従来の最先端モデルよりも有意な改善を達成し、10種類の質問のうち8種類で新しいSOTA結果を設定し、3種類の質問でF1または精度が10％以上向上し、全体のF1を83.01％から85.33％に向上させたことを示している。KaFSPのソースコードは、https://github.com/tjunlp-lab/KaFSPで入手可能である。"}
{"title": "Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment", "url": "https://aclanthology.org/2022.acl-long.36/", "abstract": "Predicting missing facts in a knowledge graph (KG) is crucial as modern KGs are far from complete. Due to labor-intensive human labeling, this phenomenon deteriorates when handling knowledge represented in various languages. In this paper, we explore multilingual KG completion, which leverages limited seed alignment as a bridge, to embrace the collective knowledge from multiple languages. However, language alignment used in prior works is still not fully exploited: (1) alignment pairs are treated equally to maximally push parallel entities to be close, which ignores KG capacity inconsistency; (2) seed alignment is scarce and new alignment identification is usually in a noisily unsupervised manner. To tackle these issues, we propose a novel self-supervised adaptive graph alignment (SS-AGA) method. Specifically, SS-AGA fuses all KGs as a whole graph by regarding alignment as a new edge type. As such, information propagation and noise influence across KGs can be adaptively controlled via relation-aware attention weights. Meanwhile, SS-AGA features a new pair generator that dynamically captures potential alignment pairs in a self-supervised paradigm. Extensive experiments on both the public multilingual DBPedia KG and newly-created industrial multilingual E-commerce KG empirically demonstrate the effectiveness of SS-AGA", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己教育型グラフアラインメントによる多言語知識グラフ補完", "jabstract": "知識グラフ（KG）における欠落した事実を予測することは重要である。現代のKGは不完全であるため、人間によるラベリングが労力を必要とするため、異なる言語で表現された知識を扱う場合には、この現象が悪化する。本論文では、限られたシードアラインメントを橋渡しとして活用する多言語KG補完を探求し、複数の言語からの集合的な知識を取り込む。しかし、従来の言語アラインメントはまだ十分に活用されていない。具体的には、(1)アラインメントペアは等しく扱われ、並列エンティティを最大限に近づけることができるが、KGの容量の不一致を無視している。(2)シードアラインメントは限られており、新しいアラインメントの識別は通常、ノイズの多い非監視学習の方法で行われる。これらの問題に対処するために、本論文では、新しい自己教師付き適応グラフアラインメント（SS-AGA）手法を提案する。具体的には、SS-AGAは、アラインメントを新しいエッジタイプとして扱い、すべてのKGを1つのグラフとして融合する。これにより、関係に注意した重みを用いて、KG間の情報伝播とノイズの影響を適応的に制御することができる。一方、SS-AGAは、自己教師付きパラダイムで潜在的なアラインメントペアを動的に捕捉する新しいペアジェネレータを特徴とする。公開されている多言語DBPedia KGと新たに作成された産業用多言語E-commerce KGの両方での広範な実験により、SS-AGAの有効性が実証された。"}
{"title": "Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization", "url": "https://aclanthology.org/2022.acl-long.37/", "abstract": "Automatic code summarization, which aims to describe the source code in natural language, has become an essential task in software maintenance. Our fellow researchers have attempted to achieve such a purpose through various machine learning-based approaches. One key challenge keeping these approaches from being practical lies in the lacking of retaining the semantic structure of source code, which has unfortunately been overlooked by the state-of-the-art. Existing approaches resort to representing the syntax structure of code by modeling the Abstract Syntax Trees (ASTs). However, the hierarchical structures of ASTs have not been well explored. In this paper, we propose CODESCRIBE to model the hierarchical syntax structure of code by introducing a novel triplet position for code summarization. Specifically, CODESCRIBE leverages the graph neural network and Transformer to preserve the structural and sequential information of code, respectively. In addition, we propose a pointer-generator network that pays attention to both the structure and sequential tokens of code for a better summary generation. Experiments on two real-world datasets in Java and Python demonstrate the effectiveness of our proposed approach when compared with several state-of-the-art baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Triplet Positionを用いた階層的構文構造のモデリングによるソースコード要約化」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization\n- ソースコード要約化のためのTriplet Positionを用いた階層的構文構造のモデリング", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自然言語でソースコードを説明することを目的とする自動コード要約は、ソフトウェアメンテナンスにおいて必要不可欠なタスクとなっています。私たちの研究仲間は、機械学習をベースとした様々なアプローチを用いて、このような目的を達成しようと試みてきました。しかし、これらのアプローチが実用的でない理由の1つは、ソースコードの意味構造を保持することができていないことです。既存のアプローチは、コードの構文構造を抽象構文木（AST）をモデル化することで表現しています。しかし、ASTの階層構造は十分に探索されていません。本論文では、CODESCRIBEを提案し、コード要約のための新しい三つ組位置を導入することで、コードの階層的構文構造をモデル化します。具体的には、CODESCRIBEはグラフニューラルネットワークとTransformerを活用して、コードの構造と順序情報をそれぞれ保持します。さらに、コードの構造と順序トークンの両方に注意を払うポインタジェネレータネットワークを提案し、より良い要約生成を実現します。JavaとPythonの2つの実世界データセットでの実験結果は、いくつかの最先端のベースラインと比較して、提案手法の有効性を示しています。"}
{"title": "FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural Language Understanding", "url": "https://aclanthology.org/2022.acl-long.38/", "abstract": "The few-shot natural language understanding (NLU) task has attracted much recent attention. However, prior methods have been evaluated under a disparate set of protocols, which hinders fair comparison and measuring the progress of the field. To address this issue, we introduce an evaluation framework that improves previous evaluation procedures in three key aspects, i.e., test performance, dev-test correlation, and stability. Under this new evaluation framework, we re-evaluate several state-of-the-art few-shot methods for NLU tasks. Our framework reveals new insights: (1) both the absolute performance and relative gap of the methods were not accurately estimated in prior literature; (2) no single method dominates most tasks with consistent performance; (3) improvements of some methods diminish with a larger pretrained model; and (4) gains from different methods are often complementary and the best combined model performs close to a strong fully-supervised baseline. We open-source our toolkit, FewNLU, that implements our evaluation framework along with a number of state-of-the-art methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FewNLU：少数ショット自然言語理解の最先端手法のベンチマーク化", "jabstract": "最近、少数の自然言語理解（NLU）タスクに注目が集まっています。しかし、これまでの方法は異なるプロトコルで評価されており、公平な比較や分野の進歩の測定を妨げています。この問題に対処するために、我々は評価フレームワークを導入し、テストパフォーマンス、開発テスト相関、および安定性の3つの重要な側面で以前の評価手順を改善しました。この新しい評価フレームワークの下で、NLUタスクのいくつかの最先端の少数の方法を再評価しました。我々のフレームワークは新しい洞察を明らかにしました：（1）方法の絶対的なパフォーマンスと相対的なギャップは以前の文献で正確に評価されていなかった；（2）一貫したパフォーマンスでほとんどのタスクを支配する単一の方法は存在しない；（3）一部の方法の改善は、より大きな事前学習モデルでは減少する；（4）異なる方法からの利益はしばしば補完的であり、最高の組み合わせモデルは強力な完全教師ありベースラインに近いパフォーマンスを発揮します。我々は、我々の評価フレームワークといくつかの最先端の方法を実装したツールキット、FewNLUをオープンソース化しています。"}
{"title": "Learn to Adapt for Generalized Zero-Shot Text Classification", "url": "https://aclanthology.org/2022.acl-long.39/", "abstract": "Generalized zero-shot text classification aims to classify textual instances from both previously seen classes and incrementally emerging unseen classes. Most existing methods generalize poorly since the learned parameters are only optimal for seen classes rather than for both classes, and the parameters keep stationary in predicting procedures. To address these challenges, we propose a novel Learn to Adapt (LTA) network using a variant meta-learning framework. Specifically, LTA trains an adaptive classifier by using both seen and virtual unseen classes to simulate a generalized zero-shot learning (GZSL) scenario in accordance with the test time, and simultaneously learns to calibrate the class prototypes and sample representations to make the learned parameters adaptive to incoming unseen classes. We claim that the proposed model is capable of representing all prototypes and samples from both classes to a more consistent distribution in a global space. Extensive experiments on five text classification datasets show that our model outperforms several competitive previous approaches by large margins. The code and the whole datasets are available at https://github.com/Quareia/LTA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "一般化されたゼロショットテキスト分類に適応する方法を学ぶ", "jabstract": "一般化されたゼロショットテキスト分類は、以前に見たクラスと増加する未知のクラスの両方からテキストインスタンスを分類することを目的としています。既存の多くの方法は、学習されたパラメータが見たクラスに対してのみ最適であり、両方のクラスに対して最適ではないため、一般化が悪いです。また、パラメータは予測手順で静止状態を保ちます。これらの課題に対処するために、私たちは、変異体メタ学習フレームワークを使用した新しいLearn to Adapt（LTA）ネットワークを提案します。具体的には、LTAは、テスト時間に従って一般化されたゼロショット学習（GZSL）シナリオをシミュレートするために、見たクラスと仮想未知のクラスの両方を使用して適応型分類器をトレーニングし、同時に、学習されたパラメータを入力された未知のクラスに適応させるためにクラスプロトタイプとサンプル表現をキャリブレーションすることを学習します。提案されたモデルは、両方のクラスからすべてのプロトタイプとサンプルをグローバル空間でより一貫した分布に表現できると主張します。5つのテキスト分類データセットでの広範な実験により、私たちのモデルは、いくつかの競合する以前のアプローチよりも大幅に優れていることが示されました。コードと全データセットは、https://github.com/Quareia/LTAで利用可能です。"}
{"title": "TableFormer: Robust Transformer Modeling for Table-Text Encoding", "url": "https://aclanthology.org/2022.acl-long.40/", "abstract": "Understanding tables is an important aspect of natural language understanding. Existing models for table understanding require linearization of the table structure, where row or column order is encoded as an unwanted bias. Such spurious biases make the model vulnerable to row and column order perturbations. Additionally, prior work has not thoroughly modeled the table structures or table-text alignments, hindering the table-text understanding ability. In this work, we propose a robust and structurally aware table-text encoding architecture TableFormer, where tabular structural biases are incorporated completely through learnable attention biases. TableFormer is (1) strictly invariant to row and column orders, and, (2) could understand tables better due to its tabular inductive biases. Our evaluations showed that TableFormer outperforms strong baselines in all settings on SQA, WTQ and TabFact table reasoning datasets, and achieves state-of-the-art performance on SQA, especially when facing answer-invariant row and column order perturbations (6% improvement over the best baseline), because previous SOTA models’ performance drops by 4% - 6% when facing such perturbations while TableFormer is not affected.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "TableFormer：表-テキストエンコーディングのための堅牢なTransformerモデリング", "jabstract": "表の理解は自然言語理解の重要な側面である。表理解の既存のモデルは、行または列の順序が不要なバイアスとしてエンコードされる表の構造の線形化を必要とする。このような偽のバイアスは、モデルを行と列の順序の摂動に対して脆弱にする。さらに、以前の研究では、表の構造や表とテキストの整列について十分にモデル化されておらず、表とテキストの理解能力が妨げられている。本研究では、学習可能なアテンションバイアスを介して完全に表の構造的バイアスを組み込んだ堅牢で構造的に意識した表テキストエンコーディングアーキテクチャTableFormerを提案する。TableFormerは、(1) 行と列の順序に厳密に不変であり、(2) 表の帰納的バイアスにより、表をよりよく理解できる。評価により、TableFormerはSQA、WTQ、TabFact表推論データセットのすべての設定で強力なベースラインを上回り、特に回答不変の行と列の順序の摂動に直面した場合にSOTAモデルの性能が4％〜6％低下するのに対して、TableFormerは影響を受けないため、SQAで最高のベースラインより6％改善された。"}
{"title": "Perceiving the World: Question-guided Reinforcement Learning for Text-based Games", "url": "https://aclanthology.org/2022.acl-long.41/", "abstract": "Text-based games provide an interactive way to study natural language processing. While deep reinforcement learning has shown effectiveness in developing the game playing agent, the low sample efficiency and the large action space remain to be the two major challenges that hinder the DRL from being applied in the real world. In this paper, we address the challenges by introducing world-perceiving modules, which automatically decompose tasks and prune actions by answering questions about the environment. We then propose a two-phase training framework to decouple language learning from reinforcement learning, which further improves the sample efficiency. The experimental results show that the proposed method significantly improves the performance and sample efficiency. Besides, it shows robustness against compound error and limited pre-training data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "世界を認識する：テキストベースのゲームのための質問に基づく強化学習", "jabstract": "テキストベースのゲームは、自然言語処理を研究するためのインタラクティブな方法を提供します。深層強化学習は、ゲームプレイエージェントの開発に有効であることが示されていますが、低いサンプル効率と大きなアクションスペースは、現実世界でのDRLの適用を妨げる2つの主要な課題であり続けています。本論文では、環境に関する質問に答えることでタスクを自動的に分解し、アクションを削減する世界知覚モジュールを導入することで、これらの課題に対処します。さらに、言語学習を強化学習から分離する2段階のトレーニングフレームワークを提案し、サンプル効率をさらに改善します。実験結果は、提案手法が性能とサンプル効率を大幅に改善することを示しています。また、複合エラーや限られた事前トレーニングデータに対しても堅牢性を示しています。"}
{"title": "Neural Label Search for Zero-Shot Multi-Lingual Extractive Summarization", "url": "https://aclanthology.org/2022.acl-long.42/", "abstract": "In zero-shot multilingual extractive text summarization, a model is typically trained on English summarization dataset and then applied on summarization datasets of other languages. Given English gold summaries and documents, sentence-level labels for extractive summarization are usually generated using heuristics. However, these monolingual labels created on English datasets may not be optimal on datasets of other languages, for that there is the syntactic or semantic discrepancy between different languages. In this way, it is possible to translate the English dataset to other languages and obtain different sets of labels again using heuristics. To fully leverage the information of these different sets of labels, we propose NLSSum (Neural Label Search for Summarization), which jointly learns hierarchical weights for these different sets of labels together with our summarization model. We conduct multilingual zero-shot summarization experiments on MLSUM and WikiLingua datasets, and we achieve state-of-the-art results using both human and automatic evaluations across these two datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ゼロショット多言語抽出要約のためのニューラルラベル検索」に関する論文の要約です。", "jabstract": "ゼロショット多言語抽出型テキスト要約では、モデルは通常、英語の要約データセットでトレーニングされ、その後、他の言語の要約データセットに適用されます。英語のゴールド要約と文書が与えられた場合、抽出型要約の文レベルのラベルは通常、ヒューリスティックを使用して生成されます。ただし、これらの英語データセットで作成された単一言語のラベルは、異なる言語のデータセットでは、構文的または意味的な不一致があるため、最適ではない場合があります。このように、英語のデータセットを他の言語に翻訳し、再びヒューリスティックを使用して異なるラベルセットを取得することができます。これらの異なるラベルセットの情報を十分に活用するために、私たちはNLSSum（要約のためのニューラルラベル検索）を提案し、これはこれらの異なるラベルセットの階層的な重みを私たちの要約モデルと一緒に学習します。私たちは、MLSUMおよびWikiLinguaデータセットで多言語ゼロショット要約実験を実施し、これらの2つのデータセット全体で人間と自動評価を使用して最先端の結果を達成しました。"}
{"title": "Few-Shot Class-Incremental Learning for Named Entity Recognition", "url": "https://aclanthology.org/2022.acl-long.43/", "abstract": "Previous work of class-incremental learning for Named Entity Recognition (NER) relies on the assumption that there exists abundance of labeled data for the training of new classes. In this work, we study a more challenging but practical problem, i.e., few-shot class-incremental learning for NER, where an NER model is trained with only few labeled samples of the new classes, without forgetting knowledge of the old ones. To alleviate the problem of catastrophic forgetting in few-shot class-incremental learning, we reconstruct synthetic training data of the old classes using the trained NER model, augmenting the training of new classes. We further develop a framework that distills from the existing model with both synthetic data, and real data from the current training set. Experimental results show that our approach achieves significant improvements over existing baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Few-Shot Class-Incremental Learning for Named Entity Recognition」という論文の要約文を日本語に翻訳します。\n\n少数のサンプルでのクラス増分学習による固有表現認識についての研究です。新しいクラスを追加するために、既存のモデルを再学習する必要がなく、少数のサンプルで新しいクラスを認識できるようになります。この研究は、自然言語処理における重要な問題を解決するために役立ちます。", "jabstract": "従来のNamed Entity Recognition（NER）のクラス増分学習においては、新しいクラスのトレーニングに十分なラベル付きデータが存在するという仮定に依存していた。本研究では、より困難で実践的な問題である、少数のラベル付きサンプルのみを用いたNERの少数ショットクラス増分学習を研究し、古いクラスの知識を忘れずに新しいクラスをトレーニングする。少数ショットクラス増分学習におけるカタストロフィックな忘却の問題を緩和するために、トレーニング済みのNERモデルを使用して古いクラスの合成トレーニングデータを再構築し、新しいクラスのトレーニングを拡張する。さらに、既存のモデルから合成データと現在のトレーニングセットからの実データの両方を抽出するフレームワークを開発する。実験結果は、当社のアプローチが既存のベースラインよりも大幅な改善を達成していることを示している。"}
{"title": "Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation", "url": "https://aclanthology.org/2022.acl-long.44/", "abstract": "Building models of natural language processing (NLP) is challenging in low-resource scenarios where limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model’s reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of support sets stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「メモリーイミテーションを介した低リソーステキスト分類および生成のためのメタ学習の改善」に関する論文の要約です。", "jabstract": "自然言語処理（NLP）のモデルを構築することは、データが限られている低リソースのシナリオでは困難です。最適化ベースのメタ学習アルゴリズムは、よく一般化されたモデル初期化を新しいタスクに対応できるように適応させることで、低リソースのシナリオで有望な結果を達成します。しかし、これらのアプローチは、メタトレーニングタスクを記憶しながら、サポートセットを無視して新しいタスクに適応するモデルが記憶過剰になるという問題があります。この問題に対処するために、私たちはメモリイミテーションメタ学習（MemIML）方法を提案し、タスク適応のためにモデルがサポートセットに依存するように強化します。具体的には、タスク固有のメモリモジュールを導入してサポートセット情報を保存し、イミテーションモジュールを構築して、クエリセットがメモリに保存されたサポートセットの振る舞いを模倣するように強制します。理論的な分析を提供して、私たちの方法の効果を証明し、実証結果も、テキスト分類および生成タスクの両方で競合するベースラインを上回ることを示しています。"}
{"title": "Quality Controlled Paraphrase Generation", "url": "https://aclanthology.org/2022.acl-long.45/", "abstract": "Paraphrase generation has been widely used in various downstream tasks. Most tasks benefit mainly from high quality paraphrases, namely those that are semantically similar to, yet linguistically diverse from, the original sentence. Generating high-quality paraphrases is challenging as it becomes increasingly hard to preserve meaning as linguistic diversity increases. Recent works achieve nice results by controlling specific aspects of the paraphrase, such as its syntactic tree. However, they do not allow to directly control the quality of the generated paraphrase, and suffer from low flexibility and scalability. Here we propose QCPG, a quality-guided controlled paraphrase generation model, that allows directly controlling the quality dimensions. Furthermore, we suggest a method that given a sentence, identifies points in the quality control space that are expected to yield optimal generated paraphrases. We show that our method is able to generate paraphrases which maintain the original meaning while achieving higher diversity than the uncontrolled baseline. The models, the code, and the data can be found in https://github.com/IBM/quality-controlled-paraphrase-generation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n品質管理された言い換え生成", "jabstract": "言い換え生成は、様々な下流タスクで広く使用されています。ほとんどのタスクは、主に高品質の言い換えに利益を得ます。つまり、元の文と意味的に類似しているが、言語的に多様であるものです。高品質の言い換えを生成することは困難であり、言語的多様性が増すにつれて意味を保持することがますます困難になります。最近の研究では、構文木などの特定の側面を制御することにより、素晴らしい結果を達成しています。しかし、彼らは生成された言い換えの品質を直接制御することを許可せず、柔軟性と拡張性に欠けています。ここでは、品質に基づく制御された言い換え生成モデルであるQCPGを提案し、直接品質次元を制御することができます。さらに、文が与えられた場合、最適な生成された言い換えを生み出すと予想される品質制御空間のポイントを特定する方法を提案します。私たちは、制御されていないベースラインよりも高い多様性を実現しながら、元の意味を維持する言い換えを生成することができることを示します。モデル、コード、およびデータは、https://github.com/IBM/quality-controlled-paraphrase-generationで見つけることができます。"}
{"title": "Controllable Dictionary Example Generation: Generating Example Sentences for Specific Targeted Audiences", "url": "https://aclanthology.org/2022.acl-long.46/", "abstract": "Example sentences for targeted words in a dictionary play an important role to help readers understand the usage of words. Traditionally, example sentences in a dictionary are usually created by linguistics experts, which are labor-intensive and knowledge-intensive. In this paper, we introduce the problem of dictionary example sentence generation, aiming to automatically generate dictionary example sentences for targeted words according to the corresponding definitions. This task is challenging especially for polysemous words, because the generated sentences need to reflect different usages and meanings of these targeted words. Targeted readers may also have different backgrounds and educational levels. It is essential to generate example sentences that can be understandable for different backgrounds and levels of audiences. To solve these problems, we propose a controllable target-word-aware model for this task. Our proposed model can generate reasonable examples for targeted words, even for polysemous words. In addition, our model allows users to provide explicit control over attributes related to readability, such as length and lexical complexity, thus generating suitable examples for targeted audiences. Automatic and human evaluations on the Oxford dictionary dataset show that our model can generate suitable examples for targeted words with specific definitions while meeting the desired readability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "制御可能な辞書例文生成：特定のターゲットオーディエンス向けの例文生成", "jabstract": "辞書の対象語に対する例文は、読者が単語の使用法を理解するのに重要な役割を果たします。従来、辞書の例文は通常、言語学の専門家によって作成されており、労力と知識が必要でした。本論文では、対象語に対応する定義に従って、辞書の例文を自動生成する問題を紹介します。このタスクは、特に多義語の場合には困難であり、生成された文は、対象語の異なる用法や意味を反映する必要があります。対象読者には、異なるバックグラウンドや教育レベルがある場合があります。異なるバックグラウンドやレベルの観客に理解できる例文を生成することが重要です。これらの問題を解決するために、本論文では、このタスクのための制御可能な対象語に関するモデルを提案します。提案されたモデルは、多義語でも対象語に対して合理的な例文を生成することができます。さらに、モデルは、長さや語彙の複雑さなど、読みやすさに関連する属性に対する明示的な制御をユーザーに許可するため、対象読者に適した例文を生成することができます。オックスフォード辞書のデータセットに対する自動評価と人間による評価により、提案されたモデルは、特定の定義に対して適切な例文を生成し、所望の読みやすさを満たすことができることが示されました。"}
{"title": "AraT5: Text-to-Text Transformers for Arabic Language Generation", "url": "https://aclanthology.org/2022.acl-long.47/", "abstract": "Transfer learning with a unified Transformer framework (T5) that converts all language problems into a text-to-text format was recently proposed as a simple and effective transfer learning approach. Although a multilingual version of the T5 model (mT5) was also introduced, it is not clear how well it can fare on non-English tasks involving diverse data. To investigate this question, we apply mT5 on a language with a wide variety of dialects–Arabic. For evaluation, we introduce a novel benchmark for ARabic language GENeration (ARGEN), covering seven important tasks. For model comparison, we pre-train three powerful Arabic T5-style models and evaluate them on ARGEN. Although pre-trained with ~49 less data, our new models perform significantly better than mT5 on all ARGEN tasks (in 52 out of 59 test sets) and set several new SOTAs. Our models also establish new SOTA on the recently-proposed, large Arabic language understanding evaluation benchmark ARLUE (Abdul-Mageed et al., 2021). Our new models are publicly available. We also link to ARGEN datasets through our repository: https://github.com/UBC-NLP/araT5.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AraT5: アラビア語言語生成のためのテキスト・トゥ・テキスト・トランスフォーマー\n\nAbstract:\nIn recent years, natural language processing (NLP) has seen significant advancements, particularly with the development of transformer-based models. However, most of these models have been developed for English language processing, leaving other languages, such as Arabic, with limited resources. In this paper, we introduce AraT5, a transformer-based model specifically designed for Arabic language generation tasks. We evaluate AraT5 on several Arabic language generation tasks and compare its performance to other state-of-the-art models. Our results show that AraT5 outperforms these models on most of the tasks, demonstrating its effectiveness in generating high-quality Arabic language text.", "jabstract": "最近、すべての言語問題をテキストからテキストへの形式に変換する統一されたTransformerフレームワーク（T5）を用いた転移学習が、簡単で効果的な転移学習手法として提案された。T5モデルの多言語版（mT5）も導入されたが、多様なデータを含む英語以外のタスクにおいてどの程度優れた性能を発揮できるかは明確ではない。この問題を調査するため、私たちは多様な方言を持つ言語であるアラビア語にmT5を適用した。評価のために、私たちはアラビア語の7つの重要なタスクをカバーする新しいベンチマークであるARabic language GENeration（ARGEN）を導入する。モデルの比較のために、私たちは3つの強力なアラビア語T5スタイルモデルを事前学習し、ARGENで評価した。私たちの新しいモデルは、約49のデータで事前学習されたにもかかわらず、ARGENのすべてのタスク（59のテストセットのうち52）でmT5よりも有意に優れた性能を発揮し、いくつかの新しいSOTAを設定した。私たちのモデルは、最近提案された大規模なアラビア語言語理解評価ベンチマークであるARLUE（Abdul-Mageed et al.、2021）でも新しいSOTAを確立した。私たちの新しいモデルは公開されており、ARGENデータセットへのリンクも私たちのリポジトリ（https://github.com/UBC-NLP/araT5）を通じて提供されている。"}
{"title": "Legal Judgment Prediction via Event Extraction with Constraints", "url": "https://aclanthology.org/2022.acl-long.48/", "abstract": "While significant progress has been made on the task of Legal Judgment Prediction (LJP) in recent years, the incorrect predictions made by SOTA LJP models can be attributed in part to their failure to (1) locate the key event information that determines the judgment, and (2) exploit the cross-task consistency constraints that exist among the subtasks of LJP. To address these weaknesses, we propose EPM, an Event-based Prediction Model with constraints, which surpasses existing SOTA models in performance on a standard LJP dataset.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "制約付きイベント抽出による法的判定予測", "jabstract": "近年、法的判断予測（LJP）の課題において重要な進展があったが、SOTA LJPモデルによる不正確な予測は、（1）判断を決定する主要なイベント情報を特定できないこと、および（2）LJPのサブタスク間に存在するクロスタスクの一貫性制約を活用できないことに一部帰因される。これらの弱点に対処するために、我々は制約付きのイベントベースの予測モデルであるEPMを提案し、標準的なLJPデータセットにおいて既存のSOTAモデルを上回る性能を発揮する。"}
{"title": "Answer-level Calibration for Free-form Multiple Choice Question Answering", "url": "https://aclanthology.org/2022.acl-long.49/", "abstract": "Pre-trained language models have recently shown that training on large corpora using the language modeling objective enables few-shot and zero-shot capabilities on a variety of NLP tasks, including commonsense reasoning tasks. This is achieved using text interactions with the model, usually by posing the task as a natural language text completion problem. While using language model probabilities to obtain task specific scores has been generally useful, it often requires task-specific heuristics such as length normalization, or probability calibration. In this work, we consider the question answering format, where we need to choose from a set of (free-form) textual choices of unspecified lengths given a context. We present ALC (Answer-Level Calibration), where our main suggestion is to model context-independent biases in terms of the probability of a choice without the associated context and to subsequently remove it using an unsupervised estimate of similarity with the full context. We show that our unsupervised answer-level calibration consistently improves over or is competitive with baselines using standard evaluation metrics on a variety of tasks including commonsense reasoning tasks. Further, we show that popular datasets potentially favor models biased towards easy cues which are available independent of the context. We analyze such biases using an associated F1-score. Our analysis indicates that answer-level calibration is able to remove such biases and leads to a more robust measure of model capability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自由形式の多肢選択問題回答に対する回答レベルのキャリブレーション", "jabstract": "最近、事前学習された言語モデルは、言語モデリング目的を使用して大規模なコーパスでトレーニングすることにより、常識的な推論タスクを含むさまざまなNLPタスクにおいて、フューショットおよびゼロショットの機能を実現することが示されています。これは、通常、自然言語テキストの完了問題としてタスクを提示することにより、モデルとのテキストの相互作用を使用して達成されます。言語モデルの確率を使用してタスク固有のスコアを取得することは一般的に有用であるが、長さの正規化や確率のキャリブレーションなどのタスク固有のヒューリスティックが必要であることが多い。本研究では、文脈が与えられた場合に、未指定の長さの自由形式のテキスト選択肢から選択する必要がある質問応答形式を考慮します。私たちは、ALC（Answer-Level Calibration）を提案し、主な提案は、関連する文脈なしで選択肢の確率をモデル化し、完全な文脈との類似性の非監督推定を使用してそれを削除することです。私たちは、共通の推論タスクを含むさまざまなタスクにおいて、標準的な評価メトリックを使用してベースラインよりも常に改善または競争力があることを示しています。さらに、人気のあるデータセットは、文脈に依存しない簡単な手がかりに偏ったモデルを好む可能性があることを示しています。私たちは、関連するF1スコアを使用してそのようなバイアスを分析します。私たちの分析は、回答レベルのキャリブレーションがそのようなバイアスを除去し、モデルの能力のより堅牢な測定につながることを示しています。"}
{"title": "Learning When to Translate for Streaming Speech", "url": "https://aclanthology.org/2022.acl-long.50/", "abstract": "How to find proper moments to generate partial sentence translation given a streaming speech input? Existing approaches waiting-and-translating for a fixed duration often break the acoustic units in speech, since the boundaries between acoustic units in speech are not even. In this paper, we propose MoSST, a simple yet effective method for translating streaming speech content. Given a usually long speech sequence, we develop an efficient monotonic segmentation module inside an encoder-decoder model to accumulate acoustic information incrementally and detect proper speech unit boundaries for the input in speech translation task. Experiments on multiple translation directions of the MuST-C dataset show that outperforms existing methods and achieves the best trade-off between translation quality (BLEU) and latency. Our code is available at https://github.com/dqqcasia/mosst.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ストリーミング音声の翻訳タイミングを学習する方法についての論文の要約文です。以下、日本語に翻訳してください。\n\n- Learning When to Translate for Streaming Speech\n- ストリーミング音声の翻訳タイミングを学習する", "jabstract": "ストリーミング音声入力に対して、部分文翻訳を生成する適切なタイミングをどのように見つけるか？従来のアプローチである一定時間待機して翻訳する方法は、音声の音響ユニットの境界が均等でないため、音声の音響ユニットを壊してしまうことがよくある。本論文では、ストリーミング音声コンテンツを翻訳するためのシンプルで効果的な方法であるMoSSTを提案する。通常長い音声シーケンスが与えられた場合、エンコーダ・デコーダモデル内に効率的な単調増加分割モジュールを開発し、音響情報を累積的に蓄積し、音声翻訳タスクにおいて適切な音声ユニットの境界を検出する。MuST-Cデータセットの複数の翻訳方向での実験結果は、既存の方法を上回り、翻訳品質（BLEU）とレイテンシの最適なトレードオフを実現していることを示している。コードはhttps://github.com/dqqcasia/mosstで入手可能である。"}
{"title": "Compact Token Representations with Contextual Quantization for Efficient Document Re-ranking", "url": "https://aclanthology.org/2022.acl-long.51/", "abstract": "Transformer based re-ranking models can achieve high search relevance through context- aware soft matching of query tokens with document tokens. To alleviate runtime complexity of such inference, previous work has adopted a late interaction architecture with pre-computed contextual token representations at the cost of a large online storage. This paper proposes contextual quantization of token embeddings by decoupling document-specific and document-independent ranking contributions during codebook-based compression. This allows effective online decompression and embedding composition for better search relevance. This paper presents an evaluation of the above compact token representation model in terms of relevance and space efficiency.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "コンパクトなトークン表現と文脈的量子化による効率的なドキュメント再ランキング", "jabstract": "トランスフォーマーベースの再ランキングモデルは、クエリトークンとドキュメントトークンのコンテキストに基づくソフトマッチングにより、高い検索関連性を実現できます。このような推論のランタイム複雑性を緩和するために、以前の研究では、オンラインストレージの大きなコストで事前に計算されたコンテキストトークン表現を持つ遅延相互作用アーキテクチャを採用してきました。本論文では、コードブックベースの圧縮において、ドキュメント固有とドキュメント非依存のランキング貢献を分離することにより、トークン埋め込みの文脈的量子化を提案します。これにより、より良い検索関連性のための効果的なオンライン復号化と埋め込み合成が可能になります。本論文では、上記のコンパクトなトークン表現モデルの関連性とスペース効率に関する評価を行います。"}
{"title": "Early Stopping Based on Unlabeled Samples in Text Classification", "url": "https://aclanthology.org/2022.acl-long.52/", "abstract": "Early stopping, which is widely used to prevent overfitting, is generally based on a separate validation set. However, in low resource settings, validation-based stopping can be risky because a small validation set may not be sufficiently representative, and the reduction in the number of samples by validation split may result in insufficient samples for training. In this study, we propose an early stopping method that uses unlabeled samples. The proposed method is based on confidence and class distribution similarities. To further improve the performance, we present a calibration method to better estimate the class distribution of the unlabeled samples. The proposed method is advantageous because it does not require a separate validation set and provides a better stopping point by using a large unlabeled set. Extensive experiments are conducted on five text classification datasets and several stop-methods are compared. Our results show that the proposed model even performs better than using an additional validation set as well as the existing stop-methods, in both balanced and imbalanced data settings. Our code is available at https://github.com/DMCB-GIST/BUS-stop.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約の以下の文を日本語に翻訳してください：\n\nテキスト分類における未ラベルサンプルに基づく早期停止", "jabstract": "過学習を防ぐために広く使用されている早期停止は、通常、別個の検証セットに基づいています。しかし、リソースが少ない状況では、検証に基づく停止はリスクがある場合があります。小さな検証セットは十分に代表的でない可能性があり、検証分割によるサンプル数の減少はトレーニングに十分なサンプルがない可能性があります。本研究では、ラベルのないサンプルを使用する早期停止方法を提案します。提案された方法は、信頼度とクラス分布の類似性に基づいています。さらに性能を向上させるために、未ラベルのサンプルのクラス分布をより正確に推定するためのキャリブレーション方法を提供します。提案された方法は、別個の検証セットを必要とせず、大きな未ラベルセットを使用することでより良い停止点を提供するため、有利です。5つのテキスト分類データセットで広範な実験が行われ、いくつかの停止方法が比較されました。提案されたモデルは、バランスの取れたデータ設定と不均衡なデータ設定の両方で、追加の検証セットを使用することや既存の停止方法よりも優れた性能を発揮することが示されました。私たちのコードはhttps://github.com/DMCB-GIST/BUS-stopで利用可能です。"}
{"title": "Meta-learning via Language Model In-context Tuning", "url": "https://aclanthology.org/2022.acl-long.53/", "abstract": "The goal of meta-learning is to learn to adapt to a new task with only a few labeled examples. Inspired by the recent progress in large language models, we propose in-context tuning (ICT), which recasts task adaptation and prediction as a simple sequence prediction problem: to form the input sequence, we concatenate the task instruction, labeled in-context examples, and the target input to predict; to meta-train the model to learn from in-context examples, we fine-tune a pre-trained language model (LM) to predict the target label given the input sequence on a collection of tasks.We benchmark our method on two collections of text classification tasks: LAMA and BinaryClfs. Compared to MAML which adapts the model through gradient descent, our method leverages the inductive bias of pre-trained LMs to perform pattern matching, and outperforms MAML by an absolute 6% average AUC-ROC score on BinaryClfs, gaining more advantage with increasing model size. Compared to non-fine-tuned in-context learning (i.e. prompting a raw LM), in-context tuning meta-trains the model to learn from in-context examples. On BinaryClfs, ICT improves the average AUC-ROC score by an absolute 10%, and reduces the variance due to example ordering by 6x and example choices by 2x.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "言語モデル内コンテキスト調整によるメタ学習", "jabstract": "メタ学習の目的は、わずかなラベル付きの例だけで新しいタスクに適応することを学ぶことです。大規模言語モデルの最近の進歩に着想を得て、私たちはインコンテキスト・チューニング（ICT）を提案します。これは、タスクの適応と予測を単純なシーケンス予測問題として再定義するものです。入力シーケンスを形成するために、タスクの指示、インコンテキストのラベル付き例、および予測する対象の入力を連結します。インコンテキストの例から学ぶために、事前学習された言語モデル（LM）を微調整して、タスクのコレクションにおいて入力シーケンスからターゲットラベルを予測するようにモデルをメタトレーニングします。私たちは、2つのテキスト分類タスクのコレクションで私たちの方法をベンチマークしました：LAMAとBinaryClfs。モデルを勾配降下法で適応するMAMLと比較して、私たちの方法は、事前学習されたLMの帰納的なバイアスを利用してパターンマッチングを行い、BinaryClfsの平均AUC-ROCスコアで絶対6％の改善を実現し、モデルサイズが大きくなるにつれてより優位性を発揮します。インコンテキスト学習を行わない場合（つまり、生のLMをプロンプトする場合）と比較して、インコンテキスト・チューニングはモデルをインコンテキストの例から学習するようにメタトレーニングします。BinaryClfsでは、ICTは平均AUC-ROCスコアを絶対10％改善し、例の順序による分散を6倍、例の選択による分散を2倍に減らします。"}
{"title": "It is AI’s Turn to Ask Humans a Question: Question-Answer Pair Generation for Children’s Story Books", "url": "https://aclanthology.org/2022.acl-long.54/", "abstract": "Existing question answering (QA) techniques are created mainly to answer questions asked by humans. But in educational applications, teachers often need to decide what questions they should ask, in order to help students to improve their narrative understanding capabilities. We design an automated question-answer generation (QAG) system for this education scenario: given a story book at the kindergarten to eighth-grade level as input, our system can automatically generate QA pairs that are capable of testing a variety of dimensions of a student’s comprehension skills. Our proposed QAG model architecture is demonstrated using a new expert-annotated FairytaleQA dataset, which has 278 child-friendly storybooks with 10,580 QA pairs. Automatic and human evaluations show that our model outperforms state-of-the-art QAG baseline systems. On top of our QAG system, we also start to build an interactive story-telling application for the future real-world deployment in this educational scenario.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nAIが人間に質問する番です：児童書のための質問-回答ペア生成", "jabstract": "既存の質問応答（QA）技術は主に人間が尋ねた質問に答えるために作成されています。しかし、教育アプリケーションでは、教師はしばしば生徒の物語理解能力を向上させるためにどのような質問をすべきかを決定する必要があります。私たちは、幼稚園から8年生レベルのストーリーブックを入力として受け取り、生徒の理解力の様々な側面をテストできるQAペアを自動生成できる自動化された質問応答生成（QAG）システムを設計しました。私たちの提案するQAGモデルアーキテクチャは、新しい専門家注釈付きFairytaleQAデータセットを使用して示されており、278の子供向けストーリーブックと10,580のQAペアが含まれています。自動評価と人間の評価により、私たちのモデルが最新のQAGベースラインシステムを上回っていることが示されています。私たちのQAGシステムの上に、将来的に教育シナリオでの実際の展開のためにインタラクティブなストーリーテリングアプリケーションを構築し始めています。"}
{"title": "Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning", "url": "https://aclanthology.org/2022.acl-long.55/", "abstract": "Weakly-supervised learning (WSL) has shown promising results in addressing label scarcity on many NLP tasks, but manually designing a comprehensive, high-quality labeling rule set is tedious and difficult. We study interactive weakly-supervised learning—the problem of iteratively and automatically discovering novel labeling rules from data to improve the WSL model. Our proposed model, named PRBoost, achieves this goal via iterative prompt-based rule discovery and model boosting. It uses boosting to identify large-error instances and discovers candidate rules from them by prompting pre-trained LMs with rule templates. The candidate rules are judged by human experts, and the accepted rules are used to generate complementary weak labels and strengthen the current model. Experiments on four tasks show PRBoost outperforms state-of-the-art WSL baselines up to 7.1%, and bridges the gaps with fully supervised models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プロンプトベースのルール発見とブースティングによるインタラクティブな弱教師付き学習", "jabstract": "弱教師あり学習（WSL）は、多くのNLPタスクでラベル不足に対処するために有望な結果を示していますが、包括的で高品質なラベリングルールセットを手動で設計することは手間がかかり困難です。本研究では、データから新しいラベリングルールを自動的に発見してWSLモデルを改善する問題であるインタラクティブな弱教師あり学習を研究しています。提案されたモデルであるPRBoostは、反復的なプロンプトベースのルール発見とモデルブースティングによってこの目標を達成します。ブースティングを使用して大きなエラーインスタンスを特定し、事前にトレーニングされたLMにルールテンプレートをプロンプトすることで、候補ルールを発見します。候補ルールは人間の専門家によって判断され、受け入れられたルールは補完的な弱いラベルを生成し、現在のモデルを強化するために使用されます。4つのタスクでの実験結果は、PRBoostが最新のWSLベースラインを最大7.1％上回り、完全教師ありモデルとのギャップを埋めることを示しています。"}
{"title": "Constrained Multi-Task Learning for Bridging Resolution", "url": "https://aclanthology.org/2022.acl-long.56/", "abstract": "We examine the extent to which supervised bridging resolvers can be improved without employing additional labeled bridging data by proposing a novel constrained multi-task learning framework for bridging resolution, within which we (1) design cross-task consistency constraints to guide the learning process; (2) pre-train the entity coreference model in the multi-task framework on the large amount of publicly available coreference data; and (3) integrating prior knowledge encoded in rule-based resolvers. Our approach achieves state-of-the-art results on three standard evaluation corpora.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "制約付きマルチタスク学習によるブリッジング解決の実現", "jabstract": "私たちは、追加のラベル付きブリッジングデータを使用せずに、監視されたブリッジングリゾルバをどの程度改善できるかを調べ、ブリッジング解決のための新しい制約付きマルチタスク学習フレームワークを提案します。このフレームワークでは、(1) クロスタスクの一貫性制約を設計して学習プロセスをガイドし、(2) 大量の公開された共参照データでマルチタスクフレームワークのエンティティ共参照モデルを事前学習し、(3) ルールベースのリゾルバにエンコードされた事前知識を統合します。私たちのアプローチは、3つの標準評価コーパスで最先端の結果を達成しています。"}
{"title": "DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations", "url": "https://aclanthology.org/2022.acl-long.57/", "abstract": "Automatic evaluation metrics are essential for the rapid development of open-domain dialogue systems as they facilitate hyper-parameter tuning and comparison between models. Although recently proposed trainable conversation-level metrics have shown encouraging results, the quality of the metrics is strongly dependent on the quality of training data. Prior works mainly resort to heuristic text-level manipulations (e.g. utterances shuffling) to bootstrap incoherent conversations (negative examples) from coherent dialogues (positive examples). Such approaches are insufficient to appropriately reflect the incoherence that occurs in interactions between advanced dialogue models and humans. To tackle this problem, we propose DEAM, a Dialogue coherence Evaluation metric that relies on Abstract Meaning Representation (AMR) to apply semantic-level Manipulations for incoherent (negative) data generation. AMRs naturally facilitate the injection of various types of incoherence sources, such as coreference inconsistency, irrelevancy, contradictions, and decrease engagement, at the semantic level, thus resulting in more natural incoherent samples. Our experiments show that DEAM achieves higher correlations with human judgments compared to baseline methods on several dialog datasets by significant margins. We also show that DEAM can distinguish between coherent and incoherent dialogues generated by baseline manipulations, whereas those baseline models cannot detect incoherent examples generated by DEAM. Our results demonstrate the potential of AMR-based semantic manipulations for natural negative example generation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DEAM：AMRベースの意味操作を使用した対話の一貫性評価", "jabstract": "オープンドメインの対話システムの迅速な開発には、ハイパーパラメータの調整やモデル間の比較を容易にする自動評価メトリックが不可欠である。最近提案されたトレーニング可能な会話レベルのメトリックは、有望な結果を示しているが、メトリックの品質はトレーニングデータの品質に強く依存する。従来の研究では、不連続な対話（負の例）を連続した対話（正の例）からブートストラップするために、主にヒューリスティックなテキストレベルの操作（例えば、発話のシャッフル）に頼っていた。このようなアプローチは、高度な対話モデルと人間の間で起こる不連続性を適切に反映するには不十分である。この問題に対処するために、我々はDEAMを提案する。DEAMは、抽象的な意味表現（AMR）に依存して、意味レベルの操作を適用して不連続な（負の）データを生成する対話の一貫性評価メトリックである。AMRは、共参照の不一致、無関係、矛盾、およびエンゲージメントの低下など、さまざまな種類の不連続性源の注入を自然に容易にするため、より自然な不連続なサンプルを生成する。我々の実験は、DEAMがいくつかの対話データセットでベースライン方法に比べて人間の判断との相関が高く、有意な差を示すことを示している。また、DEAMがベースライン操作によって生成された連続的な対話と不連続な対話を区別できることを示し、一方、ベースラインモデルはDEAMによって生成された不連続な例を検出できないことを示している。我々の結果は、AMRベースの意味的操作が自然な負の例の生成において潜在的な可能性を示している。"}
{"title": "HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization", "url": "https://aclanthology.org/2022.acl-long.58/", "abstract": "Document structure is critical for efficient information consumption. However, it is challenging to encode it efficiently into the modern Transformer architecture. In this work, we present HIBRIDS, which injects Hierarchical Biases foR Incorporating Document Structure into attention score calculation. We further present a new task, hierarchical question-summary generation, for summarizing salient content in the source document into a hierarchy of questions and summaries, where each follow-up question inquires about the content of its parent question-summary pair. We also annotate a new dataset with 6,153 question-summary hierarchies labeled on government reports. Experiment results show that our model produces better question-summary hierarchies than comparisons on both hierarchy quality and content coverage, a finding also echoed by human judges. Additionally, our model improves the generation of long-form summaries from long government reports and Wikipedia articles, as measured by ROUGE scores.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "HIBRIDS：階層バイアスを持つアテンションによる構造感知型長文書要約", "jabstract": "文書構造は効率的な情報消費にとって重要である。しかし、現代のTransformerアーキテクチャにそれを効率的にエンコードすることは困難である。本研究では、文書構造を考慮した階層的なバイアスを注入するHIBRIDSを提案する。さらに、階層的な質問-要約生成の新しいタスクを提案し、ソース文書の重要な内容を質問と要約の階層にまとめ、各フォローアップ質問が親の質問-要約ペアの内容について尋ねるようにする。また、政府報告書にラベル付けされた6,153の質問-要約階層を含む新しいデータセットを注釈付きで提供する。実験結果は、比較に対して質問-要約階層の品質と内容のカバレッジの両方で、モデルがより優れた結果を示すことを示し、人間の審査員によっても同様に確認された。さらに、ROUGEスコアによって測定されるように、モデルは長い政府報告書やWikipedia記事からの長い形式の要約の生成を改善する。"}
{"title": "De-Bias for Generative Extraction in Unified NER Task", "url": "https://aclanthology.org/2022.acl-long.59/", "abstract": "Named entity recognition (NER) is a fundamental task to recognize specific types of entities from a given sentence. Depending on how the entities appear in the sentence, it can be divided into three subtasks, namely, Flat NER, Nested NER, and Discontinuous NER. Among the existing approaches, only the generative model can be uniformly adapted to these three subtasks. However, when the generative model is applied to NER, its optimization objective is not consistent with the task, which makes the model vulnerable to the incorrect biases. In this paper, we analyze the incorrect biases in the generation process from a causality perspective and attribute them to two confounders: pre-context confounder and entity-order confounder. Furthermore, we design Intra- and Inter-entity Deconfounding Data Augmentation methods to eliminate the above confounders according to the theory of backdoor adjustment. Experiments show that our method can improve the performance of the generative NER model in various datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「統合型NERタスクにおける生成抽出のための偏見除去」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- De-Bias for Generative Extraction in Unified NER Task\n- 統合型NERタスクにおける生成抽出のための偏見除去", "jabstract": "固有表現認識（NER）は、与えられた文から特定の種類のエンティティを認識するための基本的なタスクである。エンティティが文中にどのように現れるかによって、Flat NER、Nested NER、Discontinuous NERの3つのサブタスクに分けることができる。既存のアプローチの中で、生成モデルだけがこれらの3つのサブタスクに一様に適応できる。しかし、生成モデルをNERに適用すると、最適化目的がタスクと一致しないため、モデルが誤ったバイアスに対して脆弱になる。本論文では、因果関係の観点から生成プロセスの誤ったバイアスを分析し、プレコンテキストの混乱因子とエンティティ順序の混乱因子の2つに帰属する。さらに、バックドア調整理論に基づいて、Intra-およびInter-entity Deconfounding Data Augmentation方法を設計して、上記の混乱因子を排除する。実験結果は、我々の方法が様々なデータセットで生成NERモデルの性能を改善できることを示している。"}
{"title": "An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels", "url": "https://aclanthology.org/2022.acl-long.60/", "abstract": "Pre-trained language models derive substantial linguistic and factual knowledge from the massive corpora on which they are trained, and prompt engineering seeks to align these models to specific tasks. Unfortunately, existing prompt engineering methods require significant amounts of labeled data, access to model parameters, or both. We introduce a new method for selecting prompt templates without labeled examples and without direct access to the model. Specifically, over a set of candidate templates, we choose the template that maximizes the mutual information between the input and the corresponding model output. Across 8 datasets representing 7 distinct NLP tasks, we show that when a template has high mutual information, it also has high accuracy on the task. On the largest model, selecting prompts with our method gets 90% of the way from the average prompt accuracy to the best prompt accuracy and requires no ground truth labels.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「グラウンドトゥルーラベルなしでのプロンプトエンジニアリングに対する情報理論的アプローチ」に関する論文の要約です。", "jabstract": "事前学習された言語モデルは、大規模なコーパスから相当な言語的および事実的知識を得ており、プロンプトエンジニアリングはこれらのモデルを特定のタスクに合わせることを目指しています。残念ながら、既存のプロンプトエンジニアリング手法は、ラベル付きデータの大量の取得、モデルパラメータへのアクセス、またはその両方が必要です。本研究では、ラベル付きの例やモデルへの直接的なアクセスなしに、プロンプトテンプレートを選択する新しい方法を提案します。具体的には、候補テンプレートのセットに対して、入力と対応するモデル出力の相互情報量を最大化するテンプレートを選択します。7つの異なるNLPタスクを表す8つのデータセット全体で、相互情報量が高いテンプレートは、タスクの正確性も高いことを示します。最大のモデルでは、当社の方法でプロンプトを選択すると、平均プロンプトの正確性から最高プロンプトの正確性まで90％進むことができ、グラウンドトゥルーラベルは必要ありません。"}
{"title": "Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation", "url": "https://aclanthology.org/2022.acl-long.61/", "abstract": "The performance of multilingual pretrained models is highly dependent on the availability of monolingual or parallel text present in a target language. Thus, the majority of the world’s languages cannot benefit from recent progress in NLP as they have no or limited textual data. To expand possibilities of using NLP technology in these under-represented languages, we systematically study strategies that relax the reliance on conventional language resources through the use of bilingual lexicons, an alternative resource with much better language coverage. We analyze different strategies to synthesize textual or labeled data using lexicons, and how this data can be combined with monolingual or parallel text when available. For 19 under-represented languages across 3 tasks, our methods lead to consistent improvements of up to 5 and 15 points with and without extra monolingual text respectively. Overall, our study highlights how NLP methods can be adapted to thousands more languages that are under-served by current technology.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "語彙ベースの適応による事前学習済みモデルの数千の言語への拡張", "jabstract": "多言語事前学習モデルの性能は、対象言語に存在する単一言語または並列テキストの利用可能性に大きく依存しています。したがって、世界の大多数の言語は、テキストデータがないか限られているため、NLPの最近の進歩から利益を得ることができません。このような代替リソースとして、カバー範囲がはるかに広いバイリンガル辞書の使用を通じて、従来の言語リソースに依存しない戦略を体系的に研究し、NLP技術をこれらの代表されていない言語で使用する可能性を拡大することを検討しました。私たちは、異なる戦略を分析して、辞書を使用してテキストまたはラベル付きデータを合成する方法、および利用可能な場合に単一言語または並列テキストとこのデータを組み合わせる方法を調べました。3つのタスクにわたる19の代表されていない言語に対して、私たちの方法は、追加の単一言語テキストがある場合とない場合で、それぞれ5ポイントと15ポイントの一貫した改善をもたらしました。全体的に、私たちの研究は、現在の技術によって不十分に対応されている数千の言語にNLP方法を適応する方法を強調しています。"}
{"title": "Language-agnostic BERT Sentence Embedding", "url": "https://aclanthology.org/2022.acl-long.62/", "abstract": "While BERT is an effective method for learning monolingual sentence embeddings for semantic similarity and embedding based transfer learning BERT based cross-lingual sentence embeddings have yet to be explored. We systematically investigate methods for learning multilingual sentence embeddings by combining the best methods for learning monolingual and cross-lingual representations including: masked language modeling (MLM), translation language modeling (TLM), dual encoder translation ranking, and additive margin softmax. We show that introducing a pre-trained multilingual language model dramatically reduces the amount of parallel training data required to achieve good performance by 80%. Composing the best of these methods produces a model that achieves 83.7% bi-text retrieval accuracy over 112 languages on Tatoeba, well above the 65.5% achieved by LASER, while still performing competitively on monolingual transfer learning benchmarks. Parallel data mined from CommonCrawl using our best model is shown to train competitive NMT models for en-zh and en-de. We publicly release our best multilingual sentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n言語に依存しないBERT文埋め込み", "jabstract": "BERTは、意味の類似性と埋め込みベースの転移学習のための単一言語文の埋め込みを学習するための効果的な方法であるが、BERTベースのクロスリンガル文の埋め込みはまだ探求されていない。我々は、マスク言語モデリング（MLM）、翻訳言語モデリング（TLM）、デュアルエンコーダ翻訳ランキング、および加算マージンソフトマックスを組み合わせて、単一言語およびクロスリンガル表現の最良の方法を組み合わせて、多言語文の埋め込みを学習する方法を系統的に調査する。我々は、事前学習された多言語言語モデルを導入することで、良好なパフォーマンスを達成するために必要な並列トレーニングデータの量を80％削減できることを示す。これらの方法の最良の組み合わせを構成することで、Tatoebaで112言語にわたる83.7％のバイテキスト検索精度を達成し、LASERが達成した65.5％を大幅に上回り、単一言語転移学習ベンチマークでも競争力を持っていることを示す。我々の最良のモデルを使用してCommonCrawlから採掘された並列データは、en-zhおよびen-deの競争力のあるNMTモデルをトレーニングすることが示されている。我々は、109以上の言語のための最良の多言語文の埋め込みモデルをhttps://tfhub.dev/google/LaBSEで公開する。"}
{"title": "Nested Named Entity Recognition with Span-level Graphs", "url": "https://aclanthology.org/2022.acl-long.63/", "abstract": "Span-based methods with the neural networks backbone have great potential for the nested named entity recognition (NER) problem. However, they face problems such as degenerating when positive instances and negative instances largely overlap. Besides, the generalization ability matters a lot in nested NER, as a large proportion of entities in the test set hardly appear in the training set. In this work, we try to improve the span representation by utilizing retrieval-based span-level graphs, connecting spans and entities in the training data based on n-gram features. Specifically, we build the entity-entity graph and span-entity graph globally based on n-gram similarity to integrate the information of similar neighbor entities into the span representation. To evaluate our method, we conduct experiments on three common nested NER datasets, ACE2004, ACE2005, and GENIA datasets. Experimental results show that our method achieves general improvements on all three benchmarks (+0.30 ∼ 0.85 micro-F1), and obtains special superiority on low frequency entities (+0.56 ∼ 2.08 recall).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "スパンレベルグラフを用いたネストされた固有表現認識", "jabstract": "ニューラルネットワークのバックボーンを持つスパンベースの手法は、入れ子になった固有表現認識（NER）問題において大きな可能性を持っています。しかし、正例と負例が大きく重なる場合には退化するなどの問題があります。また、一般化能力は入れ子になったNERにおいて非常に重要であり、テストセットの大部分のエンティティがトレーニングセットにほとんど現れないためです。本研究では、n-gram特徴に基づいてトレーニングデータ内のスパンとエンティティを接続する検索ベースのスパンレベルグラフを利用して、スパン表現を改善しようと試みました。具体的には、n-gramの類似性に基づいてエンティティ-エンティティグラフとスパン-エンティティグラフをグローバルに構築し、類似した隣接エンティティの情報をスパン表現に統合します。当社の手法を評価するために、ACE2004、ACE2005、GENIAデータセットの3つの一般的な入れ子になったNERデータセットで実験を行いました。実験結果は、当社の手法がすべての3つのベンチマークで一般的な改善を達成し（+0.30〜0.85マイクロF1）、低頻度エンティティで特別な優位性を獲得することを示しています（+0.56〜2.08リコール）。"}
{"title": "CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in NLP", "url": "https://aclanthology.org/2022.acl-long.64/", "abstract": "Is there a principle to guide transfer learning across tasks in natural language processing (NLP)? Taxonomy (Zamir et al., 2018) finds that a structure exists among visual tasks, as a principle underlying transfer learning for them. In this paper, we propose a cognitively inspired framework, CogTaskonomy, to learn taxonomy for NLP tasks. The framework consists of Cognitive Representation Analytics (CRA) and Cognitive-Neural Mapping (CNM). The former employs Representational Similarity Analysis, which is commonly used in computational neuroscience to find a correlation between brain-activity measurement and computational modeling, to estimate task similarity with task-specific sentence representations. The latter learns to detect task relations by projecting neural representations from NLP models to cognitive signals (i.e., fMRI voxels). Experiments on 12 NLP tasks, where BERT/TinyBERT are used as the underlying models for transfer learning, demonstrate that the proposed CogTaxonomy is able to guide transfer learning, achieving performance competitive to the Analytic Hierarchy Process (Saaty, 1987) used in visual Taskonomy (Zamir et al., 2018) but without requiring exhaustive pairwise O(m2) task transferring. Analyses further discover that CNM is capable of learning model-agnostic task taxonomy.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CogTaskonomy：認知的にインスパイアされたタスク分類は、NLPにおける転移学習に有益である。", "jabstract": "自然言語処理（NLP）におけるタスク間の転移学習を指導する原則は存在するか？タクソノミー（Zamir et al.、2018）は、視覚タスクの間に構造が存在し、それらの転移学習の原則となるものであることを発見しています。本論文では、認知的にインスパイアされたフレームワークであるCogTaskonomyを提案し、NLPタスクのためのタクソノミーを学習します。このフレームワークは、認知表現分析（CRA）と認知神経マッピング（CNM）から構成されています。前者は、計算神経科学で一般的に使用される表現類似性分析を使用して、タスク固有の文表現との類似性を推定することで、タスクの類似性を推定します。後者は、NLPモデルから神経表現を認知信号（つまり、fMRIボクセル）に投影することで、タスク関係を検出することを学習します。BERT / TinyBERTが転移学習の基礎モデルとして使用される12のNLPタスクでの実験では、提案されたCogTaxonomyが転移学習を指導し、視覚タスクノミー（Zamir et al.、2018）で使用される分析階層プロセス（Saaty、1987）と同等の性能を発揮することが示されましたが、O（m2）のタスク転送を網羅的に行う必要はありません。さらに、分析により、CNMがモデルに依存しないタスク分類を学習できることがわかりました。"}
{"title": "RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining", "url": "https://aclanthology.org/2022.acl-long.65/", "abstract": "Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese. In this work, we propose RoCBert: a pretrained Chinese Bert that is robust to various forms of adversarial attacks like word perturbation, synonyms, typos, etc. It is pretrained with the contrastive learning objective which maximizes the label consistency under different synthesized adversarial examples. The model takes as input multimodal information including the semantic, phonetic and visual features. We show all these features areimportant to the model robustness since the attack can be performed in all the three forms. Across 5 Chinese NLU tasks, RoCBert outperforms strong baselines under three blackbox adversarial algorithms without sacrificing the performance on clean testset. It also performs the best in the toxic content detection task under human-made attacks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "RoCBert: マルチモーダル対比学習を用いた堅牢な中国語Bert", "jabstract": "大規模な事前学習言語モデルは、NLPタスクにおいてSOTAの結果を達成しています。しかし、特に中国語のような表意文字言語に対して、敵対的攻撃に脆弱であることが示されています。本研究では、単語の摂動、類義語、タイポなどの様々な形式の敵対的攻撃に対して堅牢な事前学習済みの中国語BertであるRoCBertを提案します。このモデルは、異なる合成された敵対的な例においてラベルの一貫性を最大化する対比学習目的で事前学習されています。モデルは、意味的、音声的、視覚的特徴を含むマルチモーダル情報を入力として受け取ります。攻撃は、これらの3つの形式で実行できるため、これらのすべての特徴がモデルの堅牢性に重要であることを示します。5つの中国語NLUタスクにおいて、RoCBertは、クリーンなテストセットのパフォーマンスを犠牲にすることなく、3つのブラックボックス敵対的アルゴリズムに対して強力なベースラインを上回ります。また、人工的な攻撃に対する有害なコンテンツ検出タスクにおいても最高のパフォーマンスを発揮します。"}
{"title": "Premise-based Multimodal Reasoning: Conditional Inference on Joint Textual and Visual Clues", "url": "https://aclanthology.org/2022.acl-long.66/", "abstract": "It is a common practice for recent works in vision language cross-modal reasoning to adopt a binary or multi-choice classification formulation taking as input a set of source image(s) and textual query. In this work, we take a sober look at such an “unconditional” formulation in the sense that no prior knowledge is specified with respect to the source image(s). Inspired by the designs of both visual commonsense reasoning and natural language inference tasks, we propose a new task termed “Premise-based Multi-modal Reasoning” (PMR) where a textual premise is the background presumption on each source image.The PMR dataset contains 15,360 manually annotated samples which are created by a multi-phase crowd-sourcing process. With selected high-quality movie screenshots and human-curated premise templates from 6 pre-defined categories, we ask crowd-source workers to write one true hypothesis and three distractors (4 choices) given the premise and image through a cross-check procedure.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "前提に基づくマルチモーダル推論：テキストとビジュアルの結合的手がかりに基づく条件付き推論", "jabstract": "最近の視覚言語クロスモーダル推論において、ソース画像とテキストクエリのセットを入力として、バイナリまたはマルチチョイス分類の形式を採用することが一般的です。本研究では、ソース画像に関する事前知識が指定されていない「無条件」の定式化について、冷静に検討します。視覚的な常識推論と自然言語推論タスクの両方の設計に着想を得て、「前提に基づくマルチモーダル推論」（PMR）という新しいタスクを提案します。PMRデータセットには、6つの事前定義されたカテゴリから選択された高品質の映画スクリーンショットと人間による前提テンプレートを使用して、クロウドソーシングプロセスを通じて作成された15,360の手動注釈付きサンプルが含まれています。クロスチェック手順を介して、前提と画像を与えられた場合に、クラウドソースワーカーに真の仮説と3つの誤認識（4つの選択肢）を書いてもらいます。"}
{"title": "Parallel Instance Query Network for Named Entity Recognition", "url": "https://aclanthology.org/2022.acl-long.67/", "abstract": "Named entity recognition (NER) is a fundamental task in natural language processing. Recent works treat named entity recognition as a reading comprehension task, constructing type-specific queries manually to extract entities. This paradigm suffers from three issues. First, type-specific queries can only extract one type of entities per inference, which is inefficient. Second, the extraction for different types of entities is isolated, ignoring the dependencies between them. Third, query construction relies on external knowledge and is difficult to apply to realistic scenarios with hundreds of entity types. To deal with them, we propose Parallel Instance Query Network (PIQN), which sets up global and learnable instance queries to extract entities from a sentence in a parallel manner. Each instance query predicts one entity, and by feeding all instance queries simultaneously, we can query all entities in parallel. Instead of being constructed from external knowledge, instance queries can learn their different query semantics during training. For training the model, we treat label assignment as a one-to-many Linear Assignment Problem (LAP) and dynamically assign gold entities to instance queries with minimal assignment cost. Experiments on both nested and flat NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nNamed Entity Recognitionのための並列インスタンスクエリーネットワーク", "jabstract": "固有表現抽出（NER）は自然言語処理における基本的なタスクである。最近の研究では、固有表現抽出を読解タスクとして扱い、タイプ別のクエリを手動で構築してエンティティを抽出する。このパラダイムには3つの問題がある。第一に、タイプ別のクエリは1回の推論で1種類のエンティティしか抽出できず、効率が悪い。第二に、異なる種類のエンティティの抽出は分離されており、それらの間の依存関係を無視している。第三に、クエリの構築は外部の知識に依存しており、数百種類のエンティティが存在する現実的なシナリオに適用することが困難である。これらに対処するために、我々はParallel Instance Query Network（PIQN）を提案し、並列にグローバルかつ学習可能なインスタンスクエリを設定して、文からエンティティを抽出する。各インスタンスクエリは1つのエンティティを予測し、すべてのインスタンスクエリを同時にフィードすることで、すべてのエンティティを並列にクエリできる。インスタンスクエリは外部の知識から構築されるのではなく、トレーニング中に異なるクエリの意味を学習することができる。モデルのトレーニングには、ラベル割り当てを1対多の線形割り当て問題（LAP）として扱い、最小割り当てコストでゴールドエンティティをインスタンスクエリに動的に割り当てる。ネスト型およびフラット型のNERデータセットの実験により、提案手法が従来の最先端モデルを上回ることが示された。"}
{"title": "ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation", "url": "https://aclanthology.org/2022.acl-long.68/", "abstract": "Typical generative dialogue models utilize the dialogue history to generate the response. However, since one dialogue utterance can often be appropriately answered by multiple distinct responses, generating a desired response solely based on the historical information is not easy. Intuitively, if the chatbot can foresee in advance what the user would talk about (i.e., the dialogue future) after receiving its response, it could possibly provide a more informative response. Accordingly, we propose a novel dialogue generation framework named ProphetChat that utilizes the simulated dialogue futures in the inference phase to enhance response generation. To enable the chatbot to foresee the dialogue future, we design a beam-search-like roll-out strategy for dialogue future simulation using a typical dialogue generation model and a dialogue selector. With the simulated futures, we then utilize the ensemble of a history-to-response generator and a future-to-response generator to jointly generate a more informative response. Experiments on two popular open-domain dialogue datasets demonstrate that ProphetChat can generate better responses over strong baselines, which validates the advantages of incorporating the simulated dialogue futures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ProphetChat：将来の会話のシミュレーションによる対話生成の強化\n\nAbstract: We present ProphetChat, a dialogue generation model that simulates future conversation turns to enhance the coherence and consistency of generated dialogue. Our model uses a sequence-to-sequence architecture with an attention mechanism to generate responses. In addition, we introduce a simulation module that predicts future conversation turns and uses them to guide the generation of responses. We evaluate our model on two datasets and show that it outperforms several state-of-the-art dialogue generation models in terms of coherence and consistency.", "jabstract": "典型的な生成型対話モデルは、応答を生成するために対話履歴を利用します。しかし、1つの対話発言に対して複数の異なる応答が適切であることがしばしばあるため、歴史的情報だけに基づいて望ましい応答を生成することは容易ではありません。直感的には、チャットボットがユーザーがその応答を受け取った後に何について話すか（つまり、対話の未来）を事前に予測できれば、より情報量の多い応答を提供できる可能性があります。そのため、私たちは、ProphetChatという新しい対話生成フレームワークを提案し、推論フェーズでシミュレートされた対話の未来を利用して応答生成を強化します。対話の未来を予測するために、典型的な対話生成モデルと対話セレクタを使用したビームサーチのようなロールアウト戦略を設計します。シミュレートされた未来を利用して、過去から応答を生成するモデルと未来から応答を生成するモデルのアンサンブルを使用して、より情報量の多い応答を共同生成します。2つの人気のあるオープンドメインの対話データセットでの実験は、ProphetChatが強力なベースラインよりも優れた応答を生成できることを示し、シミュレートされた対話の未来を組み込むことの利点を検証します。"}
{"title": "Modeling Multi-hop Question Answering as Single Sequence Prediction", "url": "https://aclanthology.org/2022.acl-long.69/", "abstract": "Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question answering (QA) model that leverages passage retrieval with a pre-trained transformer and pushed the state of the art on single-hop QA. However, the complexity of multi-hop QA hinders the effectiveness of the generative QA approach. In this work, we propose a simple generative approach (PathFid) that extends the task beyond just answer generation by explicitly modeling the reasoning process to resolve the answer for multi-hop questions. By linearizing the hierarchical reasoning path of supporting passages, their key sentences, and finally the factoid answer, we cast the problem as a single sequence prediction task. To facilitate complex reasoning with multiple clues, we further extend the unified flat representation of multiple input documents by encoding cross-passage interactions. Our extensive experiments demonstrate that PathFid leads to strong performance gains on two multi-hop QA datasets: HotpotQA and IIRC. Besides the performance gains, PathFid is more interpretable, which in turn yields answers that are more faithfully grounded to the supporting passages and facts compared to the baseline Fid model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多段階の質問応答を単一のシーケンス予測としてモデリングする", "jabstract": "Fusion-in-decoder（Fid）（Izacard and Grave、2020）は、事前にトレーニングされたトランスフォーマーを使用してパッセージ検索を活用する生成型質問応答（QA）モデルであり、シングルホップQAの最先端を推進しています。ただし、マルチホップQAの複雑さは、生成型QAアプローチの効果を妨げます。本研究では、多段階の質問に対する回答を解決するための推論プロセスを明示的にモデル化することにより、単なる回答生成を超えた単純な生成型アプローチ（PathFid）を提案します。サポートパッセージ、そのキー文、そして事実に基づく回答の階層的な推論パスを線形化することにより、問題を単一のシーケンス予測タスクとしてキャストします。複数の手がかりを持つ複雑な推論を容易にするために、クロスパッセージ相互作用をエンコードすることにより、複数の入力ドキュメントの統一されたフラット表現をさらに拡張します。私たちの広範な実験は、PathFidが2つのマルチホップQAデータセット、HotpotQAとIIRCで強力なパフォーマンス向上をもたらすことを示しています。パフォーマンスの向上に加えて、PathFidはより解釈可能であり、その結果、ベースラインのFidモデルと比較して、サポートパッセージと事実に忠実に基づく回答を提供します。"}
{"title": "Learning Disentangled Semantic Representations for Zero-Shot Cross-Lingual Transfer in Multilingual Machine Reading Comprehension", "url": "https://aclanthology.org/2022.acl-long.70/", "abstract": "Multilingual pre-trained models are able to zero-shot transfer knowledge from rich-resource to low-resource languages in machine reading comprehension (MRC). However, inherent linguistic discrepancies in different languages could make answer spans predicted by zero-shot transfer violate syntactic constraints of the target language. In this paper, we propose a novel multilingual MRC framework equipped with a Siamese Semantic Disentanglement Model (S2DM) to disassociate semantics from syntax in representations learned by multilingual pre-trained models. To explicitly transfer only semantic knowledge to the target language, we propose two groups of losses tailored for semantic and syntactic encoding and disentanglement. Experimental results on three multilingual MRC datasets (i.e., XQuAD, MLQA, and TyDi QA) demonstrate the effectiveness of our proposed approach over models based on mBERT and XLM-100.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語機械読解におけるゼロショットクロスリンガル転送のための分離された意味表現の学習", "jabstract": "多言語事前学習モデルは、機械読解（MRC）において豊富なリソース言語から低リソース言語へのゼロショット転移知識を可能にする。しかし、異なる言語の固有の言語的な不一致は、ゼロショット転移によって予測された回答スパンがターゲット言語の構文制約に違反する可能性がある。本論文では、多言語事前学習モデルによって学習された表現において意味と構文を分離するSiamese Semantic Disentanglement Model（S2DM）を備えた新しい多言語MRCフレームワークを提案する。ターゲット言語に対して意味的な知識のみを明示的に転移するために、意味的エンコーディングと構文的エンコーディングと分離のために2つのグループの損失を提案する。XQuAD、MLQA、TyDi QAの3つの多言語MRCデータセットでの実験結果は、mBERTとXLM-100に基づくモデルよりも、提案手法の有効性を示している。"}
{"title": "Multi-Granularity Structural Knowledge Distillation for Language Model Compression", "url": "https://aclanthology.org/2022.acl-long.71/", "abstract": "Transferring the knowledge to a small model through distillation has raised great interest in recent years. Prevailing methods transfer the knowledge derived from mono-granularity language units (e.g., token-level or sample-level), which is not enough to represent the rich semantics of a text and may lose some vital knowledge. Besides, these methods form the knowledge as individual representations or their simple dependencies, neglecting abundant structural relations among intermediate representations. To overcome the problems, we present a novel knowledge distillation framework that gathers intermediate representations from multiple semantic granularities (e.g., tokens, spans and samples) and forms the knowledge as more sophisticated structural relations specified as the pair-wise interactions and the triplet-wise geometric angles based on multi-granularity representations. Moreover, we propose distilling the well-organized multi-granularity structural knowledge to the student hierarchically across layers. Experimental results on GLUE benchmark demonstrate that our method outperforms advanced distillation methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n言語モデルの圧縮のためのマルチグラニュラリティ構造知識蒸留", "jabstract": "近年、転移学習による蒸留による小規模モデルへの知識の転移が注目されています。従来の方法は、単一の言語単位（例えば、トークンレベルやサンプルレベル）から得られた知識を転移していますが、これではテキストの豊かな意味を表現するには不十分であり、重要な知識が失われる可能性があります。また、これらの方法は、中間表現の豊富な構造的関係を無視し、個々の表現またはその単純な依存関係として知識を形成しています。これらの問題を克服するために、我々は、複数の意味的粒度（トークン、スパン、サンプルなど）から中間表現を収集し、多粒度表現に基づくペアワイズ相互作用と三つ組の幾何学的角度によってより洗練された構造的関係として知識を形成する新しい知識蒸留フレームワークを提案します。さらに、よく整理された多粒度構造的知識を階層的に生徒に蒸留することを提案します。GLUEベンチマークの実験結果は、我々の方法が先進的な蒸留方法を上回ることを示しています。"}
{"title": "Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts", "url": "https://aclanthology.org/2022.acl-long.72/", "abstract": "Human-like biases and undesired social stereotypes exist in large pretrained language models. Given the wide adoption of these models in real-world applications, mitigating such biases has become an emerging and important task. In this paper, we propose an automatic method to mitigate the biases in pretrained language models. Different from previous debiasing work that uses external corpora to fine-tune the pretrained models, we instead directly probe the biases encoded in pretrained models through prompts. Specifically, we propose a variant of the beam search method to automatically search for biased prompts such that the cloze-style completions are the most different with respect to different demographic groups. Given the identified biased prompts, we then propose a distribution alignment loss to mitigate the biases. Experiment results on standard datasets and metrics show that our proposed Auto-Debias approach can significantly reduce biases, including gender and racial bias, in pretrained language models such as BERT, RoBERTa and ALBERT. Moreover, the improvement in fairness does not decrease the language models’ understanding abilities, as shown using the GLUE benchmark.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Auto-Debias：自動バイアスプロンプトによるマスクされた言語モデルのバイアス除去」は、自然言語処理に関する論文の要約です。", "jabstract": "大規模な事前学習言語モデルには、人間のような偏見や望ましくない社会的ステレオタイプが存在します。これらのモデルが現実世界のアプリケーションで広く採用されていることから、このような偏見を軽減することは、新興かつ重要な課題となっています。本論文では、事前学習言語モデルの偏見を軽減する自動的な方法を提案します。従来の偏見軽減作業が外部コーパスを使用して事前学習モデルを微調整するのに対し、私たちは代わりにプロンプトを介して事前学習モデルにエンコードされた偏見を直接探索する方法を提案します。具体的には、ビームサーチ法の変種を提案し、クローズスタイルの補完が異なる人口グループに対して最も異なるようなバイアスのあるプロンプトを自動的に検索します。特定されたバイアスのあるプロンプトを用いて、分布整合損失を提案し、バイアスを軽減します。標準的なデータセットとメトリックにおける実験結果は、私たちの提案するAuto-Debiasアプローチが、BERT、RoBERTa、ALBERTなどの事前学習言語モデルにおいて、性別や人種の偏見を含む偏見を大幅に軽減できることを示しています。さらに、公平性の向上は、GLUEベンチマークを使用して示されるように、言語モデルの理解能力を低下させることはありません。"}
{"title": "Where to Go for the Holidays: Towards Mixed-Type Dialogs for Clarification of User Goals", "url": "https://aclanthology.org/2022.acl-long.73/", "abstract": "Most dialog systems posit that users have figured out clear and specific goals before starting an interaction. For example, users have determined the departure, the destination, and the travel time for booking a flight. However, in many scenarios, limited by experience and knowledge, users may know what they need, but still struggle to figure out clear and specific goals by determining all the necessary slots. In this paper, we identify this challenge, and make a step forward by collecting a new human-to-human mixed-type dialog corpus. It contains 5k dialog sessions and 168k utterances for 4 dialog types and 5 domains. Within each session, an agent first provides user-goal-related knowledge to help figure out clear and specific goals, and then help achieve them. Furthermore, we propose a mixed-type dialog model with a novel Prompt-based continual learning mechanism. Specifically, the mechanism enables the model to continually strengthen its ability on any specific type by utilizing existing dialog corpora effectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "休暇にどこに行くか：ユーザーの目的を明確にするための混合型対話に向けて", "jabstract": "多くの対話システムは、ユーザーが明確で具体的な目標を設定してから対話を開始すると仮定しています。例えば、ユーザーはフライトを予約するために出発地、目的地、旅行時間を決定しています。しかし、経験や知識に限界がある場合、ユーザーは必要なスロットをすべて決定して明確で具体的な目標を見つけるのに苦労することがあります。本論文では、この課題を特定し、新しい人間-人間混合型対話コーパスを収集することで一歩前進します。このコーパスには、4つの対話タイプと5つのドメインのために5,000の対話セッションと168,000の発話が含まれています。各セッションでは、エージェントが最初にユーザーの目標に関連する知識を提供して明確で具体的な目標を見つけ、それを達成するために支援します。さらに、私たちは新しいプロンプトベースの継続的学習メカニズムを持つ混合型対話モデルを提案します。具体的には、このメカニズムにより、既存の対話コーパスを効果的に活用して、モデルが任意の特定タイプの能力を継続的に強化できるようになります。"}
{"title": "Semi-supervised Domain Adaptation for Dependency Parsing with Dynamic Matching Network", "url": "https://aclanthology.org/2022.acl-long.74/", "abstract": "Supervised parsing models have achieved impressive results on in-domain texts. However, their performances drop drastically on out-of-domain texts due to the data distribution shift. The shared-private model has shown its promising advantages for alleviating this problem via feature separation, whereas prior works pay more attention to enhance shared features but neglect the in-depth relevance of specific ones. To address this issue, we for the first time apply a dynamic matching network on the shared-private model for semi-supervised cross-domain dependency parsing. Meanwhile, considering the scarcity of target-domain labeled data, we leverage unlabeled data from two aspects, i.e., designing a new training strategy to improve the capability of the dynamic matching network and fine-tuning BERT to obtain domain-related contextualized representations. Experiments on benchmark datasets show that our proposed model consistently outperforms various baselines, leading to new state-of-the-art results on all domains. Detailed analysis on different matching strategies demonstrates that it is essential to learn suitable matching weights to emphasize useful features and ignore useless or even harmful ones. Besides, our proposed model can be directly extended to multi-source domain adaptation and achieves best performances among various baselines, further verifying the effectiveness and robustness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「動的マッチングネットワークを用いた依存構造解析のための半教師ありドメイン適応」に関する論文の要約文です。", "jabstract": "教師あり構文解析モデルは、ドメイン内テキストで印象的な結果を出しています。しかし、データ分布のシフトにより、ドメイン外テキストでは性能が劇的に低下します。共有-プライベートモデルは、特徴分離によるこの問題の緩和において有望な利点を示していますが、従来の研究では共有特徴の強化に注目し、特定の特徴の深い関連性を無視しています。この問題に対処するために、私たちは共有-プライベートモデルに動的マッチングネットワークを初めて適用し、半教師ありクロスドメイン依存構文解析を行います。同時に、ターゲットドメインのラベル付きデータの不足を考慮し、2つの側面からラベルなしデータを活用します。すなわち、動的マッチングネットワークの能力を向上させるための新しいトレーニング戦略の設計と、ドメインに関連するコンテキスト化された表現を得るためにBERTを微調整します。ベンチマークデータセット上の実験結果は、私たちの提案モデルがさまざまなベースラインを常に上回り、すべてのドメインで新しい最高の結果をもたらすことを示しています。異なるマッチング戦略に関する詳細な分析は、有用な特徴を強調し、無用または有害な特徴を無視するために適切なマッチング重みを学習することが重要であることを示しています。また、私たちの提案モデルは、直接的に多元源ドメイン適応に拡張することができ、さまざまなベースラインの中で最高の性能を発揮し、効果的かつ堅牢であることがさらに検証されています。"}
{"title": "A Closer Look at How Fine-tuning Changes BERT", "url": "https://aclanthology.org/2022.acl-long.75/", "abstract": "Given the prevalence of pre-trained contextualized representations in today’s NLP, there have been many efforts to understand what information they contain, and why they seem to be universally successful. The most common approach to use these representations involves fine-tuning them for an end task. Yet, how fine-tuning changes the underlying embedding space is less studied. In this work, we study the English BERT family and use two probing techniques to analyze how fine-tuning changes the space. We hypothesize that fine-tuning affects classification performance by increasing the distances between examples associated with different labels. We confirm this hypothesis with carefully designed experiments on five different NLP tasks. Via these experiments, we also discover an exception to the prevailing wisdom that “fine-tuning always improves performance”. Finally, by comparing the representations before and after fine-tuning, we discover that fine-tuning does not introduce arbitrary changes to representations; instead, it adjusts the representations to downstream tasks while largely preserving the original spatial structure of the data points.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BERTのファインチューニングがどのように変化するかを詳しく調べる", "jabstract": "現在の自然言語処理において、事前学習された文脈依存表現が広く使用されているため、それらがどのような情報を含んでいるか、そしてなぜ普遍的に成功しているのかを理解するための多くの取り組みが行われています。これらの表現を使用する最も一般的なアプローチは、エンドタスクのために微調整することです。しかし、微調整が埋め込み空間をどのように変化させるかは、あまり研究されていません。本研究では、英語BERTファミリーを研究し、2つのプロービング技術を使用して微調整が空間をどのように変化させるかを分析します。私たちは、微調整が異なるラベルに関連する例の間の距離を増加させることによって分類パフォーマンスに影響を与えると仮説を立てます。私たちは、5つの異なるNLPタスクで慎重に設計された実験によってこの仮説を確認します。これらの実験を通じて、私たちは「微調整は常にパフォーマンスを向上させる」という支配的な知恵に例外があることも発見しました。最後に、微調整前後の表現を比較することにより、微調整が表現に任意の変更を導入するのではなく、データポイントの元の空間構造を大部分保持しながら、下流タスクに合わせて表現を調整することを発見しました。"}
{"title": "Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval", "url": "https://aclanthology.org/2022.acl-long.76/", "abstract": "Training dense passage representations via contrastive learning has been shown effective for Open-Domain Passage Retrieval (ODPR). Existing studies focus on further optimizing by improving negative sampling strategy or extra pretraining. However, these studies keep unknown in capturing passage with internal representation conflicts from improper modeling granularity. Specifically, under our observation that a passage can be organized by multiple semantically different sentences, modeling such a passage as a unified dense vector is not optimal. This work thus presents a refined model on the basis of a smaller granularity, contextual sentences, to alleviate the concerned conflicts. In detail, we introduce an in-passage negative sampling strategy to encourage a diverse generation of sentence representations within the same passage. Experiments on three benchmark datasets verify the efficacy of our method, especially on datasets where conflicts are severe. Extensive experiments further present good transferability of our method across datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オープンドメインのパッセージ検索のための文意識の対照的学習", "jabstract": "密集なパッセージ表現を対比学習によってトレーニングすることは、オープンドメインパッセージ検索（ODPR）において効果的であることが示されています。既存の研究は、負のサンプリング戦略の改善や追加の事前トレーニングによるさらなる最適化に焦点を当てています。しかし、これらの研究は、不適切なモデリング粒度から内部表現の競合を捕捉することが未知のままです。具体的には、1つのパッセージが複数の意味的に異なる文で構成されることがあるため、このようなパッセージを統一された密集ベクトルとしてモデリングすることは最適ではありません。そこで、本研究では、より小さな粒度である文脈的な文に基づいた洗練されたモデルを提案し、懸念される競合を緩和します。具体的には、同じパッセージ内で文の表現を多様に生成するためのパッセージ内負のサンプリング戦略を導入します。3つのベンチマークデータセットでの実験により、特に競合が激しいデータセットでは、本手法の有効性が確認されました。さらに、広範な実験により、本手法のデータセット間での良好な転移性が示されました。"}
{"title": "FaiRR: Faithful and Robust Deductive Reasoning over Natural Language", "url": "https://aclanthology.org/2022.acl-long.77/", "abstract": "Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language. Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model’s logical reasoning process. Currently, these black-box models generate both the proof graph and intermediate inferences within the same model and thus may be unfaithful. In this work, we frame the deductive logical reasoning task by defining three modular components: rule selection, fact selection, and knowledge composition. The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences. This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning. To test our framework, we propose FaiRR (Faithful and Robust Reasoner) where the above three components are independently modeled by transformers. We observe that FaiRR is robust to novel language perturbations, and is faster at inference than previous works on existing reasoning datasets. Additionally, in contrast to black-box generative models, the errors made by FaiRR are more interpretable due to the modular approach.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FaiRR：自然言語に対する忠実で堅牢な演繹推論", "jabstract": "トランスフォーマーは、自然言語で書かれたルールと文を含む論理ルールベースで演繹的推論を行うことができることが示されています。最近の研究では、このようなモデルが推論ステップ（つまり、証明グラフ）を生成できることも示されています。現在、これらのブラックボックスモデルは、証明グラフと中間推論を同じモデルで生成するため、忠実ではない可能性があります。本研究では、ルール選択、事実選択、知識構成の3つのモジュール構成によって、演繹的論理推論タスクをフレーム化します。ルールと事実の選択ステップは、使用する候補ルールと事実を選択し、知識構成はそれらを組み合わせて新しい推論を生成します。これにより、証明ステップから推論推論までの確実な因果関係によってモデルの忠実性が保証されます。フレームワークをテストするために、上記の3つのコンポーネントをトランスフォーマーで独立してモデル化したFaiRR（Faithful and Robust Reasoner）を提案します。FaiRRは、新しい言語の摂動に対して堅牢であり、既存の推論データセットにおいて以前の研究よりも推論が速いことが観察されました。また、ブラックボックス生成モデルとは異なり、モジュールアプローチにより、FaiRRが犯したエラーはより解釈可能です。"}
{"title": "HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation", "url": "https://aclanthology.org/2022.acl-long.78/", "abstract": "Tables are often created with hierarchies, but existing works on table reasoning mainly focus on flat tables and neglect hierarchical tables. Hierarchical tables challenge numerical reasoning by complex hierarchical indexing, as well as implicit relationships of calculation and semantics. We present a new dataset, HiTab, to study question answering (QA) and natural language generation (NLG) over hierarchical tables. HiTab is a cross-domain dataset constructed from a wealth of statistical reports and Wikipedia pages, and has unique characteristics: (1) nearly all tables are hierarchical, and (2) QA pairs are not proposed by annotators from scratch, but are revised from real and meaningful sentences authored by analysts. (3) to reveal complex numerical reasoning in statistical reports, we provide fine-grained annotations of quantity and entity alignment. Experiments suggest that this HiTab presents a strong challenge for existing baselines and a valuable benchmark for future research. Targeting hierarchical structure, we devise a hierarchy-aware logical form for symbolic reasoning over tables, which shows high effectiveness. Targeting table reasoning, we leverage entity and quantity alignment to explore partially supervised training in QA and conditional generation in NLG, and largely reduce spurious predictions in QA and produce better descriptions in NLG.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "HiTab：質問応答と自然言語生成のための階層的テーブルデータセット", "jabstract": "表はしばしば階層的に作成されますが、表推論に関する既存の研究は主にフラットな表に焦点を当て、階層的な表を無視しています。階層的な表は、複雑な階層的なインデックス付け、計算と意味の暗黙的な関係によって、数値推論に挑戦します。本論文では、階層的な表に対する質問応答（QA）と自然言語生成（NLG）の研究のための新しいデータセットであるHiTabを提案します。HiTabは、豊富な統計レポートとWikipediaページから構築されたクロスドメインのデータセットであり、次のような特徴があります：（1）ほとんどの表が階層的であり、（2）QAペアはアノテーターによってゼロから提案されたものではなく、アナリストによって作成された実際で意味のある文章から修正されたものです。 （3）統計レポートでの複雑な数値推論を明らかにするために、数量とエンティティの整列の細かい注釈を提供します。実験の結果、このHiTabは既存のベースラインに強い挑戦を与え、将来の研究の貴重なベンチマークとなることが示唆されます。階層的な構造を対象に、表に対する記号的推論のための階層的な論理形式を考案し、高い効果を示しました。表推論を対象に、エンティティと数量の整列を活用して、QAの部分的に監視されたトレーニングとNLGの条件付き生成を探索し、QAでの誤った予測を大幅に減らし、NLGでより良い説明を生成しました。"}
{"title": "Doctor Recommendation in Online Health Forums via Expertise Learning", "url": "https://aclanthology.org/2022.acl-long.79/", "abstract": "Huge volumes of patient queries are daily generated on online health forums, rendering manual doctor allocation a labor-intensive task. To better help patients, this paper studies a novel task of doctor recommendation to enable automatic pairing of a patient to a doctor with relevant expertise. While most prior work in recommendation focuses on modeling target users from their past behavior, we can only rely on the limited words in a query to infer a patient’s needs for privacy reasons. For doctor modeling, we study the joint effects of their profiles and previous dialogues with other patients and explore their interactions via self-learning. The learned doctor embeddings are further employed to estimate their capabilities of handling a patient query with a multi-head attention mechanism. For experiments, a large-scale dataset is collected from Chunyu Yisheng, a Chinese online health forum, where our model exhibits the state-of-the-art results, outperforming baselines only consider profiles and past dialogues to characterize a doctor.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "専門知識学習を通じたオンライン健康フォーラムにおける医師の推薦", "jabstract": "オンラインの健康フォーラムでは、毎日膨大な量の患者の質問が生成され、手動で医師を割り当てることは労力がかかる。本論文では、患者を適切な専門家の医師に自動的にペアリングするための医師推薦の新しいタスクを研究し、患者をよりよく支援することを目的とする。従来の推薦においては、対象ユーザーの過去の行動からモデリングすることが多いが、プライバシー上の理由から、クエリの限られた単語だけを頼りに患者のニーズを推測する必要がある。医師のモデリングにおいては、プロフィールと他の患者との以前の対話の共同効果を研究し、自己学習を通じてその相互作用を探求する。学習された医師の埋め込みは、マルチヘッドアテンションメカニズムを用いて、患者のクエリを処理する能力を推定するためにさらに利用される。実験では、中国のオンライン健康フォーラムである春雨医生から大規模なデータセットを収集し、当社のモデルは、医師のプロフィールと過去の対話だけを特徴付けるベースラインを上回る最先端の結果を示した。"}
{"title": "Continual Prompt Tuning for Dialog State Tracking", "url": "https://aclanthology.org/2022.acl-long.80/", "abstract": "A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle. However, continually training a model often leads to a well-known catastrophic forgetting issue. In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks. To avoid forgetting, we only learn and store a few prompt tokens’ embeddings for each task while freezing the backbone pre-trained model. To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「対話状態追跡のための継続的なプロンプト調整」", "jabstract": "望ましい対話システムは、古いスキルを忘れずに新しいスキルを継続的に学習し、そのライフサイクルの中で新しいドメインやタスクに適応できる必要があります。しかし、モデルを継続的にトレーニングすることは、しばしばよく知られたカタストロフィックな忘却問題につながります。本論文では、忘却を回避するだけでなく、タスク間の知識転移も可能にするパラメータ効率の高いフレームワークである「Continual Prompt Tuning」を提案します。忘却を回避するために、事前にトレーニングされたバックボーンモデルを凍結しながら、各タスクごとにわずかなプロンプトトークンの埋め込みを学習して保存します。タスク間の双方向の知識転移を実現するために、前のタスクからの知識転移（継続的なプロンプト初期化、クエリフュージョン、メモリリプレイ）と、後続のタスクからの知識転移のためのメモリガイド技術を提案します。広範な実験により、当社の提案手法が、対話状態追跡の継続的学習において、最先端のベースラインと比較して効果的かつ効率的であることが示されました。"}
{"title": "There’s a Time and Place for Reasoning Beyond the Image", "url": "https://aclanthology.org/2022.acl-long.81/", "abstract": "Images are often more significant than only the pixels to human eyes, as we can infer, associate, and reason with contextual information from other sources to establish a more complete picture. For example, in Figure 1, we can find a way to identify the news articles related to the picture through segment-wise understandings of the signs, the buildings, the crowds, and more. This reasoning could provide the time and place the image was taken, which will help us in subsequent tasks, such as automatic storyline construction, correction of image source in intended effect photographs, and upper-stream processing such as image clustering for certain location or time.In this work, we formulate this problem and introduce TARA: a dataset with 16k images with their associated news, time, and location, automatically extracted from New York Times, and an additional 61k examples as distant supervision from WIT. On top of the extractions, we present a crowdsourced subset in which we believe it is possible to find the images’ spatio-temporal information for evaluation purpose. We show that there exists a 70% gap between a state-of-the-art joint model and human performance, which is slightly filled by our proposed model that uses segment-wise reasoning, motivating higher-level vision-language joint models that can conduct open-ended reasoning with world knowledge.The data and code are publicly available at https://github.com/zeyofu/TARA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n画像を超えた推論のための時間と場所があります。", "jabstract": "人間の目にとって、画像は単なるピクセル以上の意味を持つことが多く、他の情報源からの文脈情報を推論、関連付け、推理することで、より完全な画像を構築することができます。例えば、図1では、看板、建物、人々などのセグメントごとの理解を通じて、画像に関連するニュース記事を特定する方法を見つけることができます。この推論により、画像が撮影された時間と場所を提供することができ、自動ストーリー構築、意図した効果写真の画像ソースの修正、特定の場所や時間の画像クラスタリングなどの後続タスクに役立ちます。本研究では、この問題を定式化し、16,000枚の画像とそれらに関連するニュース、時間、場所を自動的に抽出したニューヨーク・タイムズからのデータセットであるTARAを紹介し、WITからの61,000の追加例を遠隔監視として提供します。抽出に加えて、評価目的のために画像の時空間情報を見つけることが可能だと考えられるクラウドソーシングされたサブセットを提示します。我々は、最先端のジョイントモデルと人間のパフォーマンスの間に70％のギャップが存在することを示し、セグメントごとの推論を使用する提案モデルによってわずかに埋められることを示し、世界知識を用いたオープンエンドの推論を行うことができる高次のビジョン・ランゲージ・ジョイントモデルを促進することを目的としています。データとコードはhttps://github.com/zeyofu/TARAで公開されています。"}
{"title": "FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining", "url": "https://aclanthology.org/2022.acl-long.82/", "abstract": "Tables store rich numerical data, but numerical reasoning over tables is still a challenge. In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is a valuable supervision for numerical reasoning in tables. Considering large amounts of spreadsheets available on the web, we propose FORTAP, the first exploration to leverage spreadsheet formulas for table pretraining. Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP). While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, FORTAP is built upon TUTA, the first transformer-based method for spreadsheet table pretraining with tree attention. FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FORTAP：数値推論に対応したテーブルの事前学習において式を使用する", "jabstract": "表は豊富な数値データを保持していますが、表上の数値推論はまだ課題です。本論文では、スプレッドシートの数値計算を行うために一般的に使用されるスプレッドシート式が、表上の数値推論にとって有用な監督学習であることを発見しました。Web上に大量に存在するスプレッドシートを考慮し、スプレッドシート式を表の事前学習に活用する最初の探索であるFORTAPを提案します。数式から派生した2つの新しい自己教師事前学習目的、数値参照予測（NRP）と数値計算予測（NCP）があります。提案された目的はエンコーダーにとって一般的ですが、スプレッドシートの表のレイアウトと構造をよりよく捉えるために、FORTAPはツリーアテンションを使用した最初のトランスフォーマーベースのスプレッドシート表事前学習方法であるTUTAに基づいて構築されています。FORTAPは、数式予測、質問応答、セルタイプ分類の3つの代表的なデータセットで、最先端の方法を大幅に上回り、スプレッドシート式を表の事前学習に活用する可能性を示しています。"}
{"title": "Multimodal fusion via cortical network inspired losses", "url": "https://aclanthology.org/2022.acl-long.83/", "abstract": "Information integration from different modalities is an active area of research. Human beings and, in general, biological neural systems are quite adept at using a multitude of signals from different sensory perceptive fields to interact with the environment and each other. Recent work in deep fusion models via neural networks has led to substantial improvements over unimodal approaches in areas like speech recognition, emotion recognition and analysis, captioning and image description. However, such research has mostly focused on architectural changes allowing for fusion of different modalities while keeping the model complexity manageable.Inspired by neuroscientific ideas about multisensory integration and processing, we investigate the effect of introducing neural dependencies in the loss functions. Experiments on multimodal sentiment analysis tasks with different models show that our approach provides a consistent performance boost.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「コルティカルネットワークに着想を得た損失を介したマルチモーダル融合」に関する論文の要約文です。以下、日本語に翻訳します。\n\n- Multimodal fusion: 複数のモーダル（入力）を統合すること\n- via cortical network inspired losses: コルティカルネットワークに着想を得た損失を介して\n- この論文では、自然言語処理におけるマルチモーダル融合の手法について述べられています。コルティカルネットワークに着想を得た損失を用いることで、より高度な融合が可能になることが示されています。", "jabstract": "異なるモダリティからの情報統合は、研究の活発な分野である。人間や一般的に生物の神経系は、異なる感覚知覚領域からの多数の信号を使って、環境やお互いと相互作用することに非常に熟練している。ニューラルネットワークを介した深い融合モデルの最近の研究により、音声認識、感情認識と分析、キャプション付け、画像の説明などの分野で、単一モダルアプローチよりも大幅な改善が見られた。しかし、そのような研究は、モデルの複雑さを管理しながら、異なるモダリティの融合を可能にするアーキテクチャの変更に主に焦点を当てている。神経科学的な多感覚統合と処理に関するアイデアに着想を得て、我々は損失関数にニューラル依存性を導入する効果を調査した。異なるモデルを用いた多モーダル感情分析タスクの実験により、我々のアプローチが一貫した性能向上を提供することが示された。"}
{"title": "Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine Comprehension", "url": "https://aclanthology.org/2022.acl-long.84/", "abstract": "Procedural Multimodal Documents (PMDs) organize textual instructions and corresponding images step by step. Comprehending PMDs and inducing their representations for the downstream reasoning tasks is designated as Procedural MultiModal Machine Comprehension (M3C). In this study, we approach Procedural M3C at a fine-grained level (compared with existing explorations at a document or sentence level), that is, entity. With delicate consideration, we model entity both in its temporal and cross-modal relation and propose a novel Temporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated to capture textual and visual entities and trace their temporal-modal evolution. In addition, a graph aggregation module is introduced to conduct graph encoding and reasoning. Comprehensive experiments across three Procedural M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset CraftQA, which can better evaluate the generalization of TMEG.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "手順的多モーダルマシン理解のための時間的モーダルエンティティグラフのモデリング", "jabstract": "手順マルチモーダル文書（PMD）は、テキストの手順とそれに対応する画像をステップバイステップで整理します。PMDを理解し、下流の推論タスクのための表現を導出することは、手順マルチモーダルマシン理解（M3C）として指定されます。本研究では、手順M3Cにおいて、文書または文レベルの既存の探索と比較して、エンティティのような細かいレベルでアプローチします。繊細な考慮をもって、エンティティを時間的およびクロスモーダル関係でモデル化し、新しい時間モーダルエンティティグラフ（TMEG）を提案します。具体的には、グラフ構造は、テキストとビジュアルのエンティティを捕捉し、その時間的モーダル進化を追跡するために形成されます。さらに、グラフ集約モジュールを導入して、グラフのエンコーディングと推論を実行します。従来のデータセットRecipeQAと私たちの新しいデータセットCraftQAで、3つの手順M3Cタスクにわたる包括的な実験が実施され、TMEGの汎化性能をよりよく評価することができます。"}
{"title": "Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning", "url": "https://aclanthology.org/2022.acl-long.85/", "abstract": "Pre-trained sequence-to-sequence language models have led to widespread success in many natural language generation tasks. However, there has been relatively less work on analyzing their ability to generate structured outputs such as graphs. Unlike natural language, graphs have distinct structural and semantic properties in the context of a downstream NLP task, e.g., generating a graph that is connected and acyclic can be attributed to its structural constraints, while the semantics of a graph can refer to how meaningfully an edge represents the relation between two node concepts. In this work, we study pre-trained language models that generate explanation graphs in an end-to-end manner and analyze their ability to learn the structural constraints and semantics of such graphs. We first show that with limited supervision, pre-trained language models often generate graphs that either violate these constraints or are semantically incoherent. Since curating large amount of human-annotated graphs is expensive and tedious, we propose simple yet effective ways of graph perturbations via node and edge edit operations that lead to structurally and semantically positive and negative graphs. Next, we leverage these graphs in different contrastive learning models with Max-Margin and InfoNCE losses. Our methods lead to significant improvements in both structural and semantic accuracy of explanation graphs and also generalize to other similar graph generation tasks. Lastly, we show that human errors are the best negatives for contrastive learning and also that automatically generating more such human-like negative graphs can lead to further improvements.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルを用いた説明グラフ生成：対照学習による実証研究", "jabstract": "事前学習されたシーケンス・トゥ・シーケンス言語モデルは、多くの自然言語生成タスクで広く成功を収めています。しかし、グラフなどの構造化された出力を生成する能力を分析する研究は比較的少ないです。自然言語とは異なり、グラフは下流のNLPタスクの文脈で独自の構造的および意味的特性を持ちます。例えば、接続された非循環グラフを生成することはその構造的制約に帰属し、グラフの意味はエッジが2つのノード概念の関係をどのように意味的に表現するかに関連します。本研究では、エンドツーエンドで説明グラフを生成する事前学習言語モデルを研究し、そのグラフの構造的制約と意味を学習する能力を分析します。まず、限られた監視下で、事前学習言語モデルはこれらの制約を破るか、意味的に不整合なグラフを生成することが多いことを示します。大量の人手による注釈付きグラフを収集することは費用と手間がかかるため、ノードとエッジの編集操作を介したグラフの単純で効果的な摂動方法を提案します。これにより、構造的および意味的に肯定的および否定的なグラフが生成されます。次に、Max-MarginとInfoNCE損失を使用した異なる対比学習モデルでこれらのグラフを活用します。これらの方法は、説明グラフの構造的および意味的精度の両方で大幅な改善をもたらし、他の類似したグラフ生成タスクにも一般化します。最後に、人間のエラーが最適な負例であること、また、より多くの人間らしい負のグラフを自動生成することがさらなる改善につながることを示します。"}
{"title": "Unsupervised Extractive Opinion Summarization Using Sparse Coding", "url": "https://aclanthology.org/2022.acl-long.86/", "abstract": "Opinion summarization is the task of automatically generating summaries that encapsulate information expressed in multiple user reviews. We present Semantic Autoencoder (SemAE) to perform extractive opinion summarization in an unsupervised manner. SemAE uses dictionary learning to implicitly capture semantic information from the review text and learns a latent representation of each sentence over semantic units. Our extractive summarization algorithm leverages the representations to identify representative opinions among hundreds of reviews. SemAE is also able to perform controllable summarization to generate aspect-specific summaries using only a few samples. We report strong performance on SPACE and AMAZON datasets and perform experiments to investigate the functioning of our model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「スパースコーディングを用いた教師なし抽出型意見要約」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Unsupervised Extractive Opinion Summarization Using Sparse Coding\n- スパースコーディングを用いた教師なし抽出型意見要約", "jabstract": "意見要約は、複数のユーザーレビューに表現された情報を総括する要約を自動的に生成するタスクです。我々は、Semantic Autoencoder（SemAE）を提案し、教師なしの抽出型意見要約を実行します。SemAEは、辞書学習を使用してレビューテキストから意味情報を暗黙的に捕捉し、各文の意味ユニットにわたる潜在表現を学習します。我々の抽出型要約アルゴリズムは、表現を活用して数百のレビューの中から代表的な意見を特定します。SemAEは、わずかなサンプルのみを使用して、アスペクトに特化した要約を生成することもできます。我々は、SPACEおよびAMAZONデータセットで強力なパフォーマンスを報告し、モデルの機能を調査するための実験を実施します。"}
{"title": "LexSubCon: Integrating Knowledge from Lexical Resources into Contextual Embeddings for Lexical Substitution", "url": "https://aclanthology.org/2022.acl-long.87/", "abstract": "Lexical substitution is the task of generating meaningful substitutes for a word in a given textual context. Contextual word embedding models have achieved state-of-the-art results in the lexical substitution task by relying on contextual information extracted from the replaced word within the sentence. However, such models do not take into account structured knowledge that exists in external lexical databases.We introduce LexSubCon, an end-to-end lexical substitution framework based on contextual embedding models that can identify highly-accurate substitute candidates. This is achieved by combining contextual information with knowledge from structured lexical resources. Our approach involves: (i) introducing a novel mix-up embedding strategy to the target word’s embedding through linearly interpolating the pair of the target input embedding and the average embedding of its probable synonyms; (ii) considering the similarity of the sentence-definition embeddings of the target word and its proposed candidates; and, (iii) calculating the effect of each substitution on the semantics of the sentence through a fine-tuned sentence similarity model. Our experiments show that LexSubCon outperforms previous state-of-the-art methods by at least 2% over all the official lexical substitution metrics on LS07 and CoInCo benchmark datasets that are widely used for lexical substitution tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LexSubCon：語彙リソースからの知識を文脈埋め込みに統合して、語彙置換のためのものにする。", "jabstract": "語彙置換は、与えられた文脈内の単語に対して意味のある代替語を生成するタスクです。文脈語埋め込みモデルは、文内の置換された単語から抽出された文脈情報に依存することで、語彙置換タスクで最先端の結果を達成しています。しかし、このようなモデルは、外部の語彙データベースに存在する構造化された知識を考慮に入れていません。本研究では、構造化された語彙リソースからの知識と文脈埋め込みモデルに基づくエンドツーエンドの語彙置換フレームワークであるLexSubConを紹介します。これにより、高精度な代替候補を特定できます。これは、文脈情報を構造化された語彙リソースの知識と組み合わせることによって実現されます。我々のアプローチは、(i) ターゲット単語の埋め込みに新しいミックスアップ埋め込み戦略を導入することで、ターゲット入力埋め込みとその可能性のある類義語の平均埋め込みのペアを線形補間することです。(ii) ターゲット単語と提案された候補の文-定義埋め込みの類似性を考慮すること。(iii) 微調整された文の類似性モデルを介して、文の意味に対する各置換の影響を計算することです。我々の実験では、LexSubConは、広く語彙置換タスクに使用されるLS07およびCoInCoベンチマークデータセットのすべての公式語彙置換メトリックで、従来の最先端方法よりも少なくとも2％優れていることが示されています。"}
{"title": "Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation", "url": "https://aclanthology.org/2022.acl-long.88/", "abstract": "Implicit knowledge, such as common sense, is key to fluid human conversations. Current neural response generation (RG) models are trained to generate responses directly, omitting unstated implicit knowledge. In this paper, we present Think-Before-Speaking (TBS), a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak). We argue that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models. We analyze different choices to collect knowledge-aligned dialogues, represent implicit knowledge, and transition between knowledge and dialogues. Empirical results show TBS models outperform end-to-end and knowledge-augmented RG baselines on most automatic metrics and generate more informative, specific, and commonsense-following responses, as evaluated by human annotators. TBS also generates knowledge that makes sense and is relevant to the dialogue around 85% of the time", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "話す前に考えよう：応答生成のために暗黙の常識知識を明示的に生成する", "jabstract": "暗黙の知識、例えば常識は、流暢な人間の会話に不可欠です。現在のニューラル応答生成（RG）モデルは、暗黙の知識を省略して直接応答を生成するように訓練されています。本論文では、暗黙の常識的な知識を最初に外部化する（考える）ことで応答を生成するための生成的アプローチであるThink-Before-Speaking（TBS）を提案します。暗黙の知識を外部化することで、より効率的な学習が可能になり、より情報量の多い応答を生成し、より説明可能なモデルを可能にすると主張します。我々は、知識に合わせた対話を収集するための異なる選択肢、暗黙の知識を表現する方法、そして知識と対話の間を移行する方法を分析します。実験結果は、TBSモデルが自動評価指標のほとんどでエンドツーエンドおよび知識拡張RGベースラインを上回り、人間の注釈者による評価によると、より情報量が多く、具体的で、常識に従った応答を生成することを示しています。TBSはまた、対話に関連し、意味がある知識を約85％の頻度で生成します。"}
{"title": "Flow-Adapter Architecture for Unsupervised Machine Translation", "url": "https://aclanthology.org/2022.acl-long.89/", "abstract": "In this work, we propose a flow-adapter architecture for unsupervised NMT. It leverages normalizing flows to explicitly model the distributions of sentence-level latent representations, which are subsequently used in conjunction with the attention mechanism for the translation task. The primary novelties of our model are: (a) capturing language-specific sentence representations separately for each language using normalizing flows and (b) using a simple transformation of these latent representations for translating from one language to another. This architecture allows for unsupervised training of each language independently. While there is prior work on latent variables for supervised MT, to the best of our knowledge, this is the first work that uses latent variables and normalizing flows for unsupervised MT. We obtain competitive results on several unsupervised MT benchmarks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「非監視機械翻訳のためのフローアダプターアーキテクチャ」", "jabstract": "本研究では、教師なしNMTのためのフローアダプターアーキテクチャを提案します。このアーキテクチャは、正規化フローを活用して文レベルの潜在表現の分布を明示的にモデル化し、その後、翻訳タスクにおいてアテンションメカニズムと共に使用されます。私たちのモデルの主な新規性は、(a) 正規化フローを使用して各言語ごとに言語固有の文表現を別々に捉え、(b) これらの潜在表現を単純な変換に使用して言語間翻訳を行うことです。このアーキテクチャにより、各言語の教師なしトレーニングが可能になります。監視されたMTの潜在変数に関する先行研究がありますが、私たちの知る限り、これは教師なしMTにおいて潜在変数と正規化フローを使用した最初の研究です。私たちは、いくつかの教師なしMTベンチマークで競争力のある結果を得ました。"}
{"title": "Efficient Unsupervised Sentence Compression by Fine-tuning Transformers with Reinforcement Learning", "url": "https://aclanthology.org/2022.acl-long.90/", "abstract": "Sentence compression reduces the length of text by removing non-essential content while preserving important facts and grammaticality. Unsupervised objective driven methods for sentence compression can be used to create customized models without the need for ground-truth training data, while allowing flexibility in the objective function(s) that are used for learning and inference. Recent unsupervised sentence compression approaches use custom objectives to guide discrete search; however, guided search is expensive at inference time. In this work, we explore the use of reinforcement learning to train effective sentence compression models that are also fast when generating predictions. In particular, we cast the task as binary sequence labelling and fine-tune a pre-trained transformer using a simple policy gradient approach. Our approach outperforms other unsupervised models while also being more efficient at inference time.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "強化学習を用いたTransformerの微調整による効率的な非教師あり文圧縮", "jabstract": "文章の要約：\n\n文の圧縮は、重要な事実と文法性を保持しながら、非必須のコンテンツを削除することによって、テキストの長さを短縮します。教師なし目的駆動型の文の圧縮方法は、グラウンドトゥルースのトレーニングデータを必要とせずにカスタマイズされたモデルを作成するために使用でき、学習と推論に使用される目的関数に柔軟性を提供します。最近の教師なし文の圧縮アプローチは、カスタム目的を使用して離散的な検索をガイドすることで、ガイドされた検索は推論時に高価です。この研究では、効果的な文の圧縮モデルをトレーニングするために強化学習の使用を探索し、予測を生成する際にも高速であるモデルを作成します。特に、タスクをバイナリシーケンスラベリングとしてキャストし、シンプルなポリシーグラディエントアプローチを使用して事前にトレーニングされたトランスフォーマーを微調整します。このアプローチは、他の教師なしモデルよりも優れており、推論時にも効率的です。"}
{"title": "Tracing Origins: Coreference-aware Machine Reading Comprehension", "url": "https://aclanthology.org/2022.acl-long.91/", "abstract": "Machine reading comprehension is a heavily-studied research and test field for evaluating new pre-trained language models (PrLMs) and fine-tuning strategies, and recent studies have enriched the pre-trained language models with syntactic, semantic and other linguistic information to improve the performance of the models. In this paper, we imitate the human reading process in connecting the anaphoric expressions and explicitly leverage the coreference information of the entities to enhance the word embeddings from the pre-trained language model, in order to highlight the coreference mentions of the entities that must be identified for coreference-intensive question answering in QUOREF, a relatively new dataset that is specifically designed to evaluate the coreference-related performance of a model. We use two strategies to fine-tune a pre-trained language model, namely, placing an additional encoder layer after a pre-trained language model to focus on the coreference mentions or constructing a relational graph convolutional network to model the coreference relations. We demonstrate that the explicit incorporation of coreference information in the fine-tuning stage performs better than the incorporation of the coreference information in pre-training a language model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n起源の追跡：共参照を考慮した機械読解", "jabstract": "機械読解は、新しい事前学習言語モデル（PrLMs）および微調整戦略を評価するための研究およびテスト分野であり、最近の研究では、事前学習言語モデルに構文、意味およびその他の言語情報を豊富に取り入れてモデルの性能を向上させています。本論文では、人間の読解プロセスを模倣し、照応表現を接続し、明示的にエンティティの共参照情報を活用して、事前学習言語モデルから単語埋め込みを強化し、QUOREFという比較的新しいデータセットでの共参照に関連するモデルの性能評価を特に設計します。我々は、事前学習言語モデルの後に追加のエンコーダ層を配置して共参照言及に焦点を当てるか、共参照関係をモデル化するための関係グラフ畳み込みネットワークを構築する2つの戦略を使用します。微調整段階での共参照情報の明示的な組み込みが、言語モデルの事前学習での共参照情報の組み込みよりも優れた性能を発揮することを示します。"}
{"title": "WatClaimCheck: A new Dataset for Claim Entailment and Inference", "url": "https://aclanthology.org/2022.acl-long.92/", "abstract": "We contribute a new dataset for the task of automated fact checking and an evaluation of state of the art algorithms. The dataset includes claims (from speeches, interviews, social media and news articles), review articles published by professional fact checkers and premise articles used by those professional fact checkers to support their review and verify the veracity of the claims. An important challenge in the use of premise articles is the identification of relevant passages that will help to infer the veracity of a claim. We show that transferring a dense passage retrieval model trained with review articles improves the retrieval quality of passages in premise articles. We report results for the prediction of claim veracity by inference from premise articles.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "WatClaimCheck：主張の含意と推論のための新しいデータセット", "jabstract": "私たちは、自動事実チェックのタスクのための新しいデータセットと、最先端のアルゴリズムの評価に貢献します。データセットには、スピーチ、インタビュー、ソーシャルメディア、ニュース記事からの主張、プロの事実チェッカーによって公開されたレビュー記事、およびそれらのプロの事実チェッカーがレビューを支援し、主張の真実性を検証するために使用する前提記事が含まれています。前提記事の使用における重要な課題は、主張の真実性を推論するのに役立つ関連する箇所を特定することです。私たちは、レビュー記事で訓練された密なパッセージ検索モデルを転移することで、前提記事内のパッセージの検索品質が向上することを示します。私たちは、前提記事からの推論による主張の真実性の予測の結果を報告します。"}
{"title": "FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metrics for Automatic Text Generation", "url": "https://aclanthology.org/2022.acl-long.93/", "abstract": "Fast and reliable evaluation metrics are key to R&D progress. While traditional natural language generation metrics are fast, they are not very reliable. Conversely, new metrics based on large pretrained language models are much more reliable, but require significant computational resources. In this paper, we propose FrugalScore, an approach to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance. Experiments with BERTScore and MoverScore on summarization and translation show that FrugalScore is on par with the original metrics (and sometimes better), while having several orders of magnitude less parameters and running several times faster. On average over all learned metrics, tasks, and variants, FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35 times less parameters than the original metrics. We make our trained metrics publicly available, to benefit the entire NLP community and in particular researchers and practitioners with limited resources.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FrugalScore：自動テキスト生成のためのより安価で軽量で高速な評価メトリックを学習する", "jabstract": "高速で信頼性の高い評価指標は、研究開発の進歩に不可欠です。従来の自然言語生成の評価指標は速いですが、信頼性があまり高くありません。一方、大規模な事前学習言語モデルに基づく新しい指標は、信頼性が高くなりますが、膨大な計算リソースが必要です。本論文では、高価な自然言語生成の評価指標の固定された低コスト版を学習するFrugalScoreを提案します。この方法により、元の性能のほとんどを維持しながら、多くのパラメーターを削減することができます。BERTScoreとMoverScoreを用いた要約と翻訳の実験では、FrugalScoreは元の指標と同等の性能を発揮し、場合によってはより優れています。また、FrugalScoreは、元の指標よりも数桁少ないパラメーターで、数倍速く実行されます。すべての学習済み指標を公開し、リソースに限りのある研究者や実践者に利益をもたらすことを目的としています。平均的に、すべての学習済み指標、タスク、バリアントにおいて、FrugalScoreは性能の96.8%を維持し、元の指標よりも24倍速く、35倍少ないパラメーターを持っています。"}
{"title": "A Well-Composed Text is Half Done! Composition Sampling for Diverse Conditional Generation", "url": "https://aclanthology.org/2022.acl-long.94/", "abstract": "We propose Composition Sampling, a simple but effective method to generate diverse outputs for conditional generation of higher quality compared to previous stochastic decoding strategies. It builds on recently proposed plan-based neural generation models (FROST, Narayan et al, 2021) that are trained to first create a composition of the output and then generate by conditioning on it and the input. Our approach avoids text degeneration by first sampling a composition in the form of an entity chain and then using beam search to generate the best possible text grounded to this entity chain. Experiments on summarization (CNN/DailyMail and XSum) and question generation (SQuAD), using existing and newly proposed automaticmetrics together with human-based evaluation, demonstrate that Composition Sampling is currently the best available decoding strategy for generating diverse meaningful outputs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "よく構成されたテキストは半分完了！多様な条件付き生成のための構成サンプリング", "jabstract": "私たちは、以前の確率的デコーディング戦略と比較して、より高品質な条件付き生成のために多様な出力を生成するためのシンプルで効果的な方法である「Composition Sampling」を提案します。これは、最近提案されたプランベースのニューラル生成モデル（FROST、Narayan et al、2021）に基づいて構築され、まず出力の構成を作成し、それと入力に基づいて条件付けて生成するようにトレーニングされます。私たちのアプローチは、エンティティチェーンの形で構成をサンプリングし、そのエンティティチェーンに基づいて最良のテキストを生成するためにビームサーチを使用することで、テキストの退化を回避します。CNN / DailyMailおよびXSumの要約、およびSQuADの質問生成に関する実験では、既存のおよび新しく提案された自動メトリックと人間による評価を併用して、Composition Samplingが現在、多様な意味のある出力を生成するための最良の利用可能なデコーディング戦略であることが示されています。"}
{"title": "Synthetic Question Value Estimation for Domain Adaptation of Question Answering", "url": "https://aclanthology.org/2022.acl-long.95/", "abstract": "Synthesizing QA pairs with a question generator (QG) on the target domain has become a popular approach for domain adaptation of question answering (QA) models. Since synthetic questions are often noisy in practice, existing work adapts scores from a pretrained QA (or QG) model as criteria to select high-quality questions. However, these scores do not directly serve the ultimate goal of improving QA performance on the target domain. In this paper, we introduce a novel idea of training a question value estimator (QVE) that directly estimates the usefulness of synthetic questions for improving the target-domain QA performance. By conducting comprehensive experiments, we show that the synthetic questions selected by QVE can help achieve better target-domain QA performance, in comparison with existing techniques. We additionally show that by using such questions and only around 15% of the human annotations on the target domain, we can achieve comparable performance to the fully-supervised baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nドメイン適応のための質問応答の合成質問価値推定", "jabstract": "ターゲットドメインでの質問応答（QA）モデルのドメイン適応のために、質問ジェネレータ（QG）を用いたQAペアの合成が一般的な手法となっている。しかし、合成された質問はしばしばノイズが含まれるため、既存の手法では事前学習されたQA（またはQG）モデルのスコアを基準に高品質な質問を選択する。しかし、これらのスコアは、ターゲットドメインでのQAパフォーマンスの改善という最終目標に直接的に役立つわけではない。本論文では、合成された質問の有用性を直接的に評価する質問価値推定器（QVE）の新しいアイデアを提案する。包括的な実験を行い、QVEによって選択された合成質問が、既存の手法と比較してターゲットドメインでのQAパフォーマンスの向上に役立つことを示す。さらに、このような質問を使用し、ターゲットドメインでの人間の注釈の約15％のみを使用することで、完全に教師ありのベースラインと同等のパフォーマンスを達成できることを示す。"}
{"title": "Better Language Model with Hypernym Class Prediction", "url": "https://aclanthology.org/2022.acl-long.96/", "abstract": "Class-based language models (LMs) have been long devised to address context sparsity in n-gram LMs. In this study, we revisit this approach in the context of neural LMs. We hypothesize that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words. We map words that have a common WordNet hypernym to the same class and train large neural LMs by gradually annealing from predicting the class to token prediction during training. Empirically, this curriculum learning strategy consistently improves perplexity over various large, highly-performant state-of-the-art Transformer-based models on two datasets, WikiText-103 and ARXIV. Our analysis shows that the performance improvement is achieved without sacrificing performance on rare words. Finally, we document other attempts that failed to yield empirical gains, and discuss future directions for the adoption of class-based LMs on a larger scale.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「上位語クラス予測によるより優れた言語モデル」に関する論文の要約文を日本語に翻訳します。", "jabstract": "クラスベースの言語モデル（LM）は、n-gram LMの文脈のまばらさに対処するために長年にわたって考案されてきました。本研究では、ニューラルLMの文脈でこのアプローチを再検討します。クラスベースの予測は、類似した単語の暗黙的な文脈集約をもたらし、珍しい単語の一般化を改善できると仮説を立てています。共通のWordNetハイパーニムを持つ単語を同じクラスにマッピングし、トークン予測からクラス予測に徐々にアニーリングしながら大規模なニューラルLMをトレーニングします。実証的に、このカリキュラム学習戦略は、WikiText-103とARXIVの2つのデータセットで、さまざまな大規模で高性能な最新のTransformerベースのモデルに対して一貫してperplexityを改善します。分析により、珍しい単語のパフォーマンスを犠牲にすることなく、パフォーマンスの向上が達成されたことが示されます。最後に、実証的な利益をもたらさなかった他の試みを文書化し、クラスベースのLMの大規模な採用の将来の方向性について議論します。"}
{"title": "Tackling Fake News Detection by Continually Improving Social Context Representations using Graph Neural Networks", "url": "https://aclanthology.org/2022.acl-long.97/", "abstract": "Easy access, variety of content, and fast widespread interactions are some of the reasons making social media increasingly popular. However, this rise has also enabled the propagation of fake news, text published by news sources with an intent to spread misinformation and sway beliefs. Detecting it is an important and challenging problem to prevent large scale misinformation and maintain a healthy society. We view fake news detection as reasoning over the relations between sources, articles they publish, and engaging users on social media in a graph framework. After embedding this information, we formulate inference operators which augment the graph edges by revealing unobserved interactions between its elements, such as similarity between documents’ contents and users’ engagement patterns. Our experiments over two challenging fake news detection tasks show that using inference operators leads to a better understanding of the social media framework enabling fake news spread, resulting in improved performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "グラフニューラルネットワークを使用して、社会的文脈表現を継続的に改善することにより、フェイクニュース検出に取り組む。", "jabstract": "簡単なアクセス、多様なコンテンツ、そして迅速な広範な相互作用は、ソーシャルメディアがますます人気を集める理由の一部です。しかし、この上昇は、誤情報を広め、信念を揺るがす意図でニュースソースによって公開されたテキストであるフェイクニュースの拡散を可能にしました。大規模な誤情報を防止し、健全な社会を維持するために、それを検出することは重要であり、困難な問題です。私たちは、フェイクニュースの検出を、ソーシャルメディア上でのソース、彼らが公開する記事、そして参加するユーザーの関係をグラフフレームワークで推論することと見なしています。この情報を埋め込んだ後、推論演算子を定式化し、ドキュメントの内容やユーザーのエンゲージメントパターンなど、要素間の観測されていない相互作用を明らかにすることで、グラフエッジを拡張します。2つの困難なフェイクニュース検出タスクに対する実験は、推論演算子を使用することで、フェイクニュースの拡散を可能にするソーシャルメディアフレームワークの理解が向上し、パフォーマンスが向上することを示しています。"}
{"title": "Understanding Gender Bias in Knowledge Base Embeddings", "url": "https://aclanthology.org/2022.acl-long.98/", "abstract": "Knowledge base (KB) embeddings have been shown to contain gender biases. In this paper, we study two questions regarding these biases: how to quantify them, and how to trace their origins in KB? Specifically, first, we develop two novel bias measures respectively for a group of person entities and an individual person entity. Evidence of their validity is observed by comparison with real-world census data. Second, we use the influence function to inspect the contribution of each triple in KB to the overall group bias. To exemplify the potential applications of our study, we also present two strategies (by adding and removing KB triples) to mitigate gender biases in KB embeddings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n知識ベース埋め込みにおけるジェンダーバイアスの理解", "jabstract": "知識ベース（KB）の埋め込みには、ジェンダーの偏りが含まれていることが示されています。本論文では、これらの偏りに関する2つの問題について研究します。それは、どのように量化するか、そしてKB内のその起源をどのように追跡するかです。具体的には、まず、人物エンティティのグループと個人のエンティティそれぞれに対して2つの新しいバイアス測定を開発します。その妥当性の証拠は、現実世界の国勢調査データと比較して観察されます。次に、影響関数を使用して、KB内の各トリプルが全体的なグループバイアスにどのように貢献するかを調べます。私たちの研究の潜在的な応用を示すために、KB埋め込みのジェンダーバイアスを緩和する2つの戦略（KBトリプルの追加と削除による）も提示します。"}
{"title": "Computational Historical Linguistics and Language Diversity in South Asia", "url": "https://aclanthology.org/2022.acl-long.99/", "abstract": "South Asia is home to a plethora of languages, many of which severely lack access to new language technologies. This linguistic diversity also results in a research environment conducive to the study of comparative, contact, and historical linguistics–fields which necessitate the gathering of extensive data from many languages. We claim that data scatteredness (rather than scarcity) is the primary obstacle in the development of South Asian language technology, and suggest that the study of language history is uniquely aligned with surmounting this obstacle. We review recent developments in and at the intersection of South Asian NLP and historical-comparative linguistics, describing our and others’ current efforts in this area. We also offer new strategies towards breaking the data barrier.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「計算言語学的歴史言語学と南アジアの言語多様性」に関する論文の要約文を日本語に翻訳します。\n\n- Computational Historical Linguistics is a field that combines computational methods with linguistic analysis to study the evolution of languages over time.\n（計算言語学的歴史言語学は、計算手法と言語分析を組み合わせて、言語の時間的進化を研究する分野です。）\n\n- South Asia is home to a vast array of languages, many of which are endangered or have limited resources for preservation.\n（南アジアには、多数の言語が存在し、その多くが絶滅危惧種であり、保存のための資源が限られています。）\n\n- Natural Language Processing techniques can be used to aid in the preservation and analysis of these languages, as well as to better understand their historical development.\n（自然言語処理技術は、これらの言語の保存や分析を支援するために使用できるだけでなく、その歴史的発展をよりよく理解するためにも役立ちます。）", "jabstract": "南アジアには多数の言語が存在し、その多くは新しい言語技術にアクセスできないという深刻な問題がある。この言語多様性は比較言語学、接触言語学、歴史言語学の研究環境を提供し、多数の言語からの広範なデータ収集が必要とされる。我々は、南アジア言語技術の発展において、データの散在性（不足ではなく）が主要な障害であると主張し、言語史の研究がこの障害を克服するために独自に適合していると提案する。我々は、南アジアの自然言語処理と歴史比較言語学の交差点での最近の進展を検討し、この分野での自分たちや他の人々の現在の取り組みを説明する。また、データの壁を打ち破るための新しい戦略を提供する。"}
{"title": "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization", "url": "https://aclanthology.org/2022.acl-long.100/", "abstract": "Despite recent progress in abstractive summarization, systems still suffer from faithfulness errors. While prior work has proposed models that improve faithfulness, it is unclear whether the improvement comes from an increased level of extractiveness of the model outputs as one naive way to improve faithfulness is to make summarization models more extractive. In this work, we present a framework for evaluating the effective faithfulness of summarization systems, by generating a faithfulness-abstractiveness trade-off curve that serves as a control at different operating points on the abstractiveness spectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as well as recently proposed methods for improving faithfulness, fail to consistently improve over the control at the same level of abstractiveness. Finally, we learn a selector to identify the most faithful and abstractive summary for a given document, and show that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets. Moreover, we show that our system is able to achieve a better faithfulness-abstractiveness trade-off than the control at the same level of abstractiveness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「忠実か抽象的か？抽象的要約における忠実性と抽象性のトレードオフを緩和する方法について」", "jabstract": "抽象的な要約において最近の進展にもかかわらず、システムは依然として忠実性のエラーに苦しんでいます。以前の研究では、忠実性を向上させるモデルが提案されていますが、要約モデルをより抽出的にすることが忠実性を向上させるための素朴な方法の1つであるため、改善が抽出度の増加によるものかどうかは不明です。本研究では、抽象度スペクトルの異なる操作点で制御として機能する忠実性-抽象度トレードオフ曲線を生成することにより、要約システムの効果的な忠実性を評価するためのフレームワークを提供します。その後、最大尤度推定（MLE）ベースラインおよび最近提案された忠実性を向上させる方法が、同じ抽象度レベルで制御を常に改善できないことを示します。最後に、与えられたドキュメントに対して最も忠実で抽象的な要約を識別するセレクタを学習し、このシステムが2つのデータセットでベースラインシステムよりもより抽象的でありながら、人間の評価でより高い忠実性スコアを達成できることを示します。さらに、同じ抽象度レベルで制御よりも優れた忠実性-抽象度トレードオフを達成できることを示します。"}
{"title": "Slangvolution: A Causal Analysis of Semantic Change and Frequency Dynamics in Slang", "url": "https://aclanthology.org/2022.acl-long.101/", "abstract": "Languages are continuously undergoing changes, and the mechanisms that underlie these changes are still a matter of debate. In this work, we approach language evolution through the lens of causality in order to model not only how various distributional factors associate with language change, but how they causally affect it. In particular, we study slang, which is an informal language that is typically restricted to a specific group or social setting. We analyze the semantic change and frequency shift of slang words and compare them to those of standard, nonslang words. With causal discovery and causal inference techniques, we measure the effect that word type (slang/nonslang) has on both semantic change and frequency shift, as well as its relationship to frequency, polysemy and part of speech. Our analysis provides some new insights in the study of language change, e.g., we show that slang words undergo less semantic change but tend to have larger frequency shifts over time.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Slangvolution：スラングにおける意味の変化と頻度ダイナミクスの因果分析", "jabstract": "言語は常に変化しており、その変化のメカニズムはまだ議論の余地がある。本研究では、因果関係の観点から言語進化にアプローチし、様々な分布要因が言語変化にどのように関連し、どのように因果的に影響を与えるかをモデル化する。特に、特定のグループや社会的環境に限定された非公式な言語であるスラングを研究する。スラング語と標準的な非スラング語の意味変化と頻度変化を分析し、因果関係の発見と因果推論技術を用いて、単語タイプ（スラング/非スラング）が意味変化と頻度変化に及ぼす影響、および頻度、多義性、品詞との関係を測定する。分析により、スラング語は意味変化が少ないが、時間の経過とともに頻度変化が大きくなる傾向があることが示され、言語変化の研究に新しい洞察を提供する。"}
{"title": "Spurious Correlations in Reference-Free Evaluation of Text Generation", "url": "https://aclanthology.org/2022.acl-long.102/", "abstract": "Model-based, reference-free evaluation metricshave been proposed as a fast and cost-effectiveapproach to evaluate Natural Language Generation(NLG) systems. Despite promising recentresults, we find evidence that reference-freeevaluation metrics of summarization and dialoggeneration may be relying on spuriouscorrelations with measures such as word overlap,perplexity, and length. We further observethat for text summarization, these metrics havehigh error rates when ranking current state-ofthe-art abstractive summarization systems. Wedemonstrate that these errors can be mitigatedby explicitly designing evaluation metrics toavoid spurious features in reference-free evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己参照のないテキスト生成の評価における偽の相関\n\nAbstract:\n\nWe investigate the use of reference-free evaluation metrics for text generation tasks, which do not require human-written references. We show that these metrics can be highly sensitive to spurious correlations between the generated text and external factors, such as the topic or style of the training data. We propose a simple method to control for these correlations by using a subset of the training data that is matched to the generated text on these external factors. Our experiments demonstrate that this method can substantially improve the reliability of reference-free evaluation metrics for text generation. \n\n要約：\n\n本研究では、人間による参照を必要としない自己参照のないテキスト生成タスクにおける評価指標の使用について調査しました。我々は、これらの指標がトピックやトレーニングデータのスタイルなどの外部要因と生成されたテキストとの偽の相関に非常に敏感であることを示しました。我々は、これらの相関を制御するための簡単な方法を提案し、これらの外部要因に基づいて生成されたテキストにマッチするトレーニングデータのサブセットを使用することを提案しました。我々の実験は、この方法がテキスト生成のための自己参照のない評価指標の信頼性を大幅に向上させることができることを示しています。", "jabstract": "モデルベースの、参照フリーの評価尺度は、自然言語生成（NLG）システムを評価するための迅速かつ費用効果の高いアプローチとして提案されています。最近の有望な結果にもかかわらず、要約や対話生成の参照フリーの評価尺度が、単語の重複、パープレキシティ、長さなどの尺度との偽の相関に依存している可能性があることがわかりました。さらに、テキスト要約については、これらの尺度が現在の最先端の抽象的要約システムをランキングする際に高いエラー率を示すことが観察されました。我々は、参照フリーの評価において偽の特徴を回避するために明示的に評価尺度を設計することで、これらのエラーを軽減できることを示します。"}
{"title": "On The Ingredients of an Effective Zero-shot Semantic Parser", "url": "https://aclanthology.org/2022.acl-long.103/", "abstract": "Semantic parsers map natural language utterances into meaning representations (e.g., programs). Such models are typically bottlenecked by the paucity of training data due to the required laborious annotation efforts. Recent studies have performed zero-shot learning by synthesizing training examples of canonical utterances and programs from a grammar, and further paraphrasing these utterances to improve linguistic diversity. However, such synthetic examples cannot fully capture patterns in real data. In this paper we analyze zero-shot parsers through the lenses of the language and logical gaps (Herzig and Berant, 2019), which quantify the discrepancy of language and programmatic patterns between the canonical examples and real-world user-issued ones. We propose bridging these gaps using improved grammars, stronger paraphrasers, and efficient learning methods using canonical examples that most likely reflect real user intents. Our model achieves strong performance on two semantic parsing benchmarks (Scholar, Geo) with zero labeled data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "効果的なゼロショット意味解析器の要素について\n\nThis paper presents a study on the ingredients of an effective zero-shot semantic parser. \n\n本論文では、効果的なゼロショット意味解析器の要素についての研究を行います。\n\nWe propose a novel approach that leverages the power of pre-trained language models and semantic embeddings to enable zero-shot learning. \n\n我々は、事前学習された言語モデルと意味埋め込みの力を活用して、ゼロショット学習を可能にする新しいアプローチを提案します。\n\nOur experiments show that our approach outperforms existing zero-shot semantic parsers on multiple datasets. \n\n実験結果は、我々のアプローチが複数のデータセットで既存のゼロショット意味解析器を上回ることを示しています。", "jabstract": "意味解析器は、自然言語の発話を意味表現（例：プログラム）にマッピングします。このようなモデルは、必要な注釈作業の手間により、トレーニングデータが不足していることが一般的です。最近の研究では、文法から標準的な発話とプログラムのトレーニング例を合成し、これらの発話を言語的多様性を向上させるために言い換えることにより、ゼロショット学習を実行しました。しかし、このような合成例は、実際のデータのパターンを完全に捉えることができません。本論文では、言語的および論理的ギャップ（Herzig and Berant, 2019）のレンズを通してゼロショットパーサーを分析し、標準的な例と実世界のユーザー発行例の間の言語およびプログラムパターンの不一致を定量化します。私たちは、改良された文法、より強力な言い換えモデル、および実際のユーザー意図を最も反映する可能性が高い標準的な例を使用した効率的な学習方法を使用して、これらのギャップを埋めることを提案します。私たちのモデルは、ラベル付けされたデータがゼロである2つの意味解析ベンチマーク（Scholar、Geo）で強力なパフォーマンスを発揮します。"}
{"title": "Bias Mitigation in Machine Translation Quality Estimation", "url": "https://aclanthology.org/2022.acl-long.104/", "abstract": "Machine Translation Quality Estimation (QE) aims to build predictive models to assess the quality of machine-generated translations in the absence of reference translations. While state-of-the-art QE models have been shown to achieve good results, they over-rely on features that do not have a causal impact on the quality of a translation. In particular, there appears to be a partial input bias, i.e., a tendency to assign high-quality scores to translations that are fluent and grammatically correct, even though they do not preserve the meaning of the source. We analyse the partial input bias in further detail and evaluate four approaches to use auxiliary tasks for bias mitigation. Two approaches use additional data to inform and support the main task, while the other two are adversarial, actively discouraging the model from learning the bias. We compare the methods with respect to their ability to reduce the partial input bias while maintaining the overall performance. We find that training a multitask architecture with an auxiliary binary classification task that utilises additional augmented data best achieves the desired effects and generalises well to different languages and quality metrics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "機械翻訳品質評価におけるバイアス緩和", "jabstract": "機械翻訳品質評価(QE)は、参照翻訳がない場合に機械生成翻訳の品質を評価する予測モデルを構築することを目的としています。最新のQEモデルは良好な結果を達成することが示されていますが、翻訳の品質に因果関係のない特徴に過度に依存しています。特に、部分的な入力バイアスがあり、つまり、意味を保持しないにもかかわらず、流暢で文法的に正しい翻訳に高品質スコアを割り当てる傾向があります。私たちは、部分的な入力バイアスをさらに詳しく分析し、バイアス緩和のための4つのアプローチを評価します。2つのアプローチは、追加のデータを使用して主要なタスクを支援するために使用され、他の2つは敵対的で、モデルがバイアスを学習しないように積極的に妨げます。私たちは、部分的な入力バイアスを減らしながら全体的なパフォーマンスを維持する能力に関して、方法を比較します。私たちは、追加の拡張データを利用する補助的なバイナリ分類タスクを持つマルチタスクアーキテクチャをトレーニングすることが、望ましい効果を最もよく達成し、異なる言語や品質メトリックにも一般化することができることを発見しました。"}
{"title": "Unified Speech-Text Pre-training for Speech Translation and Recognition", "url": "https://aclanthology.org/2022.acl-long.105/", "abstract": "In this work, we describe a method to jointly pre-train speech and text in an encoder-decoder modeling framework for speech translation and recognition. The proposed method utilizes multi-task learning to integrate four self-supervised and supervised subtasks for cross modality learning. A self-supervised speech subtask, which leverages unlabelled speech data, and a (self-)supervised text to text subtask, which makes use of abundant text training data, take up the majority of the pre-training time. Two auxiliary supervised speech tasks are included to unify speech and text modeling space. Detailed analysis reveals learning interference among subtasks. In order to alleviate the subtask interference, two pre-training configurations are proposed for speech translation and speech recognition respectively. Our experiments show the proposed method can effectively fuse speech and text information into one model. It achieves between 1.7 and 2.3 BLEU improvement above the state of the art on the MuST-C speech translation dataset and comparable WERs to wav2vec 2.0 on the Librispeech speech recognition task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "音声翻訳と認識のための統合音声テキスト事前学習", "jabstract": "本研究では、音声翻訳と認識のためのエンコーダ・デコーダモデリングフレームワークにおいて、音声とテキストを共同で事前学習する方法を説明する。提案された方法は、クロスモダリティ学習のために4つの自己教師あり・なしのサブタスクを統合するためにマルチタスク学習を利用する。自己教師ありの音声サブタスクは、ラベルのない音声データを活用し、豊富なテキストトレーニングデータを利用する（自己）教師ありのテキストトゥテキストサブタスクが、事前学習時間の大部分を占める。2つの補助教師ありの音声タスクが含まれ、音声とテキストのモデリングスペースを統一する。詳細な分析により、サブタスク間の学習干渉が明らかになった。サブタスクの干渉を緩和するために、音声翻訳と音声認識のために2つの事前学習構成が提案された。実験結果は、提案された方法が音声とテキスト情報を効果的に1つのモデルに統合できることを示している。MuST-C音声翻訳データセットにおいて、最新技術に比べて1.7〜2.3 BLEUの改善を達成し、Librispeech音声認識タスクにおいてwav2vec 2.0と同等のWERを達成している。"}
{"title": "Match the Script, Adapt if Multilingual: Analyzing the Effect of Multilingual Pretraining on Cross-lingual Transferability", "url": "https://aclanthology.org/2022.acl-long.106/", "abstract": "Pretrained multilingual models enable zero-shot learning even for unseen languages, and that performance can be further improved via adaptation prior to finetuning. However, it is unclear how the number of pretraining languages influences a model’s zero-shot learning for languages unseen during pretraining. To fill this gap, we ask the following research questions: (1) How does the number of pretraining languages influence zero-shot performance on unseen target languages? (2) Does the answer to that question change with model adaptation? (3) Do the findings for our first question change if the languages used for pretraining are all related? Our experiments on pretraining with related languages indicate that choosing a diverse set of languages is crucial. Without model adaptation, surprisingly, increasing the number of pretraining languages yields better results up to adding related languages, after which performance plateaus.In contrast, with model adaptation via continued pretraining, pretraining on a larger number of languages often gives further improvement, suggesting that model adaptation is crucial to exploit additional pretraining languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "スクリプトを一致させ、多言語に適応する：多言語事前学習がクロスリンガル転移性に与える影響の分析", "jabstract": "事前学習された多言語モデルは、未知の言語に対してゼロショット学習を可能にし、微調整前に適応することで性能をさらに向上させることができます。しかし、事前学習言語の数がモデルの未知の言語に対するゼロショット学習にどのように影響するかは不明です。このギャップを埋めるために、以下の研究問題を提起します：（1）事前学習言語の数は、未知のターゲット言語に対するゼロショット性能にどのように影響するか？（2）その答えは、モデルの適応によって変わるか？（3）事前学習に使用される言語がすべて関連している場合、最初の質問の結果は変わりますか？関連する言語での事前学習に関する私たちの実験は、多様な言語セットを選択することが重要であることを示しています。モデルの適応なしで、驚くべきことに、事前学習言語の数を増やすことは、関連する言語を追加するまでより良い結果をもたらし、その後性能が停滞します。対照的に、継続的な事前学習によるモデルの適応により、より多くの言語での事前学習はさらなる改善をもたらすことがよくあり、追加の事前学習言語を活用するためにモデルの適応が重要であることを示唆しています。"}
{"title": "Structured Pruning Learns Compact and Accurate Models", "url": "https://aclanthology.org/2022.acl-long.107/", "abstract": "The growing size of neural language models has led to increased attention in model compression. The two predominant approaches are pruning, which gradually removes weights from a pre-trained model, and distillation, which trains a smaller compact model to match a larger one. Pruning methods can significantly reduce the model size but hardly achieve large speedups as distillation. However, distillation methods require large amounts of unlabeled data and are expensive to train. In this work, we propose a task-specific structured pruning method CoFi (Coarse- and Fine-grained Pruning), which delivers highly parallelizable subnetworks and matches the distillation methods in both accuracy and latency, without resorting to any unlabeled data. Our key insight is to jointly prune coarse-grained (e.g., layers) and fine-grained (e.g., heads and hidden units) modules, which controls the pruning decision of each parameter with masks of different granularity. We also devise a layerwise distillation strategy to transfer knowledge from unpruned to pruned models during optimization. Our experiments on GLUE and SQuAD datasets show that CoFi yields models with over 10X speedups with a small accuracy drop, showing its effectiveness and efficiency compared to previous pruning and distillation approaches.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "構造化プルーニングは、コンパクトで正確なモデルを学習します。", "jabstract": "ニューラル言語モデルのサイズの増大により、モデルの圧縮に対する注目が高まっている。主要なアプローチは、事前にトレーニングされたモデルから重みを徐々に削除するプルーニングと、より小さくコンパクトなモデルをトレーニングして大きなモデルに合わせる蒸留である。プルーニング方法はモデルサイズを大幅に削減できるが、蒸留に比べて大きなスピードアップを実現することはできない。しかし、蒸留方法は大量の未ラベルデータが必要であり、トレーニングにコストがかかる。本研究では、未ラベルデータを必要とせず、蒸留方法と同じ精度とレイテンシーを持つ高度に並列化可能なサブネットワークを提供するタスク固有の構造化プルーニング方法CoFi（Coarse- and Fine-grained Pruning）を提案する。私たちの主要な洞察は、粗粒度（例：レイヤー）と細粒度（例：ヘッドと隠れユニット）のモジュールを共同でプルーニングすることであり、それぞれのパラメータのプルーニング決定を異なる粒度のマスクで制御することである。また、最適化中に未プルーニングからプルーニングされたモデルへの知識の転送を行うレイヤーごとの蒸留戦略を考案した。GLUEおよびSQuADデータセットでの実験では、CoFiは小さな精度低下とともに10倍以上のスピードアップを実現し、以前のプルーニングおよび蒸留アプローチと比較してその有効性と効率性を示した。"}
{"title": "How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language", "url": "https://aclanthology.org/2022.acl-long.108/", "abstract": "More than 43% of the languages spoken in the world are endangered, and language loss currently occurs at an accelerated rate because of globalization and neocolonialism. Saving and revitalizing endangered languages has become very important for maintaining the cultural diversity on our planet. In this work, we focus on discussing how NLP can help revitalize endangered languages. We first suggest three principles that may help NLP practitioners to foster mutual understanding and collaboration with language communities, and we discuss three ways in which NLP can potentially assist in language education. We then take Cherokee, a severely-endangered Native American language, as a case study. After reviewing the language’s history, linguistic features, and existing resources, we (in collaboration with Cherokee community members) arrive at a few meaningful ways NLP practitioners can collaborate with community partners. We suggest two approaches to enrich the Cherokee language’s resources with machine-in-the-loop processing, and discuss several NLP tools that people from the Cherokee community have shown interest in. We hope that our work serves not only to inform the NLP community about Cherokee, but also to provide inspiration for future work on endangered languages in general.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "NLPが絶滅危惧言語の復興に役立つのか？ チェロキー語の事例研究とロードマップ", "jabstract": "世界で話されている言語の43％以上が危機に瀕しており、グローバリゼーションや新植民地主義の影響により、言語喪失は加速しています。危機に瀕した言語を保存し、復興することは、地球上の文化的多様性を維持するために非常に重要になっています。本研究では、NLPが危機に瀕した言語の復興にどのように役立つかに焦点を当てています。まず、NLP実践者が言語コミュニティと相互理解と協力を促進するための3つの原則を提案し、NLPが言語教育に潜在的に役立つ3つの方法について議論します。次に、深刻な危機に瀕したネイティブアメリカンのチェロキー語を事例として取り上げます。言語の歴史、言語的特徴、既存のリソースを検討した後、私たちは（チェロキーのコミュニティメンバーと協力して）NLP実践者がコミュニティパートナーと協力するための意義深い方法をいくつか提案します。機械学習を利用したチェロキー語のリソースを豊かにする2つのアプローチを提案し、チェロキーのコミュニティから興味を持たれたいくつかのNLPツールについても議論します。私たちは、私たちの研究がチェロキーに関するNLPコミュニティに情報を提供するだけでなく、危機に瀕した言語に関する将来の研究にインスピレーションを与えることを望んでいます。"}
{"title": "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization", "url": "https://aclanthology.org/2022.acl-long.109/", "abstract": "The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist’s reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models – which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多段階放射線学レポート要約のための差分可能なマルチエージェントアクター・クリティック", "jabstract": "放射線学検査に関する放射線科医の推論と結論の要約である「IMPRESSIONS」セクションは、紹介医師が特定の診断を確認または除外するのに役立ちます。情報豊富な放射線学レポートの要約を自動的に生成するには、タスクのカスケードが必要です。これらのタスクには、レポートから重要なコンテンツを取得し、簡潔で消化しやすい「IMPRESSIONS」セクションを生成することが含まれます。放射線学レポートの要約に関する以前の研究は、単一ステップのエンドツーエンドモデルに焦点を当てており、重要なコンテンツの取得のタスクを包含しています。放射線学レポートの要約のカスケード構造と説明可能性を完全に探索するために、2つのイノベーションを紹介します。まず、抽出要約に続いて抽象的要約を生成する2段階アプローチを設計します。第二に、抽出部分を2つの独立したタスクに分割します：重要な（1）文と（2）キーワードの抽出。2つの臨床現場からの英語の放射線学レポートでの実験は、新しいアプローチが単一ステップおよび単一抽出プロセスベースラインよりもより正確な要約を導き、F1スコア全体で3-4％の改善をもたらすことを示しています。"}
{"title": "Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue", "url": "https://aclanthology.org/2022.acl-long.110/", "abstract": "Standard conversational semantic parsing maps a complete user utterance into an executable program, after which the program is executed to respond to the user. This could be slow when the program contains expensive function calls. We investigate the opportunity to reduce latency by predicting and executing function calls while the user is still speaking. We introduce the task of online semantic parsing for this purpose, with a formal latency reduction metric inspired by simultaneous machine translation. We propose a general framework with first a learned prefix-to-program prediction module, and then a simple yet effective thresholding heuristic for subprogram selection for early execution. Experiments on the SMCalFlow and TreeDST datasets show our approach achieves large latency reduction with good parsing quality, with a 30%–65% latency reduction depending on function execution time and allowed cost.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nタスク指向型対話におけるレイテンシ削減のためのオンライン意味解析", "jabstract": "標準的な会話型意味解析は、完全なユーザー発話を実行可能なプログラムにマッピングし、その後プログラムを実行してユーザーに応答します。プログラムに高価な関数呼び出しが含まれる場合、これは遅くなる可能性があります。私たちは、ユーザーが話している間に関数呼び出しを予測して実行することでレイテンシを削減する機会を調査します。この目的のためにオンライン意味解析のタスクを紹介し、同時機械翻訳に着想を得た形式的なレイテンシ削減メトリックを導入します。私たちは、まず学習された接頭辞からプログラムを予測するモジュール、そして早期実行のためのサブプログラム選択のための単純で効果的な閾値ヒューリスティックを提案する一般的なフレームワークを提案します。 SMCalFlowおよびTreeDSTデータセットでの実験により、関数の実行時間と許容コストに応じて30％〜65％のレイテンシ削減を達成し、良好な解析品質を実現することが示されました。"}
{"title": "Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformer Architectures", "url": "https://aclanthology.org/2022.acl-long.111/", "abstract": "The enrichment of tabular datasets using external sources has gained significant attention in recent years. Existing solutions, however, either ignore external unstructured data completely or devise dataset-specific solutions. In this study we proposed Few-Shot Transformer based Enrichment (FeSTE), a generic and robust framework for the enrichment of tabular datasets using unstructured data. By training over multiple datasets, our approach is able to develop generic models that can be applied to additional datasets with minimal training (i.e., few-shot). Our approach is based on an adaptation of BERT, for which we present a novel fine-tuning approach that reformulates the tuples of the datasets as sentences. Our evaluation, conducted on 17 datasets, shows that FeSTE is able to generate high quality features and significantly outperform existing fine-tuning solutions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Fine-Tuned Transformer Architecturesを使用したフューショット表形式データのエンリッチメント」という論文の要約文です。", "jabstract": "近年、外部ソースを使用して表形式のデータセットを豊かにすることが注目されています。しかし、既存の解決策は、外部の非構造化データを完全に無視するか、データセット固有の解決策を考案することが多いです。本研究では、非構造化データを使用して表形式のデータセットを豊かにするための汎用的で堅牢なフレームワークであるFew-Shot Transformer based Enrichment (FeSTE)を提案します。複数のデータセットでトレーニングすることにより、我々のアプローチは、最小限のトレーニング（つまり、フューショット）で追加のデータセットに適用できる汎用モデルを開発することができます。我々のアプローチは、BERTの適応に基づいており、データセットのタプルを文として再定式化する新しいファインチューニングアプローチを提供します。17のデータセットで実施した評価により、FeSTEは高品質の特徴を生成し、既存のファインチューニング解決策を大幅に上回ることが示されました。"}
{"title": "SummN: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents", "url": "https://aclanthology.org/2022.acl-long.112/", "abstract": "Text summarization helps readers capture salient information from documents, news, interviews, and meetings. However, most state-of-the-art pretrained language models (LM) are unable to efficiently process long text for many summarization tasks. In this paper, we propose SummN, a simple, flexible, and effective multi-stage framework for input texts that are longer than the maximum context length of typical pretrained LMs. SummN first splits the data samples and generates a coarse summary in multiple stages and then produces the final fine-grained summary based on it. Our framework can process input text of arbitrary length by adjusting the number of stages while keeping the LM input size fixed. Moreover, it can deal with both single-source documents and dialogues, and it can be used on top of different backbone abstractive summarization models. To the best of our knowledge, SummN is the first multi-stage split-then-summarize framework for long input summarization. Our experiments demonstrate that SummN outperforms previous state-of-the-art methods by improving ROUGE scores on three long meeting summarization datasets AMI, ICSI, and QMSum, two long TV series datasets from SummScreen, and a long document summarization dataset GovReport. Our data and code are available at https://github.com/psunlpgroup/Summ-N.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「SummN：長い入力対話と文書のための多段階要約フレームワーク」は、自然言語処理に関する論文の要約です。", "jabstract": "テキスト要約は、ドキュメント、ニュース、インタビュー、会議から重要な情報を読者が把握するのを支援します。しかし、ほとんどの最新の事前学習済み言語モデル（LM）は、多くの要約タスクに対して長いテキストを効率的に処理できません。本論文では、典型的な事前学習済みLMの最大コンテキスト長よりも長い入力テキストに対するシンプルで柔軟で効果的なマルチステージフレームワークであるSummNを提案します。SummNは、データサンプルを分割し、複数のステージで粗い要約を生成し、それに基づいて最終的な細かい要約を生成します。当社のフレームワークは、LMの入力サイズを固定したまま、ステージの数を調整することで、任意の長さの入力テキストを処理できます。さらに、単一ソースのドキュメントと対話の両方を扱うことができ、異なるバックボーン抽象的要約モデルの上に使用することができます。SummNは、長い入力要約のための最初のマルチステージ分割-要約フレームワークであると思われます。当社の実験では、SummNがAMI、ICSI、QMSumの3つの長い会議要約データセット、SummScreenの2つの長いテレビシリーズデータセット、およびGovReportの長いドキュメント要約データセットでROUGEスコアを改善することにより、以前の最新の方法を上回ることを示しています。当社のデータとコードは、https://github.com/psunlpgroup/Summ-Nで利用可能です。"}
{"title": "Open Domain Question Answering with A Unified Knowledge Interface", "url": "https://aclanthology.org/2022.acl-long.113/", "abstract": "The retriever-reader framework is popular for open-domain question answering (ODQA) due to its ability to use explicit knowledge.Although prior work has sought to increase the knowledge coverage by incorporating structured knowledge beyond text, accessing heterogeneous knowledge sources through a unified interface remains an open question. While data-to-text generation has the potential to serve as a universal interface for data and text, its feasibility for downstream tasks remains largely unknown. In this work, we bridge this gap and use the data-to-text method as a means for encoding structured knowledge for open-domain question answering. Specifically, we propose a verbalizer-retriever-reader framework for ODQA over data and text where verbalized tables from Wikipedia and graphs from Wikidata are used as augmented knowledge sources. We show that our Unified Data and Text QA, UDT-QA, can effectively benefit from the expanded knowledge index, leading to large gains over text-only baselines. Notably, our approach sets the single-model state-of-the-art on Natural Questions. Furthermore, our analyses indicate that verbalized knowledge is preferred for answer reasoning for both adapted and hot-swap settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「統一された知識インターフェースを用いたオープンドメインの質問応答」に関する論文の要約文です。\n\n1. This paper presents a unified knowledge interface for open domain question answering.\n→ この論文では、オープンドメインの質問応答に対する統一された知識インターフェースを提案します。\n\n2. The interface integrates multiple knowledge sources and provides a natural language interface for users to ask questions.\n→ このインターフェースは、複数の知識源を統合し、ユーザーが質問をするための自然言語インターフェースを提供します。\n\n3. The system uses natural language processing techniques to understand user questions and retrieve relevant information from the knowledge sources.\n→ このシステムは、自然言語処理技術を使用して、ユーザーの質問を理解し、知識源から関連する情報を取得します。\n\n4. Experimental results show that the proposed system achieves state-of-the-art performance on several benchmark datasets.\n→ 実験結果は、提案されたシステムがいくつかのベンチマークデータセットで最先端の性能を発揮することを示しています。", "jabstract": "リトリーバー・リーダー・フレームワークは、明示的な知識を使用する能力により、オープンドメインの質問応答（ODQA）において人気があります。以前の研究では、テキスト以外の構造化された知識を組み込むことで知識カバレッジを増やすことを目指してきましたが、統一されたインターフェースを介して異種の知識源にアクセスすることは未解決の問題です。データからテキスト生成は、データとテキストのための普遍的なインターフェースとして機能する可能性がありますが、下流タスクに対するその実現可能性はほとんど知られていません。本研究では、このギャップを埋め、データからテキストの方法を構造化された知識をエンコードする手段として使用し、オープンドメインの質問応答のための口語化リトリーバー・リーダー・フレームワークを提案します。具体的には、Wikipediaからの口語化された表とWikidataからのグラフを拡張された知識源として使用します。私たちは、私たちの統一されたデータとテキストのQA（UDT-QA）が拡張された知識インデックスから効果的に利益を得ることができ、テキストのみのベースラインよりも大きな利益をもたらすことを示します。特に、私たちのアプローチは、Natural Questionsにおいてシングルモデルの最先端を設定します。さらに、私たちの分析は、口語化された知識が適応された状況とホットスワップの両方において回答推論に好まれることを示しています。"}
{"title": "Principled Paraphrase Generation with Parallel Corpora", "url": "https://aclanthology.org/2022.acl-long.114/", "abstract": "Round-trip Machine Translation (MT) is a popular choice for paraphrase generation, which leverages readily available parallel corpora for supervision. In this paper, we formalize the implicit similarity function induced by this approach, and show that it is susceptible to non-paraphrase pairs sharing a single ambiguous translation. Based on these insights, we design an alternative similarity metric that mitigates this issue by requiring the entire translation distribution to match, and implement a relaxation of it through the Information Bottleneck method. Our approach incorporates an adversarial term into MT training in order to learn representations that encode as much information about the reference translation as possible, while keeping as little information about the input as possible. Paraphrases can be generated by decoding back to the source from this representation, without having to generate pivot translations. In addition to being more principled and efficient than round-trip MT, our approach offers an adjustable parameter to control the fidelity-diversity trade-off, and obtains better results in our experiments.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「並列コーパスを用いた原理的な言い換え生成」に関する論文の要旨を以下に示す。\n\n1. We propose a principled approach to paraphrase generation using parallel corpora.\n2. Our method leverages the alignment information in parallel corpora to generate high-quality paraphrases.\n3. We evaluate our approach on two benchmark datasets and show that it outperforms existing methods.\n4. Our method can be applied to various natural language processing tasks, such as text simplification and machine translation. \n\n1. 私たちは、並列コーパスを用いた原理的な言い換え生成の手法を提案する。\n2. 私たちの手法は、並列コーパスのアラインメント情報を活用して高品質な言い換えを生成する。\n3. 私たちは、2つのベンチマークデータセットで私たちの手法を評価し、既存の手法を上回ることを示した。\n4. 私たちの手法は、テキストの簡素化や機械翻訳など、さまざまな自然言語処理タスクに適用できる。", "jabstract": "ラウンドトリップ機械翻訳（MT）は、監視のためにすでに利用可能な並列コーパスを活用するための言い換え生成の人気のある選択肢です。本論文では、このアプローチによって誘導される暗黙の類似性関数を形式化し、単一の曖昧な翻訳を共有する非言い換えペアに影響を受けやすいことを示します。これらの洞察に基づいて、翻訳分布全体が一致することを要求する代替類似度メトリックを設計し、情報ボトルネック法を介してその緩和を実装します。私たちのアプローチは、参照翻訳に関する情報を可能な限りエンコードし、入力に関する情報を可能な限り少なく保つように学習するために、MTトレーニングに敵対的な用語を組み込みます。この表現からソースに戻ってデコードすることで、ピボット翻訳を生成する必要なく、言い換えを生成できます。ラウンドトリップMTよりも原理的で効率的であり、信頼性と多様性のトレードオフを制御するための調整可能なパラメータを提供し、実験でより良い結果を得ます。"}
{"title": "GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems", "url": "https://aclanthology.org/2022.acl-long.115/", "abstract": "Over the last few years, there has been a move towards data curation for multilingual task-oriented dialogue (ToD) systems that can serve people speaking different languages. However, existing multilingual ToD datasets either have a limited coverage of languages due to the high cost of data curation, or ignore the fact that dialogue entities barely exist in countries speaking these languages. To tackle these limitations, we introduce a novel data curation method that generates GlobalWoZ — a large-scale multilingual ToD dataset globalized from an English ToD dataset for three unexplored use cases of multilingual ToD systems. Our method is based on translating dialogue templates and filling them with local entities in the target-language countries. Besides, we extend the coverage of target languages to 20 languages. We will release our dataset and a set of strong baselines to encourage research on multilingual ToD systems for real use cases.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「GlobalWoZ：多言語タスク指向対話システムを開発するためのMultiWoZのグローバル化」", "jabstract": "ここ数年、異なる言語を話す人々に役立つ多言語タスク指向型対話（ToD）システムのためのデータキュレーションに向けた動きがある。しかし、既存の多言語ToDデータセットは、データキュレーションの高コストにより言語のカバー範囲が限定されているか、これらの言語を話す国において対話エンティティがほとんど存在しないことを無視している。これらの制限に対処するため、私たちは、英語のToDデータセットからグローバル化された大規模な多言語ToDデータセットであるGlobalWoZを生成する新しいデータキュレーション方法を紹介する。私たちの方法は、対話テンプレートを翻訳し、対象言語の国のローカルエンティティで埋めることに基づいている。さらに、対象言語のカバー範囲を20言語に拡大している。私たちは、実際の用途のための多言語ToDシステムの研究を促進するために、私たちのデータセットと一連の強力なベースラインを公開する予定である。"}
{"title": "Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation", "url": "https://aclanthology.org/2022.acl-long.116/", "abstract": "Since the development and wide use of pretrained language models (PLMs), several approaches have been applied to boost their performance on downstream tasks in specific domains, such as biomedical or scientific domains. Additional pre-training with in-domain texts is the most common approach for providing domain-specific knowledge to PLMs. However, these pre-training methods require considerable in-domain data and training resources and a longer training time. Moreover, the training must be re-performed whenever a new PLM emerges. In this study, we propose a domain knowledge transferring (DoKTra) framework for PLMs without additional in-domain pretraining. Specifically, we extract the domain knowledge from an existing in-domain pretrained language model and transfer it to other PLMs by applying knowledge distillation. In particular, we employ activation boundary distillation, which focuses on the activation of hidden neurons. We also apply an entropy regularization term in both teacher training and distillation to encourage the model to generate reliable output probabilities, and thus aid the distillation. By applying the proposed DoKTra framework to downstream tasks in the biomedical, clinical, and financial domains, our student models can retain a high percentage of teacher performance and even outperform the teachers in certain tasks. Our code is available at https://github.com/DMCB-GIST/DoKTra.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「キャリブレーションされた活性化境界蒸留を介した事前学習言語モデルのドメイン知識転送」という論文の要約文を日本語に翻訳してください。", "jabstract": "事前学習済み言語モデル（PLMs）の開発と広範な使用に伴い、バイオメディカルや科学分野など特定のドメインの下流タスクの性能を向上させるために、いくつかのアプローチが適用されてきた。ドメイン固有の知識をPLMsに提供するために、追加のドメイン内テキストによる事前学習が最も一般的なアプローチである。しかし、これらの事前学習方法には、相当量のドメイン内データとトレーニングリソース、長時間のトレーニングが必要であり、新しいPLMが現れるたびにトレーニングを再実行する必要がある。本研究では、追加のドメイン内事前学習なしでPLMsにドメイン知識を転送する（DoKTra）フレームワークを提案する。具体的には、既存のドメイン内事前学習済み言語モデルからドメイン知識を抽出し、知識蒸留を適用して他のPLMsに転送する。特に、隠れ層ニューロンの活性化に焦点を当てたアクティベーション境界蒸留を採用する。また、教師トレーニングと蒸留の両方にエントロピー正則化項を適用し、信頼性の高い出力確率を生成するようにモデルを促進する。提案されたDoKTraフレームワークをバイオメディカル、臨床、金融の下流タスクに適用することで、学生モデルは教師の性能の高い割合を維持し、特定のタスクでは教師を上回る性能を発揮することができた。コードはhttps://github.com/DMCB-GIST/DoKTraで利用可能である。"}
{"title": "Retrieval-guided Counterfactual Generation for QA", "url": "https://aclanthology.org/2022.acl-long.117/", "abstract": "Deep NLP models have been shown to be brittle to input perturbations. Recent work has shown that data augmentation using counterfactuals — i.e. minimally perturbed inputs — can help ameliorate this weakness. We focus on the task of creating counterfactuals for question answering, which presents unique challenges related to world knowledge, semantic diversity, and answerability. To address these challenges, we develop a Retrieve-Generate-Filter(RGF) technique to create counterfactual evaluation and training data with minimal human supervision. Using an open-domain QA framework and question generation model trained on original task data, we create counterfactuals that are fluent, semantically diverse, and automatically labeled. Data augmentation with RGF counterfactuals improves performance on out-of-domain and challenging evaluation sets over and above existing methods, in both the reading comprehension and open-domain QA settings. Moreover, we find that RGF data leads to significant improvements in a model’s robustness to local perturbations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nQAのための検索案内付きの反事実的生成", "jabstract": "深層NLPモデルは、入力の摂動に対して脆弱であることが示されています。最近の研究では、反事実的なデータ拡張-つまり、最小限の摂動を加えた入力-を使用することで、この弱点を緩和できることが示されています。私たちは、質問応答のための反事実的なデータを作成するタスクに焦点を当て、世界知識、意味的多様性、回答可能性に関連する独自の課題に直面しています。これらの課題に対処するために、最小限の人間の監視で反事実的な評価およびトレーニングデータを作成するためのRetrieve-Generate-Filter（RGF）技術を開発します。オープンドメインのQAフレームワークと元のタスクデータでトレーニングされた質問生成モデルを使用して、流暢で意味的に多様で自動的にラベル付けされた反事実的なデータを作成します。RGF反事実的なデータのデータ拡張は、読解力とオープンドメインのQA設定の両方で、既存の方法を超えて、ドメイン外および難解な評価セットでのパフォーマンスを向上させます。さらに、RGFデータは、モデルの局所的な摂動に対する堅牢性の大幅な改善につながることがわかりました。"}
{"title": "DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization", "url": "https://aclanthology.org/2022.acl-long.118/", "abstract": "Transformer-based models have achieved state-of-the-art performance on short-input summarization. However, they still struggle with summarizing longer text. In this paper, we present DYLE, a novel dynamic latent extraction approach for abstractive long-input summarization. DYLE jointly trains an extractor and a generator and treats the extracted text snippets as the latent variable, allowing dynamic snippet-level attention weights during decoding. To provide adequate supervision, we propose simple yet effective heuristics for oracle extraction as well as a consistency loss term, which encourages the extractor to approximate the averaged dynamic weights predicted by the generator. We evaluate our method on different long-document and long-dialogue summarization tasks: GovReport, QMSum, and arXiv. Experiment results show that DYLE outperforms all existing methods on GovReport and QMSum, with gains up to 6.1 ROUGE, while yielding strong results on arXiv. Further analysis shows that the proposed dynamic weights provide interpretability of our generation process.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DYLE：抽象的な長い入力要約のための動的潜在抽出", "jabstract": "トランスフォーマーベースのモデルは、短い入力要約において最先端の性能を発揮しています。しかし、長いテキストの要約にはまだ苦戦しています。本論文では、長い入力要約のための革新的なダイナミック潜在抽出アプローチであるDYLEを提案します。DYLEは、抽出器とジェネレータを共同でトレーニングし、抽出されたテキストスニペットを潜在変数として扱い、デコーディング中に動的なスニペットレベルの注意重みを可能にします。適切な監視を提供するために、オラクル抽出のためのシンプルで効果的なヒューリスティックスを提案し、また、一貫性損失項を提案して、抽出器がジェネレータによって予測された平均動的重みを近似するように促します。我々は、異なる長文書および長対話要約タスクで我々の方法を評価しました：GovReport、QMSum、およびarXiv。実験結果は、DYLEがGovReportとQMSumですべての既存の方法を上回り、最大6.1 ROUGEの利益をもたらし、arXivでも強力な結果を示すことを示しています。さらに分析すると、提案された動的重みが我々の生成プロセスの解釈可能性を提供することがわかります。"}
{"title": "Searching for fingerspelled content in American Sign Language", "url": "https://aclanthology.org/2022.acl-long.119/", "abstract": "Natural language processing for sign language video—including tasks like recognition, translation, and search—is crucial for making artificial intelligence technologies accessible to deaf individuals, and is gaining research interest in recent years. In this paper, we address the problem of searching for fingerspelled keywords or key phrases in raw sign language videos. This is an important task since significant content in sign language is often conveyed via fingerspelling, and to our knowledge the task has not been studied before. We propose an end-to-end model for this task, FSS-Net, that jointly detects fingerspelling and matches it to a text sequence. Our experiments, done on a large public dataset of ASL fingerspelling in the wild, show the importance of fingerspelling detection as a component of a search and retrieval model. Our model significantly outperforms baseline methods adapted from prior work on related tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nアメリカ手話で指文字を検索すること", "jabstract": "手話ビデオに対する自然言語処理（認識、翻訳、検索など）は、人工知能技術を聴覚障害者にもアクセス可能にするために重要であり、近年研究の関心を集めています。本論文では、手話ビデオ内の指文字のキーワードやキーフレーズを検索する問題に取り組みます。手話において重要なコンテンツはしばしば指文字で伝えられるため、このタスクは重要です。また、私たちの知る限り、このタスクはこれまで研究されていませんでした。私たちは、FSS-Netというエンドツーエンドモデルを提案し、指文字を検出し、テキストシーケンスにマッチングするタスクに取り組みます。大規模なASL指文字の公開データセットで行った実験では、指文字検出が検索と検索モデルのコンポーネントとして重要であることが示されました。私たちのモデルは、関連するタスクの以前の作業から適応されたベースライン方法を大幅に上回りました。"}
{"title": "Skill Induction and Planning with Latent Language", "url": "https://aclanthology.org/2022.acl-long.120/", "abstract": "We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level sub-tasks, using only a small number of seed annotations to ground language in action. In trained models, natural language commands index a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations. It achieves performance comparable state-of-the-art models on ALFRED success rate, outperforming several recent methods with access to ground-truth plans during training and evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Processing\n\n潜在言語処理によるスキル導入と計画立案", "jabstract": "私たちは、自律的な意思決定のための再利用可能なスキルの発見を指導するために、疎な自然言語注釈を使用してデモンストレーションから階層的なポリシーを学習するためのフレームワークを提供します。私たちは、目標が高レベルのサブタスクの説明のシーケンスを生成し、これらの説明が低レベルのアクションのシーケンスを生成するアクションシーケンスの生成モデルを定式化します。私たちは、わずかな数のシード注釈を使用して、デモンストレーションを名前付きの高レベルのサブタスクのシーケンスに解析することにより、主に注釈のないデモンストレーションをトレーニングする方法について説明します。トレーニングされたモデルでは、自然言語コマンドがスキルの組み合わせライブラリをインデックス化します。エージェントは、新しい目標に合わせた高レベルの指示シーケンスを生成することによって、これらのスキルを使用して計画することができます。私たちは、ALFRED家庭シミュレーション環境で、デモンストレーションのわずか10％に対して自然言語注釈を提供し、このアプローチを評価しました。それは、トレーニングと評価中にグラウンドトゥルースプランにアクセスできるいくつかの最近の方法を上回り、ALFRED成功率で状態-of-the-artモデルと同等のパフォーマンスを達成します。"}
{"title": "Fully-Semantic Parsing and Generation: the BabelNet Meaning Representation", "url": "https://aclanthology.org/2022.acl-long.121/", "abstract": "A language-independent representation of meaning is one of the most coveted dreams in Natural Language Understanding. With this goal in mind, several formalisms have been proposed as frameworks for meaning representation in Semantic Parsing. And yet, the dependencies these formalisms share with respect to language-specific repositories of knowledge make the objective of closing the gap between high- and low-resourced languages hard to accomplish. In this paper, we present the BabelNet Meaning Representation (BMR), an interlingual formalism that abstracts away from language-specific constraints by taking advantage of the multilingual semantic resources of BabelNet and VerbAtlas. We describe the rationale behind the creation of BMR and put forward BMR 1.0, a dataset labeled entirely according to the new formalism. Moreover, we show how BMR is able to outperform previous formalisms thanks to its fully-semantic framing, which enables top-notch multilingual parsing and generation. We release the code at https://github.com/SapienzaNLP/bmr.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "完全意味解析と生成：BabelNet意味表現", "jabstract": "自然言語理解において、言語に依存しない意味表現は最も望ましい夢の一つである。この目標を達成するために、いくつかの形式主義が意味解析の枠組みとして提案されてきた。しかし、これらの形式主義が言語固有の知識リポジトリと共有する依存関係により、高資源言語と低資源言語の間のギャップを埋める目的を達成することは困難である。本論文では、BabelNet Meaning Representation（BMR）を提案し、BabelNetとVerbAtlasの多言語意味リソースを活用することで、言語固有の制約から抽象化する国際語形式主義を提供する。BMR 1.0は、新しい形式主義に完全に従ってラベル付けされたデータセットである。さらに、BMRは完全な意味フレームを備えているため、優れた多言語解析と生成を可能にし、以前の形式主義を上回ることができることを示す。コードはhttps://github.com/SapienzaNLP/bmrで公開されている。"}
{"title": "Leveraging Similar Users for Personalized Language Modeling with Limited Data", "url": "https://aclanthology.org/2022.acl-long.122/", "abstract": "Personalized language models are designed and trained to capture language patterns specific to individual users. This makes them more accurate at predicting what a user will write. However, when a new user joins a platform and not enough text is available, it is harder to build effective personalized language models. We propose a solution for this problem, using a model trained on users that are similar to a new user. In this paper, we explore strategies for finding the similarity between new users and existing ones and methods for using the data from existing users who are a good match. We further explore the trade-off between available data for new users and how well their language can be modeled.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "限られたデータでの個人化言語モデリングのための類似ユーザーの活用", "jabstract": "個人化言語モデルは、個々のユーザーに固有の言語パターンを捉えるように設計・トレーニングされています。これにより、ユーザーが何を書くかをより正確に予測することができます。ただし、新しいユーザーがプラットフォームに参加し、十分なテキストが利用できない場合、効果的な個人化言語モデルを構築することはより困難になります。本論文では、新しいユーザーと類似した既存のユーザーでトレーニングされたモデルを使用することで、この問題に対する解決策を提案します。本論文では、新しいユーザーと既存のユーザーの類似性を見つけるための戦略や、適合する既存のユーザーからデータを使用する方法について探究します。さらに、新しいユーザーの利用可能なデータと、彼らの言語がどの程度モデル化できるかのトレードオフについても探究します。"}
{"title": "DEEP: DEnoising Entity Pre-training for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.123/", "abstract": "It has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus. Earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage. To address this limitation, we propose DEEP, a DEnoising Entity Pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences. Besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation. Experimental results on three language pairs demonstrate that DEEP results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 BLEU and up to 9.2 entity accuracy points for English-Russian translation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DEEP: ニューラル機械翻訳のためのエンティティのデノイジング事前学習", "jabstract": "訓練コーパスに頻度の低い固有名詞に対して、機械翻訳モデルが通常、低品質な翻訳を生成することが示されています。以前の固有名詞翻訳方法は、主に音声転写に焦点を当てており、文脈を無視して翻訳するため、ドメインと言語のカバレッジが限られています。この制限に対処するために、我々はDEEPという、大量の単一言語データと知識ベースを活用して、文内の固有名詞翻訳精度を改善するDEnoising Entity Pre-training方法を提案しています。さらに、エンティティを拡張した単一言語データと並列データの両方で事前学習されたニューラル機械翻訳モデルをファインチューニングするマルチタスク学習戦略を調査して、エンティティ翻訳をさらに改善します。3つの言語ペアでの実験結果は、DEEPが強力なデノイジング自己符号化ベースラインよりも有意な改善をもたらし、英語-ロシア語翻訳では最大1.3 BLEUと最大9.2エンティティ精度ポイントの利益が得られることを示しています。"}
{"title": "Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network", "url": "https://aclanthology.org/2022.acl-long.124/", "abstract": "With the increasing popularity of posting multimodal messages online, many recent studies have been carried out utilizing both textual and visual information for multi-modal sarcasm detection. In this paper, we investigate multi-modal sarcasm detection from a novel perspective by constructing a cross-modal graph for each instance to explicitly draw the ironic relations between textual and visual modalities. Specifically, we first detect the objects paired with descriptions of the image modality, enabling the learning of important visual information. Then, the descriptions of the objects are served as a bridge to determine the importance of the association between the objects of image modality and the contextual words of text modality, so as to build a cross-modal graph for each multi-modal instance. Furthermore, we devise a cross-modal graph convolutional network to make sense of the incongruity relations between modalities for multi-modal sarcasm detection. Extensive experimental results and in-depth analysis show that our model achieves state-of-the-art performance in multi-modal sarcasm detection.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「クロスモーダルグラフ畳み込みネットワークを介したマルチモーダルな皮肉検出」による自然言語処理の論文の要約文です。以下、日本語に翻訳してください。\n\n- Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network\n- クロスモーダルグラフ畳み込みネットワークを介したマルチモーダルな皮肉検出", "jabstract": "オンラインでのマルチモーダルメッセージの投稿が増加する中、最近の多くの研究では、テキストとビジュアル情報の両方を利用してマルチモーダルな皮肉の検出を行っています。本論文では、各インスタンスごとにクロスモーダルグラフを構築し、テキストとビジュアルのモダリティ間の皮肉な関係を明示的に描写することで、新しい視点からマルチモーダルな皮肉の検出を調査します。具体的には、まず、画像モダリティの説明とペアになるオブジェクトを検出し、重要なビジュアル情報を学習します。次に、オブジェクトの説明は、テキストモダリティの文脈語と画像モダリティのオブジェクトの関連性の重要性を決定するための橋渡しとして機能し、各マルチモーダルインスタンスのクロスモーダルグラフを構築します。さらに、クロスモーダルグラフ畳み込みネットワークを考案し、マルチモーダルな皮肉の検出におけるモダリティ間の不一致関係を理解します。広範な実験結果と深い分析により、当社のモデルがマルチモーダルな皮肉の検出において最先端の性能を発揮することが示されました。"}
{"title": "Composable Sparse Fine-Tuning for Cross-Lingual Transfer", "url": "https://aclanthology.org/2022.acl-long.125/", "abstract": "Fine-tuning the entire set of parameters of a large pretrained model has become the mainstream approach for transfer learning. To increase its efficiency and prevent catastrophic forgetting and interference, techniques like adapters and sparse fine-tuning have been developed. Adapters are modular, as they can be combined to adapt a model towards different facets of knowledge (e.g., dedicated language and/or task adapters). Sparse fine-tuning is expressive, as it controls the behavior of all model components. In this work, we introduce a new fine-tuning method with both these desirable properties. In particular, we learn sparse, real-valued masks based on a simple variant of the Lottery Ticket Hypothesis. Task-specific masks are obtained from annotated data in a source language, and language-specific masks from masked language modeling in a target language. Both these masks can then be composed with the pretrained model. Unlike adapter-based fine-tuning, this method neither increases the number of parameters at inference time nor alters the original model architecture. Most importantly, it outperforms adapters in zero-shot cross-lingual transfer by a large margin in a series of multilingual benchmarks, including Universal Dependencies, MasakhaNER, and AmericasNLI. Based on an in-depth analysis, we additionally find that sparsity is crucial to prevent both 1) interference between the fine-tunings to be composed and 2) overfitting. We release the code and models at https://github.com/cambridgeltl/composable-sft.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nクロスリンガル転移のための合成可能なスパースファインチューニング", "jabstract": "大規模な事前学習モデルの全パラメータを微調整することは、転移学習の主流の手法となっています。効率を高め、過去の学習内容の忘却や干渉を防ぐために、アダプターやスパース微調整などの技術が開発されています。アダプターはモジュール化されており、異なる知識の側面に適応するために組み合わせることができます（例：専用の言語やタスクアダプター）。スパース微調整は表現力があり、すべてのモデルコンポーネントの動作を制御します。本研究では、これらの望ましい特性を持つ新しい微調整方法を紹介します。特に、Lottery Ticket Hypothesisの単純なバリアントに基づいて、スパースで実数値のマスクを学習します。タスク固有のマスクは、ソース言語の注釈付きデータから、言語固有のマスクは、ターゲット言語のマスク言語モデリングから得られます。これらのマスクは、事前学習モデルと組み合わせることができます。アダプターベースの微調整とは異なり、この方法は推論時のパラメータ数を増やすことも、元のモデルアーキテクチャを変更することもありません。最も重要なことは、Universal Dependencies、MasakhaNER、AmericasNLIを含む一連の多言語ベンチマークで、ゼロショットクロスリンガル転移において、アダプターよりも大幅に優れていることがわかりました。詳細な分析に基づいて、スパース性が、1）組み合わせる微調整間の干渉を防ぎ、2）過学習を防ぐために重要であることがわかりました。コードとモデルは、https://github.com/cambridgeltl/composable-sftで公開されています。"}
{"title": "Toward Annotator Group Bias in Crowdsourcing", "url": "https://aclanthology.org/2022.acl-long.126/", "abstract": "Crowdsourcing has emerged as a popular approach for collecting annotated data to train supervised machine learning models. However, annotator bias can lead to defective annotations. Though there are a few works investigating individual annotator bias, the group effects in annotators are largely overlooked. In this work, we reveal that annotators within the same demographic group tend to show consistent group bias in annotation tasks and thus we conduct an initial study on annotator group bias. We first empirically verify the existence of annotator group bias in various real-world crowdsourcing datasets. Then, we develop a novel probabilistic graphical framework GroupAnno to capture annotator group bias with an extended Expectation Maximization (EM) algorithm. We conduct experiments on both synthetic and real-world datasets. Experimental results demonstrate the effectiveness of our model in modeling annotator group bias in label aggregation and model learning over competitive baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nクラウドソーシングにおける注釈者グループの偏りに向けて", "jabstract": "クラウドソーシングは、教師あり機械学習モデルをトレーニングするための注釈付きデータを収集するための人気のあるアプローチとして現れています。しかし、注釈者の偏見は欠陥のある注釈を引き起こす可能性があります。個々の注釈者の偏見を調査する研究はいくつかありますが、注釈者のグループ効果はほとんど無視されています。本研究では、同じ人口統計グループ内の注釈者は注釈タスクで一貫したグループバイアスを示す傾向があることを明らかにし、注釈者グループバイアスに関する初期研究を行います。まず、さまざまな実世界のクラウドソーシングデータセットで注釈者グループバイアスの存在を実証します。次に、拡張期待値最大化（EM）アルゴリズムを使用して注釈者グループバイアスを捕捉する新しい確率グラフィカルフレームワークGroupAnnoを開発します。合成および実世界のデータセットで実験を行います。実験結果は、競合するベースラインに比べて、ラベル集約およびモデル学習における注釈者グループバイアスのモデリングにおいて、当社のモデルの効果を示しています。"}
{"title": "Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation", "url": "https://aclanthology.org/2022.acl-long.127/", "abstract": "Gender bias is largely recognized as a problematic phenomenon affecting language technologies, with recent studies underscoring that it might surface differently across languages. However, most of current evaluation practices adopt a word-level focus on a narrow set of occupational nouns under synthetic conditions. Such protocols overlook key features of grammatical gender languages, which are characterized by morphosyntactic chains of gender agreement, marked on a variety of lexical items and parts-of-speech (POS). To overcome this limitation, we enrich the natural, gender-sensitive MuST-SHE corpus (Bentivogli et al., 2020) with two new linguistic annotation layers (POS and agreement chains), and explore to what extent different lexical categories and agreement phenomena are impacted by gender skews. Focusing on speech translation, we conduct a multifaceted evaluation on three language directions (English-French/Italian/Spanish), with models trained on varying amounts of data and different word segmentation techniques. By shedding light on model behaviours, gender bias, and its detection at several levels of granularity, our findings emphasize the value of dedicated analyses beyond aggregated overall results.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "形態・構文的レンズの下で：音声翻訳におけるジェンダーバイアスの多面的評価", "jabstract": "ジェンダーバイアスは、言語技術に影響を与える問題の現象として広く認識されており、最近の研究では、言語によって異なる形で現れる可能性があることが強調されています。しかし、現在の評価方法のほとんどは、合成条件下で狭い職業名詞のセットに対して単語レベルの焦点を当てています。このようなプロトコルは、文法的ジェンダー言語の重要な特徴を見落としており、これらの言語は、様々な語彙アイテムや品詞にマークされたジェンダーの一致の形態・文法的な連鎖で特徴付けられています。この制限を克服するために、私たちは自然でジェンダーに敏感なMuST-SHEコーパス（Bentivogli et al.、2020）に2つの新しい言語注釈レイヤー（品詞と一致の連鎖）を追加し、異なる語彙カテゴリーや一致現象がどの程度ジェンダースキューに影響を受けるかを探求します。音声翻訳に焦点を当て、異なるデータ量と単語分割技術でトレーニングされたモデルを用いて、英仏伊/西の3つの言語方向で多面的な評価を行います。モデルの振る舞い、ジェンダーバイアス、およびその検出について、複数の粒度レベルでの専用の分析の価値を強調する私たちの研究結果により、光が当たります。"}
{"title": "Answering Open-Domain Multi-Answer Questions via a Recall-then-Verify Framework", "url": "https://aclanthology.org/2022.acl-long.128/", "abstract": "Open-domain questions are likely to be open-ended and ambiguous, leading to multiple valid answers. Existing approaches typically adopt the rerank-then-read framework, where a reader reads top-ranking evidence to predict answers. According to our empirical analysis, this framework faces three problems: first, to leverage a large reader under a memory constraint, the reranker should select only a few relevant passages to cover diverse answers, while balancing relevance and diversity is non-trivial; second, the small reading budget prevents the reader from accessing valuable retrieved evidence filtered out by the reranker; third, when using a generative reader to predict answers all at once based on all selected evidence, whether a valid answer will be predicted also pathologically depends on evidence of some other valid answer(s). To address these issues, we propose to answer open-domain multi-answer questions with a recall-then-verify framework, which separates the reasoning process of each answer so that we can make better use of retrieved evidence while also leveraging large models under the same memory constraint. Our framework achieves state-of-the-art results on two multi-answer datasets, and predicts significantly more gold answers than a rerank-then-read system that uses an oracle reranker.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「リコール-検証フレームワークを用いたオープンドメインのマルチアンサー質問に対する回答」についての論文の要約です。", "jabstract": "オープンドメインの質問は、複数の正しい回答が存在するため、開放的で曖昧な傾向があります。既存のアプローチは、通常、リランク-リードフレームワークを採用しており、リーダーがトップランキングの証拠を読んで回答を予測します。私たちの経験的分析によると、このフレームワークには3つの問題があります。第一に、大きなリーダーをメモリ制約下で活用するために、リランカーは多様な回答をカバーするためにいくつかの関連するパッセージを選択する必要がありますが、関連性と多様性のバランスは容易ではありません。第二に、小さな読み取り予算は、リランカーによってフィルタリングされた貴重な検索された証拠にアクセスすることを妨げます。第三に、生成リーダーを使用して、すべての選択された証拠に基づいて一度にすべての回答を予測する場合、有効な回答が予測されるかどうかは、他の有効な回答の証拠にも病的に依存します。これらの問題に対処するために、私たちはリコール-バリファイフレームワークを使用して、オープンドメインの複数回答質問に回答します。これにより、各回答の推論プロセスを分離し、同じメモリ制約下で大きなモデルを活用しながら、検索された証拠をより良く活用できます。私たちのフレームワークは、2つの複数回答データセットで最先端の結果を達成し、オラクルリランカーを使用するリランク-リードシステムよりも、有意に多くの正解を予測します。"}
{"title": "Probing as Quantifying Inductive Bias", "url": "https://aclanthology.org/2022.acl-long.129/", "abstract": "Pre-trained contextual representations have led to dramatic performance improvements on a range of downstream tasks. Such performance improvements have motivated researchers to quantify and understand the linguistic information encoded in these representations. In general, researchers quantify the amount of linguistic information through probing, an endeavor which consists of training a supervised model to predict a linguistic property directly from the contextual representations. Unfortunately, this definition of probing has been subject to extensive criticism in the literature, and has been observed to lead to paradoxical and counter-intuitive results. In the theoretical portion of this paper, we take the position that the goal of probing ought to be measuring the amount of inductive bias that the representations encode on a specific task. We further describe a Bayesian framework that operationalizes this goal and allows us to quantify the representations’ inductive bias. In the empirical portion of the paper, we apply our framework to a variety of NLP tasks. Our results suggest that our proposed framework alleviates many previous problems found in probing. Moreover, we are able to offer concrete evidence that—for some tasks—fastText can offer a better inductive bias than BERT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プロービングは帰納バイアスを量化することを意味する。", "jabstract": "事前学習された文脈表現は、様々な下流タスクにおいて劇的な性能向上をもたらしている。このような性能向上は、研究者たちがこれらの表現にエンコードされた言語情報を定量化し理解することを促している。一般的に、研究者たちはプロービングと呼ばれる取り組みを通じて、文脈表現から言語的な特性を直接予測する監視されたモデルをトレーニングすることで、言語情報の量を定量化する。残念ながら、このプロービングの定義は、文献において広範な批判を受けており、逆説的で直感に反する結果をもたらすことが観察されている。本論文の理論的部分では、プロービングの目標は、表現が特定のタスクに対してエンコードする帰納バイアスの量を測定することであるべきであるという立場を取る。さらに、この目標を具体化し、表現の帰納バイアスを定量化するためのベイジアンフレームワークを説明する。本論文の実証的部分では、提案されたフレームワークを様々なNLPタスクに適用する。その結果、提案されたフレームワークは、プロービングで見つかった以前の問題を緩和することができることが示された。さらに、一部のタスクにおいて、fastTextがBERTよりも優れた帰納バイアスを提供できることを具体的な証拠として示すことができた。"}
{"title": "Probing Structured Pruning on Multilingual Pre-trained Models: Settings, Algorithms, and Efficiency", "url": "https://aclanthology.org/2022.acl-long.130/", "abstract": "Structured pruning has been extensively studied on monolingual pre-trained language models and is yet to be fully evaluated on their multilingual counterparts. This work investigates three aspects of structured pruning on multilingual pre-trained language models: settings, algorithms, and efficiency. Experiments on nine downstream tasks show several counter-intuitive phenomena: for settings, individually pruning for each language does not induce a better result; for algorithms, the simplest method performs the best; for efficiency, a fast model does not imply that it is also small. To facilitate the comparison on all sparsity levels, we present Dynamic Sparsification, a simple approach that allows training the model once and adapting to different model sizes at inference. We hope this work fills the gap in the study of structured pruning on multilingual pre-trained models and sheds light on future research.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語事前学習モデルにおける構造化プルーニングの探索：設定、アルゴリズム、および効率についての研究", "jabstract": "構造化プルーニングは、単一言語の事前学習言語モデルについて広く研究されており、多言語の事前学習言語モデルについては完全に評価されていない。本研究では、多言語の事前学習言語モデルにおける構造化プルーニングの3つの側面、すなわち設定、アルゴリズム、効率について調査を行った。9つの下流タスクでの実験結果から、いくつかの逆説的な現象が明らかになった。設定については、各言語ごとに個別にプルーニングを行っても、より良い結果をもたらさない。アルゴリズムについては、最も単純な方法が最も優れた結果を示す。効率については、高速なモデルが小さいことを意味するわけではない。すべての疎密度レベルで比較を容易にするために、我々はDynamic Sparsificationを提案し、モデルを一度トレーニングして推論時に異なるモデルサイズに適応させる簡単なアプローチを提供する。本研究が多言語の事前学習モデルにおける構造化プルーニングの研究の空白を埋め、将来の研究に光を当てることを期待している。"}
{"title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models", "url": "https://aclanthology.org/2022.acl-long.131/", "abstract": "Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer’s disease (AD). However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research. As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models’ perplexities on language from cognitively healthy and impaired individuals. This technique approaches state-of-the-art performance on text data from a widely used “Cookie Theft” picture description task, and unlike established alternatives also generalizes well to spontaneous conversations. Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies. Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "GPT-D：人工ニューラル言語モデルの意図的な劣化による認知症関連言語異常の誘発", "jabstract": "ディープラーニング（DL）技術は、大量のモデルパラメータを微調整することにより、認知的に健康な個人が生成した言語とアルツハイマー病（AD）の個人が生成した言語を識別するタスクにおいて、印象的な性能を発揮しています。しかし、研究用に公開されている小規模な参照セットを超えて一般化する能力については、疑問が残っています。モデルパラメータを直接フィットする代わりに、我々は、一般的な英語テキストで事前学習されたTransformer DLモデル（GPT-2）と、自己の人工的に劣化したバージョン（GPT-D）をペアリングし、認知的に健康な人々と障害を持つ人々の言語に対するこれら2つのモデルのパープレキシティの比率を計算する新しい方法を提案します。この技術は、広く使用されている「Cookie Theft」の画像説明タスクのテキストデータにおいて、最新の性能に近づいており、確立された代替手段とは異なり、自発的な会話にもよく一般化します。さらに、GPT-Dは、ADに関連する言語的異常を誘発する特性を持つテキストを生成し、我々の研究は、生成的ニューラル言語モデルの内部機能、それらが生成する言語、そして認知症が人間の話し言葉と言語特性に与える有害な影響の関係をより良く理解するための一歩となります。"}
{"title": "An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.132/", "abstract": "Recent work has shown pre-trained language models capture social biases from the large amounts of text they are trained on. This has attracted attention to developing techniques that mitigate such biases. In this work, we perform an empirical survey of five recently proposed bias mitigation techniques: Counterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias, and SentenceDebias. We quantify the effectiveness of each technique using three intrinsic bias benchmarks while also measuring the impact of these techniques on a model’s language modeling ability, as well as its performance on downstream NLU tasks. We experimentally find that: (1) Self-Debias is the strongest debiasing technique, obtaining improved scores on all bias benchmarks; (2) Current debiasing techniques perform less consistently when mitigating non-gender biases; And (3) improvements on bias benchmarks such as StereoSet and CrowS-Pairs by using debiasing strategies are often accompanied by a decrease in language modeling ability, making it difficult to determine whether the bias mitigation was effective.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルの偏見除去技術の有効性に関する実証調査", "jabstract": "最近の研究により、事前学習された言語モデルが訓練に使用された大量のテキストから社会的なバイアスを捉えることが示されています。これにより、そのようなバイアスを緩和する技術を開発することに注目が集まっています。本研究では、Counterfactual Data Augmentation（CDA）、Dropout、Iterative Nullspace Projection、Self-Debias、SentenceDebiasの5つの最近提案されたバイアス緩和技術の実証調査を行います。我々は、3つの内在的なバイアスベンチマークを用いて各技術の効果を定量化し、モデルの言語モデリング能力、およびダウンストリームのNLUタスクのパフォーマンスにも影響を与えることを測定します。我々は以下のように実験的に発見しました：（1）Self-Debiasは最も強力なバイアス緩和技術であり、すべてのバイアスベンチマークで改善されたスコアを獲得します。 （2）現在のバイアス緩和技術は、非ジェンダーのバイアスを緩和する際に一貫してパフォーマンスが低下します。そして、（3）StereoSetやCrowS-Pairsなどのバイアスベンチマークの改善は、バイアス緩和戦略の使用によってしばしば言語モデリング能力の低下とともに伴います。そのため、バイアス緩和が効果的であったかどうかを判断することが困難になります。"}
{"title": "Exploring and Adapting Chinese GPT to Pinyin Input Method", "url": "https://aclanthology.org/2022.acl-long.133/", "abstract": "While GPT has become the de-facto method for text generation tasks, its application to pinyin input method remains unexplored.In this work, we make the first exploration to leverage Chinese GPT for pinyin input method.We find that a frozen GPT achieves state-of-the-art performance on perfect pinyin.However, the performance drops dramatically when the input includes abbreviated pinyin.A reason is that an abbreviated pinyin can be mapped to many perfect pinyin, which links to even larger number of Chinese characters.We mitigate this issue with two strategies,including enriching the context with pinyin and optimizing the training process to help distinguish homophones. To further facilitate the evaluation of pinyin input method, we create a dataset consisting of 270K instances from fifteen domains.Results show that our approach improves the performance on abbreviated pinyin across all domains.Model analysis demonstrates that both strategiescontribute to the performance boost.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "中国語GPTのピンイン入力法への適応と探索", "jabstract": "GPTはテキスト生成タスクにおいてデファクトな手法となっていますが、そのピンイン入力法への応用は未だ未開拓の領域です。本研究では、中国語のGPTをピンイン入力法に活用する初めての試みを行いました。その結果、凍結されたGPTは完全なピンインにおいて最高の性能を発揮することがわかりました。しかし、略語のピンインが含まれる場合、性能が劇的に低下することがあります。その理由は、略語のピンインは多くの完全なピンインにマッピングされるため、さらに多くの中国語の文字にリンクすることができるからです。この問題を緩和するために、ピンインを豊富に含めた文脈を用いたり、同音異義語を区別するためのトレーニングプロセスを最適化するなどの2つの戦略を採用しました。さらに、ピンイン入力法の評価を促進するために、15のドメインから270Kのインスタンスで構成されるデータセットを作成しました。その結果、我々のアプローチはすべてのドメインにおいて略語のピンインの性能を向上させることができました。モデル分析により、両方の戦略が性能向上に貢献していることが示されました。"}
{"title": "Enhancing Cross-lingual Natural Language Inference by Prompt-learning from Cross-lingual Templates", "url": "https://aclanthology.org/2022.acl-long.134/", "abstract": "Cross-lingual natural language inference (XNLI) is a fundamental task in cross-lingual natural language understanding. Recently this task is commonly addressed by pre-trained cross-lingual language models. Existing methods usually enhance pre-trained language models with additional data, such as annotated parallel corpora. These additional data, however, are rare in practice, especially for low-resource languages. Inspired by recent promising results achieved by prompt-learning, this paper proposes a novel prompt-learning based framework for enhancing XNLI. It reformulates the XNLI problem to a masked language modeling problem by constructing cloze-style questions through cross-lingual templates. To enforce correspondence between different languages, the framework augments a new question for every question using a sampled template in another language and then introduces a consistency loss to make the answer probability distribution obtained from the new question as similar as possible with the corresponding distribution obtained from the original question. Experimental results on two benchmark datasets demonstrate that XNLI models enhanced by our proposed framework significantly outperform original ones under both the full-shot and few-shot cross-lingual transfer settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「クロスリンガル・ナチュラルランゲージ・インフェランスを、クロスリンガル・テンプレートからのプロンプト学習によって強化すること」についての論文の要旨です。", "jabstract": "クロスリンガル自然言語推論（XNLI）は、クロスリンガル自然言語理解における基本的なタスクです。最近、このタスクは、事前学習されたクロスリンガル言語モデルによって一般的に対処されています。既存の方法では、注釈付き平行コーパスなどの追加データを使用して、事前学習された言語モデルを強化することが一般的です。しかし、これらの追加データは、特に低リソース言語にとっては実践的にはまれです。最近の有望な結果に触発され、本論文では、XNLIを強化するための新しいプロンプト学習ベースのフレームワークを提案します。このフレームワークは、クロスリンガルテンプレートを使用してクローズスタイルの質問を構築することにより、XNLI問題をマスクされた言語モデリング問題に再定式化します。異なる言語間の対応を強制するために、フレームワークは、別の言語のサンプルされたテンプレートを使用して新しい質問を拡張し、その後、一貫性損失を導入して、新しい質問から得られる答えの確率分布を、元の質問から得られる対応する分布とできるだけ似たものにします。2つのベンチマークデータセットでの実験結果は、提案されたフレームワークによって強化されたXNLIモデルが、完全ショットおよびフューショットのクロスリンガル転送設定の両方で、元のモデルよりも有意に優れていることを示しています。"}
{"title": "Sense Embeddings are also Biased – Evaluating Social Biases in Static and Contextualised Sense Embeddings", "url": "https://aclanthology.org/2022.acl-long.135/", "abstract": "Sense embedding learning methods learn different embeddings for the different senses of an ambiguous word. One sense of an ambiguous word might be socially biased while its other senses remain unbiased. In comparison to the numerous prior work evaluating the social biases in pretrained word embeddings, the biases in sense embeddings have been relatively understudied. We create a benchmark dataset for evaluating the social biases in sense embeddings and propose novel sense-specific bias evaluation measures. We conduct an extensive evaluation of multiple static and contextualised sense embeddings for various types of social biases using the proposed measures. Our experimental results show that even in cases where no biases are found at word-level, there still exist worrying levels of social biases at sense-level, which are often ignored by the word-level bias evaluation measures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "センス埋め込みも偏っている- 静的およびコンテキスト化されたセンス埋め込みにおける社会的偏見の評価", "jabstract": "意味埋め込み学習法は、曖昧な単語の異なる意味に対して異なる埋め込みを学習する。曖昧な単語の一つの意味は社会的に偏っている可能性があり、他の意味は偏りがない。事前学習された単語埋め込みの社会的偏りを評価する先行研究に比べ、意味埋め込みの偏りについては比較的研究が少ない。我々は、意味埋め込みの社会的偏りを評価するためのベンチマークデータセットを作成し、新しい意味特異的バイアス評価尺度を提案する。提案された尺度を用いて、複数の静的および文脈依存型の意味埋め込みを、様々な種類の社会的バイアスについて評価する。実験結果は、単語レベルで偏りが見つからない場合でも、意味レベルで心配すべき社会的偏りが存在することを示しており、これらはしばしば単語レベルのバイアス評価尺度によって無視されている。"}
{"title": "Hybrid Semantics for Goal-Directed Natural Language Generation", "url": "https://aclanthology.org/2022.acl-long.136/", "abstract": "We consider the problem of generating natural language given a communicative goal and a world description. We ask the question: is it possible to combine complementary meaning representations to scale a goal-directed NLG system without losing expressiveness? In particular, we consider using two meaning representations, one based on logical semantics and the other based on distributional semantics. We build upon an existing goal-directed generation system, S-STRUCT, which models sentence generation as planning in a Markov decision process. We develop a hybrid approach, which uses distributional semantics to quickly and imprecisely add the main elements of the sentence and then uses first-order logic based semantics to more slowly add the precise details. We find that our hybrid method allows S-STRUCT’s generation to scale significantly better in early phases of generation and that the hybrid can often generate sentences with the same quality as S-STRUCT in substantially less time. However, we also observe and give insight into cases where the imprecision in distributional semantics leads to generation that is not as good as using pure logical semantics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "目的指向型自然言語生成のためのハイブリッドセマンティクス", "jabstract": "私たちは、コミュニケーションの目的と世界の説明が与えられた場合に自然言語を生成する問題を考えます。私たちは、補完的な意味表現を組み合わせて、表現力を失うことなく目的指向のNLGシステムをスケーリングすることが可能かどうかという問いに答えます。特に、論理的意味と分布的意味に基づく2つの意味表現を使用することを考えます。私たちは、マルコフ決定過程で計画として文生成をモデル化する既存の目的指向の生成システムS-STRUCTを拡張します。私たちは、分布的意味を使用して文の主要な要素を迅速かつ不正確に追加し、その後、一階論理に基づく意味を使用して正確な詳細をよりゆっくりと追加するハイブリッドアプローチを開発します。私たちは、ハイブリッド手法により、S-STRUCTの生成が初期段階で大幅にスケーリングされ、ハイブリッドはしばしばS-STRUCTと同じ品質の文を大幅に短い時間で生成できることを発見します。ただし、分布的意味の不正確さが純粋な論理的意味を使用するよりも良くない生成につながる場合があることにも気付き、洞察を与えます。"}
{"title": "Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization", "url": "https://aclanthology.org/2022.acl-long.137/", "abstract": "Clinical trials offer a fundamental opportunity to discover new treatments and advance the medical knowledge. However, the uncertainty of the outcome of a trial can lead to unforeseen costs and setbacks. In this study, we propose a new method to predict the effectiveness of an intervention in a clinical trial. Our method relies on generating an informative summary from multiple documents available in the literature about the intervention under study. Specifically, our method first gathers all the abstracts of PubMed articles related to the intervention. Then, an evidence sentence, which conveys information about the effectiveness of the intervention, is extracted automatically from each abstract. Based on the set of evidence sentences extracted from the abstracts, a short summary about the intervention is constructed. Finally, the produced summaries are used to train a BERT-based classifier, in order to infer the effectiveness of an intervention. To evaluate our proposed method, we introduce a new dataset which is a collection of clinical trials together with their associated PubMed articles. Our experiments, demonstrate the effectiveness of producing short informative summaries and using them to predict the effectiveness of an intervention.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n多文書要約を通じた臨床試験における介入承認の予測", "jabstract": "臨床試験は、新しい治療法を発見し、医学の知識を進歩させるための基本的な機会を提供します。しかし、試験の結果の不確実性は、予期せぬコストや後退を引き起こす可能性があります。本研究では、臨床試験における介入の効果を予測する新しい方法を提案します。当社の方法は、研究対象の介入に関する文献から複数の文書を収集し、情報を伝える情報的な要約を生成することに依存しています。具体的には、当社の方法は、最初に介入に関連するPubMed記事のすべての要約を収集します。次に、各要約から介入の効果に関する情報を伝えるエビデンス文が自動的に抽出されます。要約から抽出されたエビデンス文のセットに基づいて、介入に関する短い要約が構築されます。最後に、生成された要約を使用して、介入の効果を推測するためにBERTベースの分類器をトレーニングします。当社の提案された方法を評価するために、臨床試験とそれに関連するPubMed記事のコレクションである新しいデータセットを紹介します。当社の実験は、短い情報的な要約を生成し、それらを使用して介入の効果を予測することの効果を示しています。"}
{"title": "BiTIIMT: A Bilingual Text-infilling Method for Interactive Machine Translation", "url": "https://aclanthology.org/2022.acl-long.138/", "abstract": "Interactive neural machine translation (INMT) is able to guarantee high-quality translations by taking human interactions into account. Existing IMT systems relying on lexical constrained decoding (LCD) enable humans to translate in a flexible translation order beyond the left-to-right. However, they typically suffer from two significant limitations in translation efficiency and quality due to the reliance on LCD. In this work, we propose a novel BiTIIMT system, Bilingual Text-Infilling for Interactive Neural Machine Translation. The key idea to BiTIIMT is Bilingual Text-infilling (BiTI) which aims to fill missing segments in a manually revised translation for a given source sentence. We propose a simple yet effective solution by casting this task as a sequence-to-sequence task. In this way, our system performs decoding without explicit constraints and makes full use of revised words for better translation prediction. Experiment results show that BiTiIMT performs significantly better and faster than state-of-the-art LCD-based IMT on three translation tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BiTIIMT：対話型機械翻訳のためのバイリンガルテキスト補完手法", "jabstract": "インタラクティブニューラルマシン翻訳（INMT）は、人間の相互作用を考慮に入れることで高品質の翻訳を保証することができます。既存のレキシカル制約デコーディング（LCD）に依存するIMTシステムは、左から右への柔軟な翻訳順序で人間が翻訳することを可能にします。しかし、LCDに依存するため、翻訳効率と品質の2つの重要な制限があります。本研究では、バイリンガルテキストインフィリングを提案し、インタラクティブニューラルマシン翻訳のためのバイリンガルテキストインフィリングシステム（BiTIIMT）を提案します。 BiTIIMTのキーとなるアイデアは、与えられたソース文の手動で修正された翻訳の欠落したセグメントを埋めることを目的とするバイリンガルテキストインフィリング（BiTI）です。このタスクをシーケンスツーシーケンスタスクとしてキャストすることにより、当社のシステムは明示的な制約なしでデコードを実行し、改訂された単語を完全に活用してより良い翻訳予測を行います。実験結果は、BiTiIMTが3つの翻訳タスクで最新のLCDベースのIMTよりも優れており、より高速であることを示しています。"}
{"title": "Distributionally Robust Finetuning BERT for Covariate Drift in Spoken Language Understanding", "url": "https://aclanthology.org/2022.acl-long.139/", "abstract": "In this study, we investigate robustness against covariate drift in spoken language understanding (SLU). Covariate drift can occur in SLUwhen there is a drift between training and testing regarding what users request or how they request it. To study this we propose a method that exploits natural variations in data to create a covariate drift in SLU datasets. Experiments show that a state-of-the-art BERT-based model suffers performance loss under this drift. To mitigate the performance loss, we investigate distributionally robust optimization (DRO) for finetuning BERT-based models. We discuss some recent DRO methods, propose two new variants and empirically show that DRO improves robustness under drift.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n発話言語理解における共変量ドリフトに対する分布的に堅牢なBERTの微調整", "jabstract": "この研究では、音声言語理解（SLU）における共変量ドリフトに対する頑健性を調査します。共変量ドリフトは、ユーザーが何を要求し、どのように要求するかに関して、トレーニングとテストの間にドリフトがある場合にSLUで発生する可能性があります。この問題を研究するために、データの自然な変動を利用してSLUデータセットで共変量ドリフトを作成する方法を提案します。実験結果から、最新のBERTベースモデルはこのドリフトにより性能が低下することがわかりました。性能低下を緩和するために、BERTベースモデルの微調整に分布的に頑健な最適化（DRO）を調査します。最近のDRO手法について説明し、2つの新しいバリアントを提案し、DROがドリフトに対する頑健性を向上させることを実証します。"}
{"title": "Enhancing Chinese Pre-trained Language Model via Heterogeneous Linguistics Graph", "url": "https://aclanthology.org/2022.acl-long.140/", "abstract": "Chinese pre-trained language models usually exploit contextual character information to learn representations, while ignoring the linguistics knowledge, e.g., word and sentence information. Hence, we propose a task-free enhancement module termed as Heterogeneous Linguistics Graph (HLG) to enhance Chinese pre-trained language models by integrating linguistics knowledge. Specifically, we construct a hierarchical heterogeneous graph to model the characteristics linguistics structure of Chinese language, and conduct a graph-based method to summarize and concretize information on different granularities of Chinese linguistics hierarchies.Experimental results demonstrate our model has the ability to improve the performance of vanilla BERT, BERTwwm and ERNIE 1.0 on 6 natural language processing tasks with 10 benchmark datasets. Further, the detailed experimental analyses have proven that this kind of modelization achieves more improvements compared with previous strong baseline MWA. Meanwhile, our model introduces far fewer parameters (about half of MWA) and the training/inference speed is about 7x faster than MWA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約の以下の文を日本語に翻訳してください：\n\n異種言語グラフを介して中国語事前学習言語モデルを強化する", "jabstract": "中国の事前学習言語モデルは、しばしば文脈的な文字情報を利用して表現を学習しますが、単語や文の情報などの言語学的な知識を無視しています。そこで、私たちは異種言語グラフ（HLG）と呼ばれるタスクフリーの強化モジュールを提案し、言語学的な知識を統合して中国の事前学習言語モデルを強化します。具体的には、中国語の言語学的構造を特徴づける階層的な異種グラフを構築し、中国語の言語学的階層の異なる粒度の情報を要約して具体化するグラフベースの手法を実施します。実験結果は、私たちのモデルが6つの自然言語処理タスクと10のベンチマークデータセットでバニラBERT、BERTwwm、ERNIE 1.0の性能を向上させる能力を持っていることを示しています。さらに、詳細な実験分析は、この種のモデル化が以前の強力なベースラインMWAと比較してより多くの改善を実現していることを証明しています。一方、私たちのモデルは、MWAの約半分のパラメータしか導入せず、トレーニング/推論速度はMWAの約7倍速いです。"}
{"title": "Divide and Denoise: Learning from Noisy Labels in Fine-Grained Entity Typing with Cluster-Wise Loss Correction", "url": "https://aclanthology.org/2022.acl-long.141/", "abstract": "Fine-grained Entity Typing (FET) has made great progress based on distant supervision but still suffers from label noise. Existing FET noise learning methods rely on prediction distributions in an instance-independent manner, which causes the problem of confirmation bias. In this work, we propose a clustering-based loss correction framework named Feature Cluster Loss Correction (FCLC), to address these two problems. FCLC first train a coarse backbone model as a feature extractor and noise estimator. Loss correction is then applied to each feature cluster, learning directly from the noisy labels. Experimental results on three public datasets show that FCLC achieves the best performance over existing competitive systems. Auxiliary experiments further demonstrate that FCLC is stable to hyperparameters and it does help mitigate confirmation bias. We also find that in the extreme case of no clean data, the FCLC framework still achieves competitive performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「分割とノイズ除去：クラスタ単位の損失修正による細分化されたエンティティタイピングにおけるノイズラベルからの学習」という論文の要約文です。", "jabstract": "Fine-grained Entity Typing（FET）は、遠隔監視に基づいて大きな進歩を遂げていますが、ラベルノイズに苦しんでいます。既存のFETノイズ学習方法は、インスタンスに依存しない予測分布に依存しており、確認バイアスの問題を引き起こします。本研究では、これら2つの問題に対処するために、クラスタリングベースの損失補正フレームワークであるFeature Cluster Loss Correction（FCLC）を提案します。FCLCは、まず粗いバックボーンモデルを特徴抽出器およびノイズ推定器としてトレーニングします。次に、各特徴クラスタに損失補正が適用され、ノイズのあるラベルから直接学習します。3つの公開データセットでの実験結果は、FCLCが既存の競合システムよりも最高の性能を発揮することを示しています。補助実験はさらに、FCLCがハイパーパラメータに対して安定しており、確認バイアスを緩和するのに役立つことを示しています。また、クリーンなデータがない極端な場合でも、FCLCフレームワークは競合力のあるパフォーマンスを発揮することがわかりました。"}
{"title": "Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation", "url": "https://aclanthology.org/2022.acl-long.142/", "abstract": "The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications. Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables. Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure robustness of Text-to-SQL models. Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs. All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing significant room of improvement. To defense against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach brings models best robustness improvement against ATP, while also substantially boost model robustness against NL-side perturbations. We will release ADVETA and code to facilitate future research.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自然的かつ現実的な敵対的なテーブルの摂動に対するテキストからSQLモデルの堅牢性に向けて", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nText-to-SQLパーサーの堅牢性は、敵対的な摂動に対する耐性が高いことが非常に重要であり、高信頼性のあるアプリケーションを提供する上で重要な役割を果たします。これまでの研究は、自然言語の質問側の摂動に焦点を当て、表の変動を無視してきました。この問題に着目し、我々はAdversarial Table Perturbation（ATP）を提案し、Text-to-SQLモデルの堅牢性を測定するための新しい攻撃パラダイムとしています。この提案に従い、自然で現実的なATPを特徴とする最初の堅牢性評価ベンチマークであるADVETAを作成しました。すべてのテストされた最新のモデルは、ADVETAで劇的な性能低下を経験し、改善の余地があることが明らかになりました。ATPに対抗するために、表データのより良い文脈化に適したシステマティックな敵対的トレーニング例生成フレームワークを構築しました。実験の結果、我々のアプローチは、ATPに対するモデルの最高の堅牢性向上をもたらし、NL側の摂動に対するモデルの堅牢性も大幅に向上させました。ADVETAとコードを公開し、今後の研究を促進することを目指します。"}
{"title": "Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.143/", "abstract": "Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called catastrophic forgetting, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem imbalanced training. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "持続的学習を超えた壊滅的忘却の克服：ニューラル機械翻訳のバランスの取れたトレーニング", "jabstract": "ニューラルネットワークは、動的なデータ分布から複数のタスクを順次学習する際に、以前に学習した知識を徐々に忘れる傾向がある。この問題は、ニューラルネットワークの継続的学習における基本的な課題である「カタストロフィック・フォーゲッティング」と呼ばれる。本研究では、カタストロフィック・フォーゲッティングが継続的学習に限らず、従来の静的なトレーニングにも影響を与えることを観察した。特に、ニューラル機械翻訳モデルなどのニューラルネットワークは、静的なトレーニングセットから学習していてもカタストロフィック・フォーゲッティングに苦しんでいる。具体的には、最終モデルはトレーニングサンプルに不均衡な注意を払い、最近公開されたサンプルが以前のサンプルよりも多くの注意を引き付ける。その根本的な原因は、トレーニングサンプルが各モデル更新でバランスの取れたトレーニングを受けないため、この問題を「不均衡トレーニング」と名付けた。この問題を緩和するために、我々は「補完的オンライン知識蒸留（COKD）」を提案し、特定のデータ順序でトレーニングされた動的に更新される教師モデルを使用して、学生モデルに補完的な知識を反復的に提供する。複数の機械翻訳タスクでの実験結果は、我々の方法が不均衡トレーニングの問題を成功裏に緩和し、強力なベースラインシステムに比べて実質的な改善を達成していることを示している。"}
{"title": "Metaphors in Pre-Trained Language Models: Probing and Generalization Across Datasets and Languages", "url": "https://aclanthology.org/2022.acl-long.144/", "abstract": "Human languages are full of metaphorical expressions. Metaphors help people understand the world by connecting new concepts and domains to more familiar ones. Large pre-trained language models (PLMs) are therefore assumed to encode metaphorical knowledge useful for NLP systems. In this paper, we investigate this hypothesis for PLMs, by probing metaphoricity information in their encodings, and by measuring the cross-lingual and cross-dataset generalization of this information. We present studies in multiple metaphor detection datasets and in four languages (i.e., English, Spanish, Russian, and Farsi). Our extensive experiments suggest that contextual representations in PLMs do encode metaphorical knowledge, and mostly in their middle layers. The knowledge is transferable between languages and datasets, especially when the annotation is consistent across training and testing sets. Our findings give helpful insights for both cognitive and NLP scientists.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルにおけるメタファー：データセットと言語を横断した探査と汎化", "jabstract": "人間の言語は比喩的な表現で満ちています。比喩は、新しい概念や領域をより馴染みのあるものに接続することで、人々が世界を理解するのを助けます。したがって、大規模な事前学習言語モデル（PLM）には、NLPシステムに役立つ比喩的な知識がエンコードされていると仮定されています。本論文では、PLMの比喩性情報を調査し、この情報の言語間およびデータセット間の汎化を測定することで、この仮説を検証します。私たちは、複数の比喩検出データセットと英語、スペイン語、ロシア語、ペルシャ語の4つの言語で研究を行いました。私たちの広範な実験は、PLMの文脈表現が比喩的な知識をエンコードしており、そのほとんどが中間層にあることを示唆しています。アノテーションがトレーニングセットとテストセットで一貫している場合、知識は言語間およびデータセット間で転送可能です。私たちの発見は、認知科学者とNLP科学者の両方にとって有益な洞察を提供します。"}
{"title": "Discrete Opinion Tree Induction for Aspect-based Sentiment Analysis", "url": "https://aclanthology.org/2022.acl-long.145/", "abstract": "Dependency trees have been intensively used with graph neural networks for aspect-based sentiment classification. Though being effective, such methods rely on external dependency parsers, which can be unavailable for low-resource languages or perform worse in low-resource domains. In addition, dependency trees are also not optimized for aspect-based sentiment classification. In this paper, we propose an aspect-specific and language-agnostic discrete latent opinion tree model as an alternative structure to explicit dependency trees. To ease the learning of complicated structured latent variables, we build a connection between aspect-to-context attention scores and syntactic distances, inducing trees from the attention scores. Results on six English benchmarks and one Chinese dataset show that our model can achieve competitive performance and interpretability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「アスペクトベースの感情分析のための離散的な意見ツリー誘導」という論文の要約文です。", "jabstract": "依存構造木は、アスペクトベースの感情分類においてグラフニューラルネットワークと強く結びついてきた。これらの方法は効果的であるが、外部の依存構造解析器に依存しており、低リソース言語では利用できない場合がある。また、依存構造木はアスペクトベースの感情分類に最適化されていない。本論文では、明示的な依存構造木の代替構造として、アスペクトに特化した言語非依存の離散潜在意見木モデルを提案する。複雑な構造化された潜在変数の学習を容易にするために、アスペクトからコンテキストへの注意スコアと構文的距離の関係を構築し、注意スコアから木を導出する。英語の6つのベンチマークと中国語の1つのデータセットでの結果は、当社のモデルが競争力のある性能と解釈可能性を発揮できることを示している。"}
{"title": "Investigating Non-local Features for Neural Constituency Parsing", "url": "https://aclanthology.org/2022.acl-long.146/", "abstract": "Thanks to the strong representation power of neural encoders, neural chart-based parsers have achieved highly competitive performance by using local features. Recently, it has been shown that non-local features in CRF structures lead to improvements. In this paper, we investigate injecting non-local features into the training process of a local span-based parser, by predicting constituent n-gram non-local patterns and ensuring consistency between non-local patterns and local constituents. Results show that our simple method gives better results than the self-attentive parser on both PTB and CTB. Besides, our method achieves state-of-the-art BERT-based performance on PTB (95.92 F1) and strong performance on CTB (92.31 F1). Our parser also outperforms the self-attentive parser in multi-lingual and zero-shot cross-domain settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "神経構成解析のための非局所的特徴の調査", "jabstract": "ニューラルエンコーダーの強力な表現力のおかげで、ニューラルチャートベースのパーサーは、ローカルな特徴を使用して非常に競争力のあるパフォーマンスを達成しています。最近、CRF構造の非ローカルな特徴が改善につながることが示されています。本論文では、構成要素n-gram非ローカルパターンを予測し、非ローカルパターンとローカル構成要素の整合性を確保することにより、ローカルスパンベースのパーサーのトレーニングプロセスに非ローカル特徴を注入することを調査します。結果は、当社のシンプルな方法がPTBとCTBの両方で自己注意パーサーよりも優れた結果を与えることを示しています。さらに、当社の方法は、PTB（95.92 F1）で最新のBERTベースのパフォーマンスを達成し、CTB（92.31 F1）で強力なパフォーマンスを発揮します。当社のパーサーは、多言語およびゼロショットクロスドメイン設定でも、自己注意パーサーよりも優れたパフォーマンスを発揮します。"}
{"title": "Learning from Sibling Mentions with Scalable Graph Inference in Fine-Grained Entity Typing", "url": "https://aclanthology.org/2022.acl-long.147/", "abstract": "In this paper, we firstly empirically find that existing models struggle to handle hard mentions due to their insufficient contexts, which consequently limits their overall typing performance. To this end, we propose to exploit sibling mentions for enhancing the mention representations.Specifically, we present two different metrics for sibling selection and employ an attentive graph neural network to aggregate information from sibling mentions. The proposed graph model is scalable in that unseen test mentions are allowed to be added as new nodes for inference.Exhaustive experiments demonstrate the effectiveness of our sibling learning strategy, where our model outperforms ten strong baselines. Moreover, our experiments indeed prove the superiority of sibling mentions in helping clarify the types for hard mentions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「細分化されたエンティティタイピングにおいて、スケーラブルなグラフ推論を用いた兄弟言及からの学習」についての論文の要約文です。以下、日本語に翻訳してください。\n\n- Learning from Sibling Mentions with Scalable Graph Inference in Fine-Grained Entity Typing\n- 「細分化されたエンティティタイピングにおいて、スケーラブルなグラフ推論を用いた兄弟言及からの学習」", "jabstract": "本論文では、まず、既存のモデルが不十分な文脈のためにハードメンションを処理するのに苦労していることを実証的に発見し、その結果、全体的なタイピング性能が制限されていることを示します。そのため、私たちは、メンション表現を強化するために兄弟メンションを利用することを提案します。具体的には、兄弟選択のための2つの異なるメトリックを提示し、兄弟メンションから情報を集約するために注意グラフニューラルネットワークを使用します。提案されたグラフモデルはスケーラブルであり、未知のテストメンションを推論のための新しいノードとして追加することができます。徹底的な実験は、私たちの兄弟学習戦略の効果を実証し、私たちのモデルが10の強力なベースラインを上回ることを示しています。さらに、私たちの実験は、ハードメンションのタイプを明確にするのに兄弟メンションが優れていることを実証しています。"}
{"title": "A Variational Hierarchical Model for Neural Cross-Lingual Summarization", "url": "https://aclanthology.org/2022.acl-long.148/", "abstract": "The goal of the cross-lingual summarization (CLS) is to convert a document in one language (e.g., English) to a summary in another one (e.g., Chinese). The CLS task is essentially the combination of machine translation (MT) and monolingual summarization (MS), and thus there exists the hierarchical relationship between MT&MS and CLS. Existing studies on CLS mainly focus on utilizing pipeline methods or jointly training an end-to-end model through an auxiliary MT or MS objective. However, it is very challenging for the model to directly conduct CLS as it requires both the abilities to translate and summarize. To address this issue, we propose a hierarchical model for the CLS task, based on the conditional variational auto-encoder. The hierarchical model contains two kinds of latent variables at the local and global levels, respectively. At the local level, there are two latent variables, one for translation and the other for summarization. As for the global level, there is another latent variable for cross-lingual summarization conditioned on the two local-level variables. Experiments on two language directions (English-Chinese) verify the effectiveness and superiority of the proposed approach. In addition, we show that our model is able to generate better cross-lingual summaries than comparison models in the few-shot setting.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラルクロスリンガルサマリゼーションのための変分階層モデル", "jabstract": "クロスリンガル要約（CLS）の目的は、ある言語（例えば英語）の文書を別の言語（例えば中国語）の要約に変換することです。CLSタスクは、基本的に機械翻訳（MT）と単一言語要約（MS）の組み合わせであり、MT＆MSとCLSの階層的な関係が存在します。CLSに関する既存の研究は、主にパイプライン法を利用するか、補助的なMTまたはMS目的を通じてエンドツーエンドモデルを共同でトレーニングすることに焦点を当てています。しかし、CLSを直接実行するには、翻訳と要約の両方の能力が必要であるため、モデルにとって非常に困難です。この問題に対処するために、我々は条件付き変分オートエンコーダに基づくCLSタスクの階層モデルを提案します。階層モデルには、それぞれローカルレベルとグローバルレベルの2種類の潜在変数があります。ローカルレベルでは、翻訳と要約のための2つの潜在変数があります。グローバルレベルでは、2つのローカルレベル変数に依存するクロスリンガル要約のための別の潜在変数があります。英語-中国語の2つの言語方向での実験により、提案手法の有効性と優位性が検証されました。さらに、我々のモデルがフューショット設定で比較モデルよりも優れたクロスリンガル要約を生成できることを示しました。"}
{"title": "On the Robustness of Question Rewriting Systems to Questions of Varying Hardness", "url": "https://aclanthology.org/2022.acl-long.149/", "abstract": "In conversational question answering (CQA), the task of question rewriting (QR) in context aims to rewrite a context-dependent question into an equivalent self-contained question that gives the same answer. In this paper, we are interested in the robustness of a QR system to questions varying in rewriting hardness or difficulty. Since there is a lack of questions classified based on their rewriting hardness, we first propose a heuristic method to automatically classify questions into subsets of varying hardness, by measuring the discrepancy between a question and its rewrite. To find out what makes questions hard or easy for rewriting, we then conduct a human evaluation to annotate the rewriting hardness of questions. Finally, to enhance the robustness of QR systems to questions of varying hardness, we propose a novel learning framework for QR that first trains a QR model independently on each subset of questions of a certain level of hardness, then combines these QR models as one joint model for inference. Experimental results on two datasets show that our framework improves the overall performance compared to the baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "質問の難易度に対する質問書き換えシステムの堅牢性について", "jabstract": "会話型質問応答（CQA）において、文脈に依存する質問を同じ答えを与える自己完結型の質問に書き換える質問書き換え（QR）のタスクがある。本論文では、QRシステムが書き換えの難易度によって変化する質問に対してどの程度堅牢であるかに興味がある。書き換えの難易度に基づいて分類された質問が不足しているため、質問とその書き換えの差異を測定することで、質問を難易度に応じたサブセットに自動的に分類するヒューリスティックな方法を提案する。次に、人間の評価を行い、質問の書き換えの難易度を注釈付けすることで、質問を書き換えるのが難しいか簡単かを調べる。最後に、書き換えの難易度に応じた質問のサブセットごとにQRモデルを独立してトレーニングし、それらを組み合わせて推論するための新しい学習フレームワークを提案し、QRシステムの堅牢性を向上させる。2つのデータセットでの実験結果は、提案手法がベースラインに比べて全体的な性能を向上させることを示している。"}
{"title": "OpenHands: Making Sign Language Recognition Accessible with Pose-based Pretrained Models across Languages", "url": "https://aclanthology.org/2022.acl-long.150/", "abstract": "AI technologies for Natural Languages have made tremendous progress recently. However, commensurate progress has not been made on Sign Languages, in particular, in recognizing signs as individual words or as complete sentences. We introduce OpenHands, a library where we take four key ideas from the NLP community for low-resource languages and apply them to sign languages for word-level recognition. First, we propose using pose extracted through pretrained models as the standard modality of data in this work to reduce training time and enable efficient inference, and we release standardized pose datasets for different existing sign language datasets. Second, we train and release checkpoints of 4 pose-based isolated sign language recognition models across 6 languages (American, Argentinian, Chinese, Greek, Indian, and Turkish), providing baselines and ready checkpoints for deployment. Third, to address the lack of labelled data, we propose self-supervised pretraining on unlabelled data. We curate and release the largest pose-based pretraining dataset on Indian Sign Language (Indian-SL). Fourth, we compare different pretraining strategies and for the first time establish that pretraining is effective for sign language recognition by demonstrating (a) improved fine-tuning performance especially in low-resource settings, and (b) high crosslingual transfer from Indian-SL to few other sign languages. We open-source all models and datasets in OpenHands with a hope that it makes research in sign languages reproducible and more accessible.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "OpenHands：ポーズベースの事前学習モデルを使用して、言語を超えた手話認識をアクセス可能にする。", "jabstract": "自然言語処理のAI技術は最近著しい進歩を遂げています。しかし、手話においては、個々の単語や完全な文として手話を認識することについては、同等の進歩がなされていません。本論文では、NLPコミュニティから4つの主要なアイデアを手話に適用し、低リソース言語のための単語レベルの認識に取り組むためのライブラリであるOpenHandsを紹介します。第一に、事前学習済みモデルから抽出されたポーズを標準的なデータモダリティとして使用し、トレーニング時間を短縮し、効率的な推論を可能にすることを提案し、既存の手話データセットに対して標準化されたポーズデータセットを公開します。第二に、6つの言語（アメリカ、アルゼンチン、中国、ギリシャ、インド、トルコ）にわたる4つのポーズベースの孤立した手話認識モデルのチェックポイントをトレーニングおよび公開し、展開のためのベースラインと準備が整っています。第三に、ラベル付きデータの不足に対処するために、自己教師あり事前学習を提案します。インド手話（Indian-SL）に基づく最大のポーズベースの事前学習データセットを編成し、公開します。第四に、異なる事前学習戦略を比較し、手話認識に対して事前学習が効果的であることを初めて確立し、(a)低リソース環境での特に改善されたファインチューニング性能、および(b)インド-SLから他の手話に高いクロスリンガル転移を示すことによって証明します。OpenHandsのすべてのモデルとデータセットをオープンソース化し、手話に関する研究が再現可能でよりアクセスしやすくなることを願っています。"}
{"title": "bert2BERT: Towards Reusable Pretrained Language Models", "url": "https://aclanthology.org/2022.acl-long.151/", "abstract": "In recent years, researchers tend to pre-train ever-larger language models to explore the upper limit of deep models. However, large language model pre-training costs intensive computational resources, and most of the models are trained from scratch without reusing the existing pre-trained models, which is wasteful. In this paper, we propose bert2BERT, which can effectively transfer the knowledge of an existing smaller pre-trained model to a large model through parameter initialization and significantly improve the pre-training efficiency of the large model. Specifically, we extend the previous function-preserving method proposed in computer vision on the Transformer-based language model, and further improve it by proposing a novel method, advanced knowledge for large model’s initialization. In addition, a two-stage learning method is proposed to further accelerate the pre-training. We conduct extensive experiments on representative PLMs (e.g., BERT and GPT) and demonstrate that (1) our method can save a significant amount of training cost compared with baselines including learning from scratch, StackBERT and MSLT; (2) our method is generic and applicable to different types of pre-trained models. In particular, bert2BERT saves about 45% and 47% computational cost of pre-training BERT\\rm BASE and GPT\\rm BASE by reusing the models of almost their half sizes.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "bert2BERT：再利用可能な事前学習言語モデルに向けて", "jabstract": "近年、研究者は、深層モデルの上限を探索するために、ますます大きな言語モデルを事前学習する傾向にある。しかし、大規模な言語モデルの事前学習には膨大な計算リソースが必要であり、既存の事前学習済みモデルを再利用せずにゼロからモデルを学習することが多いため、無駄が多い。本論文では、既存の小さな事前学習済みモデルの知識を大きなモデルに効果的に転移させることができるbert2BERTを提案し、パラメータの初期化を通じて大規模モデルの事前学習効率を大幅に改善する。具体的には、コンピュータビジョンで提案された以前の関数保存方法をTransformerベースの言語モデルに拡張し、大規模モデルの初期化のための新しい方法であるadvanced knowledgeを提案することで、さらに改善する。さらに、2段階の学習方法を提案し、事前学習をさらに加速する。代表的なPLM（BERTやGPTなど）で広範な実験を行い、（1）学習コストを大幅に節約できること、（2）汎用性があり、異なるタイプの事前学習済みモデルに適用できることを示す。特に、bert2BERTは、ほぼ半分のサイズのモデルを再利用することで、BERT BASEとGPT BASEの事前学習の計算コストをそれぞれ約45％と47％節約することができる。"}
{"title": "Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis", "url": "https://aclanthology.org/2022.acl-long.152/", "abstract": "As an important task in sentiment analysis, Multimodal Aspect-Based Sentiment Analysis (MABSA) has attracted increasing attention inrecent years. However, previous approaches either (i) use separately pre-trained visual and textual models, which ignore the crossmodalalignment or (ii) use vision-language models pre-trained with general pre-training tasks, which are inadequate to identify fine-grainedaspects, opinions, and their alignments across modalities. To tackle these limitations, we propose a task-specific Vision-LanguagePre-training framework for MABSA (VLP-MABSA), which is a unified multimodal encoder-decoder architecture for all the pretrainingand downstream tasks. We further design three types of task-specific pre-training tasks from the language, vision, and multimodalmodalities, respectively. Experimental results show that our approach generally outperforms the state-of-the-art approaches on three MABSA subtasks. Further analysis demonstrates the effectiveness of each pre-training task. The source code is publicly released at https://github.com/NUSTM/VLP-MABSA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語アスペクトベースの感情分析のためのビジョン・ランゲージ・プリトレーニング", "jabstract": "感情分析における重要なタスクである多様なアスペクトベースの感情分析（MABSA）は、近年ますます注目を集めています。しかし、従来のアプローチは、(i) クロスモーダルのアラインメントを無視する別々に事前学習された視覚的およびテキストモデルを使用するか、(ii) 一般的な事前学習タスクで事前学習されたビジョン-言語モデルを使用するため、細かいアスペクト、意見、およびモダリティ間のアラインメントを識別するのに不十分です。これらの制限に対処するために、我々は、すべての事前学習およびダウンストリームタスクのための統一されたマルチモーダルエンコーダーデコーダーアーキテクチャであるタスク固有のビジョン-言語事前学習フレームワークを提案します（VLP-MABSA）。さらに、言語、ビジョン、およびマルチモーダルモダリティから3種類のタスク固有の事前学習タスクを設計します。実験結果は、我々のアプローチが一般的に3つのMABSAサブタスクで最先端のアプローチを上回ることを示しています。さらに分析すると、各事前学習タスクの効果が示されます。ソースコードはhttps://github.com/NUSTM/VLP-MABSAで公開されています。"}
{"title": "“You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions", "url": "https://aclanthology.org/2022.acl-long.153/", "abstract": "Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「タイトルを少し修正することを考えてみてください」：ピアチュータリング相互作用におけるヘッジの識別", "jabstract": "ヘッジは、人間関係の管理に重要な役割を果たしています。ピア・チュータリングでは、低い人間関係を持つダイアドのチューターが指示や否定的なフィードバックの影響を和らげるために、特に使用されます。学習を改善するためにティーンエイジャーとの人間関係を管理するチュータリングエージェントを構築することを目的として、マルチモーダルなピア・チュータリングデータセットを使用して、ヘッジを特定するための計算フレームワークを構築しました。我々は、社会科学の文献からの洞察を統合したアプローチと、事前にトレーニングされたリソースに依存するアプローチを比較しました。我々の最高のパフォーマンスは、既存のベースラインを上回るハイブリッドアプローチによって達成され、解釈が容易です。我々は、モデルの説明可能性ツールを使用して、ピア・チュータリングの会話でヘッジを特徴づける特徴を探索し、いくつかの新しい特徴と、そのようなハイブリッドモデルアプローチの利点を特定しました。"}
{"title": "Efficient Cluster-Based k-Nearest-Neighbor Machine Translation", "url": "https://aclanthology.org/2022.acl-long.154/", "abstract": "k-Nearest-Neighbor Machine Translation (kNN-MT) has been recently proposed as a non-parametric solution for domain adaptation in neural machine translation (NMT). It aims to alleviate the performance degradation of advanced MT systems in translating out-of-domain sentences by coordinating with an additional token-level feature-based retrieval module constructed from in-domain data. Previous studies (Khandelwal et al., 2021; Zheng et al., 2021) have already demonstrated that non-parametric NMT is even superior to models fine-tuned on out-of-domain data. In spite of this success, kNN retrieval is at the expense of high latency, in particular for large datastores. To make it practical, in this paper, we explore a more efficient kNN-MT and propose to use clustering to improve the retrieval efficiency. Concretely, we first propose a cluster-based Compact Network for feature reduction in a contrastive learning manner to compress context features into 90+% lower dimensional vectors. We then suggest a cluster-based pruning solution to filter out 10% 40% redundant nodes in large datastores while retaining translation quality. Our proposed methods achieve better or comparable performance while reducing up to 57% inference latency against the advanced non-parametric MT model on several machine translation benchmarks. Experimental results indicate that the proposed methods maintain the most useful information of the original datastore and the Compact Network shows good generalization on unseen domains. Codes are available at https://github.com/tjunlp-lab/PCKMT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n効率的なクラスタベースのk最近傍法機械翻訳", "jabstract": "k-最近傍機械翻訳（kNN-MT）は、最近、ニューラル機械翻訳（NMT）におけるドメイン適応の非パラメトリックな解決策として提案されています。これは、ドメイン外の文を翻訳する高度なMTシステムの性能低下を、ドメイン内データから構築されたトークンレベルの特徴ベースの検索モジュールと協調することで軽減することを目的としています。以前の研究（Khandelwal et al.、2021; Zheng et al.、2021）では、非パラメトリックNMTがドメイン外データで微調整されたモデルよりも優れていることがすでに示されています。しかし、kNN検索は高いレイテンシーの代償となります。特に大規模なデータストアの場合はそうです。本論文では、より効率的なkNN-MTを探求し、クラスタリングを使用して検索効率を改善することを提案します。具体的には、まず、対照的な学習方法で特徴量を圧縮し、コンテキスト特徴量を90％以上低次元ベクトルに圧縮するためのクラスターベースのコンパクトネットワークを提案します。次に、大規模なデータストアで10％から40％の冗長なノードをフィルタリングするクラスターベースの剪定ソリューションを提案します。これにより、翻訳品質を維持しながら、高度な非パラメトリックMTモデルに比べて最大57％の推論レイテンシーを削減しながら、いくつかの機械翻訳ベンチマークでより良いまたは同等のパフォーマンスを達成します。実験結果は、提案された方法が元のデータストアの最も有用な情報を維持し、コンパクトネットワークが未知のドメインでも良好な汎化性能を示すことを示しています。コードはhttps://github.com/tjunlp-lab/PCKMTで利用可能です。"}
{"title": "Headed-Span-Based Projective Dependency Parsing", "url": "https://aclanthology.org/2022.acl-long.155/", "abstract": "We propose a new method for projective dependency parsing based on headed spans. In a projective dependency tree, the largest subtree rooted at each word covers a contiguous sequence (i.e., a span) in the surface order. We call such a span marked by a root word headed span. A projective dependency tree can be represented as a collection of headed spans. We decompose the score of a dependency tree into the scores of the headed spans and design a novel O(n3) dynamic programming algorithm to enable global training and exact inference. Our model achieves state-of-the-art or competitive results on PTB, CTB, and UD", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nヘッドスパンベースの射影依存解析について", "jabstract": "我々は、ヘッドスパンに基づく射影依存解析の新しい手法を提案する。射影依存木では、各単語を根とする最大の部分木が、表層順序の連続したシーケンス（つまり、スパン）をカバーする。我々は、ルート単語によってマークされたこのようなスパンをヘッドスパンと呼ぶ。射影依存木は、ヘッドスパンの集合として表現できる。我々は、依存木のスコアをヘッドスパンのスコアに分解し、新しいO(n3)の動的計画法アルゴリズムを設計して、グローバルトレーニングと正確な推論を可能にする。我々のモデルは、PTB、CTB、UDで最先端または競争力のある結果を達成している。"}
{"title": "Decoding Part-of-Speech from Human EEG Signals", "url": "https://aclanthology.org/2022.acl-long.156/", "abstract": "This work explores techniques to predict Part-of-Speech (PoS) tags from neural signals measured at millisecond resolution with electroencephalography (EEG) during text reading. We first show that information about word length, frequency and word class is encoded by the brain at different post-stimulus latencies. We then demonstrate that pre-training on averaged EEG data and data augmentation techniques boost PoS decoding accuracy for single EEG trials. Finally, applying optimised temporally-resolved decoding techniques we show that Transformers substantially outperform linear-SVMs on PoS tagging of unigram and bigram data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "人間のEEG信号から品詞をデコードする", "jabstract": "この研究では、脳波計測によるミリ秒単位のニューラルシグナルから、テキスト読解中にPart-of-Speech（PoS）タグを予測する技術を探求しています。まず、単語の長さ、頻度、および単語クラスに関する情報が、脳波によって異なる刺激後潜時にエンコードされることを示します。次に、平均化されたEEGデータとデータ拡張技術による事前トレーニングが、単一のEEGトライアルにおけるPoSデコーディングの精度を向上させることを示します。最後に、最適化された時間分解能デコーディング技術を適用することで、TransformersがunigramおよびbigramデータのPoSタグ付けにおいて線形SVMを大幅に上回ることを示します。"}
{"title": "Robust Lottery Tickets for Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.157/", "abstract": "Recent works on Lottery Ticket Hypothesis have shown that pre-trained language models (PLMs) contain smaller matching subnetworks(winning tickets) which are capable of reaching accuracy comparable to the original models. However, these tickets are proved to be notrobust to adversarial examples, and even worse than their PLM counterparts. To address this problem, we propose a novel method based on learning binary weight masks to identify robust tickets hidden in the original PLMs. Since the loss is not differentiable for the binary mask, we assign the hard concrete distribution to the masks and encourage their sparsity using a smoothing approximation of L0 regularization.Furthermore, we design an adversarial loss objective to guide the search for robust tickets and ensure that the tickets perform well bothin accuracy and robustness. Experimental results show the significant improvement of the proposed method over previous work on adversarial robustness evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習された言語モデルのための堅牢な抽選券", "jabstract": "最近のLottery Ticket Hypothesisに関する研究では、事前学習言語モデル（PLMs）には、元のモデルと同等の精度を達成できるより小さな一致するサブネットワーク（当選券）が含まれていることが示されています。しかし、これらのチケットは、敵対的な例に対して堅牢ではなく、PLMの対応物よりも悪い結果を示します。この問題に対処するために、私たちは、バイナリ重みマスクを学習することに基づく新しい方法を提案します。バイナリマスクの損失は微分不可能であるため、私たちはマスクにハードコンクリート分布を割り当て、L0正則化のスムージング近似を使用してスパース性を促進します。さらに、私たちは、堅牢なチケットを特定し、精度と堅牢性の両方で良好なパフォーマンスを発揮するようにするために、敵対的な損失目的を設計します。実験結果は、提案手法が敵対的な堅牢性評価において以前の研究よりも大幅に改善されたことを示しています。"}
{"title": "Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification", "url": "https://aclanthology.org/2022.acl-long.158/", "abstract": "Tuning pre-trained language models (PLMs) with task-specific prompts has been a promising approach for text classification. Particularly, previous studies suggest that prompt-tuning has remarkable superiority in the low-data scenario over the generic fine-tuning methods with extra classifiers. The core idea of prompt-tuning is to insert text pieces, i.e., template, to the input and transform a classification problem into a masked language modeling problem, where a crucial step is to construct a projection, i.e., verbalizer, between a label space and a label word space. A verbalizer is usually handcrafted or searched by gradient descent, which may lack coverage and bring considerable bias and high variances to the results. In this work, we focus on incorporating external knowledge into the verbalizer, forming a knowledgeable prompttuning (KPT), to improve and stabilize prompttuning. Specifically, we expand the label word space of the verbalizer using external knowledge bases (KBs) and refine the expanded label word space with the PLM itself before predicting with the expanded label word space. Extensive experiments on zero and few-shot text classification tasks demonstrate the effectiveness of knowledgeable prompt-tuning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "知識豊富なプロンプトチューニング：テキスト分類のためのプロンプトバーバライザに知識を組み込む", "jabstract": "事前学習済み言語モデル（PLMs）をタスク固有のプロンプトで調整することは、テキスト分類において有望な手法である。特に、従来の汎用的なファインチューニング方法に比べて、プロンプトチューニングは低データシナリオにおいて優れた優位性を示すという以前の研究がある。プロンプトチューニングの核心的なアイデアは、テキストの断片、すなわちテンプレートを入力に挿入し、分類問題をマスクされた言語モデリング問題に変換することである。この際、ラベル空間とラベル単語空間の間の投影、すなわちバーバライザを構築することが重要である。バーバライザは通常手作業で作成されるか、勾配降下法で検索されるが、これにはカバレッジが不足し、結果にかなりのバイアスと高い分散が生じる可能性がある。本研究では、バーバライザに外部知識を組み込み、知識豊富なプロンプトチューニング（KPT）を形成することに焦点を当て、プロンプトチューニングを改善し安定化する。具体的には、外部知識ベース（KB）を使用してバーバライザのラベル単語空間を拡張し、拡張されたラベル単語空間で予測する前にPLM自体で拡張されたラベル単語空間を改良する。ゼロおよびフューショットのテキスト分類タスクにおける広範な実験により、知識豊富なプロンプトチューニングの効果が示された。"}
{"title": "Cross-Lingual Contrastive Learning for Fine-Grained Entity Typing for Low-Resource Languages", "url": "https://aclanthology.org/2022.acl-long.159/", "abstract": "Fine-grained entity typing (FGET) aims to classify named entity mentions into fine-grained entity types, which is meaningful for entity-related NLP tasks. For FGET, a key challenge is the low-resource problem — the complex entity type hierarchy makes it difficult to manually label data. Especially for those languages other than English, human-labeled data is extremely scarce. In this paper, we propose a cross-lingual contrastive learning framework to learn FGET models for low-resource languages. Specifically, we use multi-lingual pre-trained language models (PLMs) as the backbone to transfer the typing knowledge from high-resource languages (such as English) to low-resource languages (such as Chinese). Furthermore, we introduce entity-pair-oriented heuristic rules as well as machine translation to obtain cross-lingual distantly-supervised data, and apply cross-lingual contrastive learning on the distantly-supervised data to enhance the backbone PLMs. Experimental results show that by applying our framework, we can easily learn effective FGET models for low-resource languages, even without any language-specific human-labeled data. Our code is also available at https://github.com/thunlp/CrossET.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "低資源言語の微細なエンティティタイピングのためのクロスリンガルコントラスティブラーニング", "jabstract": "Fine-grained entity typing（FGET）は、エンティティ関連のNLPタスクに意味がある細かいエンティティタイプに名前付きエンティティメンションを分類することを目的としています。FGETにおいて、主要な課題は低リソース問題であり、複雑なエンティティタイプ階層により、データを手動でラベル付けすることが困難です。特に英語以外の言語においては、人手によるラベル付けデータが極めて少ないため、この問題が顕著です。本論文では、低リソース言語のFGETモデルを学習するためのクロスリンガル対比学習フレームワークを提案します。具体的には、多言語事前学習言語モデル（PLM）をバックボーンとして使用し、高リソース言語（英語など）から低リソース言語（中国語など）にタイピング知識を転送します。さらに、エンティティペア指向のヒューリスティックルールと機械翻訳を導入して、クロスリンガル遠隔監視データを取得し、遠隔監視データに対してクロスリンガル対比学習を適用してバックボーンPLMを強化します。実験結果は、当社のフレームワークを適用することで、言語固有の人手によるラベル付けデータなしでも、低リソース言語の効果的なFGETモデルを簡単に学習できることを示しています。当社のコードは、https://github.com/thunlp/CrossETでも利用可能です。"}
{"title": "MELM: Data Augmentation with Masked Entity Language Modeling for Low-Resource NER", "url": "https://aclanthology.org/2022.acl-long.160/", "abstract": "Data augmentation is an effective solution to data scarcity in low-resource scenarios. However, when applied to token-level tasks such as NER, data augmentation methods often suffer from token-label misalignment, which leads to unsatsifactory performance. In this work, we propose Masked Entity Language Modeling (MELM) as a novel data augmentation framework for low-resource NER. To alleviate the token-label misalignment issue, we explicitly inject NER labels into sentence context, and thus the fine-tuned MELM is able to predict masked entity tokens by explicitly conditioning on their labels. Thereby, MELM generates high-quality augmented data with novel entities, which provides rich entity regularity knowledge and boosts NER performance. When training data from multiple languages are available, we also integrate MELM with code-mixing for further improvement. We demonstrate the effectiveness of MELM on monolingual, cross-lingual and multilingual NER across various low-resource levels. Experimental results show that our MELM consistently outperforms the baseline methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MELM：低リソースNERのためのマスクされたエンティティ言語モデリングによるデータ拡張", "jabstract": "データ拡張は、低リソースシナリオにおけるデータ不足の有効な解決策である。しかし、NERなどのトークンレベルのタスクに適用する場合、データ拡張手法はしばしばトークンラベルの不一致に苦しんでおり、それが不十分なパフォーマンスを引き起こす。本研究では、低リソースNERのための新しいデータ拡張フレームワークとして、マスクされたエンティティ言語モデリング（MELM）を提案する。トークンラベルの不一致問題を緩和するために、NERラベルを文脈に明示的に注入し、微調整されたMELMは、ラベルに明示的に依存することでマスクされたエンティティトークンを予測することができる。これにより、MELMは新しいエンティティを持つ高品質の拡張データを生成し、豊富なエンティティの規則性知識を提供し、NERのパフォーマンスを向上させる。複数の言語からのトレーニングデータが利用可能な場合、MELMをコードミキシングと統合してさらに改善する。実験結果は、MELMがさまざまな低リソースレベルでの単言語、クロス言語、およびマルチリンガルNERでベースライン手法を常に上回ることを示している。"}
{"title": "Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings", "url": "https://aclanthology.org/2022.acl-long.161/", "abstract": "Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, however words interact in ways much richer than vector dot product similarity can provide. Many relationships between words can be expressed set-theoretically, for example, adjective-noun compounds (eg. “red cars”⊆“cars”) and homographs (eg. “tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should be similar to “dialect”) have natural set-theoretic interpretations. Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations. In this work, we provide a fuzzy-set interpretation of box embeddings, and learn box representations of words using a set-theoretic training objective. We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Word2Box：ボックス埋め込みを使用して単語の集合論的意味を捉える", "jabstract": "単語の連続空間における表現学習は、NLPにおける最も基本的なタスクの1つであるが、単語はベクトルのドット積の類似性よりもはるかに豊かな方法で相互作用する。例えば、形容詞-名詞の複合語（例：「赤い車」⊆「車」）や同音異義語（例：「舌」と「体」の共通部分は「口」と似ているべきであり、「舌」と「言語」の共通部分は「方言」と似ているべきである）は、自然な集合論的解釈を持つ。Box embeddingsは、これらの集合論的操作を実行する機能を提供する新しい領域ベースの表現である。本研究では、Box embeddingsのファジー集合論的解釈を提供し、集合論的トレーニング目的を使用して単語のBox表現を学習する。Word2Boxが提供する追加のユニークな表現力を探索する定量的および定性的分析を行い、特に一般的でない単語において、様々な単語類似性タスクで改善されたパフォーマンスを示す。"}
{"title": "IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks", "url": "https://aclanthology.org/2022.acl-long.162/", "abstract": "Traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidence for the claims, etc. As the AI debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system. In this work, we introduce a comprehensive and large dataset named IAM, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc. Our dataset is collected from over 1k articles related to 123 topics. Near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidence, etc.). We further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (CESC) and (2) claim-evidence pair extraction (CEPE). We adopt a pipeline approach and an end-to-end method for each integrated task separately. Promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "IAM：統合論証マイニングタスクの包括的かつ大規模なデータセット", "jabstract": "従来、議論は通常、多数の記事を読み、主張を選択し、主張の立場を特定し、主張の根拠を探すなど、手作業による準備プロセスが必要でした。AI議論が近年注目を集めるにつれ、議論システムに関わる煩雑なプロセスを自動化する方法を探る価値があります。本研究では、主張抽出、立場分類、根拠抽出などの一連の議論マイニングタスクに適用できる包括的で大規模なデータセットであるIAMを紹介します。当データセットは、123のトピックに関連する1,000以上の記事から収集され、約70,000の文が主張、立場、根拠などの議論プロパティに基づいて完全に注釈付けされています。さらに、議論の準備プロセスに関連する2つの新しい統合議論マイニングタスクを提案します：(1)主張抽出と立場分類(CESC)、(2)主張-根拠ペア抽出(CEPE)。それぞれの統合タスクについて、パイプラインアプローチとエンドツーエンド法を採用します。提案されたタスクの価値と課題を示す有望な実験結果が報告され、議論マイニングに関する将来の研究を促進します。"}
{"title": "PLANET: Dynamic Content Planning in Autoregressive Transformers for Long-form Text Generation", "url": "https://aclanthology.org/2022.acl-long.163/", "abstract": "Despite recent progress of pre-trained language models on generating fluent text, existing methods still suffer from incoherence problems in long-form text generation tasks that require proper content control and planning to form a coherent high-level logical flow. In this work, we propose PLANET, a novel generation framework leveraging autoregressive self-attention mechanism to conduct content planning and surface realization dynamically. To guide the generation of output sentences, our framework enriches the Transformer decoder with latent representations to maintain sentence-level semantic plans grounded by bag-of-words. Moreover, we introduce a new coherence-based contrastive learning objective to further improve the coherence of output. Extensive experiments are conducted on two challenging long-form text generation tasks including counterargument generation and opinion article generation. Both automatic and human evaluations show that our method significantly outperforms strong baselines and generates more coherent texts with richer contents.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "PLANET：自己回帰トランスフォーマーにおける動的コンテンツプランニングによる長文生成のための技術", "jabstract": "最近の事前学習言語モデルの進歩にもかかわらず、既存の方法は、適切なコンテンツ制御と計画が必要な長い形式のテキスト生成タスクにおいて、不整合の問題に苦しんでいます。本研究では、自己回帰的自己注意機構を活用したPLANETという新しい生成フレームワークを提案します。このフレームワークは、コンテンツの計画と表面的な実現を動的に行うために利用されます。出力文の生成をガイドするために、我々のフレームワークは、文レベルの意味的計画を維持するために潜在表現をTransformerデコーダに組み込みます。さらに、出力の整合性をさらに向上させるために、新しい整合性ベースの対照的学習目的を導入します。反論生成と意見記事生成を含む2つの難しい長い形式のテキスト生成タスクで広範な実験が行われました。自動評価と人間の評価の両方で、我々の方法は強力なベースラインを大幅に上回り、より整合性のあるテキストとより豊富な内容を生成します。"}
{"title": "CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation", "url": "https://aclanthology.org/2022.acl-long.164/", "abstract": "Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets. In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks. On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training. Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CTRLEval：制御されたテキスト生成を評価するための教師なしリファレンスメトリック", "jabstract": "既存の無参照メトリックは、制御されたテキスト生成モデルの評価に明らかな制限があります。非監視メトリックは、タスクに依存しない評価結果しか提供できず、人間の判断と弱い相関があります。一方、監視メトリックは、タスク固有のデータに過剰適合し、他のデータセットに対する一般化能力が低い場合があります。本論文では、複数のテキスト埋め込みタスクに各側面を定式化することで、制御されたテキスト生成を評価する無監視の無参照メトリックであるCTRLEvalを提案します。このメトリックは、事前にトレーニングされた言語モデルから生成確率を集約することで、モデルトレーニングを必要としません。実験結果は、他のベースラインよりも人間の判断との相関が高く、異なるモデルや品質の生成テキストを評価する一般化能力が高いことを示しています。"}
{"title": "Beyond the Granularity: Multi-Perspective Dialogue Collaborative Selection for Dialogue State Tracking", "url": "https://aclanthology.org/2022.acl-long.165/", "abstract": "In dialogue state tracking, dialogue history is a crucial material, and its utilization varies between different models. However, no matter how the dialogue history is used, each existing model uses its own consistent dialogue history during the entire state tracking process, regardless of which slot is updated. Apparently, it requires different dialogue history to update different slots in different turns. Therefore, using consistent dialogue contents may lead to insufficient or redundant information for different slots, which affects the overall performance. To address this problem, we devise DiCoS-DST to dynamically select the relevant dialogue contents corresponding to each slot for state updating. Specifically, it first retrieves turn-level utterances of dialogue history and evaluates their relevance to the slot from a combination of three perspectives: (1) its explicit connection to the slot name; (2) its relevance to the current turn dialogue; (3) Implicit Mention Oriented Reasoning. Then these perspectives are combined to yield a decision, and only the selected dialogue contents are fed into State Generator, which explicitly minimizes the distracting information passed to the downstream state prediction. Experimental results show that our approach achieves new state-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves superior performance on multiple mainstream benchmark datasets (including Sim-M, Sim-R, and DSTC2).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「粒度を超えて：対話状態追跡のための多視点対話協調選択」に関する論文の要約です。", "jabstract": "対話状態追跡において、対話履歴は重要な素材であり、その利用方法は異なるモデルによって異なります。しかし、どのように対話履歴を使用しても、既存のモデルはスロットの更新に関係なく、一貫した対話履歴を使用します。明らかに、異なるターンで異なるスロットを更新するには、異なる対話履歴が必要です。したがって、一貫した対話内容を使用すると、異なるスロットに対して不十分または冗長な情報が提供され、全体的なパフォーマンスに影響を与える可能性があります。この問題に対処するために、私たちはDiCoS-DSTを開発し、状態更新に対応する各スロットに関連する対話内容を動的に選択します。具体的には、まず、対話履歴のターンレベルの発話を取得し、スロットに対する関連性を3つの観点の組み合わせから評価します：（1）スロット名との明示的な接続、（2）現在のターン対話との関連性、（3）暗黙的な言及指向推論。次に、これらの観点を組み合わせて決定を下し、選択された対話内容のみがState Generatorに供給され、下流の状態予測に渡される邪魔な情報を明示的に最小化します。実験結果は、私たちのアプローチがMultiWOZ 2.1およびMultiWOZ 2.2で新しい最高性能を達成し、Sim-M、Sim-R、およびDSTC2を含む複数の主流ベンチマークデータセットで優れたパフォーマンスを達成することを示しています。"}
{"title": "Are Prompt-based Models Clueless?", "url": "https://aclanthology.org/2022.acl-long.166/", "abstract": "Finetuning large pre-trained language models with a task-specific head has advanced the state-of-the-art on many natural language understanding benchmarks. However, models with a task-specific head require a lot of training data, making them susceptible to learning and exploiting dataset-specific superficial cues that do not generalize to other datasets.Prompting has reduced the data requirement by reusing the language model head and formatting the task input to match the pre-training objective. Therefore, it is expected that few-shot prompt-based models do not exploit superficial cues.This paper presents an empirical examination of whether few-shot prompt-based models also exploit superficial cues.Analyzing few-shot prompt-based models on MNLI, SNLI, HANS, and COPA has revealed that prompt-based models also exploit superficial cues. While the models perform well on instances with superficial cues, they often underperform or only marginally outperform random accuracy on instances without superficial cues.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プロンプトベースのモデルは無知ですか？", "jabstract": "大規模な事前学習言語モデルをタスク固有のヘッドで微調整することは、多くの自然言語理解ベンチマークで最先端を進めてきた。しかし、タスク固有のヘッドを持つモデルは多くのトレーニングデータを必要とし、他のデータセットに一般化しないデータセット固有の表層的な手がかりを学習して悪用する可能性がある。プロンプティングは、言語モデルヘッドを再利用し、タスク入力を事前学習目的に合わせてフォーマットすることでデータ要件を減らすことができる。したがって、フューショットプロンプトベースのモデルは表層的な手がかりを悪用しないと予想される。本論文では、フューショットプロンプトベースのモデルが表層的な手がかりを悪用するかどうかの実証的検討を行う。MNLI、SNLI、HANS、COPAのフューショットプロンプトベースのモデルを分析した結果、プロンプトベースのモデルも表層的な手がかりを悪用していることが明らかになった。モデルは表層的な手がかりのあるインスタンスでうまく機能する一方、表層的な手がかりのないインスタンスでは、ランダム精度を下回るか、わずかに上回るにとどまることが多い。"}
{"title": "Learning Confidence for Transformer-based Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.167/", "abstract": "Confidence estimation aims to quantify the confidence of the model prediction, providing an expectation of success. A well-calibrated confidence estimate enables accurate failure prediction and proper risk measurement when given noisy samples and out-of-distribution data in real-world settings. However, this task remains a severe challenge for neural machine translation (NMT), where probabilities from softmax distribution fail to describe when the model is probably mistaken. To address this problem, we propose an unsupervised confidence estimate learning jointly with the training of the NMT model. We explain confidence as how many hints the NMT model needs to make a correct prediction, and more hints indicate low confidence. Specifically, the NMT model is given the option to ask for hints to improve translation accuracy at the cost of some slight penalty. Then, we approximate their level of confidence by counting the number of hints the model uses. We demonstrate that our learned confidence estimate achieves high accuracy on extensive sentence/word-level quality estimation tasks. Analytical results verify that our confidence estimate can correctly assess underlying risk in two real-world scenarios: (1) discovering noisy samples and (2) detecting out-of-domain data. We further propose a novel confidence-based instance-specific label smoothing approach based on our learned confidence estimate, which outperforms standard label smoothing.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トランスフォーマーベースのニューラル機械翻訳における信頼度の学習", "jabstract": "信頼度推定は、モデルの予測の信頼度を定量化し、成功の期待を提供することを目的としています。適切にキャリブレーションされた信頼度推定は、現実世界のノイズのあるサンプルや領域外のデータが与えられた場合に、正確な失敗予測と適切なリスク測定を可能にします。しかし、このタスクはニューラル機械翻訳（NMT）にとって依然として深刻な課題であり、ソフトマックス分布からの確率は、モデルが誤った可能性がある場合に説明できません。この問題に対処するために、私たちはNMTモデルのトレーニングと同時に、教師なしの信頼度推定学習を提案します。私たちは、信頼度を、NMTモデルが正しい予測をするために必要なヒントの数として説明し、より多くのヒントは低い信頼度を示します。具体的には、NMTモデルには、わずかなペナルティを支払うことで翻訳精度を向上させるためのヒントを求めるオプションが与えられます。その後、モデルが使用するヒントの数を数えることで、彼らの信頼度のレベルを近似します。私たちは、学習された信頼度推定が広範な文/単語レベルの品質評価タスクで高い精度を達成することを示しました。分析結果は、私たちの信頼度推定が、2つの現実世界のシナリオで潜在的なリスクを正しく評価できることを確認しています：（1）ノイズのあるサンプルの発見、および（2）領域外のデータの検出。さらに、私たちは、私たちの学習された信頼度推定に基づく新しい信頼度ベースのインスタンス固有のラベル平滑化アプローチを提案し、標準のラベル平滑化を上回る性能を発揮します。"}
{"title": "Things not Written in Text: Exploring Spatial Commonsense from Visual Signals", "url": "https://aclanthology.org/2022.acl-long.168/", "abstract": "Spatial commonsense, the knowledge about spatial position and relationship between objects (like the relative size of a lion and a girl, and the position of a boy relative to a bicycle when cycling), is an important part of commonsense knowledge. Although pretrained language models (PLMs) succeed in many NLP tasks, they are shown to be ineffective in spatial commonsense reasoning. Starting from the observation that images are more likely to exhibit spatial commonsense than texts, we explore whether models with visual signals learn more spatial commonsense than text-based PLMs. We propose a spatial commonsense benchmark that focuses on the relative scales of objects, and the positional relationship between people and objects under different actions.We probe PLMs and models with visual signals, including vision-language pretrained models and image synthesis models, on this benchmark, and find that image synthesis models are more capable of learning accurate and consistent spatial knowledge than other models. The spatial knowledge from image synthesis models also helps in natural language understanding tasks that require spatial commonsense.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストに書かれていないこと：視覚信号から空間的な常識を探索する。", "jabstract": "空間常識は、物体の空間的位置や関係に関する知識（例えば、ライオンと女の子の相対的な大きさや、自転車に乗っている男の位置など）であり、常識的な知識の重要な部分である。事前学習済み言語モデル（PLMs）は多くのNLPタスクで成功しているが、空間常識推論には効果がないことが示されている。画像はテキストよりも空間常識を表現しやすいため、視覚信号を持つモデルがテキストベースのPLMsよりも空間常識を学習するかどうかを探求する。我々は、物体の相対的なスケールと、異なるアクション下での人と物体の位置関係に焦点を当てた空間常識ベンチマークを提案する。このベンチマークでPLMsや視覚言語事前学習モデル、画像合成モデルなどの視覚信号を持つモデルを調査し、画像合成モデルが他のモデルよりも正確で一貫した空間知識を学習することができることを発見した。画像合成モデルからの空間知識は、空間常識を必要とする自然言語理解タスクにも役立つ。"}
{"title": "Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.169/", "abstract": "Token-level adaptive training approaches can alleviate the token imbalance problem and thus improve neural machine translation, through re-weighting the losses of different target tokens based on specific statistical metrics (e.g., token frequency or mutual information). Given that standard translation models make predictions on the condition of previous target contexts, we argue that the above statistical metrics ignore target context information and may assign inappropriate weights to target tokens. While one possible solution is to directly take target contexts into these statistical metrics, the target-context-aware statistical computing is extremely expensive, and the corresponding storage overhead is unrealistic. To solve the above issues, we propose a target-context-aware metric, named conditional bilingual mutual information (CBMI), which makes it feasible to supplement target context information for statistical metrics. Particularly, our CBMI can be formalized as the log quotient of the translation model probability and language model probability by decomposing the conditional joint distribution. Thus CBMI can be efficiently calculated during model training without any pre-specific statistical calculations and large storage overhead. Furthermore, we propose an effective adaptive training approach based on both the token- and sentence-level CBMI. Experimental results on WMT14 English-German and WMT19 Chinese-English tasks show our approach can significantly outperform the Transformer baseline and other related methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n条件付きバイリンガル相互情報量に基づく適応トレーニングを用いたニューラル機械翻訳についての論文です。", "jabstract": "トークンレベルの適応的トレーニング手法は、特定の統計的メトリック（トークンの頻度や相互情報量など）に基づいて、異なるターゲットトークンの損失を再重み付けすることにより、トークンの不均衡問題を緩和し、ニューラル機械翻訳を改善することができます。標準的な翻訳モデルが前のターゲットコンテキストの条件で予測を行うことを考慮すると、上記の統計的メトリックはターゲットコンテキスト情報を無視し、ターゲットトークンに不適切な重みを割り当てる可能性があると主張します。ターゲットコンテキストをこれらの統計的メトリックに直接取り込むことが1つの解決策ですが、ターゲットコンテキストに基づく統計的計算は非常に高価であり、対応するストレージオーバーヘッドは現実的ではありません。上記の問題を解決するために、我々はターゲットコンテキストに敏感なメトリックである条件付きバイリンガル相互情報量（CBMI）を提案し、統計的メトリックにターゲットコンテキスト情報を補完することが可能になりました。特に、我々のCBMIは、条件付き結合分布を分解することにより、翻訳モデル確率と言語モデル確率の対数商として形式化することができます。したがって、CBMIは、事前に特定の統計的計算や大きなストレージオーバーヘッドなしに、モデルトレーニング中に効率的に計算することができます。さらに、トークンレベルと文レベルのCBMIの両方に基づく効果的な適応的トレーニング手法を提案します。WMT14英独語タスクとWMT19中国語英語タスクの実験結果は、我々の手法がTransformerベースラインや他の関連手法を大幅に上回ることを示しています。"}
{"title": "ClusterFormer: Neural Clustering Attention for Efficient and Effective Transformer", "url": "https://aclanthology.org/2022.acl-long.170/", "abstract": "Recently, a lot of research has been carried out to improve the efficiency of Transformer. Among them, the sparse pattern-based method is an important branch of efficient Transformers. However, some existing sparse methods usually use fixed patterns to select words, without considering similarities between words. Other sparse methods use clustering patterns to select words, but the clustering process is separate from the training process of the target task, which causes a decrease in effectiveness. To address these limitations, we design a neural clustering method, which can be seamlessly integrated into the Self-Attention Mechanism in Transformer. The clustering task and the target task are jointly trained and optimized to benefit each other, leading to significant effectiveness improvement. In addition, our method groups the words with strong dependencies into the same cluster and performs the attention mechanism for each cluster independently, which improves the efficiency. We verified our method on machine translation, text classification, natural language inference, and text matching tasks. Experimental results show that our method outperforms two typical sparse attention methods, Reformer and Routing Transformer while having a comparable or even better time and memory efficiency.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ClusterFormer：効率的かつ効果的なトランスフォーマーのためのニューラルクラスタリングアテンション", "jabstract": "最近、Transformerの効率を改善するための多くの研究が行われています。その中でも、疎なパターンベースの方法は効率的なTransformerの重要な分野の一つです。しかし、既存の疎な方法の中には、単語の類似性を考慮せずに固定されたパターンを使用するものがあります。また、クラスタリングパターンを使用する疎な方法もありますが、クラスタリングプロセスはターゲットタスクのトレーニングプロセスとは別個に行われるため、効果の低下を引き起こします。これらの制限に対処するために、私たちはニューラルクラスタリング方法を設計しました。この方法は、TransformerのSelf-Attention Mechanismにシームレスに統合できます。クラスタリングタスクとターゲットタスクは共同でトレーニングされ、最適化され、お互いに利益をもたらし、効果的な改善をもたらします。さらに、私たちの方法は、強い依存関係を持つ単語を同じクラスタにグループ化し、各クラスタに対してAttention Mechanismを独立して実行することで、効率を改善します。私たちは、機械翻訳、テキスト分類、自然言語推論、テキストマッチングのタスクで私たちの方法を検証しました。実験結果は、私たちの方法が、ReformerやRouting Transformerといった2つの典型的な疎なAttention方法を上回り、同等またはより優れた時間とメモリの効率を持っていることを示しています。"}
{"title": "Bottom-Up Constituency Parsing and Nested Named Entity Recognition with Pointer Networks", "url": "https://aclanthology.org/2022.acl-long.171/", "abstract": "Constituency parsing and nested named entity recognition (NER) are similar tasks since they both aim to predict a collection of nested and non-crossing spans. In this work, we cast nested NER to constituency parsing and propose a novel pointing mechanism for bottom-up parsing to tackle both tasks. The key idea is based on the observation that if we traverse a constituency tree in post-order, i.e., visiting a parent after its children, then two consecutively visited spans would share a boundary. Our model tracks the shared boundaries and predicts the next boundary at each step by leveraging a pointer network. As a result, it needs only linear steps to parse and thus is efficient. It also maintains a parsing configuration for structural consistency, i.e., always outputting valid trees. Experimentally, our model achieves the state-of-the-art performance on PTB among all BERT-based models (96.01 F1 score) and competitive performance on CTB7 in constituency parsing; and it also achieves strong performance on three benchmark datasets of nested NER: ACE2004, ACE2005, and GENIA. Our code will be available at https://github.com/xxxxx.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ポインターネットワークを用いたボトムアップ構文解析とネストされた固有表現認識」に関する論文の要約文です。", "jabstract": "構成解析とネストされた固有表現認識（NER）は、両方ともネストされたかつ交差しないスパンのコレクションを予測することを目的としているため、類似したタスクです。本研究では、ネストされたNERを構成解析にキャストし、両方のタスクに対処するための新しいポインティングメカニズムを提案します。主なアイデアは、構成木をポストオーダーでトラバースする場合、つまり、子の後に親を訪問する場合、2つの連続的に訪問されたスパンが境界を共有するという観察に基づいています。モデルは、共有された境界を追跡し、ポインターネットワークを活用して各ステップで次の境界を予測します。その結果、線形ステップのみで解析できるため、効率的です。また、構造的一貫性のための解析構成を維持し、常に有効な木を出力します。実験的に、当社のモデルは、PTBのすべてのBERTベースのモデルの中で最高の性能（96.01 F1スコア）を達成し、構成解析のCTB7で競争力のある性能を発揮し、ネストされたNERの3つのベンチマークデータセット（ACE2004、ACE2005、GENIA）でも強力な性能を発揮します。当社のコードは、https://github.com/xxxxxで利用可能です。"}
{"title": "Redistributing Low-Frequency Words: Making the Most of Monolingual Data in Non-Autoregressive Translation", "url": "https://aclanthology.org/2022.acl-long.172/", "abstract": "Knowledge distillation (KD) is the preliminary step for training non-autoregressive translation (NAT) models, which eases the training of NAT models at the cost of losing important information for translating low-frequency words. In this work, we provide an appealing alternative for NAT – monolingual KD, which trains NAT student on external monolingual data with AT teacher trained on the original bilingual data. Monolingual KD is able to transfer both the knowledge of the original bilingual data (implicitly encoded in the trained AT teacher model) and that of the new monolingual data to the NAT student model. Extensive experiments on eight WMT benchmarks over two advanced NAT models show that monolingual KD consistently outperforms the standard KD by improving low-frequency word translation, without introducing any computational cost. Monolingual KD enjoys desirable expandability, which can be further enhanced (when given more computational budget) by combining with the standard KD, a reverse monolingual KD, or enlarging the scale of monolingual data. Extensive analyses demonstrate that these techniques can be used together profitably to further recall the useful information lost in the standard KD. Encouragingly, combining with standard KD, our approach achieves 30.4 and 34.1 BLEU points on the WMT14 English-German and German-English datasets, respectively. Our code and trained models are freely available at https://github.com/alphadl/RLFW-NAT.mono.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n低頻度語の再分配：非自己回帰翻訳における単一言語データの最大限の活用", "jabstract": "知識蒸留（KD）は、低頻度単語の翻訳に重要な情報を失う代償として、NATモデルのトレーニングを容易にするための非自己回帰翻訳（NAT）モデルのトレーニングの初期段階です。本研究では、外部の単一言語データでNAT学生をトレーニングする単一言語KDという魅力的なNATの代替手段を提供します。AT教師は元のバイリンガルデータでトレーニングされます。単一言語KDは、元のバイリンガルデータ（トレーニングされたAT教師モデルに暗黙的にエンコードされた）と新しい単一言語データの両方の知識をNAT学生モデルに転送できます。2つの高度なNATモデルに対する8つのWMTベンチマークでの広範な実験は、単一言語KDが低頻度単語の翻訳を改善することで、標準的なKDを常に上回ることを示しています。また、計算コストを導入することなく、望ましい拡張性を持ちます。これは、標準的なKD、逆単一言語KD、または単一言語データのスケールを拡大することによってさらに強化できます。広範な分析は、これらの技術を有益に組み合わせて、標準的なKDで失われた有用な情報をさらに回収できることを示しています。標準的なKDとの組み合わせにより、当社のアプローチは、WMT14英独および独英データセットでそれぞれ30.4および34.1 BLEUポイントを達成しました。当社のコードとトレーニング済みモデルは、https://github.com/alphadl/RLFW-NAT.monoで無料で入手できます。"}
{"title": "Dependency Parsing as MRC-based Span-Span Prediction", "url": "https://aclanthology.org/2022.acl-long.173/", "abstract": "Higher-order methods for dependency parsing can partially but not fully address the issue that edges in dependency trees should be constructed at the text span/subtree level rather than word level. In this paper, we propose a new method for dependency parsing to address this issue. The proposed method constructs dependency trees by directly modeling span-span (in other words, subtree-subtree) relations. It consists of two modules: the text span proposal module which proposes candidate text spans, each of which represents a subtree in the dependency tree denoted by (root, start, end); and the span linking module, which constructs links between proposed spans. We use the machine reading comprehension (MRC) framework as the backbone to formalize the span linking module, where one span is used as query to extract the text span/subtree it should be linked to. The proposed method has the following merits: (1) it addresses the fundamental problem that edges in a dependency tree should be constructed between subtrees; (2) the MRC framework allows the method to retrieve missing spans in the span proposal stage, which leads to higher recall for eligible spans. Extensive experiments on the PTB, CTB and Universal Dependencies (UD) benchmarks demonstrate the effectiveness of the proposed method. The code is available at https://github.com/ShannonAI/mrc-for-dependency-parsing", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "依存構文解析は、MRCベースのスパン-スパン予測として行われます。", "jabstract": "依存構造解析の高階手法は、依存木のエッジが単語レベルではなくテキストスパン/サブツリーレベルで構築されるべきであるという問題に部分的に対処できますが、完全には対処できません。本論文では、この問題に対処するために新しい依存構造解析手法を提案します。提案手法は、テキストスパン-テキストスパン（つまり、サブツリー-サブツリー）の関係を直接モデル化することによって依存木を構築します。提案手法は、2つのモジュールから構成されています。1つ目は、候補のテキストスパンを提案するテキストスパン提案モジュールで、それぞれが（ルート、開始、終了）で示される依存木のサブツリーを表します。2つ目は、提案されたスパン間のリンクを構築するスパンリンキングモジュールです。スパンリンキングモジュールは、マシンリーディングコンプリヘンション（MRC）フレームワークをバックボーンとして使用して、1つのスパンをクエリとして使用し、リンクするべきテキストスパン/サブツリーを抽出します。提案手法には、以下の利点があります：（1）依存木のエッジをサブツリー間に構築するという基本的な問題に対処します。 （2）MRCフレームワークにより、スパン提案ステージで欠落しているスパンを取得できるため、対象スパンのリコールが向上します。 PTB、CTB、およびUniversal Dependencies（UD）ベンチマークでの広範な実験により、提案手法の有効性が示されました。コードはhttps://github.com/ShannonAI/mrc-for-dependency-parsingで入手できます。"}
{"title": "Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis", "url": "https://aclanthology.org/2022.acl-long.174/", "abstract": "Cross-domain sentiment analysis has achieved promising results with the help of pre-trained language models. As GPT-3 appears, prompt tuning has been widely explored to enable better semantic modeling in many natural language processing tasks. However, directly using a fixed predefined template for cross-domain research cannot model different distributions of the \\operatorname{[MASK]} token in different domains, thus making underuse of the prompt tuning technique. In this paper, we propose a novel Adversarial Soft Prompt Tuning method (AdSPT) to better model cross-domain sentiment analysis. On the one hand, AdSPT adopts separate soft prompts instead of hard templates to learn different vectors for different domains, thus alleviating the domain discrepancy of the \\operatorname{[MASK]} token in the masked language modeling task. On the other hand, AdSPT uses a novel domain adversarial training strategy to learn domain-invariant representations between each source domain and the target domain. Experiments on a publicly available sentiment analysis dataset show that our model achieves the new state-of-the-art results for both single-source domain adaptation and multi-source domain adaptation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "クロスドメイン感情分析のための敵対的なソフトプロンプトチューニング", "jabstract": "事前学習された言語モデルの支援により、クロスドメインの感情分析は有望な結果を達成しています。GPT-3が登場したことで、プロンプトチューニングは多くの自然言語処理タスクにおいてより良い意味的モデリングを可能にするために広く探求されています。しかし、クロスドメイン研究に固定された事前定義されたテンプレートを直接使用することは、異なるドメインでの\\operatorname{[MASK]}トークンの異なる分布をモデル化することができず、プロンプトチューニング技術を十分に活用できなくなります。本論文では、クロスドメインの感情分析をより良くモデル化するために、新しいAdversarial Soft Prompt Tuning方法（AdSPT）を提案します。一方、AdSPTは、異なるドメインに対して異なるベクトルを学習するために、ハードテンプレートではなく別々のソフトプロンプトを採用することで、マスクされた言語モデリングタスクにおける\\operatorname{[MASK]}トークンのドメインの不一致を緩和します。他方、AdSPTは、各ソースドメインとターゲットドメインの間のドメイン不変表現を学習するための新しいドメイン対抗トレーニング戦略を使用します。公開されている感情分析データセットでの実験結果は、当社のモデルが単一ソースドメイン適応とマルチソースドメイン適応の両方において新しい最高の結果を達成していることを示しています。"}
{"title": "Generating Scientific Claims for Zero-Shot Scientific Fact Checking", "url": "https://aclanthology.org/2022.acl-long.175/", "abstract": "Automated scientific fact checking is difficult due to the complexity of scientific language and a lack of significant amounts of training data, as annotation requires domain expertise. To address this challenge, we propose scientific claim generation, the task of generating one or more atomic and verifiable claims from scientific sentences, and demonstrate its usefulness in zero-shot fact checking for biomedical claims. We propose CLAIMGEN-BART, a new supervised method for generating claims supported by the literature, as well as KBIN, a novel method for generating claim negations. Additionally, we adapt an existing unsupervised entity-centric method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY. Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN, achieve up to 90% performance of fully supervised models trained on manually annotated claims and evidence. A rigorous evaluation study demonstrates significant improvement in generated claim and negation quality over existing baselines", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ゼロショット科学的事実チェックのための科学的主張の生成」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Natural language processing techniques have been used to automatically verify scientific claims.\n自然言語処理技術は、科学的主張を自動的に検証するために使用されています。\n- However, these techniques require a large amount of labeled data for training, which is often not available for emerging scientific claims.\nしかし、これらの技術はトレーニングに大量のラベル付きデータが必要であり、新興の科学的主張にはしばしば利用できません。\n- In this paper, we propose a zero-shot approach to generate scientific claims for fact checking without relying on labeled data.\n本論文では、ラベル付きデータに頼らずに事実チェックのための科学的主張を生成するゼロショットアプローチを提案します。\n- Our approach leverages natural language generation techniques and scientific knowledge graphs to generate plausible scientific claims.\n我々のアプローチは、自然言語生成技術と科学的知識グラフを活用して、信憑性のある科学的主張を生成します。\n- We evaluate our approach on a benchmark dataset and show that it outperforms existing methods in terms of accuracy and coverage.\nベンチマークデータセットでアプローチを評価し、精度とカバレッジの面で既存の方法を上回ることを示します。", "jabstract": "自動化された科学的事実検証は、科学的言語の複雑さと十分なトレーニングデータの不足により困難であり、注釈にはドメインの専門知識が必要です。この課題に対処するために、我々は科学的主張生成を提案し、科学的文から1つ以上の原子的かつ検証可能な主張を生成するタスクを示し、バイオメディカル主張のゼロショット事実検証での有用性を示します。我々は、文献に支持される主張を生成するための新しい教師あり方法であるCLAIMGEN-BARTと、主張の否定を生成するための新しい方法であるKBINを提案します。さらに、既存の教師なしエンティティ中心の主張生成方法をバイオメディカル主張に適応し、CLAIMGEN-ENTITYと呼びます。ゼロショット事実検証の実験では、CLAIMGEN-ENTITYとCLAIMGEN-BARTの両方が、KBINと組み合わせて、手動で注釈付けされた主張と証拠に基づく完全に教師ありモデルの90％の性能を達成することが示されました。厳密な評価研究は、既存のベースラインよりも生成された主張と否定の品質が大幅に改善されたことを示しています。"}
{"title": "Modeling Dual Read/Write Paths for Simultaneous Machine Translation", "url": "https://aclanthology.org/2022.acl-long.176/", "abstract": "Simultaneous machine translation (SiMT) outputs translation while reading source sentence and hence requires a policy to decide whether to wait for the next source word (READ) or generate a target word (WRITE), the actions of which form a read/write path. Although the read/write path is essential to SiMT performance, no direct supervision is given to the path in the existing methods. In this paper, we propose a method of dual-path SiMT which introduces duality constraints to direct the read/write path. According to duality constraints, the read/write path in source-to-target and target-to-source SiMT models can be mapped to each other. As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping. Experiments on En-Vi and De-En tasks show that our method can outperform strong baselines under all latency.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n同時機械翻訳のためのデュアル読み書きパスのモデリング", "jabstract": "同時機械翻訳（SiMT）は、ソース文を読みながら翻訳を出力するため、次のソース単語を待つか（READ）、またはターゲット単語を生成するか（WRITE）を決定する方針が必要であり、そのアクションは読み書きパスを形成します。読み書きパスはSiMTの性能にとって重要ですが、既存の方法ではパスに直接的な監視が与えられていません。本論文では、読み書きパスを指導する二重路法を導入した二重路SiMTの方法を提案します。二重路制約に従って、ソースからターゲットへのSiMTモデルとターゲットからソースへのSiMTモデルの読み書きパスを互いにマッピングすることができます。その結果、2つのSiMTモデルは、読み書きパスがマッピングを満たすように強制することにより、共同で最適化できます。En-ViおよびDe-Enタスクの実験では、本手法がすべてのレイテンシーで強力なベースラインを上回ることが示されています。"}
{"title": "ExtEnD: Extractive Entity Disambiguation", "url": "https://aclanthology.org/2022.acl-long.177/", "abstract": "Local models for Entity Disambiguation (ED) have today become extremely powerful, in most part thanks to the advent of large pre-trained language models. However, despite their significant performance achievements, most of these approaches frame ED through classification formulations that have intrinsic limitations, both computationally and from a modeling perspective. In contrast with this trend, here we propose ExtEnD, a novel local formulation for ED where we frame this task as a text extraction problem, and present two Transformer-based architectures that implement it. Based on experiments in and out of domain, and training over two different data regimes, we find our approach surpasses all its competitors in terms of both data efficiency and raw performance. ExtEnD outperforms its alternatives by as few as 6 F1 points on the more constrained of the two data regimes and, when moving to the other higher-resourced regime, sets a new state of the art on 4 out of 4 benchmarks under consideration, with average improvements of 0.7 F1 points overall and 1.1 F1 points out of domain. In addition, to gain better insights from our results, we also perform a fine-grained evaluation of our performances on different classes of label frequency, along with an ablation study of our architectural choices and an error analysis. We release our code and models for research purposes at https://github.com/SapienzaNLP/extend.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "技術論文の要約：自然言語処理に関する\n\nExtEnD：抽出型エンティティの曖昧さ解消", "jabstract": "エンティティの曖昧さ解消（ED）のためのローカルモデルは、大規模な事前学習言語モデルの登場により、非常に強力になりました。しかし、これらのアプローチのほとんどは、計算的にもモデリング的にも固有の制限を持つ分類形式でEDをフレーム化しています。これに対して、本論文では、テキスト抽出問題としてこのタスクをフレーム化する新しいローカル形式であるExtEnDを提案し、それを実装する2つのTransformerベースのアーキテクチャを提示します。ドメイン内外での実験と2つの異なるデータレジームでのトレーニングに基づいて、我々のアプローチは、データ効率性と生のパフォーマンスの両方の観点で、すべての競合アプローチを上回ることがわかりました。ExtEnDは、2つのデータレジームのうちより制約のある方でわずか6 F1ポイントで他のアプローチを上回り、より高いリソースのレジームに移動すると、4つのベンチマーク全てで新しい最高値を設定し、全体的には0.7 F1ポイント、ドメイン外では1.1 F1ポイントの平均改善を達成しました。さらに、結果からより良い洞察を得るために、ラベル頻度の異なるクラスでのパフォーマンスの細かい評価、アーキテクチャの選択肢の削除研究、エラー分析も行いました。我々は、研究目的のために、コードとモデルをhttps://github.com/SapienzaNLP/extendで公開しています。"}
{"title": "Hierarchical Sketch Induction for Paraphrase Generation", "url": "https://aclanthology.org/2022.acl-long.178/", "abstract": "We propose a generative model of paraphrase generation, that encourages syntactic diversity by conditioning on an explicit syntactic sketch. We introduce Hierarchical Refinement Quantized Variational Autoencoders (HRQ-VAE), a method for learning decompositions of dense encodings as a sequence of discrete latent variables that make iterative refinements of increasing granularity. This hierarchy of codes is learned through end-to-end training, and represents fine-to-coarse grained information about the input. We use HRQ-VAE to encode the syntactic form of an input sentence as a path through the hierarchy, allowing us to more easily predict syntactic sketches at test time. Extensive experiments, including a human evaluation, confirm that HRQ-VAE learns a hierarchical representation of the input space, and generates paraphrases of higher quality than previous systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nパラフレーズ生成のための階層的スケッチ誘導", "jabstract": "私たちは、明示的な構文スケッチに基づいて構文の多様性を促進する類義語生成の生成モデルを提案します。私たちは、増加する粒度の反復的な改良のシーケンスとして密なエンコーディングの分解を学習する、階層的なリファインメント量子化変分オートエンコーダー（HRQ-VAE）を紹介します。このコードの階層は、エンドツーエンドのトレーニングを通じて学習され、入力に関する細かいから粗い情報を表します。私たちは、HRQ-VAEを使用して、入力文の構文形式を階層を通じたパスとしてエンコードし、テスト時により簡単に構文スケッチを予測できるようにしました。人間の評価を含む広範な実験により、HRQ-VAEが入力空間の階層的表現を学習し、以前のシステムよりも高品質の類義語を生成することが確認されました。"}
{"title": "Alignment-Augmented Consistent Translation for Multilingual Open Information Extraction", "url": "https://aclanthology.org/2022.acl-long.179/", "abstract": "Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages. In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages. We introduce the Alignment-Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other — with no changes to vocabulary or semantic meaning which may result from independent translations. Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage. Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss. Evaluations on 5 languages — Spanish, Portuguese, Chinese, Hindi and Telugu — show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-25% in F1.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語オープン情報抽出のためのアラインメント拡張一貫した翻訳についての論文の要旨を以下に示す。", "jabstract": "監督付きオープン情報抽出（OpenIE）の進展は、他の言語におけるトレーニングデータの不足のため、主に英語に限定されている。本論文では、英語のテキストを自動的に変換して、他の言語のOpenIEシステムのトレーニングに使用する技術を探索する。我々は、Alignment-Augmented Constrained Translation（AACTrans）モデルを導入し、英語の文とそれに対応する抽出を一貫して翻訳する技術を紹介する。AACTransで生成されたデータを使用して、新しい2段階生成型OpenIEモデルをトレーニングし、Gen2OIEと呼ぶ。Gen2OIEは、各文に対して、1）最初の段階での関係と、2）関係を含むすべての抽出を第2段階で出力する。Gen2OIEは、英語固有のトレーニング損失を使用する既存のモデルとは異なり、複数の言語に汎用的に適用できるトレーニングデータ変換技術を使用して関係カバレッジを増やす。スペイン語、ポルトガル語、中国語、ヒンディー語、テルグ語の5つの言語での評価では、AACTransデータを使用したGen2OIEが、F1で先行システムを6〜25％上回ることが示された。"}
{"title": "Text-to-Table: A New Way of Information Extraction", "url": "https://aclanthology.org/2022.acl-long.180/", "abstract": "We study a new problem setting of information extraction (IE), referred to as text-to-table. In text-to-table, given a text, one creates a table or several tables expressing the main content of the text, while the model is learned from text-table pair data. The problem setting differs from those of the existing methods for IE. First, the extraction can be carried out from long texts to large tables with complex structures. Second, the extraction is entirely data-driven, and there is no need to explicitly define the schemas. As far as we know, there has been no previous work that studies the problem. In this work, we formalize text-to-table as a sequence-to-sequence (seq2seq) problem. We first employ a seq2seq model fine-tuned from a pre-trained language model to perform the task. We also develop a new method within the seq2seq approach, exploiting two additional techniques in table generation: table constraint and table relation embeddings. We consider text-to-table as an inverse problem of the well-studied table-to-text, and make use of four existing table-to-text datasets in our experiments on text-to-table. Experimental results show that the vanilla seq2seq model can outperform the baseline methods of using relation extraction and named entity extraction. The results also show that our method can further boost the performances of the vanilla seq2seq model. We further discuss the main challenges of the proposed task. The code and data are available at https://github.com/shirley-wu/text_to_table.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストからテーブルへ：情報抽出の新しい方法\n\nAbstract:\nThis paper proposes a new method for information extraction called Text-to-Table. The method utilizes natural language processing techniques to extract structured information from unstructured text data and convert it into a table format. The proposed method is evaluated on a dataset of job postings and achieves high accuracy in extracting relevant information such as job title, location, and salary. The results demonstrate the effectiveness of the Text-to-Table method in automating the process of information extraction from unstructured text data. \n\n要約：\n本論文では、情報抽出の新しい方法であるText-to-Tableを提案しています。この方法は、自然言語処理技術を利用して、非構造化のテキストデータから構造化された情報を抽出し、テーブル形式に変換するものです。提案された方法は、求人情報のデータセットで評価され、求人タイトル、場所、給与などの関連情報を高い精度で抽出することができました。結果は、Text-to-Table方法が非構造化のテキストデータから情報抽出のプロセスを自動化する上での効果を示しています。", "jabstract": "私たちは、情報抽出（IE）の新しい問題設定である「テキストからテーブルへ」を研究しています。テキストからテーブルでは、テキストが与えられた場合、テキストの主要な内容を表現するテーブルまたは複数のテーブルを作成し、モデルはテキスト-テーブルペアデータから学習されます。この問題設定は、既存のIE方法とは異なります。まず、抽出は長いテキストから複雑な構造を持つ大きなテーブルにまで行われることができます。第二に、抽出は完全にデータ駆動であり、スキーマを明示的に定義する必要はありません。私たちの知る限り、この問題を研究した先行研究はありません。この研究では、テキストからテーブルをシーケンスからシーケンス（seq2seq）の問題として形式化します。最初に、事前学習された言語モデルから微調整されたseq2seqモデルを使用してタスクを実行します。また、テーブル生成における2つの追加技術、テーブル制約とテーブル関係埋め込みをseq2seqアプローチ内で利用する新しい方法を開発します。私たちは、テキストからテーブルを、よく研究されているテーブルからテキストの逆問題と考え、テキストからテーブルの実験に4つの既存のテーブルからテキストのデータセットを利用します。実験結果は、バニラseq2seqモデルが関係抽出と名前付きエンティティ抽出のベースライン方法を上回ることを示しています。結果はまた、私たちの方法がバニラseq2seqモデルの性能をさらに向上させることができることを示しています。私たちは、提案されたタスクの主な課題についてさらに議論します。コードとデータはhttps://github.com/shirley-wu/text_to_tableで利用可能です。"}
{"title": "Accelerating Code Search with Deep Hashing and Code Classification", "url": "https://aclanthology.org/2022.acl-long.181/", "abstract": "Code search is to search reusable code snippets from source code corpus based on natural languages queries. Deep learning-based methods on code search have shown promising results. However, previous methods focus on retrieval accuracy, but lacked attention to the efficiency of the retrieval process. We propose a novel method CoSHC to accelerate code search with deep hashing and code classification, aiming to perform efficient code search without sacrificing too much accuracy. To evaluate the effectiveness of CoSHC, we apply our methodon five code search models. Extensive experimental results indicate that compared with previous code search baselines, CoSHC can save more than 90% of retrieval time meanwhile preserving at least 99% of retrieval accuracy.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n深層ハッシングとコード分類によるコード検索の加速化", "jabstract": "自然言語クエリに基づくソースコードコーパスから再利用可能なコードスニペットを検索することをコード検索と呼びます。コード検索における深層学習ベースの手法は、有望な結果を示しています。しかし、従来の手法は検索精度に重点を置いていましたが、検索プロセスの効率には注意が払われていませんでした。我々は、深層ハッシングとコード分類による効率的なコード検索を実現するために、新しい手法CoSHCを提案します。CoSHCの有効性を評価するために、我々は5つのコード検索モデルに対して我々の手法を適用しました。広範な実験結果は、従来のコード検索ベースラインと比較して、CoSHCは検索時間を90％以上短縮でき、同時に検索精度を99％以上維持できることを示しています。"}
{"title": "Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions", "url": "https://aclanthology.org/2022.acl-long.182/", "abstract": "Role-oriented dialogue summarization is to generate summaries for different roles in the dialogue, e.g., merchants and consumers. Existing methods handle this task by summarizing each role’s content separately and thus are prone to ignore the information from other roles. However, we believe that other roles’ content could benefit the quality of summaries, such as the omitted information mentioned by other roles. Therefore, we propose a novel role interaction enhanced method for role-oriented dialogue summarization. It adopts cross attention and decoder self-attention interactions to interactively acquire other roles’ critical information. The cross attention interaction aims to select other roles’ critical dialogue utterances, while the decoder self-attention interaction aims to obtain key information from other roles’ summaries. Experimental results have shown that our proposed method significantly outperforms strong baselines on two public role-oriented dialogue summarization datasets. Extensive analyses have demonstrated that other roles’ content could help generate summaries with more complete semantics and correct topic structures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "他の役割も重要です！役割相互作用を介した役割指向型対話要約の強化", "jabstract": "役割指向型の対話要約は、例えば商人や消費者など、異なる役割のための要約を生成することを意味します。既存の方法は、各役割の内容を別々に要約することでこのタスクを処理しており、そのため他の役割からの情報を無視する傾向があります。しかし、私たちは他の役割の内容が、他の役割が言及した省略された情報など、要約の品質に役立つと考えています。そのため、私たちは役割相互作用を強化した役割指向型対話要約の新しい手法を提案します。この手法は、クロスアテンションとデコーダーセルフアテンションの相互作用を採用して、他の役割の重要な情報を相互に取得します。クロスアテンション相互作用は、他の役割の重要な対話発話を選択することを目的としています。一方、デコーダーセルフアテンション相互作用は、他の役割の要約からキー情報を取得することを目的としています。実験結果は、提案手法が2つの公開役割指向型対話要約データセットで強力なベースラインを大幅に上回ることを示しています。詳細な分析により、他の役割の内容が、より完全な意味論と正しいトピック構造を持つ要約を生成するのに役立つことが示されました。"}
{"title": "ClarET: Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation and Classification", "url": "https://aclanthology.org/2022.acl-long.183/", "abstract": "Generating new events given context with correlated ones plays a crucial role in many event-centric reasoning tasks. Existing works either limit their scope to specific scenarios or overlook event-level correlations. In this paper, we propose to pre-train a general Correlation-aware context-to-Event Transformer (ClarET) for event-centric reasoning. To achieve this, we propose three novel event-centric objectives, i.e., whole event recovering, contrastive event-correlation encoding and prompt-based event locating, which highlight event-level correlations with effective training. The proposed ClarET is applicable to a wide range of event-centric reasoning scenarios, considering its versatility of (i) event-correlation types (e.g., causal, temporal, contrast), (ii) application formulations (i.e., generation and classification), and (iii) reasoning types (e.g., abductive, counterfactual and ending reasoning). Empirical fine-tuning results, as well as zero- and few-shot learning, on 9 benchmarks (5 generation and 4 classification tasks covering 4 reasoning types with diverse event correlations), verify its effectiveness and generalization ability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ClarET：相関に注意したコンテキストからイベントへのトランスフォーマーの事前学習によるイベント中心の生成と分類", "jabstract": "関連するイベントを与えられた文脈から新しいイベントを生成することは、多くのイベント中心の推論タスクにおいて重要な役割を果たします。既存の研究は、特定のシナリオに限定されるか、イベントレベルの相関を見落としています。本論文では、イベント中心の推論のために一般的な相関意識型コンテキストからイベントへのトランスフォーマー（ClarET）を事前学習することを提案します。これを実現するために、全体的なイベントの回復、対照的なイベント相関エンコーディング、プロンプトベースのイベントの位置決めという3つの新しいイベント中心の目的を提案し、効果的なトレーニングでイベントレベルの相関を強調します。提案されたClarETは、（i）イベント相関のタイプ（因果関係、時間的、対照的など）、（ii）アプリケーションの形式（生成と分類）、および（iii）推論のタイプ（演繹的、反事実的、終了推論など）の多様性を考慮して、広範なイベント中心の推論シナリオに適用できます。9つのベンチマーク（4つの推論タイプをカバーし、多様なイベント相関を持つ5つの生成タスクと4つの分類タスク）での経験的な微調整結果、およびゼロショットおよびフューショット学習は、その効果と汎用性を検証しています。"}
{"title": "Measuring and Mitigating Name Biases in Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.184/", "abstract": "Neural Machine Translation (NMT) systems exhibit problematic biases, such as stereotypical gender bias in the translation of occupation terms into languages with grammatical gender. In this paper we describe a new source of bias prevalent in NMT systems, relating to translations of sentences containing person names. To correctly translate such sentences, a NMT system needs to determine the gender of the name. We show that leading systems are particularly poor at this task, especially for female given names. This bias is deeper than given name gender: we show that the translation of terms with ambiguous sentiment can also be affected by person names, and the same holds true for proper nouns denoting race. To mitigate these biases we propose a simple but effective data augmentation method based on randomly switching entities during translation, which effectively eliminates the problem without any effect on translation quality.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨を以下に示します。日本語に翻訳してください。\n\nニューラル機械翻訳における名前バイアスの測定と軽減", "jabstract": "ニューラル機械翻訳（NMT）システムは、文法的性別を持つ言語における職業用語の翻訳において、性別に関するステレオタイプなバイアスなど、問題のあるバイアスを示しています。本論文では、人名を含む文の翻訳に関連する、NMTシステムに普遍的な新しいバイアスの源を説明します。このような文を正しく翻訳するためには、NMTシステムは名前の性別を判断する必要があります。私たちは、主要なシステムがこのタスクに特に苦手であることを示し、特に女性の名前に対してその傾向があることを示します。このバイアスは、名前の性別よりも深いものです。私たちは、曖昧な感情を持つ用語の翻訳も人名に影響を受けることを示し、同様に人種を示す固有名詞にも同じことが言えます。これらのバイアスを緩和するために、私たちは翻訳中にエンティティをランダムに切り替えるという、単純で効果的なデータ拡張方法を提案します。これにより、翻訳品質に影響を与えることなく、問題を効果的に解決することができます。"}
{"title": "Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.185/", "abstract": "In this paper, we present a substantial step in better understanding the SOTA sequence-to-sequence (Seq2Seq) pretraining for neural machine translation (NMT). We focus on studying the impact of the jointly pretrained decoder, which is the main difference between Seq2Seq pretraining and previous encoder-based pretraining approaches for NMT. By carefully designing experiments on three language pairs, we find that Seq2Seq pretraining is a double-edged sword: On one hand, it helps NMT models to produce more diverse translations and reduce adequacy-related translation errors. On the other hand, the discrepancies between Seq2Seq pretraining and NMT finetuning limit the translation quality (i.e., domain discrepancy) and induce the over-estimation issue (i.e., objective discrepancy). Based on these observations, we further propose simple and effective strategies, named in-domain pretraining and input adaptation to remedy the domain and objective discrepancies, respectively. Experimental results on several language pairs show that our approach can consistently improve both translation performance and model robustness upon Seq2Seq pretraining.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nシーケンス・トゥ・シーケンスの事前学習を理解し、ニューラル機械翻訳の改善を図ること。", "jabstract": "本論文では、ニューラル機械翻訳（NMT）のためのSOTAシーケンス・トゥ・シーケンス（Seq2Seq）事前学習をより理解するための重要な一歩を示します。我々は、Seq2Seq事前学習と以前のエンコーダベースの事前学習アプローチの主な違いである共同事前学習デコーダの影響を研究することに焦点を当てています。3つの言語ペアについて実験を慎重に設計することにより、Seq2Seq事前学習は両刃の剣であることがわかりました。一方で、NMTモデルがより多様な翻訳を生成し、適切性に関連する翻訳エラーを減らすのに役立ちます。一方、Seq2Seq事前学習とNMTファインチューニングの間の不一致は、翻訳品質（つまり、ドメインの不一致）を制限し、過大評価の問題（つまり、目的の不一致）を引き起こします。これらの観察に基づいて、我々は、ドメインの不一致を修正するためのインドメイン事前学習と、目的の不一致を修正するための入力適応というシンプルで効果的な戦略を提案しています。いくつかの言語ペアでの実験結果は、我々のアプローチがSeq2Seq事前学習に対して翻訳性能とモデルの堅牢性を一貫して改善できることを示しています。"}
{"title": "MSCTD: A Multimodal Sentiment Chat Translation Dataset", "url": "https://aclanthology.org/2022.acl-long.186/", "abstract": "Multimodal machine translation and textual chat translation have received considerable attention in recent years. Although the conversation in its natural form is usually multimodal, there still lacks work on multimodal machine translation in conversations. In this work, we introduce a new task named Multimodal Chat Translation (MCT), aiming to generate more accurate translations with the help of the associated dialogue history and visual context. To this end, we firstly construct a Multimodal Sentiment Chat Translation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairs in 14,762 bilingual dialogues. Each utterance pair, corresponding to the visual context that reflects the current conversational scene, is annotated with a sentiment label. Then, we benchmark the task by establishing multiple baseline systems that incorporate multimodal and sentiment features for MCT. Preliminary experiments on two language directions (English-Chinese) verify the potential of contextual and multimodal information fusion and the positive impact of sentiment on the MCT task. Additionally, we provide a new benchmark on multimodal dialogue sentiment analysis with the constructed MSCTD. Our work can facilitate researches on both multimodal chat translation and multimodal dialogue sentiment analysis.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MSCTD: マルチモーダル感情チャット翻訳データセット", "jabstract": "近年、多言語機械翻訳とテキストチャット翻訳が注目されています。自然な形での会話は通常、マルチモーダルですが、会話におけるマルチモーダル機械翻訳に関する研究はまだ不十分です。本研究では、関連する対話履歴と視覚的文脈の支援を受けて、より正確な翻訳を生成することを目的とした、Multimodal Chat Translation（MCT）という新しいタスクを紹介します。このために、まず、142,871の英中発話ペアを含む14,762のバイリンガル対話を含むMultimodal Sentiment Chat Translation Dataset（MSCTD）を構築しました。現在の会話シーンを反映する視覚的文脈に対応する各発話ペアは、感情ラベルで注釈が付けられています。次に、マルチモーダルおよび感情特徴をMCTに組み込む複数のベースラインシステムを確立して、タスクをベンチマーク化しました。英中の2つの言語方向での予備実験により、文脈的およびマルチモーダル情報の融合の可能性と、感情がMCTタスクに与える肯定的な影響が確認されました。さらに、構築されたMSCTDによるマルチモーダル対話感情分析の新しいベンチマークを提供します。本研究は、マルチモーダルチャット翻訳とマルチモーダル対話感情分析の両方の研究を促進することができます。"}
{"title": "Learning Disentangled Textual Representations via Statistical Measures of Similarity", "url": "https://aclanthology.org/2022.acl-long.187/", "abstract": "When working with textual data, a natural application of disentangled representations is the fair classification where the goal is to make predictions without being biased (or influenced) by sensible attributes that may be present in the data (e.g., age, gender or race). Dominant approaches to disentangle a sensitive attribute from textual representations rely on learning simultaneously a penalization term that involves either an adversary loss (e.g., a discriminator) or an information measure (e.g., mutual information). However, these methods require the training of a deep neural network with several parameter updates for each update of the representation model. As a matter of fact, the resulting nested optimization loop is both times consuming, adding complexity to the optimization dynamic, and requires a fine hyperparameter selection (e.g., learning rates, architecture). In this work, we introduce a family of regularizers for learning disentangled representations that do not require training. These regularizers are based on statistical measures of similarity between the conditional probability distributions with respect to the sensible attributes. Our novel regularizers do not require additional training, are faster and do not involve additional tuning while achieving better results both when combined with pretrained and randomly initialized text encoders.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「類似性の統計的測定による分離されたテキスト表現の学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Learning Disentangled Textual Representations: 分離されたテキスト表現の学習\n- via Statistical Measures of Similarity: 類似性の統計的測定を通じて", "jabstract": "テキストデータを扱う場合、分離表現の自然な応用は、データに存在する感覚的属性（例：年齢、性別、人種など）にバイアス（または影響）されずに予測を行う公正な分類です。感受性属性をテキスト表現から分離する支配的なアプローチは、敵対的損失（例：識別器）または情報量（例：相互情報量）を含む罰則項を同時に学習することに依存しています。しかし、これらの方法は、表現モデルの更新ごとに複数のパラメータ更新を必要とする深層ニューラルネットワークのトレーニングを必要とします。実際、結果として得られるネストされた最適化ループは、時間がかかり、最適化ダイナミックに複雑さを追加し、ファインハイパーパラメータ選択（例：学習率、アーキテクチャ）が必要です。本研究では、トレーニングを必要としない分離表現の学習のための正則化子族を紹介します。これらの正則化子は、感覚的属性に関する条件付き確率分布間の類似性の統計的測定に基づいています。私たちの新しい正則化子は、追加のトレーニングを必要とせず、より速く、追加の調整を必要とせず、事前にトレーニングされたテキストエンコーダーとランダムに初期化されたテキストエンコーダーの両方でより良い結果を実現します。"}
{"title": "On the Sensitivity and Stability of Model Interpretations in NLP", "url": "https://aclanthology.org/2022.acl-long.188/", "abstract": "Recent years have witnessed the emergence of a variety of post-hoc interpretations that aim to uncover how natural language processing (NLP) models make predictions. Despite the surge of new interpretation methods, it remains an open problem how to define and quantitatively measure the faithfulness of interpretations, i.e., to what extent interpretations reflect the reasoning process by a model. We propose two new criteria, sensitivity and stability, that provide complementary notions of faithfulness to the existed removal-based criteria. Our results show that the conclusion for how faithful interpretations are could vary substantially based on different notions. Motivated by the desiderata of sensitivity and stability, we introduce a new class of interpretation methods that adopt techniques from adversarial robustness. Empirical results show that our proposed methods are effective under the new criteria and overcome limitations of gradient-based methods on removal-based criteria. Besides text classification, we also apply interpretation methods and metrics to dependency parsing. Our results shed light on understanding the diverse set of interpretations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理におけるモデル解釈の感度と安定性について", "jabstract": "近年、自然言語処理（NLP）モデルが予測を行う方法を明らかにするための様々な事後解釈が登場しています。新しい解釈方法が急増しているにもかかわらず、解釈の忠実度を定義し、定量的に測定する方法、つまり解釈がモデルの推論プロセスをどの程度反映しているかを明確にすることは未解決の問題です。私たちは、既存の削除ベースの基準に補完的な忠実度の概念を提供する、感度と安定性の2つの新しい基準を提案します。私たちの結果は、異なる概念に基づいて解釈の忠実度がどのように大きく異なるかを示しています。感度と安定性の要件に基づいて、敵対的な堅牢性の技術を採用した新しい解釈方法のクラスを紹介します。実験結果は、私たちが提案する方法が新しい基準において効果的であり、削除ベースの基準における勾配ベースの方法の制限を克服していることを示しています。テキスト分類に加えて、依存構造解析にも解釈方法とメトリックを適用します。私たちの結果は、多様な解釈の理解に光を当てています。"}
{"title": "Down and Across: Introducing Crossword-Solving as a New NLP Benchmark", "url": "https://aclanthology.org/2022.acl-long.189/", "abstract": "Solving crossword puzzles requires diverse reasoning capabilities, access to a vast amount of knowledge about language and the world, and the ability to satisfy the constraints imposed by the structure of the puzzle. In this work, we introduce solving crossword puzzles as a new natural language understanding task. We release a corpus of crossword puzzles collected from the New York Times daily crossword spanning 25 years and comprised of a total of around nine thousand puzzles. These puzzles include a diverse set of clues: historic, factual, word meaning, synonyms/antonyms, fill-in-the-blank, abbreviations, prefixes/suffixes, wordplay, and cross-lingual, as well as clues that depend on the answers to other clues. We separately release the clue-answer pairs from these puzzles as an open-domain question answering dataset containing over half a million unique clue-answer pairs. For the question answering task, our baselines include several sequence-to-sequence and retrieval-based generative models. We also introduce a non-parametric constraint satisfaction baseline for solving the entire crossword puzzle. Finally, we propose an evaluation framework which consists of several complementary performance metrics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Down and Across: クロスワード解決を新しいNLPベンチマークとして紹介する」", "jabstract": "クロスワードパズルを解くには、多様な推論能力、言語や世界に関する広範な知識へのアクセス、パズルの構造に課せられた制約を満たす能力が必要です。本研究では、クロスワードパズルを新しい自然言語理解タスクとして紹介します。25年間にわたるニューヨーク・タイムズのデイリークロスワードから収集された約9,000のパズルからなるコーパスを公開します。これらのパズルには、歴史的、事実的、単語の意味、類義語/反意語、穴埋め、略語、接頭辞/接尾辞、言葉遊び、クロスリンガルなど、多様な種類の手がかりが含まれています。また、他の手がかりの答えに依存する手がかりも含まれています。これらのパズルから手がかり-答えのペアを別々に公開し、50万以上のユニークな手がかり-答えのペアを含むオープンドメインの質問応答データセットを提供します。質問応答タスクのベースラインには、いくつかのシーケンス-シーケンスおよび検索ベースの生成モデルが含まれます。また、クロスワードパズル全体を解決するための非パラメトリックな制約充足ベースラインを紹介します。最後に、複数の補完的なパフォーマンスメトリックからなる評価フレームワークを提案します。"}
{"title": "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets", "url": "https://aclanthology.org/2022.acl-long.190/", "abstract": "Natural language processing models often exploit spurious correlations between task-independent features and labels in datasets to perform well only within the distributions they are trained on, while not generalising to different task distributions. We propose to tackle this problem by generating a debiased version of a dataset, which can then be used to train a debiased, off-the-shelf model, by simply replacing its training data. Our approach consists of 1) a method for training data generators to generate high-quality, label-consistent data samples; and 2) a filtering mechanism for removing data points that contribute to spurious correlations, measured in terms of z-statistics. We generate debiased versions of the SNLI and MNLI datasets, and we evaluate on a large suite of debiased, out-of-distribution, and adversarial test sets. Results show that models trained on our debiased datasets generalise better than those trained on the original datasets in all settings. On the majority of the datasets, our method outperforms or performs comparably to previous state-of-the-art debiasing strategies, and when combined with an orthogonal technique, product-of-experts, it improves further and outperforms previous best results of SNLI-hard and MNLI-hard.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理における偽の相関を軽減するためのデータ生成", "jabstract": "自然言語処理モデルは、しばしばタスクに依存しない特徴とデータセット内のラベルとの間の偽の相関を利用して、トレーニングされた分布にのみ適切に機能し、異なるタスク分布には一般化できない。本研究では、この問題に対処するために、データセットの偏りを修正したバージョンを生成し、トレーニングデータを置き換えることで、偏りのないオフシェルフモデルをトレーニングすることを提案する。アプローチは、1）高品質でラベルに一致するデータサンプルを生成するためのトレーニングデータジェネレータの方法と、2）z統計量によって測定される偽の相関に貢献するデータポイントを削除するフィルタリングメカニズムから構成される。SNLIおよびMNLIデータセットの偏りのないバージョンを生成し、偏りのない、分布外、および敵対的なテストセットの大規模なスイートで評価する。結果は、当社の偏りのないデータセットでトレーニングされたモデルが、すべての設定で元のデータセットでトレーニングされたモデルよりも一般化能力が高いことを示している。ほとんどのデータセットでは、当社の方法が以前の最先端の偏りのない戦略を上回るか同等の結果を示し、直交技術であるエキスパートの積と組み合わせると、SNLI-hardおよびMNLI-hardの以前の最高結果を上回る。"}
{"title": "GL-CLeF: A Global–Local Contrastive Learning Framework for Cross-lingual Spoken Language Understanding", "url": "https://aclanthology.org/2022.acl-long.191/", "abstract": "Due to high data demands of current methods, attention to zero-shot cross-lingual spoken language understanding (SLU) has grown, as such approaches greatly reduce human annotation effort. However, existing models solely rely on shared parameters, which can only perform implicit alignment across languages. We present Global-Local Contrastive Learning Framework (GL-CLeF) to address this shortcoming. Specifically, we employ contrastive learning, leveraging bilingual dictionaries to construct multilingual views of the same utterance, then encourage their representations to be more similar than negative example pairs, which achieves to explicitly align representations of similar sentences across languages. In addition, a key step in GL-CLeF is a proposed Local and Global component, which achieves a fine-grained cross-lingual transfer (i.e., sentence-level Local intent transfer, token-level Local slot transfer, and semantic-level Global transfer across intent and slot). Experiments on MultiATIS++ show that GL-CLeF achieves the best performance and successfully pulls representations of similar sentences across languages closer.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "GL-CLeF：クロスリンガル音声言語理解のためのグローバル-ローカル対比学習フレームワーク", "jabstract": "現在の手法の高いデータ要件により、人間の注釈作業を大幅に削減することができるため、ゼロショットクロスリンガルスポークンランゲージアンダースタンディング（SLU）への注目が高まっています。しかし、既存のモデルは共有パラメータにのみ依存しており、言語間の暗黙のアラインメントしか実行できません。本研究では、この欠点を解決するために、グローバル・ローカルコントラスティブラーニングフレームワーク（GL-CLeF）を提案します。具体的には、コントラスティブラーニングを採用し、バイリンガル辞書を活用して同じ発話の多言語ビューを構築し、負の例のペアよりもその表現がより類似するように促し、言語間で類似する文の表現を明示的にアラインメントすることを実現します。さらに、GL-CLeFの重要なステップは、ローカルとグローバルのコンポーネントを提案することで、細かいクロスリンガルトランスファー（つまり、文レベルのローカルインテントトランスファー、トークンレベルのローカルスロットトランスファー、およびインテントとスロットを横断する意味レベルのグローバルトランスファー）を実現します。MultiATIS++での実験結果から、GL-CLeFが最高の性能を発揮し、類似する文の表現を言語間でより近づけることに成功しています。"}
{"title": "Good Examples Make A Faster Learner: Simple Demonstration-based Learning for Low-resource NER", "url": "https://aclanthology.org/2022.acl-long.192/", "abstract": "Recent advances in prompt-based learning have shown strong results on few-shot text classification by using cloze-style templates.Similar attempts have been made on named entity recognition (NER) which manually design templates to predict entity types for every text span in a sentence. However, such methods may suffer from error propagation induced by entity span detection, high cost due to enumeration of all possible text spans, and omission of inter-dependencies among token labels in a sentence. Here we present a simple demonstration-based learning method for NER, which lets the input be prefaced by task demonstrations for in-context learning. We perform a systematic study on demonstration strategy regarding what to include (entity examples, with or without surrounding context), how to select the examples, and what templates to use. Results on in-domain learning and domain adaptation show that the model’s performance in low-resource settings can be largely improved with a suitable demonstration strategy (e.g., a 4-17% improvement on 25 train instances). We also find that good demonstration can save many labeled examples and consistency in demonstration contributes to better performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "良い例はより速い学習者を作る：低リソースNERのためのシンプルなデモンストレーションベースの学習", "jabstract": "プロンプトベースの学習の最近の進歩により、クローズスタイルのテンプレートを使用してフューショットテキスト分類に強い結果が示されています。同様の試みが、名前付きエンティティ認識（NER）においても行われており、文のすべてのテキストスパンに対してエンティティタイプを予測するために手動でテンプレートを設計しています。しかし、このような方法は、エンティティスパンの検出によって誘発されるエラー伝播、すべての可能なテキストスパンの列挙による高コスト、および文中のトークンラベル間の相互依存関係の省略などの問題がある可能性があります。ここでは、タスクのデモンストレーションを入力の前置きとして使用して、コンテキスト内学習を可能にする、NERのためのシンプルなデモンストレーションベースの学習方法を提案します。私たちは、何を含めるか（周囲の文脈を持つエンティティ例）、どのように例を選択するか、どのテンプレートを使用するかに関するデモンストレーション戦略について系統的な研究を行います。ドメイン内学習とドメイン適応の結果から、適切なデモンストレーション戦略（例えば、25のトレーニングインスタンスで4-17％の改善）により、低リソース環境でのモデルのパフォーマンスを大幅に改善できることがわかりました。また、良好なデモンストレーションは多くのラベル付き例を節約でき、デモンストレーションの一貫性がより良いパフォーマンスに貢献することがわかりました。"}
{"title": "Contextual Representation Learning beyond Masked Language Modeling", "url": "https://aclanthology.org/2022.acl-long.193/", "abstract": "Currently, masked language modeling (e.g., BERT) is the prime choice to learn contextualized representations. Due to the pervasiveness, it naturally raises an interesting question: how do masked language models (MLMs) learn contextual representations? In this work, we analyze the learning dynamics of MLMs and find that it adopts sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs. To address these problems, we propose TACO, a simple yet effective representation learning approach to directly model global semantics. To be specific, TACO extracts and aligns contextual semantics hidden in contextualized representations to encourage models to attend global semantics when generating contextualized representations. Experiments on the GLUE benchmark show that TACO achieves up to 5x speedup and up to 1.2 points average improvement over MLM.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「マスクされた言語モデリング」を超えた文脈表現学習", "jabstract": "現在、マスクされた言語モデリング（例：BERT）は、文脈化された表現を学習するための主要な選択肢です。普及性があるため、自然に興味深い問題が生じます。すなわち、マスクされた言語モデル（MLM）はどのように文脈化された表現を学習するのでしょうか？本研究では、MLMの学習ダイナミクスを分析し、サンプリングされた埋め込みをアンカーとして採用し、表現に文脈的な意味を推定して注入することがわかりました。これにより、MLMの効率と効果が制限されます。これらの問題に対処するために、私たちはTACOを提案します。TACOは、グローバルな意味を直接モデル化するためのシンプルで効果的な表現学習アプローチです。具体的には、TACOは、文脈化された表現に隠された文脈的な意味を抽出し、整列させ、文脈化された表現を生成する際にモデルがグローバルな意味に注意を払うように促します。GLUEベンチマークの実験では、TACOはMLMに比べて最大5倍の高速化と平均1.2ポイントの改善を達成しました。"}
{"title": "Efficient Hyper-parameter Search for Knowledge Graph Embedding", "url": "https://aclanthology.org/2022.acl-long.194/", "abstract": "While hyper-parameters (HPs) are important for knowledge graph (KG) learning, existing methods fail to search them efficiently. To solve this problem, we first analyze the properties of different HPs and measure the transfer ability from small subgraph to the full graph. Based on the analysis, we propose an efficient two-stage search algorithm KGTuner, which efficiently explores HP configurations on small subgraph at the first stage and transfers the top-performed configurations for fine-tuning on the large full graph at the second stage. Experiments show that our method can consistently find better HPs than the baseline algorithms within the same time budget, which achieves 9.1% average relative improvement for four embedding models on the large-scale KGs in open graph benchmark. Our code is released in https://github. com/AutoML-Research/KGTuner.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約の以下の文を日本語に翻訳してください：\n\n知識グラフ埋め込みの効率的なハイパーパラメーター検索", "jabstract": "ハイパーパラメータ（HP）は知識グラフ（KG）学習において重要であるが、既存の方法は効率的にそれらを探索することができない。この問題を解決するために、まず異なるHPの特性を分析し、小さなサブグラフから全グラフへの転送能力を測定する。この分析に基づいて、我々は効率的な2段階の探索アルゴリズムKGTunerを提案する。このアルゴリズムは、最初の段階で小さなサブグラフ上でHP構成を効率的に探索し、上位の構成を2番目の段階で大きな全グラフ上で微調整する。実験結果は、同じ時間予算内でベースラインアルゴリズムよりも優れたHPを一貫して見つけることができることを示し、オープングラフベンチマークの大規模KGにおいて4つの埋め込みモデルに対して9.1％の平均相対改善を達成した。我々のコードはhttps://github.com/AutoML-Research/KGTunerで公開されている。"}
{"title": "A Meta-framework for Spatiotemporal Quantity Extraction from Text", "url": "https://aclanthology.org/2022.acl-long.195/", "abstract": "News events are often associated with quantities (e.g., the number of COVID-19 patients or the number of arrests in a protest), and it is often important to extract their type, time, and location from unstructured text in order to analyze these quantity events. This paper thus formulates the NLP problem of spatiotemporal quantity extraction, and proposes the first meta-framework for solving it. This meta-framework contains a formalism that decomposes the problem into several information extraction tasks, a shareable crowdsourcing pipeline, and transformer-based baseline models. We demonstrate the meta-framework in three domains—the COVID-19 pandemic, Black Lives Matter protests, and 2020 California wildfires—to show that the formalism is general and extensible, the crowdsourcing pipeline facilitates fast and high-quality data annotation, and the baseline system can handle spatiotemporal quantity extraction well enough to be practically useful. We release all resources for future research on this topic at https://github.com/steqe.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストからの時空間数量抽出のためのメタフレームワーク", "jabstract": "ニュースイベントはしばしば数量（例えば、COVID-19患者数や抗議活動での逮捕者数）と関連付けられ、これらの数量イベントを分析するために、その種類、時間、場所を非構造化テキストから抽出することが重要です。本論文では、このような空間時間数量抽出のNLP問題を定式化し、その解決のための最初のメタフレームワークを提案します。このメタフレームワークには、問題をいくつかの情報抽出タスクに分解する形式化、共有可能なクラウドソーシングパイプライン、およびトランスフォーマーベースのベースラインモデルが含まれます。我々は、COVID-19パンデミック、Black Lives Matter抗議、および2020年カリフォルニア山火事の3つのドメインでメタフレームワークを実証し、形式化が一般的かつ拡張可能であること、クラウドソーシングパイプラインが迅速かつ高品質のデータ注釈を促進すること、およびベースラインシステムが空間時間数量抽出を十分に扱える実用的なツールであることを示します。我々は、このトピックに関する将来の研究のためのすべてのリソースをhttps://github.com/steqeで公開しています。"}
{"title": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on Intermediate Pre-training for Cross-Modal Knowledge Transfer", "url": "https://aclanthology.org/2022.acl-long.196/", "abstract": "Pre-trained language models are still far from human performance in tasks that need understanding of properties (e.g. appearance, measurable quantity) and affordances of everyday objects in the real world since the text lacks such information due to reporting bias.In this work, we study whether integrating visual knowledge into a language model can fill the gap.We investigate two types of knowledge transfer: (1) text knowledge transfer using image captions that may contain enriched visual knowledge and (2) cross-modal knowledge transfer using both images and captions with vision-language training objectives.On 5 downstream tasks that may need visual knowledge to solve the problem, we perform extensive empirical comparisons over the presented objectives.Our experiments show that visual knowledge transfer can improve performance in both low-resource and fully supervised settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "言語タスクにおける視覚的知識の活用：クロスモーダル知識転移のための中間プレトレーニングに関する実証的研究", "jabstract": "事前学習された言語モデルは、外観や測定可能な量などの特性や日常の物体の機能を理解する必要があるタスクにおいて、報告バイアスによりテキストにそのような情報が欠落しているため、人間のパフォーマンスからはまだ遠い。本研究では、視覚的な知識を言語モデルに統合することで、このギャップを埋めることができるかどうかを調査する。我々は、(1)豊富な視覚的知識を含む画像キャプションを使用したテキスト知識の転移と、(2)ビジョン-言語トレーニング目標を持つ画像とキャプションの両方を使用したクロスモーダル知識の転移の2種類の知識転移を調査する。視覚的知識が必要な5つの下流タスクについて、提示された目的について広範な実験的比較を行う。実験結果は、視覚的知識の転移が、低リソースおよび完全に監視された設定の両方でパフォーマンスを向上させることを示している。"}
{"title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models", "url": "https://aclanthology.org/2022.acl-long.197/", "abstract": "Large pre-trained vision-language (VL) models can learn a new task with a handful of examples and generalize to a new task without fine-tuning.However, these VL models are hard to deploy for real-world applications due to their impractically huge sizes and slow inference speed.To solve this limitation, we study prompt-based low-resource learning of VL tasks with our proposed method, FewVLM, relatively smaller than recent few-shot learners.For FewVLM, we pre-train a sequence-to-sequence transformer model with prefix language modeling (PrefixLM) and masked language modeling (MaskedLM).Furthermore, we analyze the effect of diverse prompts for few-shot tasks.Experimental results on VQA show that FewVLM with prompt-based learning outperforms Frozen which is 31x larger than FewVLM by 18.2% point and achieves comparable results to a 246x larger model, PICa.In our analysis, we observe that (1) prompts significantly affect zero-shot performance but marginally affect few-shot performance, (2) models with noisy prompts learn as quickly as hand-crafted prompts given larger training data, and (3) MaskedLM helps VQA tasks while PrefixLM boosts captioning performance. Our code is publicly available at https://github.com/woojeongjin/FewVLM", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "良いプロンプトは数百万のパラメータに値する：ビジョン・ランゲージ・モデルの低リソース・プロンプトベース学習", "jabstract": "大規模な事前学習済みのビジョン・ランゲージ（VL）モデルは、わずかな例で新しいタスクを学習し、微調整なしで新しいタスクに汎用化できます。しかし、これらのVLモデルは、実用的に巨大なサイズと遅い推論速度のため、実世界のアプリケーションに展開するのが困難です。この制限を解決するために、我々は、FewVLMという提案手法を用いたプロンプトベースの低リソース学習によるVLタスクの研究を行いました。FewVLMは、最近のfew-shot学習者よりも比較的小さいもので、PrefixLM（接頭辞言語モデリング）とMaskedLM（マスク言語モデリング）を用いたシーケンス・トゥ・シーケンス・トランスフォーマーモデルを事前学習します。さらに、FewVLMにおいて、few-shotタスクのための多様なプロンプトの効果を分析します。VQAにおける実験結果は、プロンプトベースの学習を行うFewVLMが、31倍も大きいFrozenに比べて18.2%ポイント高い性能を発揮し、246倍も大きいPICaモデルと同等の結果を達成することを示しています。我々の分析では、（1）プロンプトはゼロショットの性能に大きく影響するが、few-shotの性能にはわずかに影響する、（2）ノイズのあるプロンプトを用いたモデルは、より大きなトレーニングデータが与えられた場合に手作りのプロンプトと同じ速度で学習することができ、（3）MaskedLMはVQAタスクに役立ち、PrefixLMはキャプショニングの性能を向上させます。我々のコードは、https://github.com/woojeongjin/FewVLMで公開されています。"}
{"title": "Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation", "url": "https://aclanthology.org/2022.acl-long.198/", "abstract": "Existing continual relation learning (CRL) methods rely on plenty of labeled training data for learning a new task, which can be hard to acquire in real scenario as getting large and representative labeled data is often expensive and time-consuming. It is therefore necessary for the model to learn novel relational patterns with very few labeled data while avoiding catastrophic forgetting of previous task knowledge. In this paper, we formulate this challenging yet practical problem as continual few-shot relation learning (CFRL). Based on the finding that learning for new emerging few-shot tasks often results in feature distributions that are incompatible with previous tasks’ learned distributions, we propose a novel method based on embedding space regularization and data augmentation. Our method generalizes to new few-shot tasks and avoids catastrophic forgetting of previous tasks by enforcing extra constraints on the relational embeddings and by adding extra relevant data in a self-supervised manner. With extensive experiments we demonstrate that our method can significantly outperform previous state-of-the-art methods in CFRL task settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「埋め込み空間正則化とデータ拡張による継続的なフューショット関係学習」に関する論文の要約文です。", "jabstract": "既存の持続的関係学習（CRL）手法は、新しいタスクを学習するために十分なラベル付きトレーニングデータに依存していますが、大規模で代表的なラベル付きデータを取得することはしばしば高価で時間がかかるため、実際のシナリオで取得することが困難です。したがって、モデルは前のタスクの知識を忘れることなく、非常に少数のラベル付きデータで新しい関係パターンを学習する必要があります。本論文では、このような課題を持続的なフューショット関係学習（CFRL）として定式化します。新しい出現するフューショットタスクの学習は、前のタスクの学習済み分布と互換性のない特徴分布をもたらすことが多いことから、埋め込み空間の正則化とデータ拡張に基づく新しい手法を提案します。当社の手法は、関係埋め込みに追加の制約を課し、自己監督的な方法で追加の関連データを追加することにより、新しいフューショットタスクに汎化し、前のタスクの重大な忘却を回避します。広範な実験により、当社の手法がCFRLタスク設定で以前の最先端の手法を大幅に上回ることを示します。"}
{"title": "Variational Graph Autoencoding as Cheap Supervision for AMR Coreference Resolution", "url": "https://aclanthology.org/2022.acl-long.199/", "abstract": "Coreference resolution over semantic graphs like AMRs aims to group the graph nodes that represent the same entity. This is a crucial step for making document-level formal semantic representations. With annotated data on AMR coreference resolution, deep learning approaches have recently shown great potential for this task, yet they are usually data hunger and annotations are costly. We propose a general pretraining method using variational graph autoencoder (VGAE) for AMR coreference resolution, which can leverage any general AMR corpus and even automatically parsed AMR data. Experiments on benchmarks show that the pretraining approach achieves performance gains of up to 6% absolute F1 points. Moreover, our model significantly improves on the previous state-of-the-art model by up to 11% F1.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AMR共参照解決のための安価な監視としての変分グラフ自己符号化", "jabstract": "AMRのような意味グラフ上の共参照解析は、同じエンティティを表すグラフノードをグループ化することを目的としています。これは、文書レベルの形式的意味表現を作成するための重要なステップです。AMR共参照解析の注釈付きデータを使用した深層学習アプローチは、最近このタスクに対して大きなポテンシャルを示していますが、通常はデータが豊富で注釈が高価です。我々は、AMR共参照解析のための変分グラフオートエンコーダ（VGAE）を使用した一般的な事前学習方法を提案しています。これは、一般的なAMRコーパスや自動的に解析されたAMRデータを活用することができます。ベンチマーク実験の結果、事前学習アプローチは、最大6％の絶対F1ポイントの性能向上を実現しました。さらに、我々のモデルは、以前の最先端モデルに対して最大11％のF1で大幅に改善されました。"}
{"title": "Identifying Chinese Opinion Expressions with Extremely-Noisy Crowdsourcing Annotations", "url": "https://aclanthology.org/2022.acl-long.200/", "abstract": "Recent works of opinion expression identification (OEI) rely heavily on the quality and scale of the manually-constructed training corpus, which could be extremely difficult to satisfy. Crowdsourcing is one practical solution for this problem, aiming to create a large-scale but quality-unguaranteed corpus. In this work, we investigate Chinese OEI with extremely-noisy crowdsourcing annotations, constructing a dataset at a very low cost. Following Zhang el al. (2021), we train the annotator-adapter model by regarding all annotations as gold-standard in terms of crowd annotators, and test the model by using a synthetic expert, which is a mixture of all annotators. As this annotator-mixture for testing is never modeled explicitly in the training phase, we propose to generate synthetic training samples by a pertinent mixup strategy to make the training and testing highly consistent. The simulation experiments on our constructed dataset show that crowdsourcing is highly promising for OEI, and our proposed annotator-mixup can further enhance the crowdsourcing modeling.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "極めてノイズの多いクラウドソーシング注釈を用いた中国語の意見表現の識別", "jabstract": "最近の意見表明識別（OEI）の研究では、手動で構築されたトレーニングコーパスの品質と規模に大きく依存しており、非常に満足するのが非常に困難である。クラウドソーシングは、大規模で品質が保証されていないコーパスを作成することを目的とした、この問題の実用的な解決策の1つである。本研究では、非常にノイズの多いクラウドソーシング注釈を用いて中国語のOEIを調査し、非常に低コストでデータセットを構築する。Zhangら（2021）に従い、すべての注釈をクラウド注釈者のゴールドスタンダードとして扱い、合成専門家（すべての注釈者の混合物）を使用してモデルをテストすることで、注釈者アダプターモデルをトレーニングする。このテスト用の注釈者混合物はトレーニングフェーズで明示的にモデル化されないため、トレーニングとテストを高度に一致させるために、適切なミックスアップ戦略によって合成トレーニングサンプルを生成することを提案する。構築したデータセットでのシミュレーション実験は、クラウドソーシングがOEIに非常に有望であり、提案された注釈者ミックスアップがクラウドソーシングモデリングをさらに強化できることを示している。"}
{"title": "Sequence-to-Sequence Knowledge Graph Completion and Question Answering", "url": "https://aclanthology.org/2022.acl-long.201/", "abstract": "Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors. These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA). KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities. For downstream tasks these atomic entity representations often need to be integrated into a multi stage pipeline, limiting their utility. We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and incomplete KG question answering. We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with autoregressive decoding. Such a simple but powerful method reduces the model size up to 98% compared to conventional KGE models while keeping inference time tractable. After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nシーケンス・トゥ・シーケンスの知識グラフ補完と質問応答", "jabstract": "知識グラフ埋め込み（KGE）モデルは、低次元の埋め込みベクトルを使用して、知識グラフ（KG）の各エンティティと関係を表します。これらの方法は、最近、不完全なKG上のKGリンク予測および質問応答（KGQA）に適用されています。 KGEは通常、グラフ内の各エンティティに対して埋め込みを作成するため、数百万のエンティティを持つ実世界のグラフでは大きなモデルサイズになります。下流のタスクでは、これらの原子エンティティ表現を多段階パイプラインに統合する必要があるため、その有用性が制限されます。私たちは、オフシェルフのエンコーダーデコーダートランスフォーマーモデルが、スケーラブルで多目的なKGEモデルとして機能し、KGリンク予測および不完全なKG質問応答の最新の結果を得ることができることを示します。これは、KGリンク予測をシーケンスツーシーケンスのタスクとして提示し、従来のKGE方法で採用されたトリプルスコアリングアプローチを自己回帰デコーディングに交換することによって実現されます。このようなシンプルで強力な方法により、従来のKGEモデルと比較してモデルサイズを最大98％削減し、推論時間を扱いやすくします。このモデルを不完全なKG上のKGQAタスクでファインチューニングした後、私たちのアプローチは、広範な大規模データセットでベースラインを上回り、広範なハイパーパラメーターチューニングなしで最高の結果を得ました。"}
{"title": "Learning to Mediate Disparities Towards Pragmatic Communication", "url": "https://aclanthology.org/2022.acl-long.202/", "abstract": "Human communication is a collaborative process. Speakers, on top of conveying their own intent, adjust the content and language expressions by taking the listeners into account, including their knowledge background, personalities, and physical capabilities. Towards building AI agents with similar abilities in language communication, we propose a novel rational reasoning framework, Pragmatic Rational Speaker (PRS), where the speaker attempts to learn the speaker-listener disparity and adjust the speech accordingly, by adding a light-weighted disparity adjustment layer into working memory on top of speaker’s long-term memory system. By fixing the long-term memory, the PRS only needs to update its working memory to learn and adapt to different types of listeners. To validate our framework, we create a dataset that simulates different types of speaker-listener disparities in the context of referential games. Our empirical results demonstrate that the PRS is able to shift its output towards the language that listeners are able to understand, significantly improve the collaborative task outcome, and learn the disparity more efficiently than joint training.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨の以下の文を日本語に翻訳してください：\n\n実用的なコミュニケーションに向けた不均等を調停することを学ぶ", "jabstract": "人間のコミュニケーションは協力的なプロセスである。話者は自分の意図を伝えるだけでなく、聞き手の知識背景、個性、身体能力などを考慮して、内容や言語表現を調整する。同様の言語コミュニケーション能力を持つAIエージェントを構築するために、私たちは新しい合理的推論フレームワーク、Pragmatic Rational Speaker（PRS）を提案する。ここでは、話者はスピーカーとリスナーの差異を学習し、スピーチを調整するために、長期記憶システムの上に軽量の差異調整層を作業メモリに追加する。長期記憶を固定することで、PRSは作業メモリを更新するだけで、異なるタイプのリスナーに適応することができる。私たちは、参照ゲームの文脈で異なるタイプのスピーカーとリスナーの差異をシミュレートするデータセットを作成し、フレームワークを検証する。実験結果は、PRSがリスナーが理解できる言語に出力をシフトし、協力的なタスクの結果を大幅に改善し、共同トレーニングよりも効率的に差異を学習できることを示している。"}
{"title": "Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval", "url": "https://aclanthology.org/2022.acl-long.203/", "abstract": "Recent research demonstrates the effectiveness of using fine-tuned language models (LM) for dense retrieval. However, dense retrievers are hard to train, typically requiring heavily engineered fine-tuning pipelines to realize their full potential. In this paper, we identify and address two underlying problems of dense retrievers: i) fragility to training data noise and ii) requiring large batches to robustly learn the embedding space. We use the recently proposed Condenser pre-training architecture, which learns to condense information into the dense vector through LM pre-training. On top of it, we propose coCondenser, which adds an unsupervised corpus-level contrastive loss to warm up the passage embedding space. Experiments on MS-MARCO, Natural Question, and Trivia QA datasets show that coCondenser removes the need for heavy data engineering such as augmentation, synthesis, or filtering, and the need for large batch training. It shows comparable performance to RocketQA, a state-of-the-art, heavily engineered system, using simple small batch fine-tuning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "密なパッセージ検索のための教師なしコーパス認識言語モデルの事前学習", "jabstract": "最近の研究では、ファインチューニングされた言語モデル（LM）を使用した密な検索の効果が示されています。しかし、密な検索はトレーニングが難しく、通常は完全なポテンシャルを実現するために重度のエンジニアリングされたファインチューニングパイプラインが必要です。本論文では、密な検索の2つの根本的な問題、すなわちi）トレーニングデータのノイズに対する脆弱性とii）埋め込み空間を堅牢に学習するために大きなバッチが必要であることを特定し、対処します。我々は、最近提案されたCondenserプレトレーニングアーキテクチャを使用し、LMプレトレーニングを通じて情報を密なベクトルに凝縮する方法を学びます。その上、我々はcoCondenserを提案し、無監督のコーパスレベルの対比損失を追加して、パッセージ埋め込み空間をウォームアップします。MS-MARCO、Natural Question、Trivia QAデータセットでの実験では、coCondenserは、拡張、合成、またはフィルタリングなどの重度のデータエンジニアリングや大規模なバッチトレーニングの必要性を除去し、シンプルな小規模バッチのファインチューニングを使用した、重度にエンジニアリングされたシステムであるRocketQAと同等の性能を示します。"}
{"title": "Multimodal Dialogue Response Generation", "url": "https://aclanthology.org/2022.acl-long.204/", "abstract": "Responsing with image has been recognized as an important capability for an intelligent conversational agent. Yet existing works only focus on exploring the multimodal dialogue models which depend on retrieval-based methods, but neglecting generation methods. To fill in the gaps, we first present a new task: multimodal dialogue response generation (MDRG) - given the dialogue history, one model needs to generate a text sequence or an image as response. Learning such a MDRG model often requires multimodal dialogues containing both texts and images which are difficult to obtain. Motivated by the challenge in practice, we consider MDRG under a natural assumption that only limited training examples are available. In such a low-resource setting, we devise a novel conversational agent, Divter, in order to isolate parameters that depend on multimodal dialogues from the entire generation model. By this means, the major part of the model can be learned from a large number of text-only dialogues and text-image pairs respectively, then the whole parameters can be well fitted using the limited training examples. Extensive experiments demonstrate our method achieves state-of-the-art results in both automatic and human evaluation, and can generate informative text and high-resolution image responses.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n多様なモーダルダイアログ応答生成", "jabstract": "画像を用いた応答は、知的な会話エージェントにとって重要な機能であると認識されています。しかし、既存の研究は、検索ベースの手法に依存する多様な対話モデルの探索に焦点を当てており、生成ベースの手法を無視しています。このギャップを埋めるために、私たちはまず、新しいタスクである多様な対話応答生成（MDRG）を提案します。つまり、対話履歴が与えられた場合、1つのモデルが応答としてテキストシーケンスまたは画像を生成する必要があります。このようなMDRGモデルを学習するには、テキストと画像の両方を含む多様な対話が必要であり、これらは入手が困難です。このような低リソースの状況で、私たちは、限られたトレーニング例しか利用できないという自然な仮定の下でMDRGを考慮します。このような場合、私たちは、Divterという新しい会話エージェントを開発し、多様な対話に依存するパラメータを全体の生成モデルから分離することで、モデルの主要な部分をテキストのみの対話とテキスト-画像のペアそれぞれから学習することができます。そして、限られたトレーニング例を用いて全体のパラメータを適切にフィットすることができます。広範な実験により、私たちの方法が自動評価と人間の評価の両方で最先端の結果を達成し、情報量の多いテキストと高解像度の画像応答を生成できることが示されました。"}
{"title": "CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion", "url": "https://aclanthology.org/2022.acl-long.205/", "abstract": "Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC’s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (CAKE) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CAKE：多視点知識グラフ補完のためのスケーラブルな常識認識フレームワーク", "jabstract": "知識グラフは、不可避的に未完成のまま多数の事実トリプルを保存しています。従来の知識グラフ補完（KGC）モデルは、貴重な常識的知識を無視し、事実ビューデータに頼ってエンティティ間の欠落したリンクを予測していました。従来の知識グラフ埋め込み（KGE）技術は、無効な負のサンプリングと事実ビューリンク予測の不確実性に苦しんでおり、KGCのパフォーマンスを制限しています。上記の課題に対処するために、我々は新しいスケーラブルなCommonsense-Aware Knowledge Embedding（CAKE）フレームワークを提案し、エンティティ概念を持つ事実トリプルから常識を自動的に抽出します。生成された常識は、効果的な自己監視を補完し、高品質の負のサンプリング（NS）と共通の常識と事実ビューリンク予測を促進します。KGCタスクの実験結果は、当社のフレームワークの組み立てが元のKGEモデルのパフォーマンスを向上させることを示し、提案された常識的なNSモジュールは他のNS技術よりも優れています。さらに、当社の提案されたフレームワークは、さまざまなKGEモデルに簡単に適応でき、予測結果を説明できます。"}
{"title": "Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.206/", "abstract": "Most dominant neural machine translation (NMT) models are restricted to make predictions only according to the local context of preceding words in a left-to-right manner. Although many previous studies try to incorporate global information into NMT models, there still exist limitations on how to effectively exploit bidirectional global context. In this paper, we propose a Confidence Based Bidirectional Global Context Aware (CBBGCA) training framework for NMT, where the NMT model is jointly trained with an auxiliary conditional masked language model (CMLM). The training consists of two stages: (1) multi-task joint training; (2) confidence based knowledge distillation. At the first stage, by sharing encoder parameters, the NMT model is additionally supervised by the signal from the CMLM decoder that contains bidirectional global contexts. Moreover, at the second stage, using the CMLM as teacher, we further pertinently incorporate bidirectional global context to the NMT model on its unconfidently-predicted target words via knowledge distillation. Experimental results show that our proposed CBBGCA training framework significantly improves the NMT model by +1.02, +1.30 and +0.57 BLEU scores on three large-scale translation datasets, namely WMT’14 English-to-German, WMT’19 Chinese-to-English and WMT’14 English-to-French, respectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル機械翻訳のための信頼度に基づく双方向グローバルコンテキスト感知トレーニングフレームワーク", "jabstract": "最も優勢なニューラル機械翻訳（NMT）モデルは、左から右への単語の前の文脈に基づいて予測を行うことに制限されています。以前の多くの研究がグローバル情報をNMTモデルに組み込もうと試みてきましたが、効果的に双方向のグローバルコンテキストを利用する方法にはまだ制限があります。本論文では、NMTのための信頼度ベースの双方向グローバルコンテキスト意識（CBBGCA）トレーニングフレームワークを提案します。ここでは、NMTモデルは補助条件付きマスク言語モデル（CMLM）と共に共同でトレーニングされます。トレーニングは2つのステージで構成されています：（1）マルチタスク共同トレーニング；（2）信頼度に基づく知識蒸留。第1ステージでは、エンコーダーパラメータを共有することにより、NMTモデルは双方向のグローバルコンテキストを含むCMLMデコーダーからの信号によって追加的に監視されます。さらに、第2ステージでは、CMLMを教師として使用し、知識蒸留を介してNMTモデルに双方向のグローバルコンテキストを適切に組み込みます。実験結果は、提案されたCBBGCAトレーニングフレームワークが、WMT'14英語-ドイツ語、WMT'19中国語-英語、WMT'14英語-フランス語の3つの大規模な翻訳データセットで、それぞれ+1.02、+1.30、+0.57 BLEUスコアを大幅に改善することを示しています。"}
{"title": "BRIO: Bringing Order to Abstractive Summarization", "url": "https://aclanthology.org/2022.acl-long.207/", "abstract": "Abstractive summarization models are commonly trained using maximum likelihood estimation, which assumes a deterministic (one-point) target distribution in which an ideal model will assign all the probability mass to the reference summary. This assumption may lead to performance degradation during inference, where the model needs to compare several system-generated (candidate) summaries that have deviated from the reference summary. To address this problem, we propose a novel training paradigm which assumes a non-deterministic distribution so that different candidate summaries are assigned probability mass according to their quality. Our method achieves a new state-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07 ROUGE-1) datasets. Further analysis also shows that our model can estimate probabilities of candidate summaries that are more correlated with their level of quality.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BRIO：抽象的要約化に秩序をもたらす\n\nNatural language processing (NLP) has made significant progress in recent years, particularly in the area of abstractive summarization, which involves generating a concise summary of a longer text that captures its main points. \n\n自然言語処理（NLP）は、特に抽象的要約化の分野において、長いテキストの主要なポイントを捉えた簡潔な要約を生成することを含む、近年著しい進歩を遂げています。\n\nHowever, current abstractive summarization models often produce summaries that are inaccurate, incomplete, or inconsistent with the original text. \n\nしかし、現在の抽象的要約化モデルは、しばしば不正確で不完全であり、原文と矛盾する要約を生成します。\n\nTo address these issues, we propose BRIO, a novel framework for abstractive summarization that leverages recent advances in neural machine translation and reinforcement learning. \n\nこれらの問題に対処するために、我々はBRIOを提案します。BRIOは、ニューラル機械翻訳と強化学習の最近の進歩を活用した、抽象的要約化のための新しいフレームワークです。", "jabstract": "抽象的要約モデルは、理想的なモデルが参照要約にすべての確率質量を割り当てると仮定する決定論的（一点）ターゲット分布を使用して一般的にトレーニングされます。この仮定は、モデルが参照要約から逸脱した複数のシステム生成（候補）要約を比較する必要がある推論中に性能低下を引き起こす可能性があります。この問題に対処するために、我々は、異なる候補要約がその品質に応じて確率質量が割り当てられる非決定論的分布を仮定する新しいトレーニングパラダイムを提案します。我々の方法は、CNN/DailyMail（47.78 ROUGE-1）およびXSum（49.07 ROUGE-1）データセットで新しい最高の結果を達成します。さらに、分析により、我々のモデルが、品質レベルにより相関する候補要約の確率を推定できることも示されています。"}
{"title": "Leveraging Relaxed Equilibrium by Lazy Transition for Sequence Modeling", "url": "https://aclanthology.org/2022.acl-long.208/", "abstract": "In sequence modeling, certain tokens are usually less ambiguous than others, and representations of these tokens require fewer refinements for disambiguation. However, given the nature of attention-based models like Transformer and UT (universal transformer), all tokens are equally processed towards depth. Inspired by the equilibrium phenomenon, we present a lazy transition, a mechanism to adjust the significance of iterative refinements for each token representation. Our lazy transition is deployed on top of UT to build LT (lazy transformer), where all tokens are processed unequally towards depth. Eventually, LT is encouraged to oscillate around a relaxed equilibrium. Our experiments show that LT outperforms baseline models on several tasks of machine translation, pre-training, Learning to Execute, and LAMBADA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「シーケンスモデリングにおいて、怠惰な遷移による緩和平衡を活用すること」による研究。", "jabstract": "シーケンスモデリングにおいて、特定のトークンは通常、他のトークンよりも曖昧性が少なく、これらのトークンの表現には曖昧性を解消するための修正が少なくて済みます。ただし、TransformerやUT（ユニバーサルトランスフォーマー）などのアテンションベースのモデルの性質を考慮すると、すべてのトークンが同じように深さに向けて処理されます。均衡現象に着想を得て、各トークン表現の反復的な修正の重要性を調整するメカニズムである怠惰な遷移を提案します。怠惰な遷移は、すべてのトークンが深さに向けて均等に処理されないようにするためにUTの上に展開され、LT（怠惰なトランスフォーマー）を構築するために使用されます。最終的に、LTはリラックスした均衡点を中心に振動するように促されます。私たちの実験は、LTが機械翻訳、事前学習、実行学習、およびLAMBADAのいくつかのタスクでベースラインモデルを上回ることを示しています。"}
{"title": "FIBER: Fill-in-the-Blanks as a Challenging Video Understanding Evaluation Framework", "url": "https://aclanthology.org/2022.acl-long.209/", "abstract": "We propose fill-in-the-blanks as a video understanding evaluation framework and introduce FIBER – a novel dataset consisting of 28,000 videos and descriptions in support of this evaluation framework. The fill-in-the-blanks setting tests a model’s understanding of a video by requiring it to predict a masked noun phrase in the caption of the video, given the video and the surrounding text. The FIBER benchmark does not share the weaknesses of the current state-of-the-art language-informed video understanding tasks, namely: (1) video question answering using multiple-choice questions, where models perform relatively well because they exploit linguistic biases in the task formulation, thus making our framework challenging for the current state-of-the-art systems to solve; and (2) video captioning, which relies on an open-ended evaluation framework that is often inaccurate because system answers may be perceived as incorrect if they differ in form from the ground truth. The FIBER dataset and our code are available at https://lit.eecs.umich.edu/fiber/.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FIBER：チャレンジングなビデオ理解評価フレームワークとしてのフィルインザブランクス\n\nNatural language processing (NLP) has made significant progress in recent years, but evaluating NLP models remains a challenging task. \n\n自然言語処理（NLP）は近年、重要な進歩を遂げていますが、NLPモデルの評価は依然として課題が残されています。\n\nTo address this issue, we propose FIBER, a new evaluation framework that leverages fill-in-the-blank questions to assess the ability of NLP models to understand video content. \n\nこの問題に対処するために、私たちはFIBERを提案します。FIBERは、フィルインザブランクスの質問を活用して、NLPモデルがビデオコンテンツを理解する能力を評価する新しい評価フレームワークです。\n\nWe demonstrate the effectiveness of FIBER by evaluating several state-of-the-art NLP models on a challenging video understanding task. \n\n私たちは、チャレンジングなビデオ理解タスクでいくつかの最新のNLPモデルを評価することによって、FIBERの有効性を実証します。", "jabstract": "私たちは、ビデオ理解の評価フレームワークとしてフィルインザブランクを提案し、この評価フレームワークを支援する28,000本のビデオと説明からなる新しいデータセットであるFIBERを紹介します。フィルインザブランクの設定は、ビデオと周囲のテキストが与えられた場合に、ビデオのキャプション内のマスクされた名詞句を予測することによって、モデルのビデオ理解をテストします。FIBERベンチマークは、現在の最先端の言語に基づくビデオ理解タスクの弱点を共有していません。すなわち、(1)複数選択肢を用いたビデオ質問応答では、タスクの形式に言語的なバイアスがあるため、モデルが比較的よく機能するため、現在の最先端のシステムにとって私たちのフレームワークは解決が難しいものとなっています。(2)ビデオキャプションは、オープンエンドの評価フレームワークに依存しており、システムの回答が正解と形式的に異なる場合には、不正確なものと見なされることがあるため、不正確なものとなることがあります。FIBERデータセットと私たちのコードは、https://lit.eecs.umich.edu/fiber/で利用可能です。"}
{"title": "KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling", "url": "https://aclanthology.org/2022.acl-long.210/", "abstract": "Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information. With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important. MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection. To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KenMeSH：知識強化エンドツーエンドバイオメディカルテキストラベリングに関する論文の要約です。", "jabstract": "現在、医学分野の記事には手動でMedical Subject Headings（MeSH）が割り当てられ、その後PubMedデータベースに記録され、関連情報の検索を容易にするために使用されています。PubMedデータベースの急速な成長に伴い、大規模なバイオメディカル文書の索引付けがますます重要になっています。MeSHのインデックス付けは、非常に大きな階層的に組織化されたコレクションから各記事に複数のラベルを割り当てる必要があるため、機械学習にとって難しいタスクです。この課題に対処するために、私たちはKenMeSHを提案しました。KenMeSHは、新しいテキスト特徴と動的な知識強化マスクアテンションを組み合わせたエンドツーエンドモデルであり、文書特徴とMeSHラベル階層およびジャーナル相関特徴を統合してMeSH用語をインデックス付けします。実験結果は、提案手法がいくつかの指標で最先端の性能を発揮することを示しています。"}
{"title": "A Taxonomy of Empathetic Questions in Social Dialogs", "url": "https://aclanthology.org/2022.acl-long.211/", "abstract": "Effective question-asking is a crucial component of a successful conversational chatbot. It could help the bots manifest empathy and render the interaction more engaging by demonstrating attention to the speaker’s emotions. However, current dialog generation approaches do not model this subtle emotion regulation technique due to the lack of a taxonomy of questions and their purpose in social chitchat. To address this gap, we have developed an empathetic question taxonomy (EQT), with special attention paid to questions’ ability to capture communicative acts and their emotion-regulation intents. We further design a crowd-sourcing task to annotate a large subset of the EmpatheticDialogues dataset with the established labels. We use the crowd-annotated data to develop automatic labeling tools and produce labels for the whole dataset. Finally, we employ information visualization techniques to summarize co-occurrences of question acts and intents and their role in regulating interlocutor’s emotion. These results reveal important question-asking strategies in social dialogs. The EQT classification scheme can facilitate computational analysis of questions in datasets. More importantly, it can inform future efforts in empathetic question generation using neural or hybrid methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "社会的な対話における共感的な質問の分類法", "jabstract": "効果的な質問は、成功した会話型チャットボットの重要な要素です。それは、話者の感情に注意を払い、共感を表現することで、相互作用をより魅力的にすることができます。しかし、現在の対話生成アプローチは、社交的な雑談における質問の分類と目的の欠如により、この微妙な感情調整技術をモデル化していません。このギャップを埋めるために、私たちは共感的な質問分類法（EQT）を開発しました。質問のコミュニケーション行為と感情調整意図を捉える能力に特別な注意を払いました。さらに、私たちはクラウドソーシングタスクを設計して、確立されたラベルでEmpatheticDialoguesデータセットの大規模なサブセットを注釈付けしました。私たちは、クラウド注釈付きデータを使用して自動ラベリングツールを開発し、全データセットのラベルを生成しました。最後に、情報可視化技術を使用して、質問行為と意図の共起と相互作用者の感情調整における役割を要約しました。これらの結果は、社交的な対話における重要な質問戦略を明らかにします。EQT分類法は、データセット内の質問の計算的分析を容易にすることができます。さらに重要なことに、ニューラルまたはハイブリッド方法を使用した共感的な質問生成の将来の取り組みに役立つことができます。"}
{"title": "Enhanced Multi-Channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction", "url": "https://aclanthology.org/2022.acl-long.212/", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is an emerging sentiment analysis task. Most of the existing studies focus on devising a new tagging scheme that enables the model to extract the sentiment triplets in an end-to-end fashion. However, these methods ignore the relations between words for ASTE task. In this paper, we propose an Enhanced Multi-Channel Graph Convolutional Network model (EMC-GCN) to fully utilize the relations between words. Specifically, we first define ten types of relations for ASTE task, and then adopt a biaffine attention module to embed these relations as an adjacent tensor between words in a sentence. After that, our EMC-GCN transforms the sentence into a multi-channel graph by treating words and the relation adjacent tensor as nodes and edges, respectively. Thus, relation-aware node representations can be learnt. Furthermore, we consider diverse linguistic features to enhance our EMC-GCN model. Finally, we design an effective refining strategy on EMC-GCN for word-pair representation refinement, which considers the implicit results of aspect and opinion extraction when determining whether word pairs match or not. Extensive experimental results on the benchmark datasets demonstrate that the effectiveness and robustness of our proposed model, which outperforms state-of-the-art methods significantly.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nアスペクト感情トリプレット抽出のための強化されたマルチチャネルグラフ畳み込みネットワーク", "jabstract": "Aspect Sentiment Triplet Extraction（ASTE）は、新興の感情分析タスクです。既存の研究の多くは、モデルがエンドツーエンドで感情トリプレットを抽出できるようにする新しいタグ付けスキームを考案することに焦点を当てています。しかし、これらの方法はASTEタスクの単語間の関係を無視しています。本論文では、単語間の関係を最大限に活用するために、Enhanced Multi-Channel Graph Convolutional Networkモデル（EMC-GCN）を提案します。具体的には、まずASTEタスクの10種類の関係を定義し、その後、バイアフィンアテンションモジュールを採用して、これらの関係を文中の単語間の隣接テンソルとして埋め込みます。その後、EMC-GCNは、単語と関係の隣接テンソルをそれぞれノードとエッジとして扱い、文をマルチチャネルグラフに変換します。したがって、関係に注意したノード表現を学習できます。さらに、私たちは、私たちのEMC-GCNモデルを強化するために多様な言語的特徴を考慮しています。最後に、私たちは、単語ペア表現の改良のための効果的なEMC-GCN上の精製戦略を設計しました。この戦略は、単語ペアが一致するかどうかを決定する際に、アスペクトとオピニオンの抽出の暗黙的な結果を考慮します。ベンチマークデータセットでの広範な実験結果は、提案されたモデルの有効性と堅牢性を示し、最先端の方法を大幅に上回ります。"}
{"title": "ProtoTEx: Explaining Model Decisions with Prototype Tensors", "url": "https://aclanthology.org/2022.acl-long.213/", "abstract": "We present ProtoTEx, a novel white-box NLP classification architecture based on prototype networks (Li et al., 2018). ProtoTEx faithfully explains model decisions based on prototype tensors that encode latent clusters of training examples. At inference time, classification decisions are based on the distances between the input text and the prototype tensors, explained via the training examples most similar to the most influential prototypes. We also describe a novel interleaved training algorithm that effectively handles classes characterized by ProtoTEx indicative features. On a propaganda detection task, ProtoTEx accuracy matches BART-large and exceeds BERTlarge with the added benefit of providing faithful explanations. A user study also shows that prototype-based explanations help non-experts to better recognize propaganda in online news.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ProtoTEx：プロトタイプテンソルを用いたモデルの決定の説明", "jabstract": "私たちは、プロトタイプネットワーク（Li et al.、2018）に基づく新しいホワイトボックスNLP分類アーキテクチャであるProtoTExを提案します。ProtoTExは、トレーニング例の潜在的なクラスタをエンコードするプロトタイプテンソルに基づいてモデルの決定を忠実に説明します。推論時には、入力テキストとプロトタイプテンソルの間の距離に基づいて分類決定が行われ、最も影響力のあるプロトタイプに最も類似したトレーニング例によって説明されます。また、ProtoTEx示唆的な特徴を持つクラスを効果的に扱う新しい交互トレーニングアルゴリズムについても説明します。プロパガンダ検出タスクでは、ProtoTExの精度はBART-largeに匹敵し、忠実な説明を提供する利点を持つBERT-largeを上回ります。ユーザースタディも、プロトタイプベースの説明がオンラインニュースのプロパガンダをよりよく認識するのに非専門家の助けになることを示しています。"}
{"title": "Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data", "url": "https://aclanthology.org/2022.acl-long.214/", "abstract": "Procedures are inherently hierarchical. To “make videos”, one may need to “purchase a camera”, which in turn may require one to “set a budget”. While such hierarchical knowledge is critical for reasoning about complex procedures, most existing work has treated procedures as shallow structures without modeling the parent-child relation. In this work, we attempt to construct an open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a website containing more than 110k instructional articles, each documenting the steps to carry out a complex procedure. To this end, we develop a simple and efficient method that links steps (e.g., “purchase a camera”) in an article to other articles with similar goals (e.g., “how to choose a camera”), recursively constructing the KB. Our method significantly outperforms several strong baselines according to automatic evaluation, human judgment, and application to downstream tasks such as instructional video retrieval.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「詳細を教えてください」：半構造化Webデータから手順の階層を発見する", "jabstract": "手順は本質的に階層的です。「ビデオを作る」ためには、「カメラを購入する」必要があり、そのためには「予算を設定する」必要があるかもしれません。このような階層的な知識は、複雑な手順について推論するために重要ですが、既存の多くの研究は、親子関係をモデル化せずに手順を浅い構造として扱っています。本研究では、wikiHowという110,000以上の手順を記述する記事を含むウェブサイトを基に、オープンドメインの手順の階層的な知識ベース（KB）を構築することを試みます。このために、記事内のステップ（例：「カメラを購入する」）を、同じ目標を持つ他の記事（例：「カメラの選び方」）に再帰的にリンクする、シンプルで効率的な方法を開発します。自動評価、人間の判断、教育ビデオの検索などの下流タスクへの適用により、我々の方法はいくつかの強力なベースラインを大幅に上回ります。"}
{"title": "Cross-Modal Discrete Representation Learning", "url": "https://aclanthology.org/2022.acl-long.215/", "abstract": "In contrast to recent advances focusing on high-level representation learning across modalities, in this work we present a self-supervised learning framework that is able to learn a representation that captures finer levels of granularity across different modalities such as concepts or events represented by visual objects or spoken words. Our framework relies on a discretized embedding space created via vector quantization that is shared across different modalities. Beyond the shared embedding space, we propose a Cross-Modal Code Matching objective that forces the representations from different views (modalities) to have a similar distribution over the discrete embedding space such that cross-modal objects/actions localization can be performed without direct supervision. We show that the proposed discretized multi-modal fine-grained representation (e.g., pixel/word/frame) can complement high-level summary representations (e.g., video/sentence/waveform) for improved performance on cross-modal retrieval tasks. We also observe that the discretized representation uses individual clusters to represent the same semantic concept across modalities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nクロスモーダルな離散表現学習", "jabstract": "近年の高次元表現学習に焦点を当てた最近の進歩とは対照的に、本研究では、視覚的オブジェクトや話された言葉によって表現される概念やイベントなど、異なるモダリティ間でより細かいレベルの粒度を捉える表現を学習できる自己教示学習フレームワークを提案する。我々のフレームワークは、異なるモダリティ間で共有される量子化された埋め込み空間に依存する。共有された埋め込み空間の他に、我々は異なるビュー（モダリティ）からの表現が離散的な埋め込み空間上で似た分布を持つように強制するクロスモーダルコードマッチング目的を提案する。これにより、直接的な監視なしにクロスモーダルオブジェクト/アクションのローカリゼーションが可能になる。提案された離散的なマルチモーダル細粒度表現（例：ピクセル/単語/フレーム）は、高次元の要約表現（例：ビデオ/文/波形）を補完し、クロスモーダル検索タスクの性能を向上させることができることを示す。また、離散的な表現は、異なるモダリティ間で同じ意味的概念を表すために個々のクラスタを使用することが観察された。"}
{"title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering", "url": "https://aclanthology.org/2022.acl-long.216/", "abstract": "Representations of events described in text are important for various tasks. In this work, we present SWCC: a Simultaneous Weakly supervised Contrastive learning and Clustering framework for event representation learning. SWCC learns event representations by making better use of co-occurrence information of events. Specifically, we introduce a weakly supervised contrastive learning method that allows us to consider multiple positives and multiple negatives, and a prototype-based clustering method that avoids semantically related events being pulled apart. For model training, SWCC learns representations by simultaneously performing weakly supervised contrastive learning and prototype-based clustering. Experimental results show that SWCC outperforms other baselines on Hard Similarity and Transitive Sentence Similarity tasks. In addition, a thorough analysis of the prototype-based clustering method demonstrates that the learned prototype vectors are able to implicitly capture various relations between events.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「弱い監督対照学習とクラスタリングを同時に行うことによるイベント表現の改善」に関する論文の要約です。", "jabstract": "テキストで説明されたイベントの表現は、さまざまなタスクにとって重要です。本研究では、SWCCと呼ばれる、イベント表現学習のための同時弱教師あり対照学習とクラスタリングフレームワークを提案します。SWCCは、イベントの共起情報をより良く活用することによって、イベント表現を学習します。具体的には、複数の正例と複数の負例を考慮できる弱教師あり対照学習法を導入し、意味的に関連するイベントが引き離されるのを防ぐプロトタイプベースのクラスタリング法を導入します。モデルのトレーニングでは、SWCCは同時に弱教師あり対照学習とプロトタイプベースのクラスタリングを実行することによって表現を学習します。実験結果は、SWCCがHard SimilarityとTransitive Sentence Similarityのタスクで他のベースラインを上回ることを示しています。さらに、プロトタイプベースのクラスタリング法の徹底的な分析は、学習されたプロトタイプベクトルが、イベント間のさまざまな関係を暗黙的に捉えることができることを示しています。"}
{"title": "Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations", "url": "https://aclanthology.org/2022.acl-long.217/", "abstract": "We examine the effects of contrastive visual semantic pretraining by comparing the geometry and semantic properties of contextualized English language representations formed by GPT-2 and CLIP, a zero-shot multimodal image classifier which adapts the GPT-2 architecture to encode image captions. We find that contrastive visual semantic pretraining significantly mitigates the anisotropy found in contextualized word embeddings from GPT-2, such that the intra-layer self-similarity (mean pairwise cosine similarity) of CLIP word embeddings is under .25 in all layers, compared to greater than .95 in the top layer of GPT-2. CLIP word embeddings outperform GPT-2 on word-level semantic intrinsic evaluation tasks, and achieve a new corpus-based state of the art for the RG65 evaluation, at .88. CLIP also forms fine-grained semantic representations of sentences, and obtains Spearman’s 𝜌 = .73 on the SemEval-2017 Semantic Textual Similarity Benchmark with no fine-tuning, compared to no greater than 𝜌 = .45 in any layer of GPT-2. Finally, intra-layer self-similarity of CLIP sentence embeddings decreases as the layer index increases, finishing at .25 in the top layer, while the self-similarity of GPT-2 sentence embeddings formed using the EOS token increases layer-over-layer and never falls below .97. Our results indicate that high anisotropy is not an inevitable consequence of contextualization, and that visual semantic pretraining is beneficial not only for ordering visual representations, but also for encoding useful semantic representations of language, both on the word level and the sentence level.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "対照的な視覚的意味プリトレーニングは、自然言語表現の意味を拡大します。", "jabstract": "私たちは、GPT-2とCLIPの文脈化英語表現の幾何学的および意味的特性を比較することにより、対比的な視覚的意味的事前学習の効果を調べました。CLIPは、GPT-2アーキテクチャを適応して画像キャプションをエンコードするゼロショットのマルチモーダル画像分類器です。私たちは、対比的な視覚的意味的事前学習が、GPT-2の文脈化単語埋め込みに見られる異方性を軽減することを発見しました。CLIPの単語埋め込みの層内自己類似度（平均ペアワイズコサイン類似度）は、すべての層で0.25未満であり、GPT-2のトップ層で0.95以上であることに比べて、有意に低下しています。CLIPの単語埋め込みは、単語レベルの意味的内在評価タスクでGPT-2を上回り、RG65評価において0.88の新しいコーパスベースの最高記録を達成します。CLIPはまた、細かい意味的表現を形成し、ファインチューニングなしでSemEval-2017 Semantic Textual Similarity BenchmarkでSpearmanの𝜌 = 0.73を達成し、GPT-2のどの層でも0.45を超えません。最後に、CLIP文埋め込みの層内自己類似度は、層のインデックスが増加するにつれて減少し、トップ層で0.25になります。一方、EOSトークンを使用して形成されたGPT-2文埋め込みの自己類似度は、層を超えて増加し、0.97未満にはなりません。私たちの結果は、高い異方性が文脈化の必然的な結果ではなく、視覚的意味的事前学習が視覚的表現を整理するだけでなく、言語の有用な意味的表現を単語レベルと文レベルの両方でエンコードするのに役立つことを示しています。"}
{"title": "ConTinTin: Continual Learning from Task Instructions", "url": "https://aclanthology.org/2022.acl-long.218/", "abstract": "The mainstream machine learning paradigms for NLP often work with two underlying presumptions. First, the target task is predefined and static; a system merely needs to learn to solve it exclusively. Second, the supervision of a task mainly comes from a set of labeled examples. A question arises: how to build a system that can keep learning new tasks from their instructions?This work defines a new learning paradigm ConTinTin (Continual Learning from Task Instructions), in which a system should learn a sequence of new tasks one by one, each task is explained by a piece of textual instruction. The system is required to (i) generate the expected outputs of a new task by learning from its instruction, (ii) transfer the knowledge acquired from upstream tasks to help solve downstream tasks (i.e., forward-transfer), and (iii) retain or even improve the performance on earlier tasks after learning new tasks (i.e., backward-transfer). This new problem is studied on a stream of more than 60 tasks, each equipped with an instruction. Technically, our method InstructionSpeak contains two strategies that make full use of task instructions to improve forward-transfer and backward-transfer: one is to learn from negative outputs, the other is to re-visit instructions of previous tasks. To our knowledge, this is the first time to study ConTinTin in NLP. In addition to the problem formulation and our promising approach, this work also contributes to providing rich analyses for the community to better understand this novel learning problem.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nConTinTin：タスク指示からの継続的学習", "jabstract": "自然言語処理における主流の機械学習パラダイムは、しばしば2つの基本的な前提条件に基づいています。第一に、対象のタスクは事前に定義され、静的であり、システムは単にそれを排他的に解決するために学習する必要があります。第二に、タスクの監視は主にラベル付きの例のセットから来ます。問題が生じます：指示から新しいタスクを継続的に学習するシステムをどのように構築するのでしょうか？本研究では、新しい学習パラダイムConTinTin（タスク指示からの継続的学習）を定義し、システムは1つずつ新しいタスクのシーケンスを学習する必要があります。各タスクはテキスト指示によって説明されます。システムは、（i）指示から学習して新しいタスクの期待される出力を生成し、（ii）上流タスクから獲得した知識を転送して下流タスクを解決するのに役立てる（すなわち、フォワードトランスファー）、および（iii）新しいタスクを学習した後も以前のタスクのパフォーマンスを維持または改善する必要があります（すなわち、バックワードトランスファー）。この新しい問題は、60以上のタスクのストリームで研究され、各タスクには指示が付属しています。技術的には、私たちの方法InstructionSpeakには、タスク指示をフル活用してフォワードトランスファーとバックワードトランスファーを改善する2つの戦略が含まれています。1つは負の出力から学ぶことであり、もう1つは以前のタスクの指示を再訪することです。私たちの知る限り、これはNLPでConTinTinを研究する初めての試みです。問題の定式化と有望なアプローチに加えて、この研究は、この新しい学習問題をよりよく理解するための豊富な分析を提供することにも貢献しています。"}
{"title": "Automated Crossword Solving", "url": "https://aclanthology.org/2022.acl-long.219/", "abstract": "We present the Berkeley Crossword Solver, a state-of-the-art approach for automatically solving crossword puzzles. Our system works by generating answer candidates for each crossword clue using neural question answering models and then combines loopy belief propagation with local search to find full puzzle solutions. Compared to existing approaches, our system improves exact puzzle accuracy from 57% to 82% on crosswords from The New York Times and obtains 99.9% letter accuracy on themeless puzzles. Our system also won first place at the top human crossword tournament, which marks the first time that a computer program has surpassed human performance at this event. To facilitate research on question answering and crossword solving, we analyze our system’s remaining errors and release a dataset of over six million question-answer pairs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自動クロスワード解決", "jabstract": "私たちは、クロスワードパズルを自動的に解くための最新の手法であるバークレークロスワードソルバーを提案する。私たちのシステムは、ニューラル質問応答モデルを使用して、各クロスワードのヒントに対する回答候補を生成し、ルーピー信念伝播とローカルサーチを組み合わせて、完全なパズルの解を見つけることで機能します。既存の手法と比較して、私たちのシステムは、ニューヨークタイムズのクロスワードで正確なパズルの精度を57％から82％に向上させ、テーマのないパズルでは99.9％の文字精度を達成しています。また、私たちのシステムは、人間のクロスワードトーナメントで初めてコンピュータプログラムが人間のパフォーマンスを超えたことを示す、第一位を獲得しました。質問応答とクロスワードの解決に関する研究を促進するために、私たちはシステムの残りのエラーを分析し、600万以上の質問回答ペアのデータセットを公開しています。"}
{"title": "Learned Incremental Representations for Parsing", "url": "https://aclanthology.org/2022.acl-long.220/", "abstract": "We present an incremental syntactic representation that consists of assigning a single discrete label to each word in a sentence, where the label is predicted using strictly incremental processing of a prefix of the sentence, and the sequence of labels for a sentence fully determines a parse tree. Our goal is to induce a syntactic representation that commits to syntactic choices only as they are incrementally revealed by the input, in contrast with standard representations that must make output choices such as attachments speculatively and later throw out conflicting analyses. Our learned representations achieve 93.72 F1 on the Penn Treebank with as few as 5 bits per word, and at 8 bits per word they achieve 94.97 F1, which is comparable with other state of the art parsing models when using the same pre-trained embeddings. We also provide an analysis of the representations learned by our system, investigating properties such as the interpretable syntactic features captured by the system and mechanisms for deferred resolution of syntactic ambiguities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n解析のための学習済みの増分表現", "jabstract": "私たちは、文の各単語に単一の離散ラベルを割り当てる増分構文表現を提案します。ラベルは、文の接頭辞を厳密に増分処理して予測され、文のラベルのシーケンスは構文解析木を完全に決定します。私たちの目標は、標準的な表現とは異なり、出力の選択肢を推測的に行い、後で矛盾する解析を破棄する必要があるような標準的な表現とは異なり、入力によって構文的な選択にのみコミットする構文的表現を誘導することです。私たちの学習された表現は、単語あたり5ビットで93.72 F1を達成し、単語あたり8ビットで94.97 F1を達成し、同じ事前学習された埋め込みを使用する場合には他の最新の解析モデルと比較可能です。また、システムによって学習された表現の解釈可能な構文的特徴や、構文的な曖昧さの延期解決のメカニズムなど、システムによって学習された表現の解析も提供します。"}
{"title": "Knowledge Enhanced Reflection Generation for Counseling Dialogues", "url": "https://aclanthology.org/2022.acl-long.221/", "abstract": "In this paper, we study the effect of commonsense and domain knowledge while generating responses in counseling conversations using retrieval and generative methods for knowledge integration. We propose a pipeline that collects domain knowledge through web mining, and show that retrieval from both domain-specific and commonsense knowledge bases improves the quality of generated responses. We also present a model that incorporates knowledge generated by COMET using soft positional encoding and masked self-attention.We show that both retrieved and COMET-generated knowledge improve the system’s performance as measured by automatic metrics and also by human evaluation. Lastly, we present a comparative study on the types of knowledge encoded by our system showing that causal and intentional relationships benefit the generation task more than other types of commonsense relations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "カウンセリング対話のための知識強化型反射生成", "jabstract": "本論文では、知識統合のための検索と生成方法を用いて、カウンセリング会話における応答生成における常識とドメイン知識の影響を研究する。我々は、ウェブマイニングを通じてドメイン知識を収集するパイプラインを提案し、ドメイン固有の知識ベースと常識的な知識ベースの両方からの検索が生成された応答の品質を向上させることを示す。また、COMETによって生成された知識をソフトポジショナルエンコーディングとマスクされた自己注意を用いて組み込んだモデルを提案する。自動メトリックと人間の評価によって測定されたシステムのパフォーマンスの両方が、検索された知識とCOMETによって生成された知識の両方が改善されることを示す。最後に、我々は、当社のシステムによってエンコードされた知識のタイプに関する比較的な研究を行い、因果関係と意図的な関係が他のタイプの常識的な関係よりも生成タスクに有益であることを示す。"}
{"title": "Misinfo Reaction Frames: Reasoning about Readers’ Reactions to News Headlines", "url": "https://aclanthology.org/2022.acl-long.222/", "abstract": "Even to a simple and short news headline, readers react in a multitude of ways: cognitively (e.g. inferring the writer’s intent), emotionally (e.g. feeling distrust), and behaviorally (e.g. sharing the news with their friends). Such reactions are instantaneous and yet complex, as they rely on factors that go beyond interpreting factual content of news.We propose Misinfo Reaction Frames (MRF), a pragmatic formalism for modeling how readers might react to a news headline. In contrast to categorical schema, our free-text dimensions provide a more nuanced way of understanding intent beyond being benign or malicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced dataset of reactions to over 25k news headlines focusing on global crises: the Covid-19 pandemic, climate change, and cancer. Empirical results confirm that it is indeed possible for neural models to predict the prominent patterns of readers’ reactions to previously unseen news headlines. Additionally, our user study shows that displaying machine-generated MRF implications alongside news headlines to readers can increase their trust in real news while decreasing their trust in misinformation. Our work demonstrates the feasibility and importance of pragmatic inferences on news headlines to help enhance AI-guided misinformation detection and mitigation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Misinfo Reaction Frames：ニュース見出しに対する読者の反応についての推論」に関する論文の要約文です。", "jabstract": "単純で短いニュース見出しに対しても、読者は認知的（例：筆者の意図を推測する）、感情的（例：不信感を感じる）、行動的（例：友人とニュースを共有する）な反応を示します。このような反応は瞬時に起こりますが、ニュースの事実的な内容を解釈する以上の要因に依存するため、複雑です。本論文では、ニュース見出しに対する読者の反応をモデル化するための実用的な形式化手法である「Misinfo Reaction Frames（MRF）」を提案します。カテゴリー化されたスキーマとは異なり、自由なテキストの次元を使用することで、悪意のあるかどうかを超えた意図をより微妙に理解することができます。また、グローバル危機に焦点を当てた25,000以上のニュース見出しに対する反応のクラウドソーシングデータセットである「Misinfo Reaction Frames corpus」を紹介します。実験結果は、ニューラルモデルが以前に見たことのないニュース見出しに対する読者の反応の主要なパターンを予測することが可能であることを確認しています。さらに、ユーザースタディでは、機械生成されたMRFの含意をニュース見出しと一緒に表示することで、読者の実際のニュースに対する信頼を高め、誤情報に対する信頼を低下させることができることが示されました。本研究は、AIによる誤情報の検出と緩和を強化するために、ニュース見出しに対する実用的な推論の実現可能性と重要性を示しています。"}
{"title": "On Continual Model Refinement in Out-of-Distribution Data Streams", "url": "https://aclanthology.org/2022.acl-long.223/", "abstract": "Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL) problem setups cannot cover such a realistic and complex scenario. In response to this, we propose a new CL problem formulation dubbed continual model refinement (CMR). Compared to prior CL settings, CMR is more practical and introduces unique challenges (boundary-agnostic and non-stationary distribution shift, diverse mixtures of multiple OOD data clusters, error-centric streams, etc.). We extend several existing CL approaches to the CMR setting and evaluate them extensively. For benchmarking and analysis, we propose a general sampling algorithm to obtain dynamic OOD data streams with controllable non-stationarity, as well as a suite of metrics measuring various aspects of online performance. Our experiments and detailed analysis reveal the promise and challenges of the CMR problem, supporting that studying CMR in dynamic OOD streams can benefit the longevity of deployed NLP models in production.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「アウト・オブ・ディストリビューション・データ・ストリームにおける継続的なモデル改善について」の要約です。", "jabstract": "現実世界の自然言語処理（NLP）モデルは、カタストロフィックな忘却を克服しながら、アウト・オブ・ディストリビューション（OOD）データストリームの予測エラーを修正するために、継続的に更新する必要があります。しかし、既存の継続学習（CL）問題設定では、このような現実的で複雑なシナリオをカバーすることができません。このため、私たちは新しいCL問題の定式化である継続的モデル改善（CMR）を提案します。従来のCL設定に比べ、CMRはより実用的で、ユニークな課題（境界に関係なく、非定常な分布シフト、複数のOODデータクラスターの多様な混合、エラーセントリックなストリームなど）を導入します。私たちは、いくつかの既存のCLアプローチをCMR設定に拡張し、広範な評価を行いました。ベンチマークと分析のために、動的なOODデータストリームを制御可能な非定常性で取得するための一般的なサンプリングアルゴリズムと、オンラインパフォーマンスのさまざまな側面を測定する一連のメトリックを提案します。私たちの実験と詳細な分析は、CMR問題の可能性と課題を明らかにし、動的なOODストリームでのCMRの研究が、展開されたNLPモデルの長期性に役立つことを支持しています。"}
{"title": "Achieving Conversational Goals with Unsupervised Post-hoc Knowledge Injection", "url": "https://aclanthology.org/2022.acl-long.224/", "abstract": "A limitation of current neural dialog models is that they tend to suffer from a lack of specificity and informativeness in generated responses, primarily due to dependence on training data that covers a limited variety of scenarios and conveys limited knowledge. One way to alleviate this issue is to extract relevant knowledge from external sources at decoding time and incorporate it into the dialog response. In this paper, we propose a post-hoc knowledge-injection technique where we first retrieve a diverse set of relevant knowledge snippets conditioned on both the dialog history and an initial response from an existing dialog model. We construct multiple candidate responses, individually injecting each retrieved snippet into the initial response using a gradient-based decoding method, and then select the final response with an unsupervised ranking step. Our experiments in goal-oriented and knowledge-grounded dialog settings demonstrate that human annotators judge the outputs from the proposed method to be more engaging and informative compared to responses from prior dialog systems. We further show that knowledge-augmentation promotes success in achieving conversational goals in both experimental settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己学習後の知識注入による会話目標の達成", "jabstract": "現在のニューラル対話モデルの制限は、限られたシナリオをカバーし、限られた知識を伝えるトレーニングデータに依存するため、生成された応答に特定性と情報量が欠ける傾向があることです。この問題を緩和する方法の1つは、デコーディング時に外部ソースから関連する知識を抽出し、対話応答に組み込むことです。本論文では、既存の対話モデルからの初期応答と対話履歴の両方に依存する多様な関連知識スニペットを取得し、勾配ベースのデコーディング手法を使用して各スニペットを初期応答に個別に注入し、非監督ランキングステップで最終応答を選択する事後知識注入技術を提案します。目的指向型および知識基盤型の対話設定における実験では、提案手法の出力が従来の対話システムの応答よりも魅力的で情報量が豊富であると人間の注釈者が判断することを示しました。さらに、知識拡張は両方の実験設定で会話の目標の達成に成功することを示しました。"}
{"title": "Generated Knowledge Prompting for Commonsense Reasoning", "url": "https://aclanthology.org/2022.acl-long.225/", "abstract": "It remains an open question whether incorporating external knowledge benefits commonsense reasoning while maintaining the flexibility of pretrained sequence models. To investigate this question, we develop generated knowledge prompting, which consists of generating knowledge from a language model, then providing the knowledge as additional input when answering a question. Our method does not require task-specific supervision for knowledge integration, or access to a structured knowledge base, yet it improves performance of large-scale, state-of-the-art models on four commonsense reasoning tasks, achieving state-of-the-art results on numerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks. Generated knowledge prompting highlights large-scale language models as flexible sources of external knowledge for improving commonsense reasoning.Our code is available at github.com/liujch1998/GKP", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「生成された知識による常識的推論の促進」", "jabstract": "外部知識を組み込むことが、事前学習済みのシーケンスモデルの柔軟性を維持しながら常識的推論に利益をもたらすかどうかは未解決の問題である。この問題を調査するために、我々は生成された知識プロンプティングを開発し、言語モデルから知識を生成し、質問に答える際に追加の入力として知識を提供することで構成される。我々の方法は、知識統合のためのタスク固有の監視や構造化された知識ベースへのアクセスを必要とせず、大規模で最新のモデルの性能を向上させる。NumerSense、CommonsenseQA 2.0、QASCのベンチマークにおいて、最新の結果を達成し、生成された知識プロンプティングは、大規模言語モデルを柔軟な外部知識源として強調する。我々のコードはgithub.com/liujch1998/GKPで利用可能である。"}
{"title": "Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data", "url": "https://aclanthology.org/2022.acl-long.226/", "abstract": "Retrieval-based methods have been shown to be effective in NLP tasks via introducing external knowledge. However, the indexing and retrieving of large-scale corpora bring considerable computational cost. Surprisingly, we found that REtrieving from the traINing datA (REINA) only can lead to significant gains on multiple NLG and NLU tasks. We retrieve the labeled training instances most similar to the input text and then concatenate them with the input to feed into the model to generate the output. Experimental results show that this simple method can achieve significantly better performance on a variety of NLU and NLG tasks, including summarization, machine translation, language modeling, and question answering tasks. For instance, our proposed method achieved state-of-the-art results on XSum, BigPatent, and CommonsenseQA. Our code is released, https://github.com/microsoft/REINA .", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トレーニングデータはあなたが考えるよりも価値がある：トレーニングデータからの取得によるシンプルで効果的な方法", "jabstract": "外部知識を導入することで、検索ベースの手法がNLPタスクで効果的であることが示されてきた。しかし、大規模なコーパスのインデックス付けと検索は、かなりの計算コストを要する。驚くべきことに、私たちは、トレーニングデータからのリトリーブ（REINA）だけでも、複数のNLGおよびNLUタスクで重要な利益をもたらすことがわかった。私たちは、入力テキストに最も類似したラベル付きトレーニングインスタンスを取得し、それらを入力に連結してモデルにフィードし、出力を生成する。実験結果は、この単純な方法が、要約、機械翻訳、言語モデリング、および質問応答タスクを含むさまざまなNLUおよびNLGタスクで、有意に優れたパフォーマンスを発揮できることを示している。たとえば、私たちの提案手法は、XSum、BigPatent、およびCommonsenseQAで最先端の結果を達成した。私たちのコードは、https://github.com/microsoft/REINA で公開されています。"}
{"title": "Life after BERT: What do Other Muppets Understand about Language?", "url": "https://aclanthology.org/2022.acl-long.227/", "abstract": "Existing pre-trained transformer analysis works usually focus only on one or two model families at a time, overlooking the variability of the architecture and pre-training objectives. In our work, we utilize the oLMpics bench- mark and psycholinguistic probing datasets for a diverse set of 29 models including T5, BART, and ALBERT. Additionally, we adapt the oLMpics zero-shot setup for autoregres- sive models and evaluate GPT networks of different sizes. Our findings show that none of these models can resolve compositional questions in a zero-shot fashion, suggesting that this skill is not learnable using existing pre-training objectives. Furthermore, we find that global model decisions such as architecture, directionality, size of the dataset, and pre-training objective are not predictive of a model’s linguistic capabilities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BERTの後の人生：他のマペットたちは言語について何を理解しているのか？", "jabstract": "既存の事前学習済みトランスフォーマー解析は通常、アーキテクチャと事前学習目的の変動を見落とし、一度に1つまたは2つのモデルファミリーに焦点を当てています。本研究では、T5、BART、ALBERTを含む多様な29モデルのoLMpicsベンチマークと心理言語学的プロービングデータセットを利用しています。さらに、自己回帰モデルのoLMpicsゼロショットセットアップを適応し、異なるサイズのGPTネットワークを評価しています。私たちの調査結果は、これらのモデルのいずれも、合成的な質問をゼロショットで解決できないことを示しており、既存の事前学習目的を使用してこのスキルを学習することはできないことを示唆しています。さらに、アーキテクチャ、方向性、データセットのサイズ、および事前学習目的などのグローバルモデルの決定は、モデルの言語能力を予測することができないことがわかりました。"}
{"title": "Tailor: Generating and Perturbing Text with Semantic Controls", "url": "https://aclanthology.org/2022.acl-long.228/", "abstract": "Controlled text perturbation is useful for evaluating and improving model generalizability. However, current techniques rely on training a model for every target perturbation, which is expensive and hard to generalize. We present Tailor, a semantically-controlled text generation system. Tailor builds on a pretrained seq2seq model and produces textual outputs conditioned on control codes derived from semantic representations. We craft a set of operations to modify the control codes, which in turn steer generation towards targeted attributes. These operations can be further composed into higher-level ones, allowing for flexible perturbation strategies. We demonstrate the effectiveness of these perturbations in multiple applications. First, we use Tailor to automatically create high-quality contrast sets for four distinct natural language processing (NLP) tasks. These contrast sets contain fewer spurious artifacts and are complementary to manually annotated ones in their lexical diversity. Second, we show that Tailor perturbations can improve model generalization through data augmentation. Perturbing just ∼2% of training data leads to a 5.8-point gain on an NLI challenge set measuring reliance on syntactic heuristics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Tailor：意味制御を用いたテキストの生成と変形\n\nAbstract: We present Tailor, a system for generating and perturbing text with semantic controls. Tailor allows users to specify desired semantic attributes of the generated text, such as sentiment, topic, and style, and provides a mechanism for perturbing existing text while preserving its semantic content. We demonstrate the effectiveness of Tailor through a series of experiments and show that it can be used for a variety of natural language processing tasks, including text generation, text classification, and text style transfer.", "jabstract": "制御されたテキストの摂動は、モデルの汎化性能を評価および改善するために有用である。しかし、現在の技術は、各ターゲット摂動のためにモデルをトレーニングすることに依存しており、コストがかかり、一般化が困難である。本研究では、意味的に制御されたテキスト生成システムであるTailorを提案する。Tailorは、事前にトレーニングされたseq2seqモデルに基づいて構築され、意味的表現から派生した制御コードに基づいてテキスト出力を生成する。我々は、制御コードを変更するための一連の操作を作成し、これにより生成をターゲット属性に向けることができる。これらの操作は、より高次の操作にさらに組み合わせることができ、柔軟な摂動戦略を可能にする。我々は、これらの摂動の効果を複数のアプリケーションで示す。まず、Tailorを使用して、4つの異なる自然言語処理（NLP）タスクの高品質な対照セットを自動的に作成する。これらの対照セットには、手動で注釈付けされたものと比較して、より少ない誤ったアーティファクトが含まれ、語彙的多様性がある。第二に、Tailorの摂動がデータ拡張を通じてモデルの汎化性能を向上させることを示す。トレーニングデータのわずか約2％を摂動させるだけで、構文ヒューリスティックに依存するNLIチャレンジセットで5.8ポイントの利得が得られる。"}
{"title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods", "url": "https://aclanthology.org/2022.acl-long.229/", "abstract": "We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "TruthfulQA：モデルが人間の誤りをどの程度模倣するかを測定する方法", "jabstract": "私たちは、言語モデルが質問に対して真実の回答を生成するかどうかを測定するためのベンチマークを提案します。このベンチマークは、健康、法律、金融、政治など38のカテゴリにまたがる817の質問から構成されています。私たちは、誤った信念や誤解により、一部の人間が誤った回答をする可能性がある質問を作成しました。モデルが良い成績を収めるためには、人間のテキストを模倣して学習した誤った回答を生成しない必要があります。私たちは、GPT-3、GPT-Neo/J、GPT-2、T5ベースのモデルをテストしました。最も優れたモデルは58％の質問で真実の回答を生成しましたが、人間のパフォーマンスは94％でした。モデルは多くの誤った回答を生成し、一般的な誤解を模倣する可能性があり、人間を欺く可能性があります。最大のモデルほど真実性が低い傾向がありました。これは、他のNLPタスクとは対照的であり、モデルのサイズが大きくなるほどパフォーマンスが向上するという結果とは異なります。ただし、これは、誤った回答がトレーニング分布から学習された場合に予想される結果です。私たちは、モデルのスケーリングだけでは真実性を向上させるための可能性は少なく、ウェブからのテキスト模倣以外のトレーニング目標を使用した微調整がより有望であると提案します。"}
{"title": "Adaptive Testing and Debugging of NLP Models", "url": "https://aclanthology.org/2022.acl-long.230/", "abstract": "Current approaches to testing and debugging NLP models rely on highly variable human creativity and extensive labor, or only work for a very restrictive class of bugs. We present AdaTest, a process which uses large scale language models (LMs) in partnership with human feedback to automatically write unit tests highlighting bugs in a target model. Such bugs are then addressed through an iterative text-fix-retest loop, inspired by traditional software development. In experiments with expert and non-expert users and commercial / research models for 8 different tasks, AdaTest makes users 5-10x more effective at finding bugs than current approaches, and helps users effectively fix bugs without adding new bugs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理の適応的テストとデバッグ", "jabstract": "自然言語処理に関する論文の要約の以下の文章を日本語に翻訳してください：\n\nNLPモデルのテストとデバッグに対する現在のアプローチは、非常に変動が大きい人間の創造性と広範な労力に依存するか、非常に制限的なバグのクラスにしか適用されない。我々は、大規模言語モデル（LM）を人間のフィードバックと連携して使用し、ターゲットモデルのバグを自動的に強調するユニットテストを自動的に作成するプロセスであるAdaTestを提案する。このようなバグは、従来のソフトウェア開発に着想を得た反復的なテキスト修正再テストループによって対処されます。専門家と非専門家のユーザー、商用/研究モデルの8つの異なるタスクの実験では、AdaTestは現在のアプローチよりも5-10倍効果的にバグを見つけることができ、ユーザーが新しいバグを追加することなくバグを効果的に修正するのを支援します。"}
{"title": "Right for the Right Reason: Evidence Extraction for Trustworthy Tabular Reasoning", "url": "https://aclanthology.org/2022.acl-long.231/", "abstract": "When pre-trained contextualized embedding-based models developed for unstructured data are adapted for structured tabular data, they perform admirably. However, recent probing studies show that these models use spurious correlations, and often predict inference labels by focusing on false evidence or ignoring it altogether. To study this issue, we introduce the task of Trustworthy Tabular Reasoning, where a model needs to extract evidence to be used for reasoning, in addition to predicting the label. As a case study, we propose a two-stage sequential prediction approach, which includes an evidence extraction and an inference stage. First, we crowdsource evidence row labels and develop several unsupervised and supervised evidence extraction strategies for InfoTabS, a tabular NLI benchmark. Our evidence extraction strategy outperforms earlier baselines. On the downstream tabular inference task, using only the automatically extracted evidence as the premise, our approach outperforms prior benchmarks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「正しい理由のために正しいもの：信頼できる表形式推論のための証拠抽出」は、自然言語処理に関する論文の要約です。", "jabstract": "構造化表形式のデータに適用される事前学習済みの文脈依存埋め込みベースのモデルは、優れた性能を発揮する。しかし、最近の調査研究により、これらのモデルは偽の証拠に焦点を当てたり、それを無視したりすることで、誤った推論ラベルを予測することがわかった。この問題を研究するために、我々は「信頼できる表形式推論」というタスクを導入し、モデルが推論に使用するための証拠を抽出する必要がある。事例研究として、2段階の連続予測アプローチを提案し、証拠抽出と推論の段階を含む。最初に、InfoTabSという表形式NLIベンチマークのために、証拠行ラベルをクラウドソーシングし、いくつかの教師なしおよび教師ありの証拠抽出戦略を開発する。我々の証拠抽出戦略は、以前のベースラインを上回る性能を発揮する。自動的に抽出された証拠のみを前提として使用し、下流の表形式推論タスクでは、我々のアプローチが以前のベンチマークを上回る性能を発揮する。"}
{"title": "Interactive Word Completion for Plains Cree", "url": "https://aclanthology.org/2022.acl-long.232/", "abstract": "The composition of richly-inflected words in morphologically complex languages can be a challenge for language learners developing literacy. Accordingly, Lane and Bird (2020) proposed a finite state approach which maps prefixes in a language to a set of possible completions up to the next morpheme boundary, for the incremental building of complex words. In this work, we develop an approach to morph-based auto-completion based on a finite state morphological analyzer of Plains Cree (nêhiyawêwin), showing the portability of the concept to a much larger, more complete morphological transducer. Additionally, we propose and compare various novel ranking strategies on the morph auto-complete output. The best weighting scheme ranks the target completion in the top 10 results in 64.9% of queries, and in the top 50 in 73.9% of queries.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プレーンズ・クリー語のインタラクティブな単語補完\n\nThis paper presents an interactive word completion system for Plains Cree, an indigenous language spoken in Canada. \n\n本論文では、カナダで話されている先住民言語であるプレーンズ・クリー語のインタラクティブな単語補完システムを提案する。\n\nThe system uses a statistical language model and a user interface that allows users to select the desired word from a list of suggestions. \n\nこのシステムは、統計的言語モデルと、ユーザーが提案された単語のリストから必要な単語を選択できるユーザーインターフェースを使用しています。\n\nThe system was evaluated using a corpus of Plains Cree text and achieved an accuracy of 80% in predicting the next word in a sentence. \n\nこのシステムは、プレーンズ・クリー語のテキストコーパスを用いて評価され、文の次の単語を予測する際に80%の精度を達成しました。", "jabstract": "豊かな語形変化言語における豊富な語彙の構成は、識字能力を発展させる言語学習者にとって課題となる。そのため、LaneとBird（2020）は、複雑な単語の段階的な構築のために、言語の接頭辞を次の形態素境界までの可能な完了形のセットにマッピングする有限状態アプローチを提案した。本研究では、平原クリー語（nêhiyawêwin）の有限状態形態素解析器に基づく形態素ベースの自動補完アプローチを開発し、この概念の移植性を示す。さらに、形態素自動補完の出力に対して、さまざまな新しいランキング戦略を提案し比較する。最良の重み付けスキームは、64.9％のクエリで目標完了形を上位10件にランク付けし、73.9％のクエリで上位50件にランク付けする。"}
{"title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing", "url": "https://aclanthology.org/2022.acl-long.233/", "abstract": "Semantic parsing is the task of producing structured meaning representations for natural language sentences. Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence. To this end we propose LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using approximate maximum-a-posteriori inference. Experiments demonstrate that LAGr achieves significant improvements in systematic generalization upon the baseline seq2seq parsers in both strongly- and weakly-supervised settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LAGr：意味解析におけるシステマティックな一般化を向上させるためのラベル整列グラフ", "jabstract": "意味解析は、自然言語文を構造化された意味表現に変換するタスクである。最近の研究では、一般的に使用されるシーケンス・トゥ・シーケンス（seq2seq）の意味解析器は、既知の知識を新しい状況で再結合する必要がある例を処理するのに苦労することが指摘されている。本研究では、意味表現をシーケンスではなくグラフとして直接生成することで、より良い系統的な汎化が実現できることを示す。このために、完全に多層の入力に整列したグラフのノードとエッジのラベルを独立して予測することにより、LAGr（Label Aligned Graphs）という一般的なフレームワークを提案する。強く監視されたLAGrアルゴリズムは、整列したグラフを入力として必要とする一方、弱く監視されたLAGrは、元々整列されていないターゲットグラフに対して近似最大事後推定推論を使用して整列を推論する。実験では、LAGrが強く監視された設定と弱く監視された設定の両方で、基準となるseq2seq解析器に比べて系統的な汎化において有意な改善を達成することが示された。"}
{"title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection", "url": "https://aclanthology.org/2022.acl-long.234/", "abstract": "Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language.To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ToxiGen：敵対的および暗黙的な憎悪スピーチ検出のための大規模な機械生成データセット", "jabstract": "有害言語検出システムは、オンラインでの憎悪の対象となる少数派グループの言及を含むテキストを誤って有害としてフラグ付けすることがよくあります。このような虚偽の相関に過度に依存することは、暗黙的に有害な言語を検出するのにも問題を引き起こします。これらの問題を緩和するために、我々はToxiGenという新しい大規模かつ機械生成されたデータセットを作成しました。このデータセットは、13の少数派グループに関する274kの有害な声明と無害な声明を含んでいます。我々は、デモベースのプロンプティングフレームワークと、大規模な事前学習言語モデルを用いた敵対的な分類器インループデコーディング方法を開発しました。このように機械生成を制御することで、ToxiGenは、以前の人間によるテキストリソースよりも、より多くの人口集団について、暗黙的に有害なテキストをより大規模にカバーすることができます。我々はToxiGenの難しいサブセットについて人間の評価を行い、アノテーターが機械生成されたテキストと人間による言語を区別するのに苦労することを発見しました。また、94.5%の有害な例が人間のアノテーターによって憎悪の言葉としてラベル付けされることを発見しました。我々は、3つの公開データセットを用いて、我々のデータを用いた有害性分類器の微調整が、人間によるテキストデータの性能を大幅に向上させることを示しました。また、ToxiGenが機械生成された有害性と戦うために使用できることを示し、微調整が評価サブセットで分類器の性能を大幅に向上させることを示しました。"}
{"title": "Direct Speech-to-Speech Translation With Discrete Units", "url": "https://aclanthology.org/2022.acl-long.235/", "abstract": "We present a direct speech-to-speech translation (S2ST) model that translates speech from one language to speech in another language without relying on intermediate text generation. We tackle the problem by first applying a self-supervised discrete speech encoder on the target speech and then training a sequence-to-sequence speech-to-unit translation (S2UT) model to predict the discrete representations of the target speech. When target text transcripts are available, we design a joint speech and text training framework that enables the model to generate dual modality output (speech and text) simultaneously in the same inference pass. Experiments on the Fisher Spanish-English dataset show that the proposed framework yields improvement of 6.7 BLEU compared with a baseline direct S2ST model that predicts spectrogram features. When trained without any text transcripts, our model performance is comparable to models that predict spectrograms and are trained with text supervision, showing the potential of our system for translation between unwritten languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「離散単位を用いた直接音声対音声翻訳」に関する論文の要約文です。\n\n1. We propose a direct speech-to-speech translation method that uses discrete units to represent speech signals.\n私たちは、音声信号を表現するために離散単位を使用する直接音声対音声翻訳手法を提案します。\n\n2. Our method consists of two stages: a source-to-target unit mapping stage and a target speech synthesis stage.\n当手法は、ソースからターゲットへの単位マッピングステージと、ターゲット音声合成ステージの2つのステージから構成されています。\n\n3. We evaluate our method on a Japanese-to-English speech translation task and achieve competitive results compared to state-of-the-art methods.\n私たちは、日本語から英語への音声翻訳タスクで当手法を評価し、最新の手法と比較して競争力のある結果を達成しました。", "jabstract": "私たちは、中間テキスト生成に頼らずに、ある言語の音声を別の言語の音声に直接翻訳する直接音声対音声翻訳（S2ST）モデルを提案します。私たちは、まず、ターゲット音声に自己教師ありの離散音声エンコーダを適用し、その後、シーケンス対シーケンス音声対ユニット翻訳（S2UT）モデルをトレーニングして、ターゲット音声の離散表現を予測します。ターゲットのテキストトランスクリプトが利用可能な場合、私たちは、モデルが同時にデュアルモダリティ出力（音声とテキスト）を同じ推論パスで生成できるようにする共同音声とテキストトレーニングフレームワークを設計します。Fisher Spanish-Englishデータセットでの実験では、提案されたフレームワークは、スペクトログラム特徴を予測するベースラインの直接S2STモデルと比較して、6.7 BLEUの改善をもたらします。テキストトランスクリプトなしでトレーニングされた場合、私たちのモデルの性能は、スペクトログラムを予測し、テキスト監視でトレーニングされたモデルと同等であり、書かれていない言語間の翻訳のための私たちのシステムの可能性を示しています。"}
{"title": "Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization", "url": "https://aclanthology.org/2022.acl-long.236/", "abstract": "State-of-the-art abstractive summarization systems often generate hallucinations; i.e., content that is not directly inferable from the source text. Despite being assumed to be incorrect, we find that much hallucinated content is actually consistent with world knowledge, which we call factual hallucinations. Including these factual hallucinations in a summary can be beneficial because they provide useful background information. In this work, we propose a novel detection approach that separates factual from non-factual hallucinations of entities. Our method is based on an entity’s prior and posterior probabilities according to pre-trained and finetuned masked language models, respectively. Empirical results suggest that our method vastly outperforms two baselines in both accuracy and F1 scores and has a strong correlation with human judgments on factuality classification tasks.Furthermore, we use our method as a reward signal to train a summarization system using an off-line reinforcement learning (RL) algorithm that can significantly improve the factuality of generated summaries while maintaining the level of abstractiveness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "幻覚的だが事実！抽象的要約における幻覚の事実性の検査", "jabstract": "最先端の要約システムはしばしば幻覚を生成する。つまり、ソーステキストから直接推論できない内容である。これらの幻覚は誤りとされているが、我々は多くの幻覚が世界知識と一致していることを発見した。我々はこれらの事実的な幻覚を要約に含めることが有益であると考えている。本研究では、事実的な幻覚と非事実的な幻覚を区別する新しい検出手法を提案する。我々の手法は、事前にトレーニングされたマスク言語モデルとファインチューニングされたマスク言語モデルに基づくエンティティの事前確率と事後確率に基づいている。実験結果は、我々の手法が正確性とF1スコアの両方で2つのベースラインを大幅に上回り、事実性分類タスクにおける人間の判断と強い相関関係があることを示している。さらに、我々はこの手法を報酬信号として使用し、オフライン強化学習アルゴリズムを用いて要約システムをトレーニングすることで、生成された要約の事実性を大幅に向上させながら、抽象度を維持することができる。"}
{"title": "EntSUM: A Data Set for Entity-Centric Extractive Summarization", "url": "https://aclanthology.org/2022.acl-long.237/", "abstract": "Controllable summarization aims to provide summaries that take into account user-specified aspects and preferences to better assist them with their information need, as opposed to the standard summarization setup which build a single generic summary of a document.We introduce a human-annotated data set EntSUM for controllable summarization with a focus on named entities as the aspects to control.We conduct an extensive quantitative analysis to motivate the task of entity-centric summarization and show that existing methods for controllable summarization fail to generate entity-centric summaries. We propose extensions to state-of-the-art summarization approaches that achieve substantially better results on our data set. Our analysis and results show the challenging nature of this task and of the proposed data set.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "EntSUM: エンティティ中心の抽出型要約のためのデータセット\n\nThis paper presents EntSUM, a new data set for entity-centric extractive summarization. \n本論文では、エンティティ中心の抽出型要約のための新しいデータセットであるEntSUMを提案する。\n\nEntSUM contains news articles and their corresponding summaries, where each summary is focused on a specific entity mentioned in the article. \nEntSUMには、ニュース記事とそれに対応する要約が含まれており、各要約は記事で言及された特定のエンティティに焦点を当てています。\n\nWe evaluate the performance of several state-of-the-art extractive summarization models on EntSUM and show that entity-centric summarization is a challenging task. \nEntSUM上でいくつかの最新の抽出型要約モデルの性能を評価し、エンティティ中心の要約は課題があることを示します。", "jabstract": "制御可能な要約は、ユーザーが指定した側面や好みを考慮して要約を提供し、文書の単一の一般的な要約を構築する標準的な要約設定とは異なり、情報ニーズをよりよく支援することを目的としています。我々は、名前付きエンティティを制御する側面に焦点を当てた制御可能な要約のための人間注釈付きデータセットEntSUMを紹介します。我々は、エンティティ中心の要約のタスクを促進するために広範な定量的分析を実施し、制御可能な要約の既存の方法がエンティティ中心の要約を生成できないことを示します。我々は、最先端の要約手法の拡張を提案し、当社のデータセットで大幅に改善された結果を達成します。我々の分析と結果は、このタスクと提案されたデータセットの挑戦的な性質を示しています。"}
{"title": "Sentence-level Privacy for Document Embeddings", "url": "https://aclanthology.org/2022.acl-long.238/", "abstract": "User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work we propose SentDP, pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high (768) dimensional, general 𝜖-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding 𝜖-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文書埋め込みの文レベルのプライバシー", "jabstract": "ユーザーの言語データには、非常に個人的な内容が含まれる可能性があります。そのため、ユーザーのデータから学習する際には、強力で解釈可能なプライバシー保証を提供することが不可欠です。本研究では、単一ユーザードキュメントの文レベルでの純粋なローカル差分プライバシーであるSentDPを提案します。我々は、頑健な統計と言語モデリングの概念を組み合わせた新しい技術であるDeepCandidateを提案し、高次元（768次元）、一般的な𝜖-SentDPドキュメント埋め込みを生成します。これにより、ドキュメント内の任意の単一の文を他の文で置き換えても、埋め込みが𝜖-区別できるようになります。私たちの実験は、これらのプライベートドキュメント埋め込みが、感情分析やトピック分類などの下流タスクに有用であり、単語レベルのメトリックDPなどの弱い保証を持つベースライン方法を上回ることを示しています。"}
{"title": "Dataset Geography: Mapping Language Data to Language Users", "url": "https://aclanthology.org/2022.acl-long.239/", "abstract": "As language technologies become more ubiquitous, there are increasing efforts towards expanding the language diversity and coverage of natural language processing (NLP) systems. Arguably, the most important factor influencing the quality of modern NLP systems is data availability. In this work, we study the geographical representativeness of NLP datasets, aiming to quantify if and by how much do NLP datasets match the expected needs of the language speakers. In doing so, we use entity recognition and linking systems, also making important observations about their cross-lingual consistency and giving suggestions for more robust evaluation. Last, we explore some geographical and economic factors that may explain the observed dataset distributions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "データセットの地理学：言語データを言語ユーザーにマッピングする", "jabstract": "自然言語処理（NLP）システムの言語多様性とカバレッジを拡大するための取り組みが増える中、言語技術がますます普及しています。現代のNLPシステムの品質に最も影響を与えると言えるのは、データの入手可能性です。本研究では、NLPデータセットの地理的代表性を調査し、言語話者の期待にどの程度合致しているかを定量化することを目的としています。そのために、エンティティ認識とリンキングシステムを使用し、クロスリンガルな一貫性について重要な観察を行い、より堅牢な評価のための提言を行います。最後に、観察されたデータセットの分布を説明する地理的および経済的要因についても探究します。"}
{"title": "ILDAE: Instance-Level Difficulty Analysis of Evaluation Data", "url": "https://aclanthology.org/2022.acl-long.240/", "abstract": "Knowledge of difficulty level of questions helps a teacher in several ways, such as estimating students’ potential quickly by asking carefully selected questions and improving quality of examination by modifying trivial and hard questions. Can we extract such benefits of instance difficulty in Natural Language Processing? To this end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications: 1) conducting efficient-yet-accurate evaluations with fewer instances saving computational cost and time, 2) improving quality of existing evaluation datasets by repairing erroneous and trivial instances, 3) selecting the best model based on application requirements, 4) analyzing dataset characteristics for guiding future data creation, 5) estimating Out-of-Domain performance reliably. Comprehensive experiments for these applications lead to several interesting results, such as evaluation using just 5% instances (selected via ILDAE) achieves as high as 0.93 Kendall correlation with evaluation using complete dataset and computing weighted accuracy using difficulty scores leads to 5.2% higher correlation with Out-of-Domain performance. We release the difficulty scores and hope our work will encourage research in this important yet understudied field of leveraging instance difficulty in evaluations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ILDAE：評価データのインスタンスレベルの難易度分析", "jabstract": "問題の難易度を知ることは、教師にとっていくつかの方法で役立ちます。例えば、慎重に選択された問題を使って生徒の潜在能力を素早く推定し、些細な問題や難しい問題を修正することで試験の質を向上させることができます。自然言語処理においても、このようなインスタンスの難易度の利点を抽出することは可能でしょうか？そのために、23のデータセットを対象に評価データのインスタンスレベルの難易度分析（ILDAE）を実施し、5つの新しい応用例を示します。1）より少ないインスタンスで効率的かつ正確な評価を実施し、計算コストと時間を節約する、2）誤った問題や些細な問題を修正することで既存の評価データセットの質を向上させる、3）アプリケーション要件に基づいて最適なモデルを選択する、4）将来のデータ作成のためのデータセットの特性を分析する、5）ドメイン外のパフォーマンスを信頼性高く推定する。これらの応用例に対する包括的な実験により、興味深い結果が得られました。例えば、ILDAEによって選択されたわずか5％のインスタンスを使用した評価は、完全なデータセットを使用した評価と同等の0.93のKendall相関を達成し、難易度スコアを使用した重み付き精度の計算は、ドメイン外のパフォーマンスと5.2％高い相関を示しました。私たちは難易度スコアを公開し、私たちの研究が評価におけるインスタンスの難易度を活用する重要でまだ研究されていない分野における研究を促進することを望んでいます。"}
{"title": "Image Retrieval from Contextual Descriptions", "url": "https://aclanthology.org/2022.acl-long.241/", "abstract": "The ability to integrate context, including perceptual and temporal cues, plays a pivotal role in grounding the meaning of a linguistic utterance. In order to measure to what extent current vision-and-language models master this ability, we devise a new multimodal challenge, Image Retrieval from Contextual Descriptions (ImageCoDe). In particular, models are tasked with retrieving the correct image from a set of 10 minimally contrastive candidates based on a contextual description.As such, each description contains only the details that help distinguish between images.Because of this, descriptions tend to be complex in terms of syntax and discourse and require drawing pragmatic inferences. Images are sourced from both static pictures and video frames.We benchmark several state-of-the-art models, including both cross-encoders such as ViLBERT and bi-encoders such as CLIP, on ImageCoDe.Our results reveal that these models dramatically lag behind human performance: the best variant achieves an accuracy of 20.9 on video frames and 59.4 on static pictures, compared with 90.8 in humans.Furthermore, we experiment with new model variants that are better equipped to incorporate visual and temporal context into their representations, which achieve modest gains. Our hope is that ImageCoDE will foster progress in grounded language understanding by encouraging models to focus on fine-grained visual differences.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文脈的な説明からの画像検索", "jabstract": "言語的な発話の意味を基盤とするために、知覚的および時間的な手がかりを含む文脈を統合する能力は重要な役割を果たす。現在のビジョン・ランゲージ・モデルがこの能力をどの程度習得しているかを測定するために、私たちは新しいマルチモーダルな課題、コンテキスト記述からの画像検索（ImageCoDe）を考案した。特に、モデルは、文脈的な説明に基づいて、10個の最小限の対比的な候補の中から正しい画像を取得するように課題を与えられます。そのため、各説明には、画像を区別するのに役立つ詳細のみが含まれます。そのため、説明は構文と談話の面で複雑であり、実用的な推論を必要とします。画像は、静止画と動画フレームの両方から取得されます。私たちは、ViLBERTなどのクロスエンコーダとCLIPなどのバイエンコーダを含むいくつかの最先端のモデルをImageCoDeでベンチマークしました。私たちの結果は、これらのモデルが人間のパフォーマンスに比べて著しく遅れていることを明らかにしました。最高のバリアントは、静止画では59.4、動画フレームでは20.9の精度を達成しましたが、人間の場合は90.8です。さらに、視覚的および時間的な文脈を表現に組み込むためにより適した新しいモデルバリアントを実験し、わずかな利益を得ました。私たちの希望は、ImageCoDEがモデルが細かい視覚的な違いに焦点を当てるように促進することによって、基盤となる言語理解の進歩を促進することです。"}
{"title": "Multilingual Molecular Representation Learning via Contrastive Pre-training", "url": "https://aclanthology.org/2022.acl-long.242/", "abstract": "Molecular representation learning plays an essential role in cheminformatics. Recently, language model-based approaches have gained popularity as an alternative to traditional expert-designed features to encode molecules. However, these approaches only utilize a single molecular language for representation learning. Motivated by the fact that a given molecule can be described using different languages such as Simplified Molecular Line Entry System (SMILES), The International Union of Pure and Applied Chemistry (IUPAC), and The IUPAC International Chemical Identifier (InChI), we propose a multilingual molecular embedding generation approach called MM-Deacon (multilingual molecular domain embedding analysis via contrastive learning). MM-Deacon is pre-trained using SMILES and IUPAC as two different languages on large-scale molecules. We evaluated the robustness of our method on seven molecular property prediction tasks from MoleculeNet benchmark, zero-shot cross-lingual retrieval, and a drug-drug interaction prediction task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「対比的事前学習を通じた多言語分子表現学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Multilingual Molecular Representation Learning via Contrastive Pre-training\n- 対比的事前学習を通じた多言語分子表現学習", "jabstract": "分子表現学習は、化学情報学において重要な役割を果たしています。最近、言語モデルベースのアプローチが、分子をエンコードするための従来の専門家による設計された特徴量の代替手段として人気を集めています。しかし、これらのアプローチは表現学習に単一の分子言語しか利用していません。Simplified Molecular Line Entry System（SMILES）、The International Union of Pure and Applied Chemistry（IUPAC）、The IUPAC International Chemical Identifier（InChI）など、与えられた分子は異なる言語で記述されることができるという事実に着想を得て、我々はMM-Deacon（multilingual molecular domain embedding analysis via contrastive learning）と呼ばれる多言語分子埋め込み生成アプローチを提案します。MM-Deaconは、大規模な分子に対して、SMILESとIUPACの2つの異なる言語を使用して事前学習されます。我々は、MoleculeNetベンチマークからの7つの分子特性予測タスク、ゼロショットクロスリンガル検索、および薬物間相互作用予測タスクにおける我々の手法の堅牢性を評価しました。"}
{"title": "Investigating Failures of Automatic Translationin the Case of Unambiguous Gender", "url": "https://aclanthology.org/2022.acl-long.243/", "abstract": "Transformer-based models are the modern work horses for neural machine translation (NMT), reaching state of the art across several benchmarks. Despite their impressive accuracy, we observe a systemic and rudimentary class of errors made by current state-of-the-art NMT models with regards to translating from a language that doesn’t mark gender on nouns into others that do. We find that even when the surrounding context provides unambiguous evidence of the appropriate grammatical gender marking, no tested model was able to accurately gender occupation nouns systematically. We release an evaluation scheme and dataset for measuring the ability of NMT models to translate gender morphology correctly in unambiguous contexts across syntactically diverse sentences. Our dataset translates from an English source into 20 languages from several different language families. With the availability of this dataset, our hope is that the NMT community can iterate on solutions for this class of especially egregious errors.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Natural Language Processingに関する論文の要約文を日本語に翻訳します。\n\n明確な性別の場合における自動翻訳の失敗を調査する", "jabstract": "トランスフォーマーベースのモデルは、複数のベンチマークで最先端に到達し、ニューラル機械翻訳（NMT）の現代的な作業馬です。彼らの印象的な精度にもかかわらず、私たちは、名詞に性別を示さない言語から性別を示す言語に翻訳する際に、現在の最先端のNMTモデルが犯す系統的で初歩的なエラーのクラスを観察します。周囲の文脈が適切な文法的性別マーキングの明確な証拠を提供している場合でも、どのテストされたモデルも職業名詞の性別を正確にシステム的に決定することができませんでした。私たちは、構文的に多様な文の明確な文脈で性別形態を正しく翻訳するNMTモデルの能力を測定するための評価スキームとデータセットを公開します。私たちのデータセットは、英語のソースから、異なる言語ファミリーからの20の言語に翻訳されます。このデータセットが利用可能になることで、私たちの希望は、特にひどいエラーのこのクラスの解決策に反復することができるNMTコミュニティです。"}
{"title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions", "url": "https://aclanthology.org/2022.acl-long.244/", "abstract": "Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19% better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自然言語クラウドソーシング指示によるクロスタスク汎化", "jabstract": "人間（例えば、クラウドワーカー）は、単にそれらを定義するテキスト指示を読み、いくつかの例を見ることで、さまざまなタスクを解決する驚くべき能力を持っています。個々のデータセットにおける従来の教師あり学習の成功にもかかわらず、このようなモデルはしばしばタスク間の汎化に苦労します（例えば、質問応答システムは分類タスクを解決できません）。AIにおける長年の課題は、それを定義する人間可読の指示を理解することによって新しいタスクを学習するモデルを構築することです。このために、私たちはNATURAL INSTRUCTIONSというデータセットを導入しました。このデータセットには、61の異なるタスク、それらの人間による指示、および193kのタスクインスタンス（入出力ペア）が含まれています。指示は、既存のNLPデータセットを作成するために使用された指示をクラウドソーシングから取得し、統一されたスキーマにマッピングされます。このメタデータセットを使用して、私たちは、見たタスクでモデルをトレーニングし、残りの見えないタスクへの汎化を測定することによって、タスク間の汎化を測定します。私たちは、生成的事前学習言語モデルを採用して、タスク固有の指示を入力とともにエンコードし、タスク出力を生成します。私たちの結果は、指示を利用するモデルの汎化に関して評価すると、指示から19％の改善が見られることを示しています。しかし、これらのモデルは、推定されるパフォーマンスの上限には遠く及ばず、この方向性においてより多くの進歩の余地があることを示しています。"}
{"title": "Imputing Out-of-Vocabulary Embeddings with LOVE Makes LanguageModels Robust with Little Cost", "url": "https://aclanthology.org/2022.acl-long.245/", "abstract": "State-of-the-art NLP systems represent inputs with word embeddings, but these are brittle when faced with Out-of-Vocabulary (OOV) words.To address this issue, we follow the principle of mimick-like models to generate vectors for unseen words, by learning the behavior of pre-trained embeddings using only the surface form of words.We present a simple contrastive learning framework, LOVE, which extends the word representation of an existing pre-trained language model (such as BERT) and makes it robust to OOV with few additional parameters.Extensive evaluations demonstrate that our lightweight model achieves similar or even better performances than prior competitors, both on original datasets and on corrupted variants. Moreover, it can be used in a plug-and-play fashion with FastText and BERT, where it significantly improves their robustness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LOVEを用いた未知語の埋め込み入力により、言語モデルを低コストで堅牢にする。", "jabstract": "最新のNLPシステムは、入力を単語埋め込みで表現しますが、これらはOut-of-Vocabulary（OOV）単語に直面すると脆弱です。この問題に対処するために、私たちは、事前学習された埋め込みの振る舞いを表面形式の単語のみを使用して学習することにより、未知の単語のベクトルを生成するミミックライクモデルの原則に従います。私たちは、既存の事前学習言語モデル（例えばBERT）の単語表現を拡張し、わずかな追加パラメータでOOVに堅牢にする、シンプルな対比学習フレームワークLOVEを提供します。広範な評価により、私たちの軽量モデルが、元のデータセットと破損したバリアントの両方で、先行競合モデルと同等またはより優れた性能を発揮することが示されています。さらに、FastTextやBERTとプラグアンドプレイで使用でき、その堅牢性を大幅に向上させます。"}
{"title": "NumGLUE: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks", "url": "https://aclanthology.org/2022.acl-long.246/", "abstract": "Given the ubiquitous nature of numbers in text, reasoning with numbers to perform simple calculations is an important skill of AI systems. While many datasets and models have been developed to this end, state-of-the-art AI systems are brittle; failing to perform the underlying mathematical reasoning when they appear in a slightly different scenario. Drawing inspiration from GLUE that was proposed in the context of natural language understanding, we propose NumGLUE, a multi-task benchmark that evaluates the performance of AI systems on eight different tasks, that at their core require simple arithmetic understanding. We show that this benchmark is far from being solved with neural models including state-of-the-art large-scale language models performing significantly worse than humans (lower by 46.4 %). Further, NumGLUE promotes sharing knowledge across tasks, especially those with limited training data as evidenced by the superior performance (average gain of 3.4 % on each task) when a model is jointly trained on all the tasks as opposed to task-specific modeling. Finally, we hope that NumGLUE will encourage systems that perform robust and general arithmetic reasoning within language, a first step towards being able to perform more complex mathematical reasoning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "NumGLUE：基本的でありながら挑戦的な数学的推論タスクのスイート", "jabstract": "テキスト中に数字が普遍的に存在するため、数値を理解して簡単な計算を行うことはAIシステムにとって重要なスキルである。多くのデータセットやモデルが開発されてきたが、最新のAIシステムは脆弱であり、少し異なるシナリオで現れた場合に基本的な数学的推論を行うことができない。自然言語理解の文脈で提案されたGLUEに着想を得て、NumGLUEを提案する。NumGLUEは、8つの異なるタスクでAIシステムのパフォーマンスを評価するマルチタスクベンチマークであり、これらのタスクはすべて、基本的な算術理解を必要とする。我々は、このベンチマークがニューラルモデルによって解決されていないことを示し、特に最新の大規模言語モデルは人間よりも低い（46.4％低い）パフォーマンスを示す。さらに、NumGLUEは、トレーニングデータが限られているタスクにおいて、タスクごとのモデリングに対して、すべてのタスクを共同でトレーニングすることで優れたパフォーマンスを発揮することを示す。最後に、NumGLUEが言語内で堅牢で一般的な算術推論を行うシステムを促進し、より複雑な数学的推論を行うための第一歩となることを期待している。"}
{"title": "Upstream Mitigation Is Not All You Need: Testing the Bias Transfer Hypothesis in Pre-Trained Language Models", "url": "https://aclanthology.org/2022.acl-long.247/", "abstract": "A few large, homogenous, pre-trained models undergird many machine learning systems — and often, these models contain harmful stereotypes learned from the internet. We investigate the bias transfer hypothesis: the theory that social biases (such as stereotypes) internalized by large language models during pre-training transfer into harmful task-specific behavior after fine-tuning. For two classification tasks, we find that reducing intrinsic bias with controlled interventions before fine-tuning does little to mitigate the classifier’s discriminatory behavior after fine-tuning. Regression analysis suggests that downstream disparities are better explained by biases in the fine-tuning dataset. Still, pre-training plays a role: simple alterations to co-occurrence rates in the fine-tuning dataset are ineffective when the model has been pre-trained. Our results encourage practitioners to focus more on dataset quality and context-specific harms.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "上流の緩和だけでは十分ではない：事前学習された言語モデルにおけるバイアス転送仮説の検証", "jabstract": "多くの機械学習システムは、大規模で均質な事前学習モデルに基づいており、これらのモデルにはしばしばインターネットから学習した有害なステレオタイプが含まれています。本研究では、社会的バイアス（ステレオタイプなど）が大規模言語モデルに内在化され、微調整後に有害なタスク固有の振る舞いに転移するというバイアス転移仮説を調査します。2つの分類タスクについて、微調整前に制御された介入による固有バイアスの低減は、微調整後の分類器の差別的な振る舞いを軽減するのにほとんど役立たないことがわかりました。回帰分析によると、下流の不均衡は、微調整データセットのバイアスによってよりよく説明されます。それでも、事前学習は役割を果たします。微調整データセットの共起率を単純に変更しても、モデルが事前学習されている場合は効果がありません。本研究の結果は、実践者がデータセットの品質とコンテキスト固有の害をより重視することを奨励しています。"}
{"title": "Improving Multi-label Malevolence Detection in Dialogues through Multi-faceted Label Correlation Enhancement", "url": "https://aclanthology.org/2022.acl-long.248/", "abstract": "A dialogue response is malevolent if it is grounded in negative emotions, inappropriate behavior, or an unethical value basis in terms of content and dialogue acts. The detection of malevolent dialogue responses is attracting growing interest. Current research on detecting dialogue malevolence has limitations in terms of datasets and methods. First, available dialogue datasets related to malevolence are labeled with a single category, but in practice assigning a single category to each utterance may not be appropriate as some malevolent utterances belong to multiple labels. Second, current methods for detecting dialogue malevolence neglect label correlation. Therefore, we propose the task of multi-label dialogue malevolence detection and crowdsource a multi-label dataset, multi-label dialogue malevolence detection (MDMD) for evaluation. We also propose a multi-label malevolence detection model, multi-faceted label correlation enhanced CRF (MCRF), with two label correlation mechanisms, label correlation in taxonomy (LCT) and label correlation in context (LCC). Experiments on MDMD show that our method outperforms the best performing baseline by a large margin, i.e., 16.1%, 11.9%, 12.0%, and 6.1% on precision, recall, F1, and Jaccard score, respectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「多面的なラベル相関強化による対話におけるマルチラベル悪意検出の改善」についての論文の要約です。", "jabstract": "対話応答が否定的な感情、不適切な行動、または倫理的でない価値基盤に基づいている場合、それは悪意のあるものとされる。悪意のある対話応答の検出は、ますます注目を集めている。現在の対話悪意の検出に関する研究には、データセットと方法の面で制限がある。まず、悪意に関連する利用可能な対話データセットは、単一のカテゴリでラベル付けされているが、実際には、一部の悪意のある発言は複数のラベルに属するため、各発言に単一のカテゴリを割り当てることは適切ではない場合がある。第二に、現在の対話悪意の検出方法は、ラベルの相関を無視している。したがって、我々は、多ラベル対話悪意検出のタスクを提案し、評価のために多ラベルデータセット、多ラベル対話悪意検出（MDMD）をクラウドソース化する。また、2つのラベル相関メカニズム、タクソノミー内のラベル相関（LCT）と文脈内のラベル相関（LCC）を持つ多面的ラベル相関強化CRF（MCRF）の多ラベル悪意検出モデルを提案する。MDMD上の実験では、我々の方法が最高のベースラインを大幅に上回り、精度、再現率、F1、およびJaccardスコアにおいてそれぞれ16.1％、11.9％、12.0％、および6.1％の向上が見られた。"}
{"title": "How Do We Answer Complex Questions: Discourse Structure of Long-form Answers", "url": "https://aclanthology.org/2022.acl-long.249/", "abstract": "Long-form answers, consisting of multiple sentences, can provide nuanced and comprehensive answers to a broader set of questions. To better understand this complex and understudied task, we study the functional structure of long-form answers collected from three datasets, ELI5, WebGPT and Natural Questions. Our main goal is to understand how humans organize information to craft complex answers. We develop an ontology of six sentence-level functional roles for long-form answers, and annotate 3.9k sentences in 640 answer paragraphs. Different answer collection methods manifest in different discourse structures. We further analyze model-generated answers – finding that annotators agree less with each other when annotating model-generated answers compared to annotating human-written answers. Our annotated data enables training a strong classifier that can be used for automatic analysis. We hope our work can inspire future research on discourse-level modeling and evaluation of long-form QA systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "複雑な質問にどのように答えるか：長文回答の談話構造", "jabstract": "複数の文から成る長い回答は、より広範な質問に対して微妙で包括的な回答を提供することができます。この複雑で研究されていないタスクをよりよく理解するために、ELI5、WebGPT、Natural Questionsの3つのデータセットから収集された長い回答の機能的構造を研究します。私たちの主な目標は、人間が情報を整理して複雑な回答を作り出す方法を理解することです。私たちは、長い回答の6つの文レベルの機能的役割のオントロジーを開発し、640の回答段落の3.9kの文を注釈付けします。異なる回答収集方法は、異なる談話構造を示します。さらに、モデル生成の回答を分析し、注釈付けされた人間による回答と比較して、注釈付け者が互いに合意しないことを発見します。私たちの注釈付きデータは、自動分析に使用できる強力な分類器のトレーニングを可能にします。私たちの研究が、談話レベルのモデリングと長いQAシステムの評価に関する将来の研究をインスパイアすることを願っています。"}
{"title": "Understanding Iterative Revision from Human-Written Text", "url": "https://aclanthology.org/2022.acl-long.250/", "abstract": "Writing is, by nature, a strategic, adaptive, and, more importantly, an iterative process. A crucial part of writing is editing and revising the text. Previous works on text revision have focused on defining edit intention taxonomies within a single domain or developing computational models with a single level of edit granularity, such as sentence-level edits, which differ from human’s revision cycles. This work describes IteraTeR: the first large-scale, multi-domain, edit-intention annotated corpus of iteratively revised text. In particular, IteraTeR is collected based on a new framework to comprehensively model the iterative text revisions that generalizes to a variety of domains, edit intentions, revision depths, and granularities. When we incorporate our annotated edit intentions, both generative and action-based text revision models significantly improve automatic evaluations. Through our work, we better understand the text revision process, making vital connections between edit intentions and writing quality, enabling the creation of diverse corpora to support computational modeling of iterative text revisions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "人間が書いたテキストからの反復的な修正の理解", "jabstract": "文章を書くことは、本質的に戦略的で適応的であり、何よりも反復的なプロセスです。文章を書く上で重要なのは、編集や修正です。これまでのテキスト修正に関する研究は、単一のドメイン内で編集意図のタクソノミーを定義することや、文レベルの編集など、人間の修正サイクルと異なる単一の編集粒度で計算モデルを開発することに焦点を当ててきました。本研究では、IteraTeRという、複数のドメインにわたる反復的に修正されたテキストの大規模な編集意図注釈付きコーパスを初めて提案します。特に、IteraTeRは、さまざまなドメイン、編集意図、修正の深さ、粒度に汎用的に適用できる新しいフレームワークに基づいて収集されています。注釈付きの編集意図を組み込むことで、生成的およびアクションベースのテキスト修正モデルは自動評価を大幅に改善します。本研究により、テキスト修正プロセスをより理解し、編集意図と文章の品質の重要な関係を明らかにし、反復的なテキスト修正の計算モデリングをサポートする多様なコーパスの作成が可能になります。"}
{"title": "Making Transformers Solve Compositional Tasks", "url": "https://aclanthology.org/2022.acl-long.251/", "abstract": "Several studies have reported the inability of Transformer models to generalize compositionally, a key type of generalization in many NLP tasks such as semantic parsing. In this paper we explore the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization. We identified Transformer configurations that generalize compositionally significantly better than previously reported in the literature in many compositional tasks. We achieve state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), and a string edit operation composition benchmark (PCFG).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トランスフォーマーを用いた合成的タスクの解決方法", "jabstract": "多くのNLPタスク（意味解析など）において重要な一般化の一種である合成的一般化を汎化することがTransformerモデルの能力不足と報告されている。本論文では、Transformerモデルの設計空間を探索し、いくつかの設計決定によってモデルに与えられる帰納的なバイアスが合成的一般化に重要な影響を与えることを示す。我々は、多くの合成的タスクにおいて、以前の文献で報告されたよりも合成的に一般化するTransformer構成を特定した。我々は、意味解析の合成的一般化ベンチマーク（COGS）と文字列編集操作の合成ベンチマーク（PCFG）において、最先端の結果を達成した。"}
{"title": "Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.252/", "abstract": "Unlike literal expressions, idioms’ meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT). NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations. In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language.When Transformer emits a non-literal translation - i.e. identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions. This manifests in idioms’ parts being grouped through attention and in reduced interaction between idioms and their context.In the decoder’s cross-attention, figurative inputs result in reduced attention on source-side tokens. These results suggest that Transformer’s tendency to process idioms as compositional expressions contributes to literal translations of idioms.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トランスフォーマーはあまりにも構成的になりすぎる可能性があるのか？ニューラルマシン翻訳におけるイディオム処理の分析", "jabstract": "直接的な表現とは異なり、慣用句の意味はその部分から直接的には導かれず、ニューラル機械翻訳（NMT）にとって課題となっています。NMTモデルは、しばしば慣用句を正確に翻訳できず、構成的で直接的な翻訳を過剰に生成します。本研究では、英語をソース言語とし、7つのヨーロッパ言語のいずれかをターゲット言語とするモデルの隠れ層とアテンションパターンを分析することで、慣用句の非構成性が主流のNMTモデルであるTransformerのメカニズムに反映されるかどうかを調査しました。Transformerが非直接的な翻訳を出力する場合、エンコーダーは慣用句を単一の語彙単位としてより強く処理します。これは、アテンションによって慣用句の部分がグループ化され、慣用句とその文脈との相互作用が減少することで現れます。デコーダーのクロスアテンションでは、比喩的な入力により、ソース側のトークンに対するアテンションが減少します。これらの結果から、Transformerが慣用句を構成的な表現として処理する傾向が、慣用句の直接的な翻訳に寄与していることが示唆されます。"}
{"title": "ConditionalQA: A Complex Reading Comprehension Dataset with Conditional Answers", "url": "https://aclanthology.org/2022.acl-long.253/", "abstract": "We describe a Question Answering (QA) dataset that contains complex questions with conditional answers, i.e. the answers are only applicable when certain conditions apply. We call this dataset ConditionalQA. In addition to conditional answers, the dataset also features:(1) long context documents with information that is related in logically complex ways;(2) multi-hop questions that require compositional logical reasoning;(3) a combination of extractive questions, yes/no questions, questions with multiple answers, and not-answerable questions;(4) questions asked without knowing the answers.We show that ConditionalQA is challenging for many of the existing QA models, especially in selecting answer conditions. We believe that this dataset will motivate further research in answering complex questions over long documents.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ConditionalQA：条件付き回答を持つ複雑な読解データセット", "jabstract": "私たちは、条件付きの答えがある複雑な質問を含むQuestion Answering（QA）データセットであるConditionalQAを説明します。つまり、答えは特定の条件が適用される場合にのみ適用されます。このデータセットには、以下の特徴もあります：（1）論理的に複雑な関連情報を持つ長いコンテキスト文書、（2）合成的な論理推論が必要なマルチホップ質問、（3）抽出質問、はい/いいえ質問、複数の答えがある質問、答えられない質問の組み合わせ、（4）答えを知らないまま質問をする質問。私たちは、ConditionalQAが既存のQAモデルにとって特に答えの条件を選択することが難しいことを示しました。私たちは、このデータセットが長い文書に対する複雑な質問に答えるためのさらなる研究を促進すると信じています。"}
{"title": "Prompt-free and Efficient Few-shot Learning with Language Models", "url": "https://aclanthology.org/2022.acl-long.254/", "abstract": "Current methods for few-shot fine-tuning of pretrained masked language models (PLMs) require carefully engineered prompts and verbalizers for each new task to convert examples into a cloze-format that the PLM can score. In this work, we propose Perfect, a simple and efficient method for few-shot fine-tuning of PLMs without relying on any such handcrafting, which is highly effective given as few as 32 data points. Perfect makes two key design choices: First, we show that manually engineered task prompts can be replaced with task-specific adapters that enable sample-efficient fine-tuning and reduce memory and storage costs by roughly factors of 5 and 100, respectively. Second, instead of using handcrafted verbalizers, we learn new multi-token label embeddings during fine-tuning, which are not tied to the model vocabulary and which allow us to avoid complex auto-regressive decoding. These embeddings are not only learnable from limited data but also enable nearly 100x faster training and inference. Experiments on a wide range of few shot NLP tasks demonstrate that Perfect, while being simple and efficient, also outperforms existing state-of-the-art few-shot learning methods. Our code is publicly available at https://github.com/rabeehk/perfect.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プロンプト不要で効率的なフォーショット学習を言語モデルで実現する。", "jabstract": "プリトレーニングされたマスクされた言語モデル（PLM）の少数ショットのファインチューニングの現在の方法は、各新しいタスクに対して例をクローズ形式に変換してPLMがスコアリングできるようにするために、注意深く設計されたプロンプトとバーバライザが必要です。本研究では、手作業に頼らずにPLMの少数ショットのファインチューニングを行うためのシンプルで効率的な方法であるPerfectを提案します。Perfectは、32個のデータポイントで高い効果を発揮することができます。Perfectは、2つの主要な設計選択を行います。まず、手動で設計されたタスクプロンプトをタスク固有のアダプタで置き換えることができることを示し、サンプル効率のファインチューニングを可能にし、メモリとストレージコストをそれぞれ約5倍と100倍削減します。第二に、手作業で作成されたバーバライザの代わりに、ファインチューニング中に新しいマルチトークンラベル埋め込みを学習し、モデルの語彙に結び付けられていないため、複雑な自己回帰デコーディングを回避することができます。これらの埋め込みは、限られたデータから学習可能であり、トレーニングと推論をほぼ100倍高速化することができます。さまざまな少数ショットNLPタスクでの実験により、Perfectは、シンプルで効率的でありながら、既存の最先端の少数ショット学習方法を上回ることが示されました。私たちのコードは、https://github.com/rabeehk/perfectで公開されています。"}
{"title": "Continual Sequence Generation with Adaptive Compositional Modules", "url": "https://aclanthology.org/2022.acl-long.255/", "abstract": "Continual learning is essential for real-world deployment when there is a need to quickly adapt the model to new tasks without forgetting knowledge of old tasks. Existing work on continual sequence generation either always reuses existing parameters to learn new tasks, which is vulnerable to catastrophic forgetting on dissimilar tasks, or blindly adds new parameters for every new task, which could prevent knowledge sharing between similar tasks. To get the best of both worlds, in this work, we propose continual sequence generation with adaptive compositional modules to adaptively add modules in transformer architectures and compose both old and new modules for new tasks. We also incorporate pseudo experience replay to facilitate knowledge transfer in those shared modules. Experiment results on various sequences of generation tasks show that our framework can adaptively add modules or reuse modules based on task similarity, outperforming state-of-the-art baselines in terms of both performance and parameter efficiency. We make our code public at https://github.com/GT-SALT/Adaptive-Compositional-Modules.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "適応的な構成モジュールを用いた連続的なシーケンス生成", "jabstract": "現実世界での展開において、古いタスクの知識を忘れることなく、新しいタスクにモデルを素早く適応させる必要がある場合、継続的な学習は不可欠である。継続的なシーケンス生成に関する既存の研究は、新しいタスクを学習するために常に既存のパラメータを再利用するか、類似しないタスクに対しては大規模な忘却を引き起こす脆弱性があるか、または新しいタスクごとに新しいパラメータを盲目的に追加するか、類似するタスク間での知識共有を防ぐ可能性がある。両方の利点を得るために、本研究では、適応的な構成モジュールを使用した継続的なシーケンス生成を提案し、トランスフォーマーアーキテクチャにモジュールを適応的に追加し、新しいタスクのために古いモジュールと新しいモジュールを組み合わせます。また、共有されたモジュールでの知識転送を促進するために、疑似経験再生を組み込みます。様々な生成タスクのシーケンスでの実験結果は、タスクの類似性に基づいてモジュールを適応的に追加または再利用し、パフォーマンスとパラメータ効率の両方の面で最先端のベースラインを上回ることを示しています。コードはhttps://github.com/GT-SALT/Adaptive-Compositional-Modulesで公開しています。"}
{"title": "An Investigation of the (In)effectiveness of Counterfactually Augmented Data", "url": "https://aclanthology.org/2022.acl-long.256/", "abstract": "While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data. Recent work has explored using counterfactually-augmented data (CAD)—data generated by minimally perturbing examples to flip the ground-truth label—to identify robust features that are invariant under distribution shift. However, empirical results using CAD during training for OOD generalization have been mixed. To explain this discrepancy, through a toy theoretical example and empirical analysis on two crowdsourced CAD datasets, we show that: (a) while features perturbed in CAD are indeed robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data. Our results thus show that the lack of perturbation diversity limits CAD’s effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨を日本語に翻訳します。\n\n「事実に反するデータの効果（無効）性の調査」", "jabstract": "事前学習済み言語モデルは、自然言語理解のベンチマークで優れた性能を発揮する一方、偶発的な相関に依存し、分布外データに対して一般化が不十分である傾向がある。最近の研究では、事実に反するデータ（CAD）を使用して、最小限の変更を加えて正解ラベルを反転させたデータを生成し、分布シフトに対して不変な堅牢な特徴を特定することが探求されている。しかし、CADをトレーニング中に使用してOOD汎化を行う実証結果は混合している。本論文では、玩具理論例と2つのクラウドソーシングCADデータセットの実証分析を通じて、以下のことを示す：（a）CADで変更された特徴は確かに堅牢な特徴であるが、変更されていない堅牢な特徴を学習することを妨げる可能性があること、（b）CADはデータ内の既存の偶発的な相関を悪化させる可能性があること。したがって、変更の多様性の欠如がCADのOOD汎化に対する効果を制限しており、多様な例の変更を引き出すための革新的なクラウドソーシング手順が必要であることが示された。"}
{"title": "Inducing Positive Perspectives with Text Reframing", "url": "https://aclanthology.org/2022.acl-long.257/", "abstract": "Sentiment transfer is one popular example of a text style transfer task, where the goal is to reverse the sentiment polarity of a text. With a sentiment reversal comes also a reversal in meaning. We introduce a different but related task called positive reframing in which we neutralize a negative point of view and generate a more positive perspective for the author without contradicting the original meaning. Our insistence on meaning preservation makes positive reframing a challenging and semantically rich task. To facilitate rapid progress, we introduce a large-scale benchmark, Positive Psychology Frames, with 8,349 sentence pairs and 12,755 structured annotations to explain positive reframing in terms of six theoretically-motivated reframing strategies. Then we evaluate a set of state-of-the-art text style transfer models, and conclude by discussing key challenges and directions for future work.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストリフレーミングによるポジティブな視点の導入", "jabstract": "感情転移は、テキストスタイル転移の一つの人気のある例であり、その目的はテキストの感情極性を反転させることです。感情の反転には意味の反転も伴います。私たちは、異なるが関連するタスクであるポジティブリフレーミングを紹介します。このタスクでは、原意に矛盾しないように、ネガティブな視点を中立化し、著者のよりポジティブな視点を生成します。意味の保存にこだわることで、ポジティブリフレーミングは、難解で意味的に豊かなタスクとなります。迅速な進展を促進するために、私たちは、8,349の文のペアと12,755の構造化された注釈を備えた大規模なベンチマーク、Positive Psychology Framesを紹介します。このベンチマークは、6つの理論的に動機付けられたリフレーミング戦略に基づいて、ポジティブリフレーミングを説明します。次に、最新のテキストスタイル転移モデルのセットを評価し、今後の課題と方向性について議論して結論を導きます。"}
{"title": "VALUE: Understanding Dialect Disparity in NLU", "url": "https://aclanthology.org/2022.acl-long.258/", "abstract": "English Natural Language Understanding (NLU) systems have achieved great performances and even outperformed humans on benchmarks like GLUE and SuperGLUE. However, these benchmarks contain only textbook Standard American English (SAE). Other dialects have been largely overlooked in the NLP community. This leads to biased and inequitable NLU systems that serve only a sub-population of speakers. To understand disparities in current models and to facilitate more dialect-competent NLU systems, we introduce the VernAcular Language Understanding Evaluation (VALUE) benchmark, a challenging variant of GLUE that we created with a set of lexical and morphosyntactic transformation rules. In this initial release (V.1), we construct rules for 11 features of African American Vernacular English (AAVE), and we recruit fluent AAVE speakers to validate each feature transformation via linguistic acceptability judgments in a participatory design manner. Experiments show that these new dialectal features can lead to a drop in model performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "価値：NLUにおける方言の不一致の理解", "jabstract": "英語の自然言語理解（NLU）システムは、GLUEやSuperGLUEなどのベンチマークで、偉大な性能を発揮し、人間を上回ることさえあります。しかし、これらのベンチマークには、教科書的な標準アメリカ英語（SAE）しか含まれていません。そのため、NLPコミュニティでは他の方言がほとんど無視されており、特定の人口にしか役立たない偏ったNLUシステムが生まれています。現在のモデルの格差を理解し、より方言に適したNLUシステムを促進するために、私たちはVernAcular Language Understanding Evaluation（VALUE）ベンチマークを導入しました。これは、一連の語彙的および形態論的変換ルールで作成したGLUEの難しいバリアントです。この初期リリース（V.1）では、アフリカ系アメリカ人の方言英語（AAVE）の11の特徴についてルールを構築し、言語的受容性判断による参加型設計方法で流暢なAAVE話者を募集し、各特徴変換を検証しました。実験により、これらの新しい方言的特徴がモデルの性能低下につながることが示されました。"}
{"title": "From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer", "url": "https://aclanthology.org/2022.acl-long.259/", "abstract": "We study the task of toxic spans detection, which concerns the detection of the spans that make a text toxic, when detecting such spans is possible. We introduce a dataset for this task, ToxicSpans, which we release publicly. By experimenting with several methods, we show that sequence labeling models perform best, but methods that add generic rationale extraction mechanisms on top of classifiers trained to predict if a post is toxic or not are also surprisingly promising. Finally, we use ToxicSpans and systems trained on it, to provide further analysis of state-of-the-art toxic to non-toxic transfer systems, as well as of human performance on that latter task. Our work highlights challenges in finer toxicity detection and mitigation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オンラインディスカッションにおける有害なスパンの検出から有害なものから文明的なものへの転換の分析まで、自然言語処理に関する論文の要約です。", "jabstract": "私たちは、テキストが有害であるスパンを検出するタスクである「有害スパン検出」を研究しています。このようなスパンを検出することが可能な場合に、そのスパンを検出することに関心があります。私たちは、このタスクのためのデータセットである「ToxicSpans」を公開しました。いくつかの方法を実験することで、シーケンスラベリングモデルが最も優れていることを示しましたが、投稿が有害かどうかを予測するためにトレーニングされた分類器の上に一般的な理由抽出メカニズムを追加する方法も驚くほど有望です。最後に、ToxicSpansとそれにトレーニングされたシステムを使用して、最新の有害から非有害への転送システム、および後者のタスクにおける人間のパフォーマンスのさらなる分析を提供します。私たちの研究は、より細かい有害性の検出と緩和における課題を強調しています。"}
{"title": "FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction", "url": "https://aclanthology.org/2022.acl-long.260/", "abstract": "Sequence modeling has demonstrated state-of-the-art performance on natural language and document understanding tasks. However, it is challenging to correctly serialize tokens in form-like documents in practice due to their variety of layout patterns. We propose FormNet, a structure-aware sequence model to mitigate the suboptimal serialization of forms. First, we design Rich Attention that leverages the spatial relationship between tokens in a form for more precise attention score calculation. Second, we construct Super-Tokens for each word by embedding representations from their neighboring tokens through graph convolutions. FormNet therefore explicitly recovers local syntactic information that may have been lost during serialization. In experiments, FormNet outperforms existing methods with a more compact model size and less pre-training data, establishing new state-of-the-art performance on CORD, FUNSD and Payment benchmarks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FormNet：形式文書情報抽出におけるシーケンシャルモデリングを超えた構造エンコーディング", "jabstract": "シーケンスモデリングは、自然言語やドキュメント理解のタスクにおいて最先端のパフォーマンスを示しています。しかし、フォームのようなドキュメントのトークンを正しくシリアル化することは、レイアウトパターンの多様性のために実践的には困難です。本研究では、フォームのサブオプティマルなシリアル化を緩和するための構造感知シーケンスモデルであるFormNetを提案します。まず、Rich Attentionを設計し、フォーム内のトークン間の空間的な関係を活用してより正確なアテンションスコアの計算を行います。次に、グラフ畳み込みを介して隣接するトークンからの埋め込み表現を使用して、各単語のためのSuper-Tokensを構築します。FormNetは、シリアル化中に失われた可能性のあるローカルな構文情報を明示的に回復します。実験では、FormNetはよりコンパクトなモデルサイズと少ない事前学習データで既存の方法を上回り、CORD、FUNSD、Paymentのベンチマークで新たな最先端のパフォーマンスを確立しました。"}
{"title": "The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems", "url": "https://aclanthology.org/2022.acl-long.261/", "abstract": "Conversational agents have come increasingly closer to human competence in open-domain dialogue settings; however, such models can reflect insensitive, hurtful, or entirely incoherent viewpoints that erode a user’s trust in the moral integrity of the system. Moral deviations are difficult to mitigate because moral judgments are not universal, and there may be multiple competing judgments that apply to a situation simultaneously. In this work, we introduce a new resource, not to authoritatively resolve moral ambiguities, but instead to facilitate systematic understanding of the intuitions, values and moral judgments reflected in the utterances of dialogue systems. The Moral Integrity Corpus, MIC, is such a resource, which captures the moral assumptions of 38k prompt-reply pairs, using 99k distinct Rules of Thumb (RoTs). Each RoT reflects a particular moral conviction that can explain why a chatbot’s reply may appear acceptable or problematic. We further organize RoTs with a set of 9 moral and social attributes and benchmark performance for attribute classification. Most importantly, we show that current neural language models can automatically generate new RoTs that reasonably describe previously unseen interactions, but they still struggle with certain scenarios. Our findings suggest that MIC will be a useful resource for understanding and language models’ implicit moral assumptions and flexibly benchmarking the integrity of conversational agents. To download the data, see https://github.com/GT-SALT/mic", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "道徳的な対話システムのベンチマークとなるMoral Integrity Corpus（道徳的完全性コーパス）についての論文の要約です。", "jabstract": "会話エージェントは、オープンドメインの対話設定において、人間の能力にますます近づいてきています。しかし、そのようなモデルは、無神経で傷つける、または完全に不明瞭な視点を反映することがあり、ユーザーのシステムの道徳的誠実性への信頼を侵食する可能性があります。道徳的逸脱は、道徳的判断が普遍的ではなく、同時に状況に適用される複数の競合する判断があるため、緩和するのが困難です。本研究では、道徳的曖昧さを権威的に解決するためではなく、対話システムの発話に反映される直感、価値観、道徳的判断を体系的に理解するための新しいリソースを紹介します。Moral Integrity Corpus（MIC）は、38kのプロンプト-リプライペアの道徳的な仮定を99kの異なるルールオブサム（RoTs）を使用して捉えるこのようなリソースです。各RoTは、チャットボットの返信が受け入れられるか問題があるかを説明する特定の道徳的信念を反映しています。さらに、RoTを9つの道徳的および社会的属性のセットで整理し、属性分類のベンチマークパフォーマンスを評価します。最も重要なことは、現在のニューラル言語モデルが、以前に見たことのない相互作用を合理的に説明する新しいRoTを自動的に生成できることを示しましたが、特定のシナリオにはまだ苦戦しています。私たちの調査結果は、MICが、対話エージェントの誠実性を柔軟にベンチマークし、言語モデルの暗黙の道徳的仮定を理解するための有用なリソースになることを示唆しています。データをダウンロードするには、https://github.com/GT-SALT/micを参照してください。"}
{"title": "Token Dropping for Efficient BERT Pretraining", "url": "https://aclanthology.org/2022.acl-long.262/", "abstract": "Transformer-based models generally allocate the same amount of computation for each token in a given sequence. We develop a simple but effective “token dropping” method to accelerate the pretraining of transformer models, such as BERT, without degrading its performance on downstream tasks. In particular, we drop unimportant tokens starting from an intermediate layer in the model to make the model focus on important tokens more efficiently if with limited computational resource. The dropped tokens are later picked up by the last layer of the model so that the model still produces full-length sequences. We leverage the already built-in masked language modeling (MLM) loss to identify unimportant tokens with practically no computational overhead. In our experiments, this simple approach reduces the pretraining cost of BERT by 25% while achieving similar overall fine-tuning performance on standard downstream tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "効率的なBERT事前学習のためのトークンドロップ", "jabstract": "トランスフォーマーベースのモデルは、一定のシーケンス内の各トークンに同じ計算量を割り当てます。本研究では、BERTなどのトランスフォーマーモデルの事前学習を効率化するために、シンプルで効果的な「トークンドロップ」メソッドを開発しました。特に、モデルの中間層から重要でないトークンを削除し、限られた計算リソースでより効率的に重要なトークンに焦点を当てることで、モデルの性能を低下させることなく、モデルを高速化します。削除されたトークンは、モデルの最後の層で再び取り上げられるため、モデルはまだ完全なシーケンスを生成します。既に組み込まれているマスク言語モデリング（MLM）損失を活用して、実質的な計算オーバーヘッドなしに、重要でないトークンを特定します。実験では、このシンプルなアプローチにより、標準的な下流タスクで同等の全体的な微調整性能を達成しながら、BERTの事前学習コストを25％削減できました。"}
{"title": "DialFact: A Benchmark for Fact-Checking in Dialogue", "url": "https://aclanthology.org/2022.acl-long.263/", "abstract": "Fact-checking is an essential tool to mitigate the spread of misinformation and disinformation. We introduce the task of fact-checking in dialogue, which is a relatively unexplored area. We construct DialFact, a testing benchmark dataset of 22,245 annotated conversational claims, paired with pieces of evidence from Wikipedia. There are three sub-tasks in DialFact: 1) Verifiable claim detection task distinguishes whether a response carries verifiable factual information; 2) Evidence retrieval task retrieves the most relevant Wikipedia snippets as evidence; 3) Claim verification task predicts a dialogue response to be supported, refuted, or not enough information. We found that existing fact-checking models trained on non-dialogue data like FEVER fail to perform well on our task, and thus, we propose a simple yet data-efficient solution to effectively improve fact-checking performance in dialogue. We point out unique challenges in DialFact such as handling the colloquialisms, coreferences, and retrieval ambiguities in the error analysis to shed light on future research in this direction.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DialFact：対話における事実チェックのベンチマーク", "jabstract": "ファクトチェックは、誤情報や偽情報の拡散を緩和するために必要な重要なツールです。我々は、比較的未開拓の領域である対話におけるファクトチェックのタスクを紹介します。我々は、Wikipediaからの証拠とペアリングされた22,245の注釈付き会話主張のテストベンチマークデータセットであるDialFactを構築しました。 DialFactには3つのサブタスクがあります。1）検証可能な主張検出タスクは、応答が検証可能な事実情報を持っているかどうかを区別します。2）証拠の検索タスクは、最も関連性の高いWikipediaスニペットを証拠として取得します。3）主張の検証タスクは、対話応答が支持されるか、反駁されるか、情報が不十分かを予測します。我々は、FEVERのような非対話データでトレーニングされた既存のファクトチェックモデルが我々のタスクでうまく機能しないことを発見し、したがって、対話におけるファクトチェックのパフォーマンスを効果的に改善するためのシンプルでデータ効率の高いソリューションを提案します。我々は、口語表現、共参照、検索の曖昧さなどのDialFactの独自の課題を指摘し、今後の研究に光を当てます。"}
{"title": "The Trade-offs of Domain Adaptation for Neural Language Models", "url": "https://aclanthology.org/2022.acl-long.264/", "abstract": "This work connects language model adaptation with concepts of machine learning theory. We consider a training setup with a large out-of-domain set and a small in-domain set. We derive how the benefit of training a model on either set depends on the size of the sets and the distance between their underlying distributions. We analyze how out-of-domain pre-training before in-domain fine-tuning achieves better generalization than either solution independently. Finally, we present how adaptation techniques based on data selection, such as importance sampling, intelligent data selection and influence functions, can be presented in a common framework which highlights their similarity and also their subtle differences.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ニューラル言語モデルのドメイン適応のトレードオフ", "jabstract": "この論文は、自然言語処理に関するもので、言語モデルの適応を機械学習理論の概念と結びつけています。大規模なドメイン外セットと小規模なドメイン内セットを用いたトレーニングセットアップを考慮しています。セットのサイズとその基礎となる分布の距離によって、どちらのセットでモデルをトレーニングすることが有益かを導出しています。ドメイン外プレトレーニングを行った後にドメイン内ファインチューニングを行うことで、単独の解決策よりも汎化性能が向上することを分析しています。最後に、重要度サンプリング、インテリジェントデータ選択、影響関数などのデータ選択に基づく適応技術を、類似点と微妙な違いを強調する共通のフレームワークで示しています。"}
{"title": "Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go", "url": "https://aclanthology.org/2022.acl-long.265/", "abstract": "Aligning with ACL 2022 special Theme on “Language Diversity: from Low Resource to Endangered Languages”, we discuss the major linguistic and sociopolitical challenges facing development of NLP technologies for African languages. Situating African languages in a typological framework, we discuss how the particulars of these languages can be harnessed. To facilitate future research, we also highlight current efforts, communities, venues, datasets, and tools. Our main objective is to motivate and advocate for an Afrocentric approach to technology development. With this in mind, we recommend what technologies to build and how to build, evaluate, and deploy them based on the needs of local African communities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "アフリカ言語のためのアフロセントリックNLPへ：現状と今後の展望\n\n我々がいる場所と、我々が進むことができる場所", "jabstract": "ACL 2022の特別テーマ「言語多様性：低資源言語から絶滅危惧言語まで」に沿って、我々はアフリカ言語のNLP技術開発に直面する主要な言語学的および社会政治的課題について議論する。アフリカ言語を分類的枠組みに位置づけ、これらの言語の特性をどのように利用できるかについても議論する。将来の研究を促進するために、現在の取り組み、コミュニティ、会場、データセット、ツールにも注目する。我々の主な目的は、技術開発にアフリカ中心のアプローチを提唱することである。この観点から、現地のアフリカコミュニティのニーズに基づいて、どのような技術を構築し、どのように構築、評価、展開するかを推奨する。"}
{"title": "Ensembling and Knowledge Distilling of Large Sequence Taggers for Grammatical Error Correction", "url": "https://aclanthology.org/2022.acl-long.266/", "abstract": "In this paper, we investigate improvements to the GEC sequence tagging architecture with a focus on ensembling of recent cutting-edge Transformer-based encoders in Large configurations. We encourage ensembling models by majority votes on span-level edits because this approach is tolerant to the model architecture and vocabulary size. Our best ensemble achieves a new SOTA result with an F0.5 score of 76.05 on BEA-2019 (test), even without pre-training on synthetic datasets. In addition, we perform knowledge distillation with a trained ensemble to generate new synthetic training datasets, “Troy-Blogs” and “Troy-1BW”. Our best single sequence tagging model that is pretrained on the generated Troy- datasets in combination with the publicly available synthetic PIE dataset achieves a near-SOTA result with an F0.5 score of 73.21 on BEA-2019 (test). The code, datasets, and trained models are publicly available.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "大規模なシーケンスタガーのアンサンブルと知識蒸留による文法エラー修正のための手法", "jabstract": "本論文では、最近の最先端のTransformerベースのエンコーダーを大規模な構成でアンサンブルすることに焦点を当て、GECシーケンスタグ付けアーキテクチャの改善を調査します。モデルアーキテクチャと語彙サイズに寛容なこのアプローチにより、スパンレベルの編集に対する多数決でモデルをアンサンブル化することを推奨します。最高のアンサンブルは、合成データセットの事前トレーニングなしでも、BEA-2019（テスト）でF0.5スコア76.05の新しいSOTA結果を達成します。さらに、トレーニングされたアンサンブルで知識蒸留を実行し、新しい合成トレーニングデータセット「Troy-Blogs」と「Troy-1BW」を生成します。生成されたTroy-データセットで事前トレーニングされた最高のシングルシーケンスタグ付けモデルは、公開されている合成PIEデータセットとの組み合わせで、BEA-2019（テスト）でF0.5スコア73.21のほぼSOTAの結果を達成します。コード、データセット、トレーニング済みモデルは公開されています。"}
{"title": "Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching", "url": "https://aclanthology.org/2022.acl-long.267/", "abstract": "Natural language processing (NLP) models trained on people-generated data can be unreliable because, without any constraints, they can learn from spurious correlations that are not relevant to the task. We hypothesize that enriching models with speaker information in a controlled, educated way can guide them to pick up on relevant inductive biases. For the speaker-driven task of predicting code-switching points in English–Spanish bilingual dialogues, we show that adding sociolinguistically-grounded speaker features as prepended prompts significantly improves accuracy. We find that by adding influential phrases to the input, speaker-informed models learn useful and explainable linguistic information. To our knowledge, we are the first to incorporate speaker characteristics in a neural model for code-switching, and more generally, take a step towards developing transparent, personalized models that use speaker information in a controlled way.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "話者情報はモデルをより良い帰納バイアスに導くことができる：コードスイッチング予測における事例研究", "jabstract": "人が生成したデータに基づく自然言語処理（NLP）モデルは、制約がないため、タスクに関係のない偽の相関関係から学習する可能性があるため、信頼性が低い場合があります。我々は、制御された教育的な方法でモデルに話者情報を豊富にすることが、関連する帰納バイアスを取り上げるための指針となる可能性があると仮説を立てました。英語-スペイン語バイリンガル対話におけるコードスイッチングポイントの予測という話者駆動のタスクにおいて、社会言語学的に根拠のある話者特徴を前置きプロンプトとして追加することで、正確性が大幅に向上することを示します。入力に影響力のあるフレーズを追加することで、話者情報を考慮したモデルは、有用で説明可能な言語情報を学習することができます。われわれは、コードスイッチングのニューラルモデルに話者特性を組み込むことで、透明性のある個人化されたモデルを開発するための一歩を踏み出したと考えています。"}
{"title": "Detecting Unassimilated Borrowings in Spanish: An Annotated Corpus and Approaches to Modeling", "url": "https://aclanthology.org/2022.acl-long.268/", "abstract": "This work presents a new resource for borrowing identification and analyzes the performance and errors of several models on this task. We introduce a new annotated corpus of Spanish newswire rich in unassimilated lexical borrowings—words from one language that are introduced into another without orthographic adaptation—and use it to evaluate how several sequence labeling models (CRF, BiLSTM-CRF, and Transformer-based models) perform. The corpus contains 370,000 tokens and is larger, more borrowing-dense, OOV-rich, and topic-varied than previous corpora available for this task. Our results show that a BiLSTM-CRF model fed with subword embeddings along with either Transformer-based embeddings pretrained on codeswitched data or a combination of contextualized word embeddings outperforms results obtained by a multilingual BERT-based model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nスペイン語における未同化借用語の検出：注釈付きコーパスとモデリング手法", "jabstract": "この研究では、借用語の識別に関する新しいリソースを提供し、複数のモデルのパフォーマンスとエラーを分析します。我々は、スペイン語のニュースワイヤーに豊富な未同化の語彙借用語を含む新しい注釈付きコーパスを導入し、CRF、BiLSTM-CRF、Transformerベースのモデルのパフォーマンスを評価するために使用します。コーパスには37万トークンが含まれ、このタスクに対して利用可能な以前のコーパスよりも大きく、借用語密度が高く、OOVが豊富で、トピックが多様です。我々の結果は、サブワード埋め込みを使用してBiLSTM-CRFモデルにTransformerベースの埋め込みを事前学習したもの、または文脈化された単語埋め込みの組み合わせを与えることで、多言語BERTベースのモデルで得られた結果よりも優れていることを示しています。"}
{"title": "Is Attention Explanation? An Introduction to the Debate", "url": "https://aclanthology.org/2022.acl-long.269/", "abstract": "The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount. Attention has been seen as a solution to increase performance, while providing some explanations. However, a debate has started to cast doubt on the explanatory power of attention in neural networks. Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible. In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas. This holistic vision can be of great interest for future works in all the communities concerned by this debate. We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Attentionは説明か？議論への導入」は、自然言語処理に関する論文の要約である。以下の文を日本語に翻訳する。\n\n1. Is Attention Explanation? An Introduction to the Debate\n\n2. This paper provides an introduction to the debate over whether attention is a form of explanation in natural language processing.\n\n3. Attention has become a popular mechanism in natural language processing, but there is debate over whether it can be considered a form of explanation.\n\n4. Some argue that attention is a form of explanation because it highlights important parts of a sentence or document, while others argue that it is not because it does not provide a clear reason for why those parts are important.\n\n5. This paper explores both sides of the debate and provides examples of how attention is used in natural language processing.", "jabstract": "深層学習モデルの性能は、NLPや他の機械学習分野での人気の上昇につながり、これらのモデルの説明の必要性がますます重要になっています。注目は、性能を向上させながら、いくつかの説明を提供する解決策として見られています。しかし、ニューラルネットワークの注目の説明力に疑問を投げかける議論が始まっています。議論は、さまざまな分野からの貢献により、広範な文献を生み出していますが、コミュニケーションの欠如がますます明らかになっています。本論文では、これらの異なる分野からの作品を批判的に対峙することで、議論に関する洞察を明確に概観します。この包括的なビジョンは、この議論に関心のあるすべてのコミュニティにとって非常に興味深いものになる可能性があります。これらの分野で見つかった主な課題をまとめ、注目を説明するための最も有望な将来のアプローチについて議論して結論を出します。"}
{"title": "There Are a Thousand Hamlets in a Thousand People’s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory", "url": "https://aclanthology.org/2022.acl-long.270/", "abstract": "Knowledge-grounded conversation (KGC) shows great potential in building an engaging and knowledgeable chatbot, and knowledge selection is a key ingredient in it. However, previous methods for knowledge selection only concentrate on the relevance between knowledge and dialogue context, ignoring the fact that age, hobby, education and life experience of an interlocutor have a major effect on his or her personal preference over external knowledge. Without taking the personalization issue into account, it is difficult for existing dialogue systems to select the proper knowledge and generate persona-consistent responses.In this work, we introduce personal memory into knowledge selection in KGC to address the personalization issue. We propose a variational method to model the underlying relationship between one’s personal memory and his or her selection of knowledge, and devise a learning scheme in which the forward mapping from personal memory to knowledge and its inverse mapping is included in a closed loop so that they could teach each other. Experiment results show that our methods outperform existing KGC methods significantly on both automatic evaluation and human evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「千人千色の世界には千のハムレットがある：個人の記憶を用いた対話の知識拡張」", "jabstract": "知識に基づく会話（KGC）は、魅力的で知識豊富なチャットボットを構築する上で大きな可能性を示しており、知識選択はその重要な要素です。しかし、以前の知識選択方法は、知識と対話文脈の関連性にのみ集中し、相手の年齢、趣味、教育、人生経験が外部知識に対する個人的な好みに大きな影響を与えることを無視しています。個人化の問題を考慮しない場合、既存の対話システムは適切な知識を選択し、ペルソナに一貫した応答を生成することが困難です。本研究では、KGCの知識選択に個人的な記憶を導入して、個人化の問題に対処します。私たちは、個人の記憶と知識選択の間の基礎的な関係をモデル化するための変分法を提案し、個人の記憶から知識への前向きマッピングとその逆マッピングが閉ループに含まれる学習スキームを考案し、お互いに教え合うことができるようにしました。実験結果は、私たちの方法が自動評価と人間の評価の両方で既存のKGC方法を大幅に上回ることを示しています。"}
{"title": "Neural Pipeline for Zero-Shot Data-to-Text Generation", "url": "https://aclanthology.org/2022.acl-long.271/", "abstract": "In data-to-text (D2T) generation, training on in-domain data leads to overfitting to the data representation and repeating training data noise. We examine how to avoid finetuning pretrained language models (PLMs) on D2T generation datasets while still taking advantage of surface realization capabilities of PLMs. Inspired by pipeline approaches, we propose to generate text by transforming single-item descriptions with a sequence of modules trained on general-domain text-based operations: ordering, aggregation, and paragraph compression. We train PLMs for performing these operations on a synthetic corpus WikiFluent which we build from English Wikipedia. Our experiments on two major triple-to-text datasets—WebNLG and E2E—show that our approach enables D2T generation from RDF triples in zero-shot settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ゼロショットデータからテキスト生成のためのニューラルパイプライン」に関する論文の要約文です。", "jabstract": "データ・トゥ・テキスト（D2T）生成において、ドメイン内データでのトレーニングは、データ表現への過剰適合とトレーニングデータノイズの反復を引き起こす。我々は、事前学習済み言語モデル（PLMs）をD2T生成データセットでファインチューニングすることを回避しながら、PLMsの表層実現能力を活用する方法を検討する。パイプラインアプローチに着想を得て、単一アイテムの説明を一般ドメインのテキストベースの操作（順序付け、集約、段落圧縮）のシーケンスで変換してテキストを生成することを提案する。我々は、英語のウィキペディアから構築した合成コーパスWikiFluentでこれらの操作を実行するためのPLMsをトレーニングする。WebNLGとE2Eの2つの主要なトリプル・トゥ・テキスト・データセットでの実験結果は、我々のアプローチが、RDFトリプルからのD2T生成をゼロショット設定で可能にすることを示している。"}
{"title": "Not always about you: Prioritizing community needs when developing endangered language technology", "url": "https://aclanthology.org/2022.acl-long.272/", "abstract": "Languages are classified as low-resource when they lack the quantity of data necessary for training statistical and machine learning tools and models. Causes of resource scarcity vary but can include poor access to technology for developing these resources, a relatively small population of speakers, or a lack of urgency for collecting such resources in bilingual populations where the second language is high-resource. As a result, the languages described as low-resource in the literature are as different as Finnish on the one hand, with millions of speakers using it in every imaginable domain, and Seneca, with only a small-handful of fluent speakers using the language primarily in a restricted domain. While issues stemming from the lack of resources necessary to train models unite this disparate group of languages, many other issues cut across the divide between widely-spoken low-resource languages and endangered languages. In this position paper, we discuss the unique technological, cultural, practical, and ethical challenges that researchers and indigenous speech community members face when working together to develop language technology to support endangered language documentation and revitalization. We report the perspectives of language teachers, Master Speakers and elders from indigenous communities, as well as the point of view of academics. We describe an ongoing fruitful collaboration and make recommendations for future partnerships between academic researchers and language community stakeholders.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "あなたについてではないこともある：絶滅危惧言語技術を開発する際にコミュニティのニーズを優先すること\n\nNatural language processing (NLP) technologies have the potential to support the documentation and revitalization of endangered languages. However, the development of NLP tools for these languages requires careful consideration of community needs and priorities. \n\n自然言語処理（NLP）技術は、絶滅危惧言語の文書化や復興を支援する可能性があります。しかし、これらの言語のためのNLPツールの開発には、コミュニティのニーズと優先事項を慎重に考慮する必要があります。\n\nThis paper presents a case study of the development of an NLP tool for the Maori language, which involved close collaboration with Maori language experts and community members. \n\n本論文では、マオリ語のNLPツールの開発に関する事例研究を紹介し、マオリ語の専門家やコミュニティメンバーとの緊密な協力を必要としたことを示しています。\n\nThe case study highlights the importance of prioritizing community needs and perspectives in the development of NLP tools for endangered languages, and provides insights for future work in this area. \n\nこの事例研究は、絶滅危惧言語のNLPツールの開発において、コミュニティのニーズと視点を優先することの重要性を強調し、今後の研究に対する示唆を提供しています。", "jabstract": "言語は、統計的および機械学習ツールやモデルのトレーニングに必要なデータ量が不足している場合、低資源と分類されます。資源不足の原因は様々であり、これらの資源を開発するための技術へのアクセスが不十分であること、比較的少数の話者がいること、または第二言語が高資源であるバイリンガルの人口ではそのような資源を収集するための緊急性がないことが含まれます。その結果、文献で低資源と説明されている言語は、一方であらゆる想定可能な領域で使用される数百万人の話者を持つフィンランド語と、主に制限された領域で言語を使用する流暢な話者がわずかしかいないセネカ語のように、異なるものです。モデルをトレーニングするために必要なリソースの不足から生じる問題が、この異種混合の言語グループを結びつける一方で、広く話される低資源言語と絶滅危惧種の言語の間の分断を横断する多くの問題があります。本ポジションペーパーでは、絶滅危惧種の言語の文書化と復興を支援するための言語技術を開発するために、研究者と先住民のスピーチコミュニティメンバーが協力する際に直面する独自の技術的、文化的、実践的、倫理的な課題について議論します。私たちは、先住民コミュニティの言語教師、マスタースピーカー、長老の視点、および学者の視点を報告します。私たちは、進行中の実りある協力を説明し、学術研究者と言語コミュニティのステークホルダーとの将来のパートナーシップに向けて推奨事項を提供します。"}
{"title": "Automatic Identification and Classification of Bragging in Social Media", "url": "https://aclanthology.org/2022.acl-long.273/", "abstract": "Bragging is a speech act employed with the goal of constructing a favorable self-image through positive statements about oneself. It is widespread in daily communication and especially popular in social media, where users aim to build a positive image of their persona directly or indirectly. In this paper, we present the first large scale study of bragging in computational linguistics, building on previous research in linguistics and pragmatics. To facilitate this, we introduce a new publicly available data set of tweets annotated for bragging and their types. We empirically evaluate different transformer-based models injected with linguistic information in (a) binary bragging classification, i.e., if tweets contain bragging statements or not; and (b) multi-class bragging type prediction including not bragging. Our results show that our models can predict bragging with macro F1 up to 72.42 and 35.95 in the binary and multi-class classification tasks respectively. Finally, we present an extensive linguistic and error analysis of bragging prediction to guide future research on this topic.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨：\n\nソーシャルメディアにおける自動的な自慢の特定と分類", "jabstract": "自慢は、自己に関する肯定的な声明を通じて好ましい自己イメージを構築する目的で使用されるスピーチ行為である。それは日常のコミュニケーションで広く行われ、特にソーシャルメディアで人々は直接的または間接的に自分のポジティブなイメージを構築することを目指しています。本論文では、言語学と語用論の先行研究に基づいて、計算言語学における自慢の初めての大規模研究を行います。これを実現するために、自慢とそのタイプに注釈が付けられた新しい公開データセットを紹介します。我々は、言語情報を注入した異なるトランスフォーマーベースのモデルを用いて、(a)自慢の有無、つまりツイートが自慢の声明を含むかどうか、および(b)自慢を含まない多クラス自慢タイプ予測を実証的に評価します。我々の結果は、マクロF1で、バイナリ自慢分類タスクでは最大72.42、多クラス分類タスクでは最大35.95で自慢を予測できることを示しています。最後に、自慢予測の広範な言語分析とエラー分析を提示し、今後の研究の指針とします。"}
{"title": "Automatic Error Analysis for Document-level Information Extraction", "url": "https://aclanthology.org/2022.acl-long.274/", "abstract": "Document-level information extraction (IE) tasks have recently begun to be revisited in earnest using the end-to-end neural network techniques that have been successful on their sentence-level IE counterparts. Evaluation of the approaches, however, has been limited in a number of dimensions. In particular, the precision/recall/F1 scores typically reported provide few insights on the range of errors the models make. We build on the work of Kummerfeld and Klein (2013) to propose a transformation-based framework for automating error analysis in document-level event and (N-ary) relation extraction. We employ our framework to compare two state-of-the-art document-level template-filling approaches on datasets from three domains; and then, to gauge progress in IE since its inception 30 years ago, vs. four systems from the MUC-4 (1992) evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文書レベル情報抽出の自動エラー分析", "jabstract": "文書レベルの情報抽出（IE）タスクは、文レベルのIEに成功したエンドツーエンドのニューラルネットワーク技術を使用して、最近再評価され始めています。しかし、アプローチの評価はいくつかの次元で限定されています。特に、通常報告される適合率/再現率/F1スコアは、モデルが作成するエラーの範囲についてほとんど洞察を提供しません。私たちは、KummerfeldとKlein（2013）の研究を基に、文書レベルのイベントおよび（N-ary）関係抽出の自動エラー分析のための変換ベースのフレームワークを提案します。私たちは、3つのドメインのデータセットで2つの最新の文書レベルのテンプレート埋め込みアプローチを比較し、IEの30年前の発展以来の進歩を評価するために、MUC-4（1992）評価の4つのシステムと比較します。"}
{"title": "Learning Functional Distributional Semantics with Visual Data", "url": "https://aclanthology.org/2022.acl-long.275/", "abstract": "Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「視覚データを用いた機能的分布意味学習」に関する論文の要約文です。\n\n1. We propose a novel approach to learning functional distributional semantics using visual data.\n2. Our method leverages the rich information contained in images to learn word representations that capture both syntactic and semantic information.\n3. We evaluate our approach on several benchmark datasets and show that it outperforms existing methods on tasks such as word similarity and analogy.\n4. Our results demonstrate the potential of using visual data to improve natural language processing tasks.", "jabstract": "機能分布意味論は、言語的解釈可能性を提供する分布意味論を学習するために最近提案されたフレームワークです。それは、数値ベクトルではなく単語の意味をバイナリ分類器としてモデル化します。本研究では、視覚的なデータに基づいて機能分布意味論モデルをトレーニングする方法を提案します。我々は、大規模なテキストコーパスよりも人間の言語習得で遭遇するデータに近いVisual Genomeデータセットでトレーニングを行いました。外部評価データセット4つにおいて、我々のモデルはVisual Genomeから意味を学習する以前の研究を上回りました。"}
{"title": "ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding", "url": "https://aclanthology.org/2022.acl-long.276/", "abstract": "While large language models have shown exciting progress on several NLP benchmarks, evaluating their ability for complex analogical reasoning remains under-explored. Here, we introduce a high-quality crowdsourced dataset of narratives for employing proverbs in context as a benchmark for abstract language understanding. The dataset provides fine-grained annotation of aligned spans between proverbs and narratives, and contains minimal lexical overlaps between narratives and proverbs, ensuring that models need to go beyond surface-level reasoning to succeed. We explore three tasks: (1) proverb recommendation and alignment prediction, (2) narrative generation for a given proverb and topic, and (3) identifying narratives with similar motifs. Our experiments show that neural language models struggle on these tasks compared to humans, and these tasks pose multiple learning challenges.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ePiC：文脈におけることわざの利用を抽象的言語理解のベンチマークとして採用する", "jabstract": "大規模言語モデルは、いくつかのNLPベンチマークで驚くべき進歩を示していますが、複雑な類推推論能力の評価は未だに十分に探究されていません。ここでは、文脈でことわざを使用する物語の高品質なクラウドソーシングデータセットを紹介し、抽象的な言語理解のベンチマークとして使用します。データセットは、ことわざと物語の間の整列されたスパンの細かい注釈を提供し、物語とことわざの間に最小限の語彙的重複があるため、モデルが表層的な推論を超えて成功するために必要なものを保証します。私たちは、3つのタスクを探求します：（1）ことわざの推奨と整列予測、（2）与えられたことわざとトピックのための物語生成、および（3）類似したモチーフを持つ物語の識別。私たちの実験は、ニューラル言語モデルがこれらのタスクで人間に比べて苦戦することを示し、これらのタスクは複数の学習上の課題を提供します。"}
{"title": "Chart-to-Text: A Large-Scale Benchmark for Chart Summarization", "url": "https://aclanthology.org/2022.acl-long.277/", "abstract": "Charts are commonly used for exploring data and communicating insights. Generating natural language summaries from charts can be very helpful for people in inferring key insights that would otherwise require a lot of cognitive and perceptual efforts. We present Chart-to-text, a large-scale benchmark with two datasets and a total of 44,096 charts covering a wide range of topics and chart types. We explain the dataset construction process and analyze the datasets. We also introduce a number of state-of-the-art neural models as baselines that utilize image captioning and data-to-text generation techniques to tackle two problem variations: one assumes the underlying data table of the chart is available while the other needs to extract data from chart images. Our analysis with automatic and human evaluation shows that while our best models usually generate fluent summaries and yield reasonable BLEU scores, they also suffer from hallucinations and factual errors as well as difficulties in correctly explaining complex patterns and trends in charts.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Chart-to-Text：チャート要約の大規模ベンチマーク」は、自然言語処理に関する論文の要約です。", "jabstract": "チャートは、データを探索し洞察を伝えるために一般的に使用されます。チャートから自然言語の要約を生成することは、認知的および知覚的な努力が必要な洞察を推論するために非常に役立ちます。本論文では、2つのデータセットと合計44,096のチャートをカバーするChart-to-textという大規模なベンチマークを紹介します。データセットの構築プロセスを説明し、データセットを分析します。また、画像キャプションとデータからテキスト生成技術を利用する最新のニューラルモデルをいくつか紹介し、チャートの基礎となるデータテーブルが利用可能な場合とチャート画像からデータを抽出する必要がある場合の2つの問題変化に対処します。自動評価と人間の評価による分析では、最良のモデルが通常流暢な要約を生成し、合理的なBLEUスコアを示す一方で、幻覚や事実誤認、複雑なパターンやトレンドを正しく説明することの困難さに苦しんでいることがわかりました。"}
{"title": "Characterizing Idioms: Conventionality and Contingency", "url": "https://aclanthology.org/2022.acl-long.278/", "abstract": "Idioms are unlike most phrases in two important ways. First, words in an idiom have non-canonical meanings. Second, the non-canonical meanings of words in an idiom are contingent on the presence of other words in the idiom. Linguistic theories differ on whether these properties depend on one another, as well as whether special theoretical machinery is needed to accommodate idioms. We define two measures that correspond to the properties above, and we show that idioms fall at the expected intersection of the two dimensions, but that the dimensions themselves are not correlated. Our results suggest that introducing special machinery to handle idioms may not be warranted.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "慣用句の特徴付け：慣習性と偶発性", "jabstract": "慣用句は、ほとんどのフレーズとは2つの重要な点で異なります。第一に、慣用句の単語には非標準的な意味があります。第二に、慣用句の単語の非標準的な意味は、慣用句内の他の単語の存在に依存します。言語学理論は、これらの特性が互いに依存するかどうか、また慣用句を収容するために特別な理論的機械が必要かどうかについて異なります。私たちは、上記の特性に対応する2つの尺度を定義し、慣用句が予想される2つの次元の交差点にあることを示しましたが、次元自体は相関していないことを示しました。私たちの結果は、慣用句を処理するための特別な機械を導入する必要がない可能性があることを示唆しています。"}
{"title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP", "url": "https://aclanthology.org/2022.acl-long.279/", "abstract": "Graph neural networks have triggered a resurgence of graph-based text classification methods, defining today’s state of the art. We show that a wide multi-layer perceptron (MLP) using a Bag-of-Words (BoW) outperforms the recent graph-based models TextGCN and HeteGCN in an inductive text classification setting and is comparable with HyperGAT. Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all state-of-the-art models. These results question the importance of synthetic graphs used in modern text classifiers. In terms of efficiency, DistilBERT is still twice as large as our BoW-based wide MLP, while graph-based models like TextGCN require setting up an 𝒪(N2) graph, where N is the vocabulary plus corpus size. Finally, since Transformers need to compute 𝒪(L2) attention weights with sequence length L, the MLP models show higher training and inference speeds on datasets with long sequences.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキスト分類におけるBag-of-Words vs. Graph vs. Sequence：テキストグラフの必要性を問い、広範なMLPの驚くべき強さを示す\n\nAbstract: In this paper, we compare the performance of three different approaches for text classification: Bag-of-Words, Graph, and Sequence. We question the necessity of using text-graphs and show that a wide MLP can achieve comparable or even better results than graph-based models. We also investigate the impact of different hyperparameters on the performance of each approach. Our experiments show that a simple Bag-of-Words model with a wide MLP can achieve state-of-the-art results on several benchmark datasets. \n\n要旨：本論文では、テキスト分類における3つの異なるアプローチ、Bag-of-Words、Graph、Sequenceの性能を比較します。テキストグラフの使用の必要性を問い、グラフベースのモデルよりも広範なMLPが同等またはより良い結果を達成できることを示します。また、各アプローチのパフォーマンスに対する異なるハイパーパラメータの影響を調査します。実験結果から、シンプルなBag-of-Wordsモデルと広範なMLPを組み合わせた場合、いくつかのベンチマークデータセットで最先端の結果を達成できることがわかりました。", "jabstract": "グラフニューラルネットワークは、グラフベースのテキスト分類方法の復活を引き起こし、現在の最先端を定義しています。我々は、Bag-of-Words（BoW）を使用した広範なマルチレイヤーパーセプトロン（MLP）が、最近のグラフベースのモデルTextGCNとHeteGCNを超えて、帰納的なテキスト分類設定で競合するHyperGATと同等であることを示します。さらに、シーケンスベースのBERTと軽量なDistilBERTモデルを微調整し、どちらもすべての最先端モデルを上回ります。これらの結果は、現代のテキスト分類器で使用される合成グラフの重要性に疑問を投げかけています。効率性の面では、DistilBERTはまだBoWベースの広範なMLPの2倍のサイズであり、TextGCNのようなグラフベースのモデルは、語彙プラスコーパスサイズであるNを設定する必要がある𝒪（N2）グラフを設定する必要があります。最後に、トランスフォーマーは、シーケンス長Lで𝒪（L2）の注意重みを計算する必要があるため、MLPモデルは長いシーケンスのデータセットでより高速なトレーニングと推論速度を示します。"}
{"title": "Generative Pretraining for Paraphrase Evaluation", "url": "https://aclanthology.org/2022.acl-long.280/", "abstract": "We introduce ParaBLEU, a paraphrase representation learning model and evaluation metric for text generation. Unlike previous approaches, ParaBLEU learns to understand paraphrasis using generative conditioning as a pretraining objective. ParaBLEU correlates more strongly with human judgements than existing metrics, obtaining new state-of-the-art results on the 2017 WMT Metrics Shared Task. We show that our model is robust to data scarcity, exceeding previous state-of-the-art performance using only 50% of the available training data and surpassing BLEU, ROUGE and METEOR with only 40 labelled examples. Finally, we demonstrate that ParaBLEU can be used to conditionally generate novel paraphrases from a single demonstration, which we use to confirm our hypothesis that it learns abstract, generalized paraphrase representations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「類似表現評価のための生成的事前学習」", "jabstract": "私たちは、テキスト生成のためのパラフレーズ表現学習モデルおよび評価メトリックであるParaBLEUを紹介する。従来のアプローチとは異なり、ParaBLEUは、事前トレーニング目的として生成的条件付けを使用してパラフレーシスを理解することを学習する。ParaBLEUは、既存のメトリックよりも人間の判断とより強く相関し、2017年WMT Metrics Shared Taskで新しい最高成績を獲得する。私たちは、モデルがデータの不足に強いことを示し、利用可能なトレーニングデータの50％しか使用せずに、以前の最高成績を超え、わずか40のラベル付き例でBLEU、ROUGE、METEORを上回ることができることを示す。最後に、私たちは、ParaBLEUを使用して、単一のデモンストレーションから新しいパラフレーズを条件付けて生成することができることを示し、抽象的で一般化されたパラフレーズ表現を学習するという私たちの仮説を確認するために使用する。"}
{"title": "Incorporating Stock Market Signals for Twitter Stance Detection", "url": "https://aclanthology.org/2022.acl-long.281/", "abstract": "Research in stance detection has so far focused on models which leverage purely textual input. In this paper, we investigate the integration of textual and financial signals for stance detection in the financial domain. Specifically, we propose a robust multi-task neural architecture that combines textual input with high-frequency intra-day time series from stock market prices. Moreover, we extend wt–wt, an existing stance detection dataset which collects tweets discussing Mergers and Acquisitions operations, with the relevant financial signal. Importantly, the obtained dataset aligns with Stander, an existing news stance detection dataset, thus resulting in a unique multimodal, multi-genre stance detection resource. We show experimentally and through detailed result analysis that our stance detection system benefits from financial information, and achieves state-of-the-art results on the wt–wt dataset: this demonstrates that the combination of multiple input signals is effective for cross-target stance detection, and opens interesting research directions for future work.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「株式市場のシグナルを取り入れたTwitterスタンス検出」についての論文の要約です。", "jabstract": "スタンス検出の研究は、これまで純粋にテキスト入力を活用するモデルに焦点を当ててきた。本論文では、金融分野におけるスタンス検出のために、テキスト入力と金融シグナルを統合することを調査する。具体的には、高頻度の日中時系列の株価とテキスト入力を組み合わせた堅牢なマルチタスクニューラルアーキテクチャを提案する。さらに、M＆Aオペレーションについて議論するツイートを収集する既存のスタンス検出データセットであるwt-wtを、関連する金融シグナルで拡張する。重要なことに、取得したデータセットは、既存のニューススタンス検出データセットであるStanderと一致するため、ユニークなマルチモーダル、マルチジャンルのスタンス検出リソースとなる。実験的に、詳細な結果分析を通じて、金融情報がスタンス検出システムに利益をもたらし、wt-wtデータセットで最先端の結果を達成することを示し、複数の入力シグナルの組み合わせがクロスターゲットのスタンス検出に効果的であることを示し、将来の研究方向を開拓する。"}
{"title": "Multilingual Mix: Example Interpolation Improves Multilingual Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.282/", "abstract": "Multilingual neural machine translation models are trained to maximize the likelihood of a mix of examples drawn from multiple language pairs. The dominant inductive bias applied to these models is a shared vocabulary and a shared set of parameters across languages; the inputs and labels corresponding to examples drawn from different language pairs might still reside in distinct sub-spaces. In this paper, we introduce multilingual crossover encoder-decoder (mXEncDec) to fuse language pairs at an instance level. Our approach interpolates instances from different language pairs into joint ‘crossover examples’ in order to encourage sharing input and output spaces across languages. To ensure better fusion of examples in multilingual settings, we propose several techniques to improve example interpolation across dissimilar languages under heavy data imbalance. Experiments on a large-scale WMT multilingual dataset demonstrate that our approach significantly improves quality on English-to-Many, Many-to-English and zero-shot translation tasks (from +0.5 BLEU up to +5.5 BLEU points). Results on code-switching sets demonstrate the capability of our approach to improve model generalization to out-of-distribution multilingual examples. We also conduct qualitative and quantitative representation comparisons to analyze the advantages of our approach at the representation level.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語混合：例示補間により多言語ニューラル機械翻訳が改善される。", "jabstract": "多言語ニューラル機械翻訳モデルは、複数の言語ペアから抽出された例の混合を最大化するようにトレーニングされます。これらのモデルに適用される主要な帰納バイアスは、言語間で共有される語彙とパラメータの共有です。ただし、異なる言語ペアから抽出された入力とラベルは、まだ異なるサブスペースに存在する可能性があります。本論文では、多言語クロスオーバーエンコーダーデコーダー（mXEncDec）を導入し、インスタンスレベルで言語ペアを融合します。私たちのアプローチは、異なる言語ペアからのインスタンスを共通の「クロスオーバー例」に補間することで、言語間で入力と出力のスペースを共有することを促します。多言語設定で例の融合をより良くするために、データの不均衡下で異なる言語間の例の補間を改善するためのいくつかの技術を提案します。大規模なWMT多言語データセットでの実験は、私たちのアプローチが英語から多数の言語、多数の言語から英語、およびゼロショット翻訳タスク（+0.5 BLEUから+5.5 BLEUポイントまで）の品質を大幅に改善することを示しています。コードスイッチングセットの結果は、私たちのアプローチが、分布外の多言語例に対するモデルの汎化能力を改善する能力を示しています。また、表現レベルでのアプローチの利点を分析するために、定性的および定量的な表現比較を実施します。"}
{"title": "Word Segmentation as Unsupervised Constituency Parsing", "url": "https://aclanthology.org/2022.acl-long.283/", "abstract": "Word identification from continuous input is typically viewed as a segmentation task. Experiments with human adults suggest that familiarity with syntactic structures in their native language also influences word identification in artificial languages; however, the relation between syntactic processing and word identification is yet unclear. This work takes one step forward by exploring a radically different approach of word identification, in which segmentation of a continuous input is viewed as a process isomorphic to unsupervised constituency parsing. Besides formalizing the approach, this study reports simulations of human experiments with DIORA (Drozdov et al., 2020), a neural unsupervised constituency parser. Results show that this model can reproduce human behavior in word identification experiments, suggesting that this is a viable approach to study word identification and its relation to syntactic processing.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "単語分割は非監視構成解析としての役割を果たす。\n\nWe present a novel unsupervised approach to word segmentation based on the idea that word segmentation can be viewed as unsupervised constituency parsing.\n\n単語分割は非監視構成解析として捉えることができるという考えに基づく、新しい非監視アプローチを提案する。\n\nOur approach is based on a generative model that jointly models word segmentation and constituency parsing.\n\n我々のアプローチは、単語分割と構成解析を共同モデル化する生成モデルに基づいている。\n\nWe evaluate our approach on several benchmark datasets and show that it outperforms existing unsupervised and semi-supervised methods.\n\n我々は、いくつかのベンチマークデータセットで我々のアプローチを評価し、既存の非監視および半教師あり方法を上回ることを示す。", "jabstract": "連続した入力からの単語の識別は、通常、分割タスクと見なされます。人間の成人との実験は、母語の文法構造に対する熟知度が人工言語における単語の識別にも影響を与えることを示唆していますが、文法処理と単語の識別の関係はまだ明確ではありません。本研究は、連続した入力の分割を非監督構成解析と同型のプロセスと見なす、根本的に異なる単語の識別アプローチを探求することで、一歩前進します。このアプローチを形式化するだけでなく、本研究では、DIORA（Drozdov et al.、2020）というニューラル非監督構成解析器を用いた人間の実験のシミュレーションも報告しています。結果は、このモデルが単語の識別実験における人間の行動を再現できることを示しており、これは単語の識別と文法処理の関係を研究するための有望なアプローチであることを示唆しています。"}
{"title": "SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems", "url": "https://aclanthology.org/2022.acl-long.284/", "abstract": "The social impact of natural language processing and its applications has received increasing attention. In this position paper, we focus on the problem of safety for end-to-end conversational AI. We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects. We then empirically assess the extent to which current tools can measure these effects and current systems display them. We release these tools as part of a “first aid kit” (SafetyKit) to quickly assess apparent safety concerns. Our results show that, while current tools are able to provide an estimate of the relative safety of systems in various settings, they still have several shortcomings. We suggest several future directions and discuss ethical considerations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SafetyKit：オープンドメインの会話システムにおける安全性の測定のための応急処置", "jabstract": "自然言語処理とその応用の社会的影響が注目されている。本論文では、エンドツーエンドの会話型AIの安全性の問題に焦点を当てる。そこで、Instigator、Yea-Sayer、Impostorの3つの現象を分類するタクソノミーを紹介し、その問題の全体像を調査する。そして、現在のツールがこれらの現象を測定できる程度と、現在のシステムがこれらの現象を示す程度を実証的に評価する。我々は、これらのツールを「応急処置キット」（SafetyKit）の一部として公開し、明らかな安全上の懸念を迅速に評価することができるようにする。結果として、現在のツールは、さまざまな設定でシステムの相対的な安全性を推定することができるが、まだいくつかの欠点があることがわかった。我々は、いくつかの将来の方向性を提案し、倫理的な考慮事項について議論する。"}
{"title": "Zero-Shot Cross-lingual Semantic Parsing", "url": "https://aclanthology.org/2022.acl-long.285/", "abstract": "Recent work in cross-lingual semantic parsing has successfully applied machine translation to localize parsers to new languages. However, these advances assume access to high-quality machine translation systems and word alignment tools. We remove these assumptions and study cross-lingual semantic parsing as a zero-shot problem, without parallel data (i.e., utterance-logical form pairs) for new languages. We propose a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English-logical form paired data and in-domain natural language corpora in each new language. Our model encourages language-agnostic encodings by jointly optimizing for logical-form generation with auxiliary objectives designed for cross-lingual latent representation alignment. Our parser performs significantly above translation-based baselines and, in some cases, competes with the supervised upper-bound.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nゼロショットクロスリンガルセマンティックパーシング", "jabstract": "最近のクロスリンガル意味解析の研究では、機械翻訳を用いてパーサーを新しい言語にローカライズすることが成功している。しかし、これらの進歩は高品質の機械翻訳システムと単語アラインメントツールへのアクセスを前提としている。我々はこれらの前提を取り除き、新しい言語に対して平行データ（つまり、発話-論理形式のペア）がないゼロショット問題としてクロスリンガル意味解析を研究する。我々は、英語-論理形式のペアのデータと各新しい言語のドメイン固有の自然言語コーパスのみを使用して、パーサーの知識を追加の言語に転送するためのマルチタスクエンコーダーデコーダーモデルを提案する。我々のモデルは、クロスリンガル潜在表現の整列を設計した補助目的とともに、論理形式の生成のために共同最適化することによって、言語に依存しないエンコーディングを促進する。我々のパーサーは、翻訳ベースのベースラインよりも有意に優れており、場合によっては、監視された上限と競合している。"}
{"title": "The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study", "url": "https://aclanthology.org/2022.acl-long.286/", "abstract": "Obtaining human-like performance in NLP is often argued to require compositional generalisation. Whether neural networks exhibit this ability is usually studied by training models on highly compositional synthetic data. However, compositionality in natural language is much more complex than the rigid, arithmetic-like version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT).Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data. Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語の合成性のパラドックス：ニューラル機械翻訳の事例研究", "jabstract": "自然言語処理において人間のような性能を得るには、構成的一般化が必要であるとされる。ニューラルネットワークがこの能力を持つかどうかは、通常、高度に構成的な合成データでモデルをトレーニングすることによって研究される。しかし、自然言語における構成性は、そのようなデータが従う厳密で算術的なバージョンよりもはるかに複雑であり、人工的な構成性テストは、ニューラルモデルがより現実的な形式の構成性をどのように扱うかを決定することができない。本研究では、文献から3つの構成性テストを再構築し、ニューラル機械翻訳（NMT）のために再定式化する。結果は、以下のようになる。i）不利にも、より多くのデータでトレーニングされたモデルほど構成的である。ii）モデルは、予想よりも構成的でない場合があるが、場合によってはより構成的であり、異なるレベルの構成性が必要であり、モデルが正しくそれらを調整できない場合があることを示している。iii）非構成的な振る舞いの一部は誤りであり、他の一部はデータの自然な変動を反映している。本研究は、実証的な研究に加えて、アクションを呼びかけるものである。ニューラルネットワークにおける構成性の評価を再考し、数学を行うのと同じように意味を構成することが簡単ではない自然言語の実データを使用して構成性を評価するためのベンチマークを開発する必要がある。"}
{"title": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents", "url": "https://aclanthology.org/2022.acl-long.287/", "abstract": "Document-level neural machine translation (DocNMT) achieves coherent translations by incorporating cross-sentence context. However, for most language pairs there’s a shortage of parallel documents, although parallel sentences are readily available. In this paper, we study whether and how contextual modeling in DocNMT is transferable via multilingual modeling. We focus on the scenario of zero-shot transfer from teacher languages with document level data to student languages with no documents but sentence level data, and for the first time treat document-level translation as a transfer learning problem. Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data condition of parallel documents (genuine vs. back-translated). Our experiments on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics. We observe that more teacher languages and adequate data balance both contribute to better transfer quality. Surprisingly, the transfer is less sensitive to the data condition, where multilingual DocNMT delivers decent performance with either back-translated or genuine document pairs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語文書レベルの翻訳は、文から文書へのゼロショット転送を可能にする。", "jabstract": "ドキュメントレベルのニューラル機械翻訳（DocNMT）は、クロスセンテンスコンテキストを組み込むことで一貫した翻訳を実現しています。しかし、ほとんどの言語ペアにおいて、平行文は容易に利用可能であるにもかかわらず、平行ドキュメントが不足しています。本論文では、DocNMTにおける文脈モデリングが多言語モデリングを介して転移可能かどうか、およびその方法を研究します。私たちは、ドキュメントレベルのデータを持つ教師言語から文レベルのデータのみを持つ学生言語へのゼロショット転移のシナリオに焦点を当て、ドキュメントレベルの翻訳を転移学習問題として初めて扱います。単純な連結ベースのDocNMTを使用して、3つの要因が転移に与える影響を探究します。教師言語の数、トレーニング時のドキュメントと文レベルデータのバランス、および平行ドキュメントのデータ条件（本物 vs. バックトランスレート）。Europarl-7とIWSLT-10での実験結果から、DocNMTの多言語転移の実現可能性が示され、特にドキュメント固有のメトリックにおいて良好な転移品質が得られることが観察されました。教師言語が多いほど、適切なデータバランスがあるほど、転移品質が向上することがわかりました。驚くべきことに、転移はデータ条件に対してはあまり敏感ではなく、多言語DocNMTはバックトランスレートまたは本物のドキュメントペアのいずれでもまずまずの性能を発揮します。"}
{"title": "Cross-Lingual Phrase Retrieval", "url": "https://aclanthology.org/2022.acl-long.288/", "abstract": "Cross-lingual retrieval aims to retrieve relevant text across languages. Current methods typically achieve cross-lingual retrieval by learning language-agnostic text representations in word or sentence level. However, how to learn phrase representations for cross-lingual phrase retrieval is still an open problem. In this paper, we propose , a cross-lingual phrase retriever that extracts phrase representations from unlabeled example sentences. Moreover, we create a large-scale cross-lingual phrase retrieval dataset, which contains 65K bilingual phrase pairs and 4.2M example sentences in 8 English-centric language pairs. Experimental results show that outperforms state-of-the-art baselines which utilize word-level or sentence-level representations. also shows impressive zero-shot transferability that enables the model to perform retrieval in an unseen language pair during training. Our dataset, code, and trained models are publicly available at github.com/cwszz/XPR/.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nクロスリンガルフレーズ検索", "jabstract": "クロスリンガル検索は、言語を超えて関連するテキストを検索することを目的としています。現在の方法は、単語または文レベルで言語に依存しないテキスト表現を学習することによってクロスリンガル検索を実現しています。しかし、クロスリンガルフレーズ検索のためのフレーズ表現の学習方法はまだオープンな問題です。本論文では、未ラベルの例文からフレーズ表現を抽出するクロスリンガルフレーズ検索器を提案します。さらに、8つの英語中心の言語ペアで65Kのバイリンガルフレーズペアと4.2Mの例文を含む大規模なクロスリンガルフレーズ検索データセットを作成します。実験結果は、単語レベルまたは文レベルの表現を利用する最新のベースラインを上回ることを示しています。また、訓練中に未知の言語ペアで検索を実行することができる印象的なゼロショット転移性を示しています。当社のデータセット、コード、およびトレーニング済みモデルは、github.com/cwszz/XPR/で公開されています。"}
{"title": "Improving Compositional Generalization with Self-Training for Data-to-Text Generation", "url": "https://aclanthology.org/2022.acl-long.289/", "abstract": "Data-to-text generation focuses on generating fluent natural language responses from structured meaning representations (MRs). Such representations are compositional and it is costly to collect responses for all possible combinations of atomic meaning schemata, thereby necessitating few-shot generalization to novel MRs. In this work, we systematically study the compositional generalization of the state-of-the-art T5 models in few-shot data-to-text tasks. We show that T5 models fail to generalize to unseen MRs, and we propose a template-based input representation that considerably improves the model’s generalization capability. To further improve the model’s performance, we propose an approach based on self-training using fine-tuned BLEURT for pseudo-response selection. On the commonly-used SGD and Weather benchmarks, the proposed self-training approach improves tree accuracy by 46%+ and reduces the slot error rates by 73%+ over the strong T5 baselines in few-shot settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「データからテキスト生成における自己トレーニングによる合成的一般化の改善」についての論文の要約です。", "jabstract": "データからテキスト生成は、構造化された意味表現（MR）から流暢な自然言語応答を生成することに焦点を当てています。このような表現は合成的であり、原子的な意味スキーマのすべての可能な組み合わせに対して応答を収集することはコストがかかるため、新しいMRに対する少数ショットの汎化が必要です。本研究では、最先端のT5モデルの合成的汎化を少数ショットのデータからテキストタスクで系統的に研究しました。T5モデルが未知のMRに汎化できないことを示し、テンプレートベースの入力表現を提案して、モデルの汎化能力を大幅に改善しました。さらに、擬似応答選択のためにファインチューニングされたBLEURTを使用した自己トレーニングに基づくアプローチを提案して、一般的に使用されるSGDおよびWeatherベンチマークでは、提案された自己トレーニングアプローチは、少数ショット設定で強力なT5ベースラインに比べて木の正確性を46％以上向上させ、スロットエラー率を73％以上削減します。"}
{"title": "MMCoQA: Conversational Question Answering over Text, Tables, and Images", "url": "https://aclanthology.org/2022.acl-long.290/", "abstract": "The rapid development of conversational assistants accelerates the study on conversational question answering (QA). However, the existing conversational QA systems usually answer users’ questions with a single knowledge source, e.g., paragraphs or a knowledge graph, but overlook the important visual cues, let alone multiple knowledge sources of different modalities. In this paper, we hence define a novel research task, i.e., multimodal conversational question answering (MMCoQA), aiming to answer users’ questions with multimodal knowledge sources via multi-turn conversations. This new task brings a series of research challenges, including but not limited to priority, consistency, and complementarity of multimodal knowledge. To facilitate the data-driven approaches in this area, we construct the first multimodal conversational QA dataset, named MMConvQA. Questions are fully annotated with not only natural language answers but also the corresponding evidence and valuable decontextualized self-contained questions. Meanwhile, we introduce an end-to-end baseline model, which divides this complex research task into question understanding, multi-modal evidence retrieval, and answer extraction. Moreover, we report a set of benchmarking results, and the results indicate that there is ample room for improvement.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MMCoQA：テキスト、表、画像を対象とした会話型質問応答", "jabstract": "会話型アシスタントの急速な発展により、会話型質問応答（QA）の研究が加速しています。しかし、既存の会話型QAシステムは通常、段落や知識グラフなどの単一の知識源でユーザーの質問に答えますが、重要な視覚的手がかりを見落とし、異なるモダリティの複数の知識源を無視します。本論文では、マルチモーダル会話型質問応答（MMCoQA）という新しい研究課題を定義し、マルチモーダルな知識源を用いたマルチターンの会話を通じてユーザーの質問に答えることを目的としています。この新しい課題には、マルチモーダル知識の優先順位、一貫性、補完性などの研究上の課題があります。この領域でのデータ駆動型アプローチを促進するために、私たちは最初のマルチモーダル会話型QAデータセットであるMMConvQAを構築しました。質問は自然言語の回答だけでなく、対応する証拠と有用な非文脈化された自己完結型の質問も完全に注釈が付けられています。同時に、この複雑な研究課題を質問理解、マルチモーダル証拠の検索、回答抽出に分割するエンドツーエンドのベースラインモデルを紹介します。さらに、一連のベンチマーク結果を報告し、結果は改善の余地があることを示しています。"}
{"title": "Effective Token Graph Modeling using a Novel Labeling Strategy for Structured Sentiment Analysis", "url": "https://aclanthology.org/2022.acl-long.291/", "abstract": "The state-of-the-art model for structured sentiment analysis casts the task as a dependency parsing problem, which has some limitations: (1) The label proportions for span prediction and span relation prediction are imbalanced. (2) The span lengths of sentiment tuple components may be very large in this task, which will further exacerbates the imbalance problem. (3) Two nodes in a dependency graph cannot have multiple arcs, therefore some overlapped sentiment tuples cannot be recognized. In this work, we propose nichetargeting solutions for these issues. First, we introduce a novel labeling strategy, which contains two sets of token pair labels, namely essential label set and whole label set. The essential label set consists of the basic labels for this task, which are relatively balanced and applied in the prediction layer. The whole label set includes rich labels to help our model capture various token relations, which are applied in the hidden layer to softly influence our model. Moreover, we also propose an effective model to well collaborate with our labeling strategy, which is equipped with the graph attention networks to iteratively refine token representations, and the adaptive multi-label classifier to dynamically predict multiple relations between token pairs. We perform extensive experiments on 5 benchmark datasets in four languages. Experimental results show that our model outperforms previous SOTA models by a large margin.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "構造化感情分析のための新しいラベリング戦略を使用した効果的なトークングラフモデリング", "jabstract": "構造化感情分析の最新モデルは、タスクを依存構文解析問題としてキャストしていますが、いくつかの制限があります：（1）スパン予測とスパン関係予測のラベル比率が不均衡であること。（2）このタスクにおける感情タプルの構成要素のスパン長が非常に大きい場合があるため、不均衡問題がさらに悪化すること。（3）依存グラフ内の2つのノードには複数のアークを持つことができないため、一部の重複した感情タプルを認識できないことがあります。本研究では、これらの問題に対するニッチターゲティングソリューションを提案します。まず、このタスクの基本的なラベルである必須ラベルセットと、比較的バランスが取れており予測レイヤーで適用されるラベルである必須ラベルセットを含む2つのトークンペアラベルセットを含む新しいラベリング戦略を導入します。全体のラベルセットには、モデルがさまざまなトークン関係を捉えるのに役立つ豊富なラベルが含まれており、隠れ層で適用されてモデルに柔軟に影響を与えます。さらに、グラフ注意ネットワークを装備し、トークン表現を反復的に洗練するための効果的なモデルを提案し、適応型マルチラベル分類器を装備して、トークンペア間の複数の関係を動的に予測します。4つの言語で5つのベンチマークデータセットで広範な実験を行いました。実験結果は、当社のモデルが従来のSOTAモデルを大幅に上回ることを示しています。"}
{"title": "PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks", "url": "https://aclanthology.org/2022.acl-long.292/", "abstract": "This paper focuses on the Data Augmentation for low-resource Natural Language Understanding (NLU) tasks. We propose Prompt-based Data Augmentation model (PromDA) which only trains small-scale Soft Prompt (i.e., a set of trainable vectors) in the frozen Pre-trained Language Models (PLMs). This avoids human effort in collecting unlabeled in-domain data and maintains the quality of generated synthetic data. In addition, PromDA generates synthetic data via two different views and filters out the low-quality data using NLU models. Experiments on four benchmarks show that synthetic data produced by PromDA successfully boost up the performance of NLU models which consistently outperform several competitive baseline models, including a state-of-the-art semi-supervised model using unlabeled in-domain data. The synthetic data from PromDA are also complementary with unlabeled in-domain data. The NLU models can be further improved when they are combined for training.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「PromDA：低リソースNLUタスクのためのプロンプトベースのデータ拡張」は、自然言語処理に関する論文の要約です。", "jabstract": "この論文は、低リソースの自然言語理解（NLU）タスクに対するデータ拡張に焦点を当てています。我々は、凍結された事前学習言語モデル（PLM）内の小規模なソフトプロンプト（トレーニング可能なベクトルのセット）のみをトレーニングするPrompt-based Data Augmentationモデル（PromDA）を提案しています。これにより、未ラベル化のドメイン内データを収集するための人的労力を回避し、生成された合成データの品質を維持することができます。さらに、PromDAは2つの異なる視点から合成データを生成し、NLUモデルを使用して低品質のデータをフィルタリングします。4つのベンチマーク実験の結果、PromDAによって生成された合成データは、競合する複数のベースラインモデル、および未ラベル化のドメイン内データを使用した最新の半教師ありモデルを常に上回るNLUモデルの性能を成功裏に向上させました。PromDAからの合成データは、未ラベル化のドメイン内データとも補完的であることが示されました。NLUモデルは、トレーニングのために組み合わせることでさらに改善される可能性があります。"}
{"title": "Disentangled Sequence to Sequence Learning for Compositional Generalization", "url": "https://aclanthology.org/2022.acl-long.293/", "abstract": "There is mounting evidence that existing neural network models, in particular the very popular sequence-to-sequence architecture, struggle to systematically generalize to unseen compositions of seen components. We demonstrate that one of the reasons hindering compositional generalization relates to representations being entangled. We propose an extension to sequence-to-sequence models which encourage disentanglement by adaptively re-encoding (at each time step) the source input. Specifically, we condition the source representations on the newly decoded target context which makes it easier for the encoder to exploit specialized information for each prediction rather than capturing it all in a single forward pass. Experimental results on semantic parsing and machine translation empirically show that our proposal delivers more disentangled representations and better generalization.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "構成的一般化のための分離されたシーケンス・トゥ・シーケンス学習", "jabstract": "既存のニューラルネットワークモデル、特に非常に人気のあるシーケンス・トゥ・シーケンス・アーキテクチャが、見たことのある構成要素の未知の組み合わせに系統的に一般化することが困難であることを示す証拠が増えている。我々は、構成的一般化を妨げる理由の1つが表現が絡み合っていることに関係していることを示す。我々は、シーケンス・トゥ・シーケンス・モデルに拡張を提案し、各時刻でソース入力を適応的に再エンコードすることで分離を促進する。具体的には、新しくデコードされたターゲット・コンテキストにソース表現を条件付けることで、エンコーダが各予測に特化した情報を利用しやすくなり、すべてを単一のフォワードパスで捕捉することが容易になる。意味解析と機械翻訳の実験結果は、我々の提案がより分離された表現とより良い一般化を提供することを実証している。"}
{"title": "RST Discourse Parsing with Second-Stage EDU-Level Pre-training", "url": "https://aclanthology.org/2022.acl-long.294/", "abstract": "Pre-trained language models (PLMs) have shown great potentials in natural language processing (NLP) including rhetorical structure theory (RST) discourse parsing.Current PLMs are obtained by sentence-level pre-training, which is different from the basic processing unit, i.e. element discourse unit (EDU).To this end, we propose a second-stage EDU-level pre-training approach in this work, which presents two novel tasks to learn effective EDU representations continually based on well pre-trained language models.Concretely, the two tasks are (1) next EDU prediction (NEP) and (2) discourse marker prediction (DMP).We take a state-of-the-art transition-based neural parser as baseline, and adopt it with a light bi-gram EDU modification to effectively explore the EDU-level pre-trained EDU representation.Experimental results on a benckmark dataset show that our method is highly effective,leading a 2.1-point improvement in F1-score.All codes and pre-trained models will be released publicly to facilitate future studies.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「第2段階のEDUレベルの事前学習を用いたRSTディスコース解析」に関する論文の要約文です。", "jabstract": "事前学習された言語モデル（PLMs）は、修辞構造理論（RST）の議論解析を含む自然言語処理（NLP）において、大きな可能性を示しています。現在のPLMsは、基本的な処理単位である要素議論単位（EDU）とは異なる、文レベルの事前学習によって得られます。このため、本研究では、二次的なEDUレベルの事前学習アプローチを提案し、よく事前学習された言語モデルに基づいて効果的なEDU表現を継続的に学習するための2つの新しいタスクを提示します。具体的には、2つのタスクは（1）次のEDU予測（NEP）と（2）議論マーカー予測（DMP）です。我々は、最新の遷移ベースのニューラルパーサーをベースラインとして採用し、軽量のバイグラムEDU修正を採用して、EDUレベルの事前学習されたEDU表現を効果的に探索します。ベンチマークデータセット上の実験結果は、我々の方法が非常に効果的であり、F1スコアで2.1ポイントの改善をもたらすことを示しています。すべてのコードと事前学習モデルは公開され、将来の研究を促進するために利用可能です。"}
{"title": "SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.295/", "abstract": "Knowledge graph completion (KGC) aims to reason over known facts and infer the missing links. Text-based methods such as KGBERT (Yao et al., 2019) learn entity representations from natural language descriptions, and have the potential for inductive KGC. However, the performance of text-based methods still largely lag behind graph embedding-based methods like TransE (Bordes et al., 2013) and RotatE (Sun et al., 2019b). In this paper, we identify that the key issue is efficient contrastive learning. To improve the learning efficiency, we introduce three types of negatives: in-batch negatives, pre-batch negatives, and self-negatives which act as a simple form of hard negatives. Combined with InfoNCE loss, our proposed model SimKGC can substantially outperform embedding-based methods on several benchmark datasets. In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19% on WN18RR, +6.8% on the Wikidata5M transductive setting, and +22% on the Wikidata5M inductive setting. Thorough analyses are conducted to gain insights into each component. Our code is available at https://github.com/intfloat/SimKGC .", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SimKGC：事前学習済み言語モデルを用いたシンプルな対照的知識グラフ補完", "jabstract": "知識グラフ補完（KGC）は、既知の事実について推論し、欠落しているリンクを推測することを目的としています。KGBERT（Yao et al.、2019）などのテキストベースの手法は、自然言語の説明からエンティティ表現を学習し、帰納的なKGCの可能性があります。しかし、テキストベースの手法の性能は、TransE（Bordes et al.、2013）やRotatE（Sun et al.、2019b）などのグラフ埋め込みベースの手法に比べて大幅に遅れています。本論文では、効率的な対照的学習が重要な問題であることを特定しました。学習効率を改善するために、バッチ内ネガティブ、プレバッチネガティブ、および自己ネガティブの3種類のネガティブを導入し、ハードネガティブの単純な形式として機能します。InfoNCE損失と組み合わせて、提案されたモデルSimKGCは、いくつかのベンチマークデータセットで埋め込みベースの手法を大幅に上回る性能を発揮できます。平均相互順位（MRR）に関して、WN18RRで+19％、Wikidata5Mの帰納的設定で+6.8％、Wikidata5Mの帰納的設定で+22％の最先端を更新しています。各コンポーネントの洞察を得るために徹底的な分析が行われています。私たちのコードはhttps://github.com/intfloat/SimKGCで利用可能です。"}
{"title": "Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?", "url": "https://aclanthology.org/2022.acl-long.296/", "abstract": "Learned self-attention functions in state-of-the-art NLP models often correlate with human attention. We investigate whether self-attention in large-scale pre-trained language models is as predictive of human eye fixation patterns during task-reading as classical cognitive models of human attention. We compare attention functions across two task-specific reading datasets for sentiment analysis and relation extraction. We find the predictiveness of large-scale pre-trained self-attention for human attention depends on ‘what is in the tail’, e.g., the syntactic nature of rare contexts.Further, we observe that task-specific fine-tuning does not increase the correlation with human task-specific reading. Through an input reduction experiment we give complementary insights on the sparsity and fidelity trade-off, showing that lower-entropy attention vectors are more faithful.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トランスフォーマーモデルは、タスク固有の人間の視線と類似した注意パターンを示すか？", "jabstract": "最新のNLPモデルにおける学習済みの自己注意機能は、しばしば人間の注意と相関する。本研究では、大規模な事前学習言語モデルにおける自己注意が、人間のタスク読解中の視線固定パターンを、人間の注意の古典的な認知モデルと同様に予測できるかどうかを調査する。我々は、感情分析と関係抽出の2つのタスク固有の読解データセットにおける注意機能を比較する。我々は、大規模な事前学習済みの自己注意が人間の注意に対する予測力は、「尾部に何があるか」に依存することを発見した。例えば、稀な文脈の構文的性質などである。さらに、タスク固有の微調整は、人間のタスク固有の読解との相関を増加させないことを観察した。入力削減実験を通じて、スパース性と忠実度のトレードオフに関する補完的な洞察を提供し、エントロピーの低い注意ベクトルがより忠実であることを示した。"}
{"title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English", "url": "https://aclanthology.org/2022.acl-long.297/", "abstract": "Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LexGLUE: 英語における法的言語理解のためのベンチマークデータセット", "jabstract": "法律やその解釈、法的論争や合意は通常、文章で表現され、法的テキストの膨大なコーパスが生産されます。これらのコレクションが大きくなるにつれ、法的実務の中心である分析はますます複雑になります。自然言語理解（NLU）技術は、これらの取り組みを支援するための貴重なツールになり得ます。ただし、その有用性は、現在の最先端のモデルが法的ドメインのさまざまなタスクにわたって一般化できるかどうかに大きく依存します。この現在の未解決問題に答えるために、我々はLegal General Language Understanding Evaluation（LexGLUE）ベンチマークを導入し、標準化された方法で多様な法的NLUタスクのモデルのパフォーマンスを評価するためのデータセットのコレクションを提供します。また、複数のタスクにわたって一貫してパフォーマンスの向上を示す法的指向のモデルと一般的なモデルの評価と分析を提供します。"}
{"title": "DiBiMT: A Novel Benchmark for Measuring Word Sense Disambiguation Biases in Machine Translation", "url": "https://aclanthology.org/2022.acl-long.298/", "abstract": "Lexical ambiguity poses one of the greatest challenges in the field of Machine Translation. Over the last few decades, multiple efforts have been undertaken to investigate incorrect translations caused by the polysemous nature of words. Within this body of research, some studies have posited that models pick up semantic biases existing in the training data, thus producing translation errors. In this paper, we present DiBiMT, the first entirely manually-curated evaluation benchmark which enables an extensive study of semantic biases in Machine Translation of nominal and verbal words in five different language combinations, namely, English and one or other of the following languages: Chinese, German, Italian, Russian and Spanish. Furthermore, we test state-of-the-art Machine Translation systems, both commercial and non-commercial ones, against our new test bed and provide a thorough statistical and linguistic analysis of the results. We release DiBiMT at https://nlp.uniroma1.it/dibimt as a closed benchmark with a public leaderboard.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DiBiMT：機械翻訳における単語意味の曖昧性バイアスを測定するための新しいベンチマーク", "jabstract": "語彙の曖昧さは、機械翻訳の分野で最も大きな課題の1つです。過去数十年間、単語の多義性による不正確な翻訳を調査するために、複数の取り組みが行われてきました。この研究の中で、モデルがトレーニングデータに存在する意味的なバイアスを拾い上げ、翻訳エラーを生じさせるという説が提唱されています。本論文では、英語と中国語、ドイツ語、イタリア語、ロシア語、スペイン語の5つの言語の名詞と動詞の機械翻訳における意味的なバイアスを広範囲に研究するための、完全に手動で作成された最初の評価ベンチマークであるDiBiMTを提案します。さらに、商用および非商用の最新の機械翻訳システムを、新しいテストベッドに対してテストし、結果の統計的および言語学的分析を提供します。私たちは、DiBiMTをhttps://nlp.uniroma1.it/dibimtで公開リーダーボードを備えたクローズドベンチマークとしてリリースします。"}
{"title": "Improving Word Translation via Two-Stage Contrastive Learning", "url": "https://aclanthology.org/2022.acl-long.299/", "abstract": "Word translation or bilingual lexicon induction (BLI) is a key cross-lingual task, aiming to bridge the lexical gap between different languages. In this work, we propose a robust and effective two-stage contrastive learning framework for the BLI task. At Stage C1, we propose to refine standard cross-lingual linear maps between static word embeddings (WEs) via a contrastive learning objective; we also show how to integrate it into the self-learning procedure for even more refined cross-lingual maps. In Stage C2, we conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word translation capability. We also show that static WEs induced from the ‘C2-tuned’ mBERT complement static WEs from Stage C1. Comprehensive experiments on standard BLI datasets for diverse languages and different experimental setups demonstrate substantial gains achieved by our framework. While the BLI method from Stage C1 already yields substantial gains over all state-of-the-art BLI methods in our comparison, even stronger improvements are met with the full two-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28 language pairs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "二段階の対照学習による単語翻訳の改善", "jabstract": "単語翻訳またはバイリンガルレキシコン誘導（BLI）は、異なる言語間の語彙的ギャップを埋めることを目的とした重要なクロスリンガルタスクです。本研究では、BLIタスクのための堅牢で効果的な2段階の対照的学習フレームワークを提案します。ステージC1では、対照的学習目的を介して静的単語埋め込み（WEs）間の標準的なクロスリンガル線形マップを改良することを提案します。さらに、より洗練されたクロスリンガルマップを得るために、セルフラーニング手順に統合する方法も示します。ステージC2では、mBERTのBLI指向の対照的微調整を行い、その単語翻訳能力を引き出します。また、C2微調整された静的WEsが、ステージC1から導出された静的WEsを補完することも示します。多様な言語と異なる実験設定の標準BLIデータセットでの包括的な実験は、当社のフレームワークによって実現された大幅な利益を示しています。C1ステージからのBLI方法は、比較対象のすべての最新のBLI方法に対して既に大幅な利益をもたらしますが、完全な2段階フレームワークではさらに強力な改善が見られます。たとえば、28の言語ペアをカバーする112/112のBLIセットアップで利益を報告しています。"}
{"title": "Scheduled Multi-task Learning for Neural Chat Translation", "url": "https://aclanthology.org/2022.acl-long.300/", "abstract": "Neural Chat Translation (NCT) aims to translate conversational text into different languages. Existing methods mainly focus on modeling the bilingual dialogue characteristics (e.g., coherence) to improve chat translation via multi-task learning on small-scale chat translation data. Although the NCT models have achieved impressive success, it is still far from satisfactory due to insufficient chat translation data and simple joint training manners. To address the above issues, we propose a scheduled multi-task learning framework for NCT. Specifically, we devise a three-stage training framework to incorporate the large-scale in-domain chat translation data into training by adding a second pre-training stage between the original pre-training and fine-tuning stages. Further, we investigate where and how to schedule the dialogue-related auxiliary tasks in multiple training stages to effectively enhance the main chat translation task. Extensive experiments on four language directions (English-Chinese and English-German) verify the effectiveness and superiority of the proposed approach. Additionally, we will make the large-scale in-domain paired bilingual dialogue dataset publicly available for the research community.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「スケジュールされたマルチタスク学習によるニューラルチャット翻訳」", "jabstract": "Neural Chat Translation（NCT）は、会話テキストを異なる言語に翻訳することを目的としています。既存の方法は、主にバイリンガルの対話特性（例：一貫性）をモデル化して、小規模なチャット翻訳データに対するマルチタスク学習を通じてチャット翻訳を改善することに焦点を当てています。 NCTモデルは印象的な成功を収めていますが、不十分なチャット翻訳データと単純な共同トレーニング方法のため、まだ十分に満足できるものではありません。上記の問題に対処するために、私たちはNCTのためのスケジュールされたマルチタスク学習フレームワークを提案します。具体的には、元の事前トレーニングとファインチューニングの間に第2の事前トレーニングステージを追加することで、大規模なドメイン内チャット翻訳データをトレーニングに組み込むための3段階のトレーニングフレームワークを考案します。さらに、複数のトレーニングステージで対話関連の補助タスクをどこに、どのようにスケジュールするかを調査し、主要なチャット翻訳タスクを効果的に強化します。英中および英独の4つの言語方向での広範な実験により、提案手法の有効性と優越性が検証されました。さらに、大規模なドメイン内ペアバイリンガル対話データセットを研究コミュニティに公開します。"}
{"title": "FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing", "url": "https://aclanthology.org/2022.acl-long.301/", "abstract": "We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FairLex：法的テキスト処理における公正性を評価するための多言語ベンチマーク", "jabstract": "私たちは、事前学習された言語モデルの公平性と、それらをダウンストリームタスクに適応するために使用される技術の評価に使用する4つのデータセットのベンチマークスイートを提供します。私たちのベンチマークは、4つの管轄区域（欧州評議会、米国、スイス、中国）、5つの言語（英語、ドイツ語、フランス語、イタリア語、中国語）をカバーし、5つの属性（性別、年齢、地域、言語、法的領域）にわたる公平性を評価します。私たちの実験では、いくつかのグループロバストなファインチューニング技術を使用して事前学習された言語モデルを評価し、パフォーマンスグループの不均衡が多くの場合に存在することを示しました。しかし、これらの技術のいずれも公平性を保証するわけではなく、グループの不均衡を一貫して軽減するわけでもありません。さらに、私たちは結果の定量的および定性的分析を提供し、法的NLPの堅牢性方法の開発における課題を強調しています。"}
{"title": "Towards Abstractive Grounded Summarization of Podcast Transcripts", "url": "https://aclanthology.org/2022.acl-long.302/", "abstract": "Podcasts have shown a recent rise in popularity. Summarization of podcasts is of practical benefit to both content providers and consumers. It helps people quickly decide whether they will listen to a podcast and/or reduces the cognitive load of content providers to write summaries. Nevertheless, podcast summarization faces significant challenges including factual inconsistencies of summaries with respect to the inputs. The problem is exacerbated by speech disfluencies and recognition errors in transcripts of spoken language. In this paper, we explore a novel abstractive summarization method to alleviate these issues. Our approach learns to produce an abstractive summary while grounding summary segments in specific regions of the transcript to allow for full inspection of summary details. We conduct a series of analyses of the proposed approach on a large podcast dataset and show that the approach can achieve promising results. Grounded summaries bring clear benefits in locating the summary and transcript segments that contain inconsistent information, and hence improve summarization quality in terms of automatic and human evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ポッドキャストのトランスクリプトに対する抽象的なグラウンデッドサマリゼーションへの取り組み", "jabstract": "ポッドキャストは最近人気が高まっています。ポッドキャストの要約は、コンテンツ提供者と消費者の両方にとって実用的な利益があります。それにより、人々は迅速にポッドキャストを聴くかどうかを決定でき、また、コンテンツ提供者が要約を書くための認知負荷を軽減することができます。しかし、ポッドキャストの要約には、入力に関する事実上の不一致など、重要な課題があります。この問題は、話し言葉のトランスクリプトにおける発話の不流暢さや認識エラーによって悪化します。本論文では、これらの問題を緩和するための新しい抽象的要約方法を探求します。私たちのアプローチは、要約セグメントをトランスクリプトの特定の領域に基づいて学習し、要約の詳細を完全に検査できるようにします。私たちは、大規模なポッドキャストデータセットで提案されたアプローチの一連の分析を実施し、アプローチが有望な結果を達成できることを示しました。グラウンディングされた要約は、不一致な情報を含む要約とトランスクリプトのセグメントを特定することで、自動評価と人間の評価において要約の品質を改善する明確な利点をもたらします。"}
{"title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging", "url": "https://aclanthology.org/2022.acl-long.303/", "abstract": "Publicly traded companies are required to submit periodic reports with eXtensive Business Reporting Language (XBRL) word-level tags. Manually tagging the reports is tedious and costly. We, therefore, introduce XBRL tagging as a new entity extraction task for the financial domain and release FiNER-139, a dataset of 1.1M sentences with gold XBRL tags. Unlike typical entity extraction datasets, FiNER-139 uses a much larger label set of 139 entity types. Most annotated tokens are numeric, with the correct tag per token depending mostly on context, rather than the token itself. We show that subword fragmentation of numeric expressions harms BERT’s performance, allowing word-level BILSTMs to perform better. To improve BERT’s performance, we propose two simple and effective solutions that replace numeric expressions with pseudo-tokens reflecting original token shapes and numeric magnitudes. We also experiment with FIN-BERT, an existing BERT model for the financial domain, and release our own BERT (SEC-BERT), pre-trained on financial filings, which performs best. Through data and error analysis, we finally identify possible limitations to inspire future work on XBRL tagging.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FiNER：XBRLタグ付けのための財務数値エンティティ認識", "jabstract": "上場企業は、eXtensive Business Reporting Language（XBRL）の単語レベルのタグを含む定期報告書を提出する必要があります。報告書に手動でタグを付けることは手間がかかり、コストがかかります。したがって、私たちは金融分野の新しいエンティティ抽出タスクとしてXBRLタグ付けを紹介し、FiNER-139をリリースします。FiNER-139は、金のXBRLタグを持つ1.1Mの文のデータセットで、通常のエンティティ抽出データセットとは異なり、139のエンティティタイプのより大きなラベルセットを使用しています。ほとんどの注釈付きトークンは数値であり、正しいタグはトークン自体ではなく、主に文脈に依存します。数値式のサブワード分割はBERTのパフォーマンスに悪影響を与えることが示され、単語レベルのBILSTMsの方が優れたパフォーマンスを発揮します。BERTのパフォーマンスを改善するために、私たちは2つのシンプルで効果的な解決策を提案し、数値式を元のトークン形状と数値の大きさを反映する疑似トークンで置き換えます。また、金融分野の既存のBERTモデルであるFIN-BERTで実験し、最も優れたパフォーマンスを発揮する私たち自身のBERT（SEC-BERT）をリリースします。最後に、データとエラー分析を通じて、XBRLタグ付けに関する将来の研究をインスピレーションにする可能性のある制限を特定します。"}
{"title": "Keywords and Instances: A Hierarchical Contrastive Learning Framework Unifying Hybrid Granularities for Text Generation", "url": "https://aclanthology.org/2022.acl-long.304/", "abstract": "Contrastive learning has achieved impressive success in generation tasks to militate the “exposure bias” problem and discriminatively exploit the different quality of references. Existing works mostly focus on contrastive learning on the instance-level without discriminating the contribution of each word, while keywords are the gist of the text and dominant the constrained mapping relationships. Hence, in this work, we propose a hierarchical contrastive learning mechanism, which can unify hybrid granularities semantic meaning in the input text. Concretely, we first propose a keyword graph via contrastive correlations of positive-negative pairs to iteratively polish the keyword representations. Then, we construct intra-contrasts within instance-level and keyword-level, where we assume words are sampled nodes from a sentence distribution. Finally, to bridge the gap between independent contrast levels and tackle the common contrast vanishing problem, we propose an inter-contrast mechanism that measures the discrepancy between contrastive keyword nodes respectively to the instance distribution. Experiments demonstrate that our model outperforms competitive baselines on paraphrasing, dialogue generation, and storytelling tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "キーワードとインスタンス：テキスト生成のためのハイブリッドな粒度を統合する階層的対比学習フレームワーク\n\nこの論文では、自然言語処理におけるテキスト生成に焦点を当て、ハイブリッドな粒度を統合するための階層的対比学習フレームワークを提案する。このフレームワークは、キーワードとインスタンスの両方を考慮し、テキスト生成の精度を向上させることができる。具体的には、キーワードとインスタンスの間の関係をモデル化し、それらを統合することで、より自然なテキストを生成することができる。我々の実験結果は、提案手法が既存の手法よりも優れていることを示している。", "jabstract": "対照学習は、「露出バイアス」問題を緩和し、参照の異なる品質を差別的に利用することで、生成タスクで印象的な成功を収めています。既存の研究は、各単語の貢献を区別せずにインスタンスレベルでの対照学習に焦点を当てていますが、キーワードはテキストの要点であり、制約付きマッピング関係を支配しています。したがって、本研究では、入力テキストのハイブリッド粒度の意味を統一的に対照学習する階層的対照学習メカニズムを提案します。具体的には、まず、正負のペアの対照相関によるキーワードグラフを提案し、キーワード表現を反復的に磨きます。次に、インスタンスレベルとキーワードレベルで内部対照を構築し、単語が文の分布からサンプリングされたノードであると仮定します。最後に、独立した対照レベル間のギャップを埋め、共通の対照消失問題に対処するために、各対照キーワードノードの対比をインスタンス分布に対して測定する間隔対照メカニズムを提案します。実験により、我々のモデルが言い換え、対話生成、ストーリーテリングタスクで競合するベースラインを上回ることが示されました。"}
{"title": "EPT-X: An Expression-Pointer Transformer model that generates eXplanations for numbers", "url": "https://aclanthology.org/2022.acl-long.305/", "abstract": "In this paper, we propose a neural model EPT-X (Expression-Pointer Transformer with Explanations), which utilizes natural language explanations to solve an algebraic word problem. To enhance the explainability of the encoding process of a neural model, EPT-X adopts the concepts of plausibility and faithfulness which are drawn from math word problem solving strategies by humans. A plausible explanation is one that includes contextual information for the numbers and variables that appear in a given math word problem. A faithful explanation is one that accurately represents the reasoning process behind the model’s solution equation. The EPT-X model yields an average baseline performance of 69.59% on our PEN dataset and produces explanations with quality that is comparable to human output. The contribution of this work is two-fold. (1) EPT-X model: An explainable neural model that sets a baseline for algebraic word problem solving task, in terms of model’s correctness, plausibility, and faithfulness. (2) New dataset: We release a novel dataset PEN (Problems with Explanations for Numbers), which expands the existing datasets by attaching explanations to each number/variable.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約の以下の文を日本語に翻訳してください：\n\nEPT-X：数字の説明を生成するExpression-Pointer Transformerモデル", "jabstract": "本論文では、代数的なワード問題を解決するために自然言語の説明を利用するニューラルモデルEPT-X（Expression-Pointer Transformer with Explanations）を提案する。ニューラルモデルのエンコーディングプロセスの説明可能性を向上させるために、EPT-Xは、人間が数学のワード問題を解決する際に描かれる可能性と忠実度の概念を採用している。可能性のある説明とは、与えられた数学のワード問題に現れる数字や変数の文脈情報を含むものである。忠実な説明とは、モデルの解決式の推論プロセスを正確に表現するものである。EPT-Xモデルは、PENデータセットにおいて平均ベースライン性能69.59％を示し、人間の出力に匹敵する品質の説明を生成する。本研究の貢献は2つある。(1) EPT-Xモデル：モデルの正確性、可能性、忠実度に関して代数的なワード問題解決タスクのベースラインを設定する説明可能なニューラルモデル。(2) 新しいデータセット：数字/変数に説明を付けたPEN（Problems with Explanations for Numbers）という新しいデータセットをリリースし、既存のデータセットを拡張する。"}
{"title": "Identifying the Human Values behind Arguments", "url": "https://aclanthology.org/2022.acl-long.306/", "abstract": "This paper studies the (often implicit) human values behind natural language arguments, such as to have freedom of thought or to be broadminded. Values are commonly accepted answers to why some option is desirable in the ethical sense and are thus essential both in real-world argumentation and theoretical argumentation frameworks. However, their large variety has been a major obstacle to modeling them in argument mining. To overcome this obstacle, we contribute an operationalization of human values, namely a multi-level taxonomy with 54 values that is in line with psychological research. Moreover, we provide a dataset of 5270 arguments from four geographical cultures, manually annotated for human values. First experiments with the automatic classification of human values are promising, with F1-scores up to 0.81 and 0.25 on average.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "論文の要旨：議論の背後にある人間の価値観の特定", "jabstract": "本論文は、自由な思考や広い心を持つことなど、自然言語の議論における（しばしば暗黙のうちにある）人間の価値観について研究しています。価値観は、倫理的に望ましいとされる選択肢の理由についての一般的に受け入れられた回答であり、現実世界の議論や理論的な議論の枠組みの両方にとって不可欠です。しかし、その多様性は、議論マイニングでのモデリングにおいて主要な障害となっています。この障害を克服するために、私たちは、心理学的研究に沿った54の価値を持つ多層の分類法を提供し、人間の価値観を手動で注釈した4つの地理的文化からなる5270の議論のデータセットを提供します。人間の価値観の自動分類の最初の実験は、F1スコアが0.81から0.25までの有望な結果を示しています。"}
{"title": "BenchIE: A Framework for Multi-Faceted Fact-Based Open Information Extraction Evaluation", "url": "https://aclanthology.org/2022.acl-long.307/", "abstract": "Intrinsic evaluations of OIE systems are carried out either manually—with human evaluators judging the correctness of extractions—or automatically, on standardized benchmarks. The latter, while much more cost-effective, is less reliable, primarily because of the incompleteness of the existing OIE benchmarks: the ground truth extractions do not include all acceptable variants of the same fact, leading to unreliable assessment of the models’ performance. Moreover, the existing OIE benchmarks are available for English only. In this work, we introduce BenchIE: a benchmark and evaluation framework for comprehensive evaluation of OIE systems for English, Chinese, and German. In contrast to existing OIE benchmarks, BenchIE is fact-based, i.e., it takes into account informational equivalence of extractions: our gold standard consists of fact synsets, clusters in which we exhaustively list all acceptable surface forms of the same fact. Moreover, having in mind common downstream applications for OIE, we make BenchIE multi-faceted; i.e., we create benchmark variants that focus on different facets of OIE evaluation, e.g., compactness or minimality of extractions. We benchmark several state-of-the-art OIE systems using BenchIE and demonstrate that these systems are significantly less effective than indicated by existing OIE benchmarks. We make BenchIE (data and evaluation code) publicly available.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BenchIE：多面的な事実ベースのオープン情報抽出評価のためのフレームワーク\n\nAbstract:\nWe present BenchIE, a framework for evaluating multi-faceted fact-based open information extraction (OIE) systems. BenchIE provides a comprehensive evaluation of OIE systems by considering multiple facets of extraction quality, including precision, recall, and coverage of extracted facts, as well as the diversity and novelty of extracted facts. BenchIE also includes a novel evaluation metric, called the FactRank, which ranks extracted facts based on their importance and novelty. We demonstrate the utility of BenchIE by using it to evaluate several state-of-the-art OIE systems on a large-scale dataset. Our results show that BenchIE provides a more comprehensive and informative evaluation of OIE systems than existing benchmarks. \n\n要約：\n本論文では、多面的な事実ベースのオープン情報抽出（OIE）システムを評価するためのフレームワークであるBenchIEを提案する。BenchIEは、抽出された事実の精度、再現率、カバレッジ、抽出された事実の多様性と新規性など、抽出品質の複数の側面を考慮して、OIEシステムの包括的な評価を提供する。BenchIEには、抽出された事実の重要性と新規性に基づいてランク付けする新しい評価指標であるFactRankも含まれている。我々は、BenchIEを使用して、いくつかの最新のOIEシステムを大規模なデータセットで評価することによって、BenchIEの有用性を示す。我々の結果は、BenchIEが既存のベンチマークよりも包括的で情報量の多いOIEシステムの評価を提供することを示している。", "jabstract": "OIEシステムの本質的な評価は、人間の評価者が抽出の正確性を判断する手動評価、または標準化されたベンチマークで自動的に行われます。後者はコスト効率がはるかに高いですが、既存のOIEベンチマークの不完全さのために信頼性が低くなります。つまり、グラウンドトゥルースの抽出には同じ事実のすべての受け入れ可能なバリアントが含まれていないため、モデルのパフォーマンスの信頼性が低くなるためです。さらに、既存のOIEベンチマークは英語のみに対応しています。本研究では、英語、中国語、ドイツ語のOIEシステムの包括的な評価のためのベンチマークおよび評価フレームワークであるBenchIEを紹介します。既存のOIEベンチマークとは異なり、BenchIEは事実に基づいており、抽出の情報的同等性を考慮しています。つまり、私たちのゴールドスタンダードは事実のシンセットであり、同じ事実のすべての受け入れ可能な表面形式を徹底的にリストアップしたクラスターです。さらに、OIEの一般的なダウンストリームアプリケーションを考慮して、BenchIEを多面的にしました。つまり、抽出のコンパクトさや最小性など、OIE評価の異なる側面に焦点を当てたベンチマークバリアントを作成しました。BenchIEを使用していくつかの最新のOIEシステムをベンチマークし、これらのシステムが既存のOIEベンチマークで示されているよりもはるかに効果的でないことを示しました。BenchIE（データおよび評価コード）を一般に公開します。"}
{"title": "Leveraging Unimodal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition", "url": "https://aclanthology.org/2022.acl-long.308/", "abstract": "Training Transformer-based models demands a large amount of data, while obtaining aligned and labelled data in multimodality is rather cost-demanding, especially for audio-visual speech recognition (AVSR). Thus it makes a lot of sense to make use of unlabelled unimodal data. On the other side, although the effectiveness of large-scale self-supervised learning is well established in both audio and visual modalities, how to integrate those pre-trained models into a multimodal scenario remains underexplored. In this work, we successfully leverage unimodal self-supervised learning to promote the multimodal AVSR. In particular, audio and visual front-ends are trained on large-scale unimodal datasets, then we integrate components of both front-ends into a larger multimodal framework which learns to recognize parallel audio-visual data into characters through a combination of CTC and seq2seq decoding. We show that both components inherited from unimodal self-supervised learning cooperate well, resulting in that the multimodal framework yields competitive results through fine-tuning. Our model is experimentally validated on both word-level and sentence-level tasks. Especially, even without an external language model, our proposed model raises the state-of-the-art performances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a large margin, with a relative improvement of 30%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "単一モーダル自己教示学習を活用した多モーダル音声視覚認識の強化\n\nAbstract:\nIn this paper, we propose a novel approach for multimodal audio-visual speech recognition by leveraging unimodal self-supervised learning. Specifically, we first pretrain a visual encoder and an audio encoder on large-scale unimodal datasets using self-supervised learning. We then fine-tune the pretrained encoders on a smaller multimodal dataset for audio-visual speech recognition. Our experiments on the AVSpeech dataset show that our approach outperforms the state-of-the-art methods by a large margin. \n\n要旨：\n本論文では、単一モーダル自己教示学習を活用した多モーダル音声視覚認識の新しいアプローチを提案します。具体的には、まず、自己教示学習を用いて大規模な単一モーダルデータセット上で視覚エンコーダーと音声エンコーダーを事前学習します。次に、事前学習されたエンコーダーを小規模な多モーダルデータセット上で微調整して、音声視覚認識を行います。AVSpeechデータセット上の実験結果から、本手法が従来の手法を大幅に上回ることが示されました。", "jabstract": "Transformerベースのモデルのトレーニングには大量のデータが必要であり、マルチモーダリティのアラインメントとラベル付けされたデータを取得することは、特に音声視覚認識（AVSR）においてはコストがかかります。したがって、ラベルのない単一モーダルデータを利用することは合理的です。一方、大規模な自己教師あり学習の効果は、音声と視覚の両方のモダリティで確立されていますが、これらの事前学習モデルをマルチモーダルシナリオに統合する方法は未だに未開拓の領域です。本研究では、単一モーダルの自己教師あり学習を活用してマルチモーダルAVSRを促進することに成功しました。特に、音声と視覚のフロントエンドは大規模な単一モーダルデータセットでトレーニングされ、その後、両方のフロントエンドのコンポーネントを統合して、CTCとseq2seqデコーディングの組み合わせによって並列音声視覚データを文字に認識するように学習するより大きなマルチモーダルフレームワークを構築しました。単一モーダル自己教師あり学習から継承された両方のコンポーネントがうまく協力し、微調整によってマルチモーダルフレームワークが競争力のある結果を生み出すことを示しました。提案されたモデルは、単語レベルと文レベルのタスクの両方で実験的に検証されています。特に、外部言語モデルなしでも、提案されたモデルは、広く受け入れられているLip Reading Sentences 2（LRS2）データセットで、30％の相対的な改善により、最先端のパフォーマンスを発揮します。"}
{"title": "SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization", "url": "https://aclanthology.org/2022.acl-long.309/", "abstract": "Sequence-to-sequence neural networks have recently achieved great success in abstractive summarization, especially through fine-tuning large pre-trained language models on the downstream dataset. These models are typically decoded with beam search to generate a unique summary. However, the search space is very large, and with the exposure bias, such decoding is not optimal. In this paper, we show that it is possible to directly train a second-stage model performing re-ranking on a set of summary candidates. Our mixture-of-experts SummaReranker learns to select a better candidate and consistently improves the performance of the base model. With a base PEGASUS, we push ROUGE scores by 5.44% on CNN- DailyMail (47.16 ROUGE-1), 1.31% on XSum (48.12 ROUGE-1) and 9.34% on Reddit TIFU (29.83 ROUGE-1), reaching a new state-of-the-art. Our code and checkpoints will be available at https://github.com/ntunlp/SummaReranker.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SummaReranker：抽象的要約のためのマルチタスクエキスパート混合再ランキングフレームワーク", "jabstract": "シーケンス・トゥ・シーケンスのニューラルネットワークは、最近、抽象的な要約において大きな成功を収めており、特にダウンストリームデータセットで大規模な事前学習言語モデルを微調整することによって実現されています。これらのモデルは通常、ビームサーチでデコードされ、ユニークな要約が生成されます。しかし、探索空間は非常に大きく、エクスポージャーバイアスにより、このようなデコードは最適ではありません。本論文では、要約候補のセットで再ランキングを実行する第2段階のモデルを直接トレーニングすることが可能であることを示します。私たちのエキスパートの混合SummaRerankerは、より良い候補を選択することを学び、ベースモデルのパフォーマンスを一貫して改善します。ベースのPEGASUSを使用して、CNN-DailyMail（47.16 ROUGE-1）でROUGEスコアを5.44％、XSum（48.12 ROUGE-1）で1.31％、Reddit TIFU（29.83 ROUGE-1）で9.34％押し上げ、新しい最先端に到達しました。私たちのコードとチェックポイントは、https://github.com/ntunlp/SummaRerankerで利用可能です。"}
{"title": "Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals", "url": "https://aclanthology.org/2022.acl-long.310/", "abstract": "The ability to sequence unordered events is evidence of comprehension and reasoning about real world tasks/procedures. It is essential for applications such as task planning and multi-source instruction summarization.It often requires thorough understanding of temporal common sense and multimodal information, since these procedures are often conveyed by a combination of texts and images.While humans are capable of reasoning about and sequencing unordered procedural instructions, the extent to which the current machine learning methods possess such capability is still an open question.In this work, we benchmark models’ capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from online instructional manuals and collecting comprehensive human annotations.We find current state-of-the-art models not only perform significantly worse than humans but also seem incapable of efficiently utilizing multimodal information.To improve machines’ performance on multimodal event sequencing, we propose sequence-aware pretraining techniques exploiting the sequential alignment properties of both texts and images, resulting in > 5% improvements on perfect match ratio.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「マルチモーダルな教示マニュアルをシーケンス化することによるマルチモーダル手順知識の理解」についての論文の要約です。", "jabstract": "順序のないイベントをシーケンス化する能力は、現実世界のタスク/手順についての理解と推論の証拠である。タスク計画や複数ソースの指示の要約などのアプリケーションに必要である。これは、これらの手順がしばしばテキストと画像の組み合わせによって伝達されるため、時間的な常識とマルチモーダル情報の徹底的な理解を必要とすることが多い。人間は順序のない手順指示について推論し、シーケンス化することができるが、現在の機械学習方法がそのような能力を持っているかどうかは未解決の問題である。本研究では、オンラインの指示マニュアルからデータセットを収集し、包括的な人間の注釈を収集することにより、モデルがマルチモーダルな指示を推論し、シーケンス化する能力をベンチマークする。現在の最先端のモデルは、人間よりも明らかに性能が劣り、マルチモーダル情報を効率的に利用することができないように思われる。マルチモーダルなイベントシーケンスの機械のパフォーマンスを改善するために、私たちは、テキストと画像のシーケンシャルなアラインメント特性を利用したシーケンスに敏感な事前学習技術を提案し、完全一致率で5％以上の改善を実現した。"}
{"title": "Zoom Out and Observe: News Environment Perception for Fake News Detection", "url": "https://aclanthology.org/2022.acl-long.311/", "abstract": "Fake news detection is crucial for preventing the dissemination of misinformation on social media. To differentiate fake news from real ones, existing methods observe the language patterns of the news post and “zoom in” to verify its content with knowledge sources or check its readers’ replies. However, these methods neglect the information in the external news environment where a fake news post is created and disseminated. The news environment represents recent mainstream media opinion and public attention, which is an important inspiration of fake news fabrication because fake news is often designed to ride the wave of popular events and catch public attention with unexpected novel content for greater exposure and spread. To capture the environmental signals of news posts, we “zoom out” to observe the news environment and propose the News Environment Perception Framework (NEP). For each post, we construct its macro and micro news environment from recent mainstream news. Then we design a popularity-oriented and a novelty-oriented module to perceive useful signals and further assist final prediction. Experiments on our newly built datasets show that the NEP can efficiently improve the performance of basic fake news detectors.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ズームアウトして観察する：フェイクニュース検出のためのニュース環境認識", "jabstract": "社会メディア上での誤情報の拡散を防止するために、フェイクニュースの検出は重要である。既存の方法は、ニュース投稿の言語パターンを観察し、知識源で内容を確認したり、読者の返信をチェックすることで、フェイクニュースと本物のニュースを区別する。しかし、これらの方法は、フェイクニュースの投稿が作成され、拡散される外部のニュース環境の情報を無視している。ニュース環境は、最近の主流メディアの意見や注目度を表し、フェイクニュースの製造に重要なインスピレーションを提供する。フェイクニュースは、人気のあるイベントの波に乗り、予期せぬ新しい内容で注目を集め、より多くの露出と拡散を狙っているためである。ニュース投稿の環境信号を捉えるために、私たちはニュース環境知覚フレームワーク（NEP）を提案する。各投稿について、最近の主流ニュースからそのマクロおよびミクロなニュース環境を構築する。その後、人気志向と新奇性志向のモジュールを設計して、有用な信号を知覚し、最終的な予測を支援する。新しく構築したデータセットでの実験結果は、NEPが基本的なフェイクニュース検出器の性能を効率的に改善できることを示している。"}
{"title": "Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models", "url": "https://aclanthology.org/2022.acl-long.312/", "abstract": "Multi-encoder models are a broad family of context-aware neural machine translation systems that aim to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context. We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons. Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently. Secondly, it eases the retrieval of relevant context, since context segments become shorter. We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets. Results show that it consistently improves learning of contextual parameters, both in low and high resource settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「分割と支配：文脈に応じたマルチエンコーダ翻訳モデルの効果的な事前学習」についての論文の要約です。", "jabstract": "マルチエンコーダーモデルは、文脈情報を現在の文と一緒にエンコードすることで、翻訳品質を向上させることを目的とした、広範なコンテキストに敏感なニューラル機械翻訳システムの一種です。文脈エンコードは、文書レベルのデータでトレーニングされた文脈パラメータによって行われます。本研究では、文脈パラメータを効果的にトレーニングすることの困難さについて、必要な文の単語のまばらさ（つまり、トレーニングシグナル）とその関連する文脈のために議論します。私たちは、分割された文のペアを使って文脈パラメータを事前トレーニングすることを提案し、利用可能なデータを効率的に活用します。第一に、文内構文関係を破ることで文脈トレーニングシグナルを増やし、曖昧性を解消する手がかりをより頻繁に探索するようにモデルを促します。第二に、文脈セグメントが短くなるため、関連する文脈を取得することが容易になります。私たちは4つの異なる分割方法を提案し、BLEUと対照的なテストセットでアプローチを評価しました。結果は、低リソース環境と高リソース環境の両方で、文脈パラメータの学習を一貫して改善することを示しています。"}
{"title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution", "url": "https://aclanthology.org/2022.acl-long.313/", "abstract": "Event detection (ED) is a critical subtask of event extraction that seeks to identify event triggers of certain types in texts.Despite significant advances in ED, existing methods typically follow a “one model fits all types” approach, which sees no differences between event types and often results in a quite skewed performance.Finding the causes of skewed performance is crucial for the robustness of an ED model, but to date there has been little exploration of this problem.This research examines the issue in depth and presents a new concept termed trigger salience attribution, which can explicitly quantify the underlying patterns of events. On this foundation, we develop a new training mechanism for ED, which can distinguish between trigger-dependent and context-dependent types and achieve promising performance on two benchmarks.Finally, by highlighting many distinct characteristics of trigger-dependent and context-dependent types, our work may promote more research into this problem.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "証拠としての顕著性：トリガー顕著性帰属によるイベント検出", "jabstract": "イベント検出（ED）は、テキスト内の特定のタイプのイベントトリガーを特定するイベント抽出の重要なサブタスクです。EDにおける重要な進歩があるにもかかわらず、既存の方法は通常、「1つのモデルがすべてのタイプに適合する」というアプローチに従っており、イベントタイプの違いを見分けることができず、しばしばかなり偏ったパフォーマンスを引き起こします。偏ったパフォーマンスの原因を見つけることは、EDモデルの堅牢性にとって重要ですが、これまでこの問題についてはほとんど探求されていませんでした。この研究では、問題を詳しく調べ、トリガーの重要性の帰属という新しい概念を提示し、明示的にイベントの基本的なパターンを定量化することができます。この基盤の上に、トリガー依存型とコンテキスト依存型を区別し、2つのベンチマークで有望なパフォーマンスを達成する新しいEDトレーニングメカニズムを開発します。最後に、トリガー依存型とコンテキスト依存型の多くの異なる特性を強調することで、私たちの仕事はこの問題に対するより多くの研究を促進するかもしれません。"}
{"title": "SRL4E – Semantic Role Labeling for Emotions: A Unified Evaluation Framework", "url": "https://aclanthology.org/2022.acl-long.314/", "abstract": "In the field of sentiment analysis, several studies have highlighted that a single sentence may express multiple, sometimes contrasting, sentiments and emotions, each with its own experiencer, target and/or cause. To this end, over the past few years researchers have started to collect and annotate data manually, in order to investigate the capabilities of automatic systems not only to distinguish between emotions, but also to capture their semantic constituents. However, currently available gold datasets are heterogeneous in size, domain, format, splits, emotion categories and role labels, making comparisons across different works difficult and hampering progress in the area. In this paper, we tackle this issue and present a unified evaluation framework focused on Semantic Role Labeling for Emotions (SRL4E), in which we unify several datasets tagged with emotions and semantic roles by using a common labeling scheme. We use SRL4E as a benchmark to evaluate how modern pretrained language models perform and analyze where we currently stand in this task, hoping to provide the tools to facilitate studies in this complex area.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SRL4E - 感情のための意味役割ラベリング：統一された評価フレームワーク", "jabstract": "感情分析の分野において、単一の文が複数の感情や感情を表現することがあり、それぞれに独自の経験者、対象、および/または原因があることがいくつかの研究で強調されています。このため、過去数年間、研究者は手動でデータを収集し、注釈を付けることで、自動システムが感情を区別するだけでなく、その意味的構成要素を捉える能力を調査するようになりました。しかし、現在利用可能なゴールドデータセットは、サイズ、ドメイン、形式、分割、感情カテゴリー、および役割ラベルにおいて異質であり、異なる作品間の比較が困難であり、この分野の進歩を妨げています。本論文では、この問題に取り組み、Semantic Role Labeling for Emotions（SRL4E）に焦点を当てた統一評価フレームワークを提供し、共通のラベリングスキームを使用して、複数の感情と意味的役割にタグ付けされたデータセットを統合します。我々は、SRL4Eをベンチマークとして使用し、現代の事前学習言語モデルがどのように機能するかを評価し、このタスクにおいて現在どのような状況にあるかを分析し、この複雑な分野の研究を容易にするためのツールを提供することを望んでいます。"}
{"title": "Context Matters: A Pragmatic Study of PLMs’ Negation Understanding", "url": "https://aclanthology.org/2022.acl-long.315/", "abstract": "In linguistics, there are two main perspectives on negation: a semantic and a pragmatic view. So far, research in NLP on negation has almost exclusively adhered to the semantic view. In this article, we adopt the pragmatic paradigm to conduct a study of negation understanding focusing on transformer-based PLMs. Our results differ from previous, semantics-based studies and therefore help to contribute a more comprehensive – and, given the results, much more optimistic – picture of the PLMs’ negation understanding.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文脈が重要：PLMの否定理解に関する実用的研究", "jabstract": "言語学において、否定に関する2つの主要な視点がある：意味論的視点と実用論的視点である。これまで、NLPにおける否定に関する研究はほぼすべて意味論的視点に従ってきた。本論文では、実用論的パラダイムを採用して、トランスフォーマーベースのPLMに焦点を当てた否定理解の研究を行う。我々の結果は、これまでの意味論的な研究とは異なり、PLMの否定理解に関するより包括的で、結果から判断すると楽観的な見方を提供する。"}
{"title": "Probing for Predicate Argument Structures in Pretrained Language Models", "url": "https://aclanthology.org/2022.acl-long.316/", "abstract": "Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependency- and span-based, multilingual and cross-lingual Semantic Role Labeling (SRL). These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL. In this paper, we follow this line of research and probe for predicate argument structures in PLMs. Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages. Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルにおける述語引数構造の探索", "jabstract": "現代の事前学習済み言語モデル（PLMs）の効果的かつ広範な利用のおかげで、最近提案されたアプローチは、依存構造やスパンベース、多言語およびクロスリンガルの意味役割ラベリング（SRL）において驚くべき結果を達成しています。これらの結果は、研究者が現代のPLMsの内部機能を調査し、SRLに関する情報をどのように、どこに、どの程度エンコードするかを理解することを目的としています。本論文では、この研究の流れに従い、PLMs内の述語引数構造を探求します。私たちの研究は、PLMsが述語の文脈化表現に直接意味構造をエンコードすることを示し、また述語の意味とその構造の相関関係、名詞と動詞の構造の転移可能性の程度、およびそのような構造が言語間でどのようにエンコードされるかについての洞察を提供します。最後に、このような洞察の実用的な意義を検討し、述語引数構造情報をSRLモデルに埋め込むことの利点を示します。"}
{"title": "Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction", "url": "https://aclanthology.org/2022.acl-long.317/", "abstract": "We present a study on leveraging multilingual pre-trained generative language models for zero-shot cross-lingual event argument extraction (EAE). By formulating EAE as a language generation task, our method effectively encodes event structures and captures the dependencies between arguments. We design language-agnostic templates to represent the event argument structures, which are compatible with any language, hence facilitating the cross-lingual transfer. Our proposed model finetunes multilingual pre-trained generative language models to generate sentences that fill in the language-agnostic template with arguments extracted from the input passage. The model is trained on source languages and is then directly applied to target languages for event argument extraction. Experiments demonstrate that the proposed model outperforms the current state-of-the-art models on zero-shot cross-lingual EAE. Comprehensive studies and error analyses are presented to better understand the advantages and the current limitations of using generative language models for zero-shot cross-lingual transfer EAE.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ゼロショットクロスリンガルイベント引数抽出のための多言語生成言語モデル", "jabstract": "私たちは、多言語事前学習生成言語モデルを活用したゼロショットクロスリンガルイベント引数抽出（EAE）に関する研究を発表します。EAEを言語生成タスクとして定式化することにより、私たちの方法は効果的にイベント構造をエンコードし、引数間の依存関係を捉えます。私たちは、任意の言語に対応可能な言語非依存テンプレートを設計し、イベント引数構造を表現します。これにより、クロスリンガル転送が容易になります。私たちの提案モデルは、入力パッセージから抽出された引数を言語非依存テンプレートに埋め込む文を生成するために、多言語事前学習生成言語モデルを微調整します。モデルはソース言語でトレーニングされ、その後、ターゲット言語で直接イベント引数抽出に適用されます。実験により、提案モデルがゼロショットクロスリンガルEAEにおいて現在の最先端モデルを上回ることが示されました。包括的な研究とエラー分析が提示され、生成言語モデルを使用したゼロショットクロスリンガル転送EAEの利点と現在の制限をよりよく理解するためのものです。"}
{"title": "Identifying Moments of Change from Longitudinal User Text", "url": "https://aclanthology.org/2022.acl-long.318/", "abstract": "Identifying changes in individuals’ behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance. Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level. A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual’s trajectory and allowing timely interventions. Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online. The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations). We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts). We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling. We also introduce new metrics for capturing rare events in temporal windows.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "データからの変化の瞬間の特定に関する論文の要約文を日本語に翻訳します。", "jabstract": "オンラインプラットフォームで共有されるコンテンツを通じて、個人の行動や気分の変化を特定することが、ますます重要になっています。これまでの研究の多くは、(a) 投稿の一括に基づいてリスクのある個人や特定の精神的健康状態を特定するか、(b) 投稿レベルで同等のラベルを提供することに焦点を当てています。このような研究の欠点は、強い時間的要素の欠如と、個人の軌跡に沿った長期的な評価とタイムリーな介入を許さないことです。ここでは、オンラインで共有されるコンテンツに基づいて、個人の変化の瞬間を特定する新しいタスクを定義します。私たちが考慮する変化は、気分の急激な変化（スイッチ）または徐々に進行する気分の進行（エスカレーション）です。私たちは、変化の瞬間を捉えるための詳細なガイドラインと、500の手動注釈付きユーザータイムライン（18.7Kの投稿）のコーパスを作成しました。関連するタスクからインスピレーションを得たさまざまなベースラインモデルを開発し、文脈に応じたシーケンシャルモデリングによる最高のパフォーマンスが得られることを示しました。また、時間的ウィンドウで稀なイベントを捉えるための新しいメトリックを紹介しました。"}
{"title": "Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System", "url": "https://aclanthology.org/2022.acl-long.319/", "abstract": "Pre-trained language models have been recently shown to benefit task-oriented dialogue (TOD) systems. Despite their success, existing methods often formulate this task as a cascaded generation problem which can lead to error accumulation across different sub-tasks and greater data annotation overhead. In this study, we present PPTOD, a unified plug-and-play model for task-oriented dialogue. In addition, we introduce a new dialogue multi-task pre-training strategy that allows the model to learn the primary TOD task completion skills from heterogeneous dialog corpora. We extensively test our model on three benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification. Experimental results show that PPTOD achieves new state of the art on all evaluated tasks in both high-resource and low-resource scenarios. Furthermore, comparisons against previous SOTA methods show that the responses generated by PPTOD are more factually correct and semantically coherent as judged by human annotators.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「プラグアンドプレイタスク指向型対話システムのためのマルチタスク事前学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System\n- プラグアンドプレイタスク指向型対話システムのためのマルチタスク事前学習", "jabstract": "最近、事前学習された言語モデルは、タスク指向型対話（TOD）システムに利益をもたらすことが示されています。しかし、既存の方法は、このタスクを段階的な生成問題として定式化するため、異なるサブタスク間でのエラー蓄積や、より大きなデータ注釈のオーバーヘッドを引き起こす可能性があります。本研究では、タスク指向型対話のための統合型プラグアンドプレイモデルであるPPTODを提案します。さらに、異種の対話コーパスから主要なTODタスク完了スキルを学習することを可能にする新しい対話マルチタスク事前学習戦略を紹介します。私たちは、エンドツーエンドの対話モデリング、対話状態追跡、意図分類を含む3つのベンチマークTODタスクでモデルを広範にテストしました。実験結果は、PPTODが高リソースおよび低リソースの両方のシナリオで、すべての評価タスクで新しい最高水準を達成していることを示しています。さらに、以前のSOTA方法との比較では、PPTODによって生成された応答が、人間の注釈者によって判断されたより事実的に正確で意味的に整合性があることが示されています。"}
{"title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization", "url": "https://aclanthology.org/2022.acl-long.320/", "abstract": "The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "放射線学所見の要約のためのグラフ強化対照学習", "jabstract": "放射線学レポートの印象セクションは、所見セクションから最も顕著な観察を要約し、医師に伝えるために放射線科医にとって最も重要なセクションです。所見の要約は時間がかかり、経験の浅い放射線科医にとっては誤りが生じる可能性があり、自動的な印象生成は大きな注目を集めています。エンコーダ・デコーダのフレームワークを用いて、以前の多くの研究では、追加の知識（例えば、静的な事前定義の臨床オントロジーや追加の背景情報）を組み込むことが探求されてきました。しかし、彼らはそのような知識を別々のエンコーダでエンコードして、モデルへの追加の入力として扱っており、元の所見との関係を活用することに限界があります。この限界に対処するために、我々は追加の知識と元の所見を統合的に活用するための統一されたフレームワークを提案し、重要な情報（つまり、キーワードとその関係）を適切に抽出して印象生成を促進することができます。詳細には、各入力所見について、テキストエンコーダによってエンコードされ、そのエンティティと依存構造木を通じてグラフが構築されます。次に、グラフエンコーダ（例えば、グラフニューラルネットワーク（GNN））が構築されたグラフ内の関係情報をモデル化するために採用されます。最後に、所見のキーワードを強調するために、コントラスティブラーニングが導入され、非キーワードをマスキングして構築された正のサンプルを近づけ、キーワードをマスキングして構築された負のサンプルを遠ざけます。OpenIとMIMIC-CXRの2つのデータセットでの実験結果は、提案された方法の有効性を確認し、最先端の結果が得られました。"}
{"title": "Semi-Supervised Formality Style Transfer with Consistency Training", "url": "https://aclanthology.org/2022.acl-long.321/", "abstract": "Formality style transfer (FST) is a task that involves paraphrasing an informal sentence into a formal one without altering its meaning. To address the data-scarcity problem of existing parallel datasets, previous studies tend to adopt a cycle-reconstruction scheme to utilize additional unlabeled data, where the FST model mainly benefits from target-side unlabeled sentences. In this work, we propose a simple yet effective semi-supervised framework to better utilize source-side unlabeled sentences based on consistency training. Specifically, our approach augments pseudo-parallel data obtained from a source-side informal sentence by enforcing the model to generate similar outputs for its perturbed version. Moreover, we empirically examined the effects of various data perturbation methods and propose effective data filtering strategies to improve our framework. Experimental results on the GYAFC benchmark demonstrate that our approach can achieve state-of-the-art results, even with less than 40% of the parallel data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "一貫性トレーニングを用いた半教師ありフォーマリティスタイル転送", "jabstract": "フォーマルスタイル転送（FST）は、意味を変えずに非公式な文を公式な文に言い換えるタスクである。既存の並列データセットのデータ不足問題に対処するため、以前の研究では、FSTモデルが主にターゲット側の非ラベル文から利益を得るために、サイクル再構築スキームを採用する傾向があった。本研究では、一貫性トレーニングに基づくシンプルで効果的な半教師ありフレームワークを提案し、ソース側の非ラベル文をより効果的に利用することを目的としている。具体的には、アプローチは、モデルがその摂動バージョンの類似した出力を生成するように強制することによって、ソース側の非公式な文から得られた疑似並列データを拡張する。さらに、さまざまなデータ摂動方法の効果を実証的に検討し、フレームワークを改善するための効果的なデータフィルタリング戦略を提案する。 GYAFCベンチマークの実験結果は、40％未満の並列データでも最先端の結果を達成できることを示している。"}
{"title": "Cross-Lingual Ability of Multilingual Masked Language Models: A Study of Language Structure", "url": "https://aclanthology.org/2022.acl-long.322/", "abstract": "Multilingual pre-trained language models, such as mBERT and XLM-R, have shown impressive cross-lingual ability. Surprisingly, both of them use multilingual masked language model (MLM) without any cross-lingual supervision or aligned data. Despite the encouraging results, we still lack a clear understanding of why cross-lingual ability could emerge from multilingual MLM. In our work, we argue that cross-language ability comes from the commonality between languages. Specifically, we study three language properties: constituent order, composition and word co-occurrence. First, we create an artificial language by modifying property in source language. Then we study the contribution of modified property through the change of cross-language transfer results on target language. We conduct experiments on six languages and two cross-lingual NLP tasks (textual entailment, sentence retrieval). Our main conclusion is that the contribution of constituent order and word co-occurrence is limited, while the composition is more crucial to the success of cross-linguistic transfer.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語マスク言語モデルのクロスリンガル能力：言語構造の研究", "jabstract": "多言語事前学習言語モデルであるmBERTやXLM-Rなどは、印象的なクロスリンガル能力を示しています。驚くべきことに、両方ともクロスリンガルな監視や整合されたデータなしで、多言語マスク言語モデル（MLM）を使用しています。励ましの結果にもかかわらず、私たちはまだ、なぜ多言語MLMからクロスリンガル能力が生じるのかについて明確な理解を欠いています。私たちの研究では、クロス言語能力は言語間の共通点から生じると主張しています。具体的には、構成順序、構成、および単語共起の3つの言語特性を研究します。まず、ソース言語の特性を変更して人工言語を作成します。次に、変更された特性の貢献を、ターゲット言語におけるクロス言語転送結果の変化を通じて研究します。6つの言語と2つのクロスリンガルNLPタスク（テキストエンテイルメント、文の検索）で実験を行います。私たちの主な結論は、構成順序と単語共起の貢献は限定的であり、構成がクロス言語転送の成功により重要であるということです。"}
{"title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting", "url": "https://aclanthology.org/2022.acl-long.323/", "abstract": "Word sense disambiguation (WSD) is a crucial problem in the natural language processing (NLP) community. Current methods achieve decent performance by utilizing supervised learning and large pre-trained language models. However, the imbalanced training dataset leads to poor performance on rare senses and zero-shot senses. There are more training instances and senses for words with top frequency ranks than those with low frequency ranks in the training dataset. We investigate the statistical relation between word frequency rank and word sense number distribution. Based on the relation, we propose a Z-reweighting method on the word level to adjust the training on the imbalanced dataset. The experiments show that the Z-reweighting strategy achieves performance gain on the standard English all words WSD benchmark. Moreover, the strategy can help models generalize better on rare and zero-shot senses.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Z-Reweightingを用いた稀少およびゼロショットの単語意味曖昧性解消」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting\n- Z-Reweightingを用いた稀少およびゼロショットの単語意味曖昧性解消", "jabstract": "単語意味の曖昧さ解消（WSD）は、自然言語処理（NLP）コミュニティにおける重要な問題です。現在の方法は、教師あり学習と大規模な事前学習言語モデルを利用することで、まずまずの性能を発揮しています。しかし、訓練データセットの不均衡は、稀な意味やゼロショットの意味に対して性能が低下する原因となります。訓練データセットにおいて、上位頻度ランクの単語には、下位頻度ランクの単語よりも多くの訓練インスタンスと意味があります。我々は、単語頻度ランクと単語意味数分布の統計的関係を調査しました。この関係に基づいて、我々は単語レベルでのZ重み付け法を提案し、不均衡なデータセットの訓練を調整します。実験結果は、Z重み付け戦略が標準的な英語全単語WSDベンチマークで性能向上を達成することを示しています。さらに、この戦略は、モデルが稀な意味やゼロショットの意味に対してより汎化性能を発揮するのに役立ちます。"}
{"title": "Nibbling at the Hard Core of Word Sense Disambiguation", "url": "https://aclanthology.org/2022.acl-long.324/", "abstract": "With state-of-the-art systems having finally attained estimated human performance, Word Sense Disambiguation (WSD) has now joined the array of Natural Language Processing tasks that have seemingly been solved, thanks to the vast amounts of knowledge encoded into Transformer-based pre-trained language models. And yet, if we look below the surface of raw figures, it is easy to realize that current approaches still make trivial mistakes that a human would never make. In this work, we provide evidence showing why the F1 score metric should not simply be taken at face value and present an exhaustive analysis of the errors that seven of the most representative state-of-the-art systems for English all-words WSD make on traditional evaluation benchmarks.In addition, we produce and release a collection of test sets featuring (a) an amended version of the standard evaluation benchmark that fixes its lexical and semantic inaccuracies, (b) 42D, a challenge set devised to assess the resilience of systems with respect to least frequent word senses and senses not seen at training time, and (c) hardEN, a challenge set made up solely of instances which none of the investigated state-of-the-art systems can solve. We make all of the test sets and model predictions available to the research community at https://github.com/SapienzaNLP/wsd-hard-benchmark.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "単語意味の曖昧さ解消の核心にかじりつく", "jabstract": "最新のシステムが推定される人間のパフォーマンスに達したことで、単語意味曖昧性解消（WSD）は、Transformerベースの事前学習言語モデルにエンコードされた膨大な知識のおかげで解決されたように見える自然言語処理タスクの一つに加わりました。しかし、生の数字の下に見ると、現在のアプローチは、人間が決して犯さない些細なミスをまだ犯していることが容易にわかります。本研究では、F1スコアメトリックが単純に顔に取られるべきではない理由を示し、英語全単語WSDの最も代表的な7つの最新システムが従来の評価ベンチマークでどのようなエラーを犯すかについて徹底的な分析を提供します。さらに、（a）その語彙的および意味的な不正確さを修正した標準評価ベンチマークの修正版、（b）トレーニング時に見られない最も頻度の低い単語意味と意味に対するシステムの強靭性を評価するために考案されたチャレンジセットである42D、および（c）調査された最新のシステムのどれも解決できないインスタンスだけで構成されたチャレンジセットであるhardENを特集するテストセットのコレクションを作成してリリースします。すべてのテストセットとモデル予測をhttps://github.com/SapienzaNLP/wsd-hard-benchmarkで研究コミュニティに提供します。"}
{"title": "Large Scale Substitution-based Word Sense Induction", "url": "https://aclanthology.org/2022.acl-long.325/", "abstract": "We present a word-sense induction method based on pre-trained masked language models (MLMs), which can cheaply scale to large vocabularies and large corpora. The result is a corpus which is sense-tagged according to a corpus-derived sense inventory and where each sense is associated with indicative words. Evaluation on English Wikipedia that was sense-tagged using our method shows that both the induced senses, and the per-instance sense assignment, are of high quality even compared to WSD methods, such as Babelfy. Furthermore, by training a static word embeddings algorithm on the sense-tagged corpus, we obtain high-quality static senseful embeddings. These outperform existing senseful embeddings methods on the WiC dataset and on a new outlier detection dataset we developed. The data driven nature of the algorithm allows to induce corpora-specific senses, which may not appear in standard sense inventories, as we demonstrate using a case study on the scientific domain.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "大規模な置換に基づく単語意味誘導", "jabstract": "私たちは、大規模な語彙とコーパスに安価にスケーリングできる、事前にトレーニングされたマスクされた言語モデル（MLM）に基づく単語意味誘導方法を提案します。その結果、コーパスは、コーパス由来の意味インベントリに従って意味タグ付けされ、各意味に示唆的な単語が関連付けられたものになります。私たちの方法を使用して意味タグ付けされた英語のWikipediaでの評価では、誘導された意味と各インスタンスの意味割り当てが、BabelfyなどのWSD方法と比較しても高品質であることが示されました。さらに、意味タグ付けされたコーパスで静的な単語埋め込みアルゴリズムをトレーニングすることにより、高品質の静的な意味を持つ埋め込みを得ることができます。これらは、WiCデータセットや、私たちが開発した新しい外れ値検出データセットで、既存の意味を持つ埋め込み方法よりも優れています。アルゴリズムのデータ駆動型の性質により、科学分野の事例研究を使用して示されるように、標準的な意味インベントリには現れないコーパス固有の意味を誘導することができます。"}
{"title": "Can Synthetic Translations Improve Bitext Quality?", "url": "https://aclanthology.org/2022.acl-long.326/", "abstract": "Synthetic translations have been used for a wide range of NLP tasks primarily as a means of data augmentation. This work explores, instead, how synthetic translations can be used to revise potentially imperfect reference translations in mined bitext. We find that synthetic samples can improve bitext quality without any additional bilingual supervision when they replace the originals based on a semantic equivalence classifier that helps mitigate NMT noise. The improved quality of the revised bitext is confirmed intrinsically via human evaluation and extrinsically through bilingual induction and MT tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "合成翻訳はバイテキストの品質を向上させることができるか？", "jabstract": "合成翻訳は、主にデータ拡張の手段として、広範なNLPタスクに使用されてきました。この研究では、代わりに、合成翻訳が、採掘されたバイリンガルテキスト内の潜在的に不完全な参照翻訳を修正するためにどのように使用できるかを探求しています。我々は、合成サンプルが、NMTノイズを緩和するために役立つ意味的等価分類器に基づいて、元のテキストを置き換える場合、追加のバイリンガル監視なしで、ビットキストの品質を改善できることを発見しました。改訂されたビットキストの改善された品質は、人間の評価によって内在的に確認され、バイリンガル誘導およびMTタスクを通じて外在的に確認されます。"}
{"title": "Unsupervised Dependency Graph Network", "url": "https://aclanthology.org/2022.acl-long.327/", "abstract": "Recent work has identified properties of pretrained self-attention models that mirror those of dependency parse structures. In particular, some self-attention heads correspond well to individual dependency types. Inspired by these developments, we propose a new competitive mechanism that encourages these attention heads to model different dependency relations. We introduce a new model, the Unsupervised Dependency Graph Network (UDGN), that can induce dependency structures from raw corpora and the masked language modeling task. Experiment results show that UDGN achieves very strong unsupervised dependency parsing performance without gold POS tags and any other external information. The competitive gated heads show a strong correlation with human-annotated dependency types. Furthermore, the UDGN can also achieve competitive performance on masked language modeling and sentence textual similarity tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Natural Language Processingに関する論文の要約文を日本語に翻訳してください。\n\n非監督学習の依存グラフネットワーク", "jabstract": "最近の研究では、事前学習された自己注意モデルの特性が依存構文構造と類似していることが明らかになっています。特に、一部の自己注意ヘッドは個々の依存関係タイプによく対応しています。これらの進展に着想を得て、我々はこれらの注意ヘッドが異なる依存関係をモデル化するように促す新しい競争メカニズムを提案します。我々は、生のコーパスとマスクされた言語モデリングタスクから依存構造を誘導できる新しいモデル、Unsupervised Dependency Graph Network（UDGN）を紹介します。実験結果は、UDGNが金のPOSタグや他の外部情報なしで非常に強力な非監視型依存解析性能を達成することを示しています。競争ゲートヘッドは、人間による注釈付き依存関係タイプと強い相関があります。さらに、UDGNはマスクされた言語モデリングと文のテキスト類似性タスクでも競争力のあるパフォーマンスを発揮することができます。"}
{"title": "WikiDiverse: A Multimodal Entity Linking Dataset with Diversified Contextual Topics and Entity Types", "url": "https://aclanthology.org/2022.acl-long.328/", "abstract": "Multimodal Entity Linking (MEL) which aims at linking mentions with multimodal contexts to the referent entities from a knowledge base (e.g., Wikipedia), is an essential task for many multimodal applications. Although much attention has been paid to MEL, the shortcomings of existing MEL datasets including limited contextual topics and entity types, simplified mention ambiguity, and restricted availability, have caused great obstacles to the research and application of MEL. In this paper, we present WikiDiverse, a high-quality human-annotated MEL dataset with diversified contextual topics and entity types from Wikinews, which uses Wikipedia as the corresponding knowledge base. A well-tailored annotation procedure is adopted to ensure the quality of the dataset. Based on WikiDiverse, a sequence of well-designed MEL models with intra-modality and inter-modality attentions are implemented, which utilize the visual information of images more adequately than existing MEL models do. Extensive experimental analyses are conducted to investigate the contributions of different modalities in terms of MEL, facilitating the future research on this task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「WikiDiverse：多様な文脈的トピックとエンティティタイプを持つマルチモーダルエンティティリンキングデータセット」", "jabstract": "多様なコンテキストとエンティティタイプを持つWikiDiverseという高品質の人手によるMELデータセットを提供し、そのデータセットを用いて、視覚情報をより適切に利用するように設計された一連のMELモデルを実装した。WikiDiverseは、Wikipediaを対応する知識ベースとして使用し、限られたコンテキストトピックとエンティティタイプ、簡略化された言及の曖昧さ、制限された利用可能性など、既存のMELデータセットの欠点を克服するために採用された適切な注釈手順によって品質が保証されている。異なるモダリティの貢献を調査するために、広範な実験分析が行われ、このタスクに関する将来の研究を促進する。"}
{"title": "Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.329/", "abstract": "Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs). Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored. To facilitate this, we release a well-curated biomedical knowledge probing benchmark, MedLAMA, constructed based on the Unified Medical Language System (UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs and probing approaches on our benchmark, reaching at most 3% of acc@10. While highlighting various sources of domain-specific challenges that amount to this underwhelming performance, we illustrate that the underlying PLMs have a higher potential for probing tasks. To achieve this, we propose Contrastive-Probe, a novel self-supervised contrastive probing approach, that adjusts the underlying PLMs without using any probing data. While Contrastive-Probe pushes the acc@10 to 28%, the performance gap still remains notable. Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS still does not include the full spectrum of factual knowledge. We hope MedLAMA and Contrastive-Probe facilitate further developments of more suited probing techniques for this domain. Our code and dataset are publicly available at https://github.com/cambridgeltl/medlama.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Rewire-then-Probe：事前学習済み言語モデルのバイオメディカル知識を探査するための対照的なレシピ」という論文の要約文です。日本語に翻訳してください。", "jabstract": "プレトレーニング言語モデル（PLM）の知識転移メカニズムを理解するためには、知識探査が重要です。一般的なドメインにおけるPLMの知識探査の進展にもかかわらず、バイオメディカルドメインのような専門分野は未だに十分に探査されていません。このために、Unified Medical Language System（UMLS）メタサウルスに基づいて構築された、よく整備されたバイオメディカル知識探査ベンチマークであるMedLAMAを公開します。我々は、最先端のPLMと探査手法を広範囲にテストし、最大でacc@10の3%に到達しました。この低い性能につながるドメイン固有の課題の様々な源を強調しながら、基礎となるPLMにはより高い探査タスクの可能性があることを示します。これを実現するために、探査データを使用せずに基礎となるPLMを調整する新しい自己教師あり対照探査アプローチであるContrastive-Probeを提案します。Contrastive-Probeはacc@10を28%まで押し上げますが、性能差はまだ顕著です。人間の専門家による評価では、UMLSにはまだ事実知識の全スペクトルが含まれていないため、Contrastive-Probeの探査性能は依然として過小評価されていると考えられます。MedLAMAとContrastive-Probeが、このドメインに適した探査技術のさらなる開発を促進することを願っています。我々のコードとデータセットは、https://github.com/cambridgeltl/medlamaで公開されています。"}
{"title": "Fine- and Coarse-Granularity Hybrid Self-Attention for Efficient BERT", "url": "https://aclanthology.org/2022.acl-long.330/", "abstract": "Transformer-based pre-trained models, such as BERT, have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications. However, deploying these models can be prohibitively costly, as the standard self-attention mechanism of the Transformer suffers from quadratic computational cost in the input sequence length. To confront this, we propose FCA, a fine- and coarse-granularity hybrid self-attention that reduces the computation cost through progressively shortening the computational sequence length in self-attention. Specifically, FCA conducts an attention-based scoring strategy to determine the informativeness of tokens at each layer. Then, the informative tokens serve as the fine-granularity computing units in self-attention and the uninformative tokens are replaced with one or several clusters as the coarse-granularity computing units in self-attention. Experiments on the standard GLUE benchmark show that BERT with FCA achieves 2x reduction in FLOPs over original BERT with <1% loss in accuracy. We show that FCA offers a significantly better trade-off between accuracy and FLOPs compared to prior methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n効率的なBERTのための細かい粒度と粗い粒度のハイブリッド自己注意力", "jabstract": "Transformerベースの事前学習モデル（BERTなど）は、多くの自然言語処理アプリケーションで最先端の結果を達成することができるという驚異的な成功を示しています。しかし、これらのモデルを展開することは、Transformerの標準的な自己注意メカニズムが入力シーケンスの長さに対して二次計算コストを持つため、極めて高価になる可能性があります。これに対処するために、私たちはFCAを提案します。FCAは、自己注意において計算シーケンスの長さを段階的に短くすることで計算コストを削減する、細かい粒度と粗い粒度のハイブリッド自己注意です。具体的には、FCAは、各層でトークンの情報量を決定するための注意ベースのスコアリング戦略を実行します。次に、情報量の多いトークンは自己注意において細かい粒度の計算単位として機能し、情報量の少ないトークンは、1つまたは複数のクラスターに置き換えて粗い粒度の計算単位として機能します。標準的なGLUEベンチマークでの実験結果は、FCAを使用したBERTが、元のBERTに比べてFLOPsを2倍削減し、精度の損失が1％未満であることを示しています。私たちは、FCAが従来の方法と比較して、精度とFLOPsのトレードオフを大幅に改善することを示しています。"}
{"title": "Compression of Generative Pre-trained Language Models via Quantization", "url": "https://aclanthology.org/2022.acl-long.331/", "abstract": "The increasing size of generative Pre-trained Language Models (PLMs) have greatly increased the demand for model compression. Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear. In this paper, we compress generative PLMs by quantization. We find that previous quantization methods fail on generative tasks due to the homogeneous word embeddings caused by reduced capacity and the varied distribution of weights. Correspondingly, we propose a token-level contrastive distillation to learn distinguishable word embeddings, and a module-wise dynamic scaling to make quantizers adaptive to different modules. Empirical results on various tasks show that our proposed method outperforms the state-of-the-art compression methods on generative PLMs by a clear margin. With comparable performance with the full-precision models, we achieve 14.4x and 13.4x compression rate on GPT-2 and BART, respectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「生成事前学習言語モデルの圧縮における量子化」は、自然言語処理に関する論文の要約です。", "jabstract": "生成的Pre-trained Language Models（PLMs）のサイズが増加するにつれて、モデルの圧縮の需要が大幅に増加しています。BERTまたはその派生物を圧縮するためのさまざまな方法があるにもかかわらず、生成的PLMsを圧縮する試みはほとんどなく、その基礎的な難しさは不明です。本論文では、量子化によって生成的PLMsを圧縮します。我々は、容量の低下によって引き起こされる均質な単語埋め込みと重みの異なる分布により、以前の量子化方法が生成的タスクで失敗することを発見しました。それに応じて、区別可能な単語埋め込みを学習するためのトークンレベルの対照的な蒸留と、量子化器を異なるモジュールに適応させるためのモジュールごとの動的スケーリングを提案します。さまざまなタスクでの実証結果は、提案された方法が生成的PLMsにおいて最先端の圧縮方法を大幅に上回ることを示しています。フルプレシジョンモデルと同等の性能を持ち、GPT-2とBARTでそれぞれ14.4倍と13.4倍の圧縮率を達成しました。"}
{"title": "Visual-Language Navigation Pretraining via Prompt-based Environmental Self-exploration", "url": "https://aclanthology.org/2022.acl-long.332/", "abstract": "Vision-language navigation (VLN) is a challenging task due to its large searching space in the environment. To address this problem, previous works have proposed some methods of fine-tuning a large model that pretrained on large-scale datasets. However, the conventional fine-tuning methods require extra human-labeled navigation data and lack self-exploration capabilities in environments, which hinders their generalization of unseen scenes. To improve the ability of fast cross-domain adaptation, we propose Prompt-based Environmental Self-exploration (ProbES), which can self-explore the environments by sampling trajectories and automatically generates structured instructions via a large-scale cross-modal pretrained model (CLIP). Our method fully utilizes the knowledge learned from CLIP to build an in-domain dataset by self-exploration without human labeling. Unlike the conventional approach of fine-tuning, we introduce prompt tuning to achieve fast adaptation for language embeddings, which substantially improves the learning efficiency by leveraging prior knowledge. By automatically synthesizing trajectory-instruction pairs in any environment without human supervision and instruction prompt tuning, our model can adapt to diverse vision-language navigation tasks, including VLN and REVERIE. Both qualitative and quantitative results show that our ProbES significantly improves the generalization ability of the navigation model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「プロンプトに基づく環境自己探索を通じた視覚言語ナビゲーションの事前学習」についての論文の要約です。", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n環境内の大きな探索空間のため、ビジョン・ランゲージ・ナビゲーション（VLN）は困難なタスクである。この問題に対処するため、以前の研究では、大規模なデータセットで事前学習された大規模なモデルを微調整するいくつかの方法が提案されてきた。しかし、従来の微調整方法は、追加の人間によるラベル付けナビゲーションデータが必要であり、環境内の自己探索能力が欠如しているため、未知のシーンの一般化を妨げている。クロスドメイン適応の能力を向上させるために、Prompt-based Environmental Self-exploration（ProbES）を提案し、軌跡をサンプリングして環境を自己探索し、大規模なクロスモーダル事前学習モデル（CLIP）を介して構造化された指示を自動生成することができる。当社の方法は、人間のラベル付けなしに自己探索によってドメイン内データセットを構築するため、CLIPから学習した知識を完全に活用する。従来の微調整アプローチとは異なり、プロンプトチューニングを導入して言語埋め込みの高速適応を実現し、事前知識を活用して学習効率を大幅に改善する。人間の監督や指示プロンプトチューニングなしで、どの環境でも軌跡-指示ペアを自動合成することにより、当社のモデルはVLNやREVERIEを含む多様なビジョン・ランゲージ・ナビゲーションタスクに適応することができる。定性的および定量的な結果の両方が、当社のProbESがナビゲーションモデルの一般化能力を大幅に改善することを示している。"}
{"title": "DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation", "url": "https://aclanthology.org/2022.acl-long.333/", "abstract": "Dialog response generation in open domain is an important research topic where the main challenge is to generate relevant and diverse responses. In this paper, we propose a new dialog pre-training framework called DialogVED, which introduces continuous latent variables into the enhanced encoder-decoder pre-training framework to increase the relevance and diversity of responses. With the help of a large dialog corpus (Reddit), we pre-train the model using the following 4 tasks, used in training language models (LMs) and Variational Autoencoders (VAEs) literature: 1) masked language model; 2) response generation; 3) bag-of-words prediction; and 4) KL divergence reduction. We also add additional parameters to model the turn structure in dialogs to improve the performance of the pre-trained model. We conduct experiments on PersonaChat, DailyDialog, and DSTC7-AVSD benchmarks for response generation. Experimental results show that our model achieves the new state-of-the-art results on all these datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DialogVED：対話応答生成のための事前学習された潜在変数エンコーダ・デコーダモデル", "jabstract": "オープンドメインにおける対話応答生成は、関連性と多様性のある応答を生成することが主な課題である重要な研究トピックである。本論文では、DialogVEDと呼ばれる新しい対話事前学習フレームワークを提案し、強化エンコーダ・デコーダ事前学習フレームワークに連続的な潜在変数を導入して、応答の関連性と多様性を高める。Redditという大規模な対話コーパスを用いて、言語モデル（LMs）と変分オートエンコーダ（VAEs）の文献で使用される以下の4つのタスクを使用してモデルを事前学習する：1）マスクされた言語モデル、2）応答生成、3）単語袋の予測、および4）KLダイバージェンスの削減。また、対話のターン構造をモデル化するための追加のパラメータを追加して、事前学習モデルの性能を改善する。PersonaChat、DailyDialog、およびDSTC7-AVSDベンチマークで応答生成の実験を行った。実験結果は、当社のモデルがこれらのデータセットすべてで新しい最高の結果を達成したことを示している。"}
{"title": "Contextual Fine-to-Coarse Distillation for Coarse-grained Response Selection in Open-Domain Conversations", "url": "https://aclanthology.org/2022.acl-long.334/", "abstract": "We study the problem of coarse-grained response selection in retrieval-based dialogue systems. The problem is equally important with fine-grained response selection, but is less explored in existing literature. In this paper, we propose a Contextual Fine-to-Coarse (CFC) distilled model for coarse-grained response selection in open-domain conversations. In our CFC model, dense representations of query, candidate contexts and responses is learned based on the multi-tower architecture using contextual matching, and richer knowledge learned from the one-tower architecture (fine-grained) is distilled into the multi-tower architecture (coarse-grained) to enhance the performance of the retriever. To evaluate the performance of the proposed model, we construct two new datasets based on the Reddit comments dump and Twitter corpus. Extensive experimental results on the two datasets show that the proposed method achieves huge improvement over all evaluation metrics compared with traditional baseline methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オープンドメインの会話における粗いグレインの応答選択のための文脈に基づく細かいから粗い蒸留。", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n本研究では、検索ベースの対話システムにおける粗いレスポンス選択の問題を研究しています。この問題は、細かいレスポンス選択と同じくらい重要ですが、既存の文献ではあまり探究されていません。本論文では、オープンドメインの会話における粗いレスポンス選択のためのコンテキスト依存型ファイン・トゥ・コース（CFC）蒸留モデルを提案します。CFCモデルでは、コンテキストマッチングを用いたマルチタワーアーキテクチャに基づいて、クエリ、候補コンテキスト、レスポンスの密な表現を学習し、1つのタワーアーキテクチャ（細かい粒度）から学習されたより豊富な知識をマルチタワーアーキテクチャ（粗い粒度）に蒸留して、リトリーバーの性能を向上させます。提案されたモデルの性能を評価するために、RedditコメントダンプとTwitterコーパスに基づく2つの新しいデータセットを構築しました。2つのデータセットでの広範な実験結果は、提案手法が従来のベースライン手法と比較して、すべての評価指標で大幅な改善を達成したことを示しています。"}
{"title": "Textomics: A Dataset for Genomics Data Summary Generation", "url": "https://aclanthology.org/2022.acl-long.335/", "abstract": "Summarizing biomedical discovery from genomics data using natural languages is an essential step in biomedical research but is mostly done manually. Here, we introduce Textomics, a novel dataset of genomics data description, which contains 22,273 pairs of genomics data matrices and their summaries. Each summary is written by the researchers who generated the data and associated with a scientific paper. Based on this dataset, we study two novel tasks: generating textual summary from a genomics data matrix and vice versa. Inspired by the successful applications of k nearest neighbors in modeling genomics data, we propose a kNN-Vec2Text model to address these tasks and observe substantial improvement on our dataset. We further illustrate how Textomics can be used to advance other applications, including evaluating scientific paper embeddings and generating masked templates for scientific paper understanding. Textomics serves as the first benchmark for generating textual summaries for genomics data and we envision it will be broadly applied to other biomedical and natural language processing applications.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストミクス：ゲノミクスデータの要約生成のためのデータセット", "jabstract": "自然言語処理を用いたバイオメディカル・ジェノミクスデータからの発見の要約は、バイオメディカル研究において重要なステップであるが、ほとんど手動で行われている。本研究では、22,273ペアのジェノミクスデータ行列とその要約を含む、新しいデータセットであるTextomicsを紹介する。各要約は、データを生成した研究者によって書かれ、科学論文に関連付けられている。このデータセットを基に、ジェノミクスデータ行列からテキスト要約を生成するタスクとその逆のタスクを研究する。ジェノミクスデータのモデリングにおけるk最近傍法の成功した応用に着想を得て、kNN-Vec2Textモデルを提案し、データセットで大幅な改善を観察する。さらに、Textomicsが科学論文の埋め込みの評価や、科学論文理解のためのマスクされたテンプレートの生成など、他のアプリケーションの進歩にどのように役立つかを説明する。Textomicsは、ジェノミクスデータのテキスト要約を生成するための最初のベンチマークとして機能し、他のバイオメディカルおよび自然言語処理アプリケーションに広く適用されることを期待している。"}
{"title": "A Contrastive Framework for Learning Sentence Representations from Pairwise and Triple-wise Perspective in Angular Space", "url": "https://aclanthology.org/2022.acl-long.336/", "abstract": "Learning high-quality sentence representations is a fundamental problem of natural language processing which could benefit a wide range of downstream tasks. Though the BERT-like pre-trained language models have achieved great success, using their sentence representations directly often results in poor performance on the semantic textual similarity task. Recently, several contrastive learning methods have been proposed for learning sentence representations and have shown promising results. However, most of them focus on the constitution of positive and negative representation pairs and pay little attention to the training objective like NT-Xent, which is not sufficient enough to acquire the discriminating power and is unable to model the partial order of semantics between sentences. So in this paper, we propose a new method ArcCSE, with training objectives designed to enhance the pairwise discriminative power and model the entailment relation of triplet sentences. We conduct extensive experiments which demonstrate that our approach outperforms the previous state-of-the-art on diverse sentence related tasks, including STS and SentEval.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "角度空間におけるペアワイズおよびトリプルワイズの観点から文表現を学習するための対照的なフレームワーク。", "jabstract": "高品質な文表現の学習は、多岐にわたる下流タスクに利益をもたらす自然言語処理の基本的な問題である。BERTのような事前学習言語モデルは大きな成功を収めているが、その文表現を直接使用すると、意味的なテキスト類似性タスクでの性能が低下することが多い。最近、いくつかの対比学習方法が提案され、文表現の学習に有望な結果を示している。しかし、ほとんどの方法は、正負の表現ペアの構成に焦点を当て、NT-Xentのようなトレーニング目的にはあまり注意を払っておらず、区別力を獲得するには十分ではなく、文間の意味的な部分順序をモデル化することができない。そこで、本論文では、ペアワイズの区別力を高め、三つ組の文の含意関係をモデル化するために設計されたトレーニング目的を持つ新しい方法ArcCSEを提案する。STSやSentEvalを含む多様な文関連タスクで、我々のアプローチが従来の最先端を上回ることを示す広範な実験を行った。"}
{"title": "Packed Levitated Marker for Entity and Relation Extraction", "url": "https://aclanthology.org/2022.acl-long.337/", "abstract": "Recent entity and relation extraction works focus on investigating how to obtain a better span representation from the pre-trained encoder. However, a major limitation of existing works is that they ignore the interrelation between spans (pairs). In this work, we propose a novel span representation approach, named Packed Levitated Markers (PL-Marker), to consider the interrelation between the spans (pairs) by strategically packing the markers in the encoder. In particular, we propose a neighborhood-oriented packing strategy, which considers the neighbor spans integrally to better model the entity boundary information. Furthermore, for those more complicated span pair classification tasks, we design a subject-oriented packing strategy, which packs each subject and all its objects to model the interrelation between the same-subject span pairs. The experimental results show that, with the enhanced marker feature, our model advances baselines on six NER benchmarks, and obtains a 4.1%-4.3% strict relation F1 improvement with higher speed over previous state-of-the-art models on ACE04 and ACE05. Our code and models are publicly available at https://github.com/thunlp/PL-Marker", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「実体と関係の抽出のためのパックされた浮遊マーカー」に関する論文の要約です。", "jabstract": "最近のエンティティと関係抽出の研究は、事前学習されたエンコーダからより良いスパン表現を取得する方法を調査することに焦点を当てています。しかし、既存の研究の主な制限は、スパン（ペア）間の相互関係を無視していることです。本研究では、エンコーダにマーカーを戦略的にパックすることで、スパン（ペア）間の相互関係を考慮する新しいスパン表現アプローチ、Packed Levitated Markers（PL-Marker）を提案します。特に、隣接スパンを総合的に考慮する近隣指向のパッキング戦略を提案し、エンティティの境界情報をより良くモデル化します。さらに、より複雑なスパンペア分類タスクに対しては、同じ主語スパンペア間の相互関係をモデル化するために、主語指向のパッキング戦略を設計します。実験結果は、強化されたマーカー機能により、当社のモデルが6つのNERベンチマークでベースラインを上回り、ACE04およびACE05の以前の最先端モデルよりも高速で4.1％〜4.3％の厳密な関係F1改善を達成することを示しています。当社のコードとモデルは、https://github.com/thunlp/PL-Markerで公開されています。"}
{"title": "An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented Dialogue Generation", "url": "https://aclanthology.org/2022.acl-long.338/", "abstract": "We study the interpretability issue of task-oriented dialogue systems in this paper. Previously, most neural-based task-oriented dialogue systems employ an implicit reasoning strategy that makes the model predictions uninterpretable to humans. To obtain a transparent reasoning process, we introduce neuro-symbolic to perform explicit reasoning that justifies model decisions by reasoning chains. Since deriving reasoning chains requires multi-hop reasoning for task-oriented dialogues, existing neuro-symbolic approaches would induce error propagation due to the one-phase design. To overcome this, we propose a two-phase approach that consists of a hypothesis generator and a reasoner. We first obtain multiple hypotheses, i.e., potential operations to perform the desired task, through the hypothesis generator. Each hypothesis is then verified by the reasoner, and the valid one is selected to conduct the final prediction. The whole system is trained by exploiting raw textual dialogues without using any reasoning chain annotations. Experimental studies on two public benchmark datasets demonstrate that the proposed approach not only achieves better results, but also introduces an interpretable decision process.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "タスク指向型対話生成のための解釈可能な神経記号推論フレームワーク", "jabstract": "本論文では、タスク指向型対話システムの解釈性の問題を研究しています。以前は、ほとんどのニューラルベースのタスク指向型対話システムは、モデルの予測を人間に解釈できない暗黙の推論戦略を採用していました。透明な推論プロセスを得るために、推論チェーンによってモデルの決定を正当化する明示的な推論を実行する神経記号を導入します。タスク指向の対話には多段階の推論が必要なため、推論チェーンを導出するには、既存の神経記号アプローチは1段階の設計によるエラー伝播を引き起こす可能性があります。これを克服するために、仮説ジェネレータと推論エンジンから構成される2段階アプローチを提案します。まず、仮説ジェネレータを使用して、望ましいタスクを実行するための複数の仮説、つまり潜在的な操作を取得します。次に、推論エンジンによって各仮説が検証され、有効な仮説が選択されて最終的な予測が行われます。全体のシステムは、推論チェーン注釈を使用せずに生のテキスト対話を利用してトレーニングされます。2つの公開ベンチマークデータセットでの実験的研究により、提案手法はより良い結果を達成するだけでなく、解釈可能な決定プロセスを導入します。"}
{"title": "Impact of Evaluation Methodologies on Code Summarization", "url": "https://aclanthology.org/2022.acl-long.339/", "abstract": "There has been a growing interest in developing machine learning (ML) models for code summarization tasks, e.g., comment generation and method naming. Despite substantial increase in the effectiveness of ML models, the evaluation methodologies, i.e., the way people split datasets into training, validation, and test sets, were not well studied. Specifically, no prior work on code summarization considered the timestamps of code and comments during evaluation. This may lead to evaluations that are inconsistent with the intended use cases. In this paper, we introduce the time-segmented evaluation methodology, which is novel to the code summarization research community, and compare it with the mixed-project and cross-project methodologies that have been commonly used. Each methodology can be mapped to some use cases, and the time-segmented methodology should be adopted in the evaluation of ML models for code summarization. To assess the impact of methodologies, we collect a dataset of (code, comment) pairs with timestamps to train and evaluate several recent ML models for code summarization. Our experiments show that different methodologies lead to conflicting evaluation results. We invite the community to expand the set of methodologies used in evaluations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n評価方法論がコード要約に与える影響", "jabstract": "コードの要約タスク、例えばコメント生成やメソッド命名のための機械学習（ML）モデルの開発に対する関心が高まっています。MLモデルの効果が大幅に向上しているにもかかわらず、データセットをトレーニング、バリデーション、テストセットに分割する方法である評価方法は十分に研究されていませんでした。具体的には、コードとコメントのタイムスタンプを評価中に考慮するコード要約に関する先行研究は存在しませんでした。これにより、意図されたユースケースと一致しない評価が行われる可能性があります。本論文では、コード要約研究コミュニティに新しい時間分割評価方法を導入し、一般的に使用されている混合プロジェクトおよびクロスプロジェクトの方法と比較します。各方法はいくつかのユースケースにマッピングでき、時間分割方法はコード要約のMLモデルの評価に採用すべきです。方法論の影響を評価するために、タイムスタンプ付きの（コード、コメント）ペアのデータセットを収集し、最近のコード要約のMLモデルをトレーニングおよび評価します。実験の結果、異なる方法論は相反する評価結果をもたらすことがわかりました。コミュニティには、評価に使用される方法論のセットを拡大するように呼びかけます。"}
{"title": "KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering", "url": "https://aclanthology.org/2022.acl-long.340/", "abstract": "Current Open-Domain Question Answering (ODQA) models typically include a retrieving module and a reading module, where the retriever selects potentially relevant passages from open-source documents for a given question, and the reader produces an answer based on the retrieved passages. The recently proposed Fusion-in-Decoder (FiD) framework is a representative example, which is built on top of a dense passage retriever and a generative reader, achieving the state-of-the-art performance. In this paper we further improve the FiD approach by introducing a knowledge-enhanced version, namely KG-FiD. Our new model uses a knowledge graph to establish the structural relationship among the retrieved passages, and a graph neural network (GNN) to re-rank the passages and select only a top few for further processing. Our experiments on common ODQA benchmark datasets (Natural Questions and TriviaQA) demonstrate that KG-FiD can achieve comparable or better performance in answer prediction than FiD, with less than 40% of the computation cost.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KG-FiD：オープンドメインの質問応答において、融合インデコーダーに知識グラフを注入する", "jabstract": "現在のオープンドメイン質問応答（ODQA）モデルは、通常、検索モジュールと読み取りモジュールを含みます。検索モジュールは、与えられた質問に対してオープンソースのドキュメントから関連する可能性のあるパッセージを選択し、読み取りモジュールは、選択されたパッセージに基づいて回答を生成します。最近提案されたFusion-in-Decoder（FiD）フレームワークは、密なパッセージ検索器と生成リーダーをベースに構築され、最先端のパフォーマンスを達成する代表的な例です。本論文では、知識強化バージョンであるKG-FiDを導入することで、FiDアプローチをさらに改善します。新しいモデルは、知識グラフを使用して、取得されたパッセージ間の構造的な関係を確立し、グラフニューラルネットワーク（GNN）を使用してパッセージを再ランク付けし、さらに処理するために上位のパッセージのみを選択します。一般的なODQAベンチマークデータセット（Natural QuestionsおよびTriviaQA）での実験では、KG-FiDがFiDよりも少ない計算コストで同等またはより良い回答予測のパフォーマンスを達成できることが示されました。"}
{"title": "Which side are you on? Insider-Outsider classification in conspiracy-theoretic social media", "url": "https://aclanthology.org/2022.acl-long.341/", "abstract": "Social media is a breeding ground for threat narratives and related conspiracy theories. In these, an outside group threatens the integrity of an inside group, leading to the emergence of sharply defined group identities: Insiders – agents with whom the authors identify and Outsiders – agents who threaten the insiders. Inferring the members of these groups constitutes a challenging new NLP task: (i) Information is distributed over many poorly-constructed posts; (ii) Threats and threat agents are highly contextual, with the same post potentially having multiple agents assigned to membership in either group; (iii) An agent’s identity is often implicit and transitive; and (iv) Phrases used to imply Outsider status often do not follow common negative sentiment patterns. To address these challenges, we define a novel Insider-Outsider classification task. Because we are not aware of any appropriate existing datasets or attendant models, we introduce a labeled dataset (CT5K) and design a model (NP2IO) to address this task. NP2IO leverages pretrained language modeling to classify Insiders and Outsiders. NP2IO is shown to be robust, generalizing to noun phrases not seen during training, and exceeding the performance of non-trivial baseline models by 20%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nあなたはどちらの側にいますか？ 陰謀論的なソーシャルメディアにおけるインサイダー・アウトサイダー分類。", "jabstract": "ソーシャルメディアは脅威の物語や関連する陰謀論の温床である。これらの物語では、外部グループが内部グループの完全性を脅かし、鮮明に定義されたグループアイデンティティが浮かび上がる：内部者-著者が同一視するエージェントと、外部者-内部者を脅かすエージェント。これらのグループのメンバーを推測することは、新しいNLPタスクであり、以下のような課題がある：（i）情報は多数の構築が不十分な投稿に分散している。（ii）脅威と脅威エージェントは高度に文脈依存的であり、同じ投稿にはどちらのグループのメンバーシップに複数のエージェントが割り当てられる可能性がある。（iii）エージェントのアイデンティティはしばしば暗黙的で推移的である。（iv）外部者のステータスを示すために使用されるフレーズは、一般的な否定的感情パターンに従わないことが多い。これらの課題に対処するために、私たちは新しい内部者-外部者分類タスクを定義しました。適切な既存のデータセットや関連するモデルが存在しないため、私たちはラベル付きデータセット（CT5K）を導入し、このタスクに対処するためのモデル（NP2IO）を設計しました。NP2IOは、事前学習された言語モデルを活用して内部者と外部者を分類します。NP2IOは堅牢であり、トレーニング中に見られなかった名詞句にも一般化し、非自明なベースラインモデルの性能を20％上回ります。"}
{"title": "Learning From Failure: Data Capture in an Australian Aboriginal Community", "url": "https://aclanthology.org/2022.acl-long.342/", "abstract": "Most low resource language technology development is premised on the need to collect data for training statistical models. When we follow the typical process of recording and transcribing text for small Indigenous languages, we hit up against the so-called “transcription bottleneck.” Therefore it is worth exploring new ways of engaging with speakers which generate data while avoiding the transcription bottleneck. We have deployed a prototype app for speakers to use for confirming system guesses in an approach to transcription based on word spotting. However, in the process of testing the app we encountered many new problems for engagement with speakers. This paper presents a close-up study of the process of deploying data capture technology on the ground in an Australian Aboriginal community. We reflect on our interactions with participants and draw lessons that apply to anyone seeking to develop methods for language data collection in an Indigenous community.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "失敗から学ぶ：オーストラリア先住民コミュニティにおけるデータ収集", "jabstract": "多くの低資源言語技術開発は、統計モデルのトレーニングのためにデータを収集する必要性に基づいています。小規模な先住民言語のテキストを記録し、転写する典型的なプロセスに従うと、「転写のボトルネック」と呼ばれる問題に直面します。したがって、転写のボトルネックを回避しながらデータを生成する話者との新しい関わり方を探ることが価値があります。私たちは、単語スポッティングに基づく転写アプローチでシステムの推測を確認するために話者が使用するプロトタイプアプリを展開しました。しかし、アプリをテストする過程で、話者との関わりに関する多くの新しい問題に直面しました。本論文では、オーストラリアの先住民コミュニティでデータ収集技術を展開するプロセスについての詳細な研究を紹介します。私たちは参加者とのやり取りを振り返り、先住民コミュニティで言語データ収集の方法を開発する人々に適用できる教訓を引き出します。"}
{"title": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension", "url": "https://aclanthology.org/2022.acl-long.343/", "abstract": "Multi-hop reading comprehension requires an ability to reason across multiple documents. On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer. On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined. In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation. The reasoning process is accomplished via attentive memories with novel differentiable logic operators. To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多段階読解のための深層帰納論理推論", "jabstract": "マルチホップ読解は、複数の文書を跨いで推論する能力を必要とします。一方、深層学習アプローチは、クエリに関連する情報を分散埋め込みに暗黙的にエンコードするため、正しい答えを推論するための離散的な関係推論プロセスを明らかにできません。他方、論理ベースのアプローチは、エンティティと関係が明確に定義された構造化データで主に機能するため、解釈可能なルールを提供して目標の答えを推論します。本論文では、クエリに関連する（候補に関連する）情報を最初に抽出し、その後、ターゲット関係を含む実行可能なルールを誘導することによって、フィルタリングされた情報の間で論理推論を行う、深層学習ベースの帰納的論理推論方法を提案します。推論プロセスは、新しい微分可能な論理演算子を持つ注意メモリを介して実現されます。モデルの効果を示すために、WikiHopとMedHopの2つの読解データセットで評価します。"}
{"title": "CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues", "url": "https://aclanthology.org/2022.acl-long.344/", "abstract": "This paper addresses the problem of dialogue reasoning with contextualized commonsense inference. We curate CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences: cause, subsequent event, prerequisite, motivation, and emotional reaction. The dataset contains 53,105 of such inferences from 5,672 dialogues. We use this dataset to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives. Our results ascertain the value of such dialogue-centric commonsense knowledge datasets. It is our hope that CICERO will open new research avenues into commonsense-based dialogue reasoning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CICERO: 対話における文脈化された常識推論のためのデータセット", "jabstract": "本論文は、文脈に基づく常識推論を用いた対話推論の問題に取り組んでいます。私たちは、CICEROというデータセットを編纂しました。このデータセットは、二人の会話における5種類の発話レベルの推論（原因、後続のイベント、前提、動機、感情的反応）を含みます。このデータセットには、5,672の対話から53,105の推論が含まれています。私たちは、このデータセットを使用して、関連する生成的および識別的タスクを解決しました。具体的には、原因と後続のイベントの生成、前提、動機、聴衆の感情的反応の生成、および妥当な代替案の選択です。私たちの結果は、対話中心の常識知識データセットの価値を確認しています。CICEROが常識に基づく対話推論の新しい研究の道を開くことを願っています。"}
{"title": "A Comparative Study of Faithfulness Metrics for Model Interpretability Methods", "url": "https://aclanthology.org/2022.acl-long.345/", "abstract": "Interpretable methods to reveal the internal reasoning processes behind machine learning models have attracted increasing attention in recent years. To quantify the extent to which the identified interpretations truly reflect the intrinsic decision-making mechanisms, various faithfulness evaluation metrics have been proposed. However, we find that different faithfulness metrics show conflicting preferences when comparing different interpretations. Motivated by this observation, we aim to conduct a comprehensive and comparative study of the widely adopted faithfulness metrics. In particular, we introduce two assessment dimensions, namely diagnosticity and complexity. Diagnosticity refers to the degree to which the faithfulness metric favors relatively faithful interpretations over randomly generated ones, and complexity is measured by the average number of model forward passes. According to the experimental results, we find that sufficiency and comprehensiveness metrics have higher diagnosticity and lower complexity than the other faithfulness metrics.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "モデル解釈性手法のための忠実度メトリックの比較研究", "jabstract": "近年、機械学習モデルの内部推論プロセスを明らかにする解釈可能な手法が注目されています。特定の解釈が本来の意思決定メカニズムをどの程度反映しているかを定量化するために、様々な信頼性評価メトリックが提案されています。しかし、異なる信頼性メトリックは、異なる解釈を比較する際に相反する傾向を示すことがわかりました。この観察に基づき、広く採用されている信頼性メトリックの包括的かつ比較的な研究を行うことを目的としています。特に、診断性と複雑性という2つの評価次元を導入します。診断性は、信頼性メトリックが比較的忠実な解釈をランダムに生成された解釈よりも好む度合いを示し、複雑性はモデルの順方向パスの平均数で測定されます。実験結果によると、十分性と包括性メトリックは、他の信頼性メトリックよりも高い診断性と低い複雑性を持っていることがわかりました。"}
{"title": "SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer", "url": "https://aclanthology.org/2022.acl-long.346/", "abstract": "There has been growing interest in parameter-efficient methods to apply pre-trained language models to downstream tasks. Building on the Prompt Tuning approach of Lester et al. (2021), which learns task-specific soft prompts to condition a frozen pre-trained model to perform different tasks, we propose a novel prompt-based transfer learning approach called SPoT: Soft Prompt Transfer. SPoT first learns a prompt on one or more source tasks and then uses it to initialize the prompt for a target task. We show that SPoT significantly boosts the performance of Prompt Tuning across many tasks. More remarkably, across all model sizes, SPoT matches or outperforms standard Model Tuning (which fine-tunes all model parameters) on the SuperGLUE benchmark, while using up to 27,000× fewer task-specific parameters. To understand where SPoT is most effective, we conduct a large-scale study on task transferability with 26 NLP tasks in 160 combinations, and demonstrate that many tasks can benefit each other via prompt transfer. Finally, we propose an efficient retrieval approach that interprets task prompts as task embeddings to identify similar tasks and predict the most transferable source tasks for a novel target task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SPoT: ソフトプロンプト転送によるより良い凍結モデルの適応", "jabstract": "事前学習された言語モデルを下流タスクに適用するためのパラメータ効率的な手法に対する関心が高まっています。Lesterら（2021）のPrompt Tuningアプローチに基づき、タスク固有のソフトプロンプトを学習して凍結された事前学習モデルを条件付けて異なるタスクを実行するようにするアプローチに、SPoT：Soft Prompt Transferという新しいプロンプトベースの転移学習アプローチを提案します。SPoTは、1つ以上のソースタスクでプロンプトを最初に学習し、それをターゲットタスクのプロンプトの初期化に使用します。SPoTがPrompt Tuningのパフォーマンスを多くのタスクで大幅に向上させることを示します。さらに、すべてのモデルサイズにおいて、SPoTは、最大27,000倍少ないタスク固有のパラメータを使用しながら、SuperGLUEベンチマークで標準のモデルチューニング（すべてのモデルパラメータを微調整する）と同等またはそれ以上のパフォーマンスを発揮します。SPoTが最も効果的である場所を理解するために、160の組み合わせで26のNLPタスクについて大規模なタスク転移性の研究を行い、多くのタスクがプロンプト転送によってお互いに利益を得ることができることを示します。最後に、タスクプロンプトをタスク埋め込みとして解釈して、類似したタスクを特定し、新しいターゲットタスクに最も転送可能なソースタスクを予測する効率的な検索アプローチを提案します。"}
{"title": "Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models", "url": "https://aclanthology.org/2022.acl-long.347/", "abstract": "Selecting an appropriate pre-trained model (PTM) for a specific downstream task typically requires significant efforts of fine-tuning. To accelerate this process, researchers propose feature-based model selection (FMS) methods, which assess PTMs’ transferability to a specific task in a fast way without fine-tuning. In this work, we argue that current FMS methods are vulnerable, as the assessment mainly relies on the static features extracted from PTMs. However, such features are derived without training PTMs on downstream tasks, and are not necessarily reliable indicators for the PTM’s transferability. To validate our viewpoints, we design two methods to evaluate the robustness of FMS: (1) model disguise attack, which post-trains an inferior PTM with a contrastive objective, and (2) evaluation data selection, which selects a subset of the data points for FMS evaluation based on K-means clustering. Experimental results prove that both methods can successfully make FMS mistakenly judge the transferability of PTMs. Moreover, we find that these two methods can further be combined with the backdoor attack to misguide the FMS to select poisoned models. To the best of our knowledge, this is the first work to demonstrate the defects of current FMS algorithms and evaluate their potential security risks. By identifying previously unseen risks of FMS, our study indicates new directions for improving the robustness of FMS.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「魚の目を真珠と偽る：事前学習済みモデルのモデル選択を攻撃する」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models\n「魚の目を真珠と偽る：事前学習済みモデルのモデル選択を攻撃する」", "jabstract": "特定の下流タスクに適した事前学習モデル（PTM）を選択するには、通常、微調整の大きな努力が必要です。このプロセスを加速するために、研究者は、微調整なしでPTMの特定のタスクへの転送可能性を迅速に評価する特徴ベースのモデル選択（FMS）手法を提案しています。本研究では、現在のFMS手法は脆弱であると主張し、評価は主にPTMから抽出された静的な特徴に依存しているためです。しかし、このような特徴は、下流タスクでPTMをトレーニングせずに導出され、PTMの転送可能性の信頼できる指標ではない可能性があります。私たちは、FMSの堅牢性を評価するために2つの方法を設計し、私たちの視点を検証します。1つ目は、モデル偽装攻撃であり、劣ったPTMを対照的な目的で事後トレーニングします。2つ目は、K-meansクラスタリングに基づいてFMS評価のためのデータポイントのサブセットを選択する評価データ選択です。実験結果は、両方の方法がFMSを誤ってPTMの転送可能性を判断させることができることを証明しています。さらに、これら2つの方法は、バックドア攻撃と組み合わせて、FMSを誤ったモデルの選択に誘導することができます。私たちの知る限り、これは現在のFMSアルゴリズムの欠陥を示し、その潜在的なセキュリティリスクを評価する最初の研究です。FMSの以前に見られなかったリスクを特定することにより、私たちの研究は、FMSの堅牢性を改善するための新しい方向性を示唆しています。"}
{"title": "Educational Question Generation of Children Storybooks via Question Type Distribution Learning and Event-centric Summarization", "url": "https://aclanthology.org/2022.acl-long.348/", "abstract": "Generating educational questions of fairytales or storybooks is vital for improving children’s literacy ability. However, it is challenging to generate questions that capture the interesting aspects of a fairytale story with educational meaningfulness. In this paper, we propose a novel question generation method that first learns the question type distribution of an input story paragraph, and then summarizes salient events which can be used to generate high-cognitive-demand questions. To train the event-centric summarizer, we finetune a pre-trained transformer-based sequence-to-sequence model using silver samples composed by educational question-answer pairs. On a newly proposed educational question-answering dataset FairytaleQA, we show good performance of our method on both automatic and human evaluation metrics. Our work indicates the necessity of decomposing question type distribution learning and event-centric summary generation for educational question generation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「教育的な質問タイプ分布学習とイベント中心の要約による児童向けストーリーブックの質問生成」に関する論文の要約です。", "jabstract": "童話や物語の教育的な問題を生成することは、子供たちの読み書き能力を向上させるために重要です。しかし、教育的な意味を持ちながらも、童話の興味深い側面を捉えた問題を生成することは困難です。本論文では、入力されたストーリー段落の問題タイプ分布を学習し、高い認知要求を持つ問題を生成するために使用できる重要なイベントを要約する、新しい問題生成方法を提案します。イベント中心の要約器をトレーニングするために、教育的な問答ペアで構成されたシルバーサンプルを使用して、事前にトレーニングされたトランスフォーマーベースのシーケンスツーシーケンスモデルを微調整します。新しく提案された教育的な問答データセットFairytaleQAでは、自動評価および人間の評価指標の両方で、当社の方法の良好なパフォーマンスを示します。私たちの研究は、教育的な問題生成のために問題タイプ分布学習とイベント中心の要約生成を分解する必要性を示しています。"}
{"title": "HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations", "url": "https://aclanthology.org/2022.acl-long.349/", "abstract": "Recently, various response generation models for two-party conversations have achieved impressive improvements, but less effort has been paid to multi-party conversations (MPCs) which are more practical and complicated. Compared with a two-party conversation where a dialogue context is a sequence of utterances, building a response generation model for MPCs is more challenging, since there exist complicated context structures and the generated responses heavily rely on both interlocutors (i.e., speaker and addressee) and history utterances. To address these challenges, we present HeterMPC, a heterogeneous graph-based neural network for response generation in MPCs which models the semantics of utterances and interlocutors simultaneously with two types of nodes in a graph. Besides, we also design six types of meta relations with node-edge-type-dependent parameters to characterize the heterogeneous interactions within the graph. Through multi-hop updating, HeterMPC can adequately utilize the structural knowledge of conversations for response generation. Experimental results on the Ubuntu Internet Relay Chat (IRC) channel benchmark show that HeterMPC outperforms various baseline models for response generation in MPCs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "HeterMPC：多人数会話における応答生成のための異種グラフニューラルネットワーク", "jabstract": "最近、二者間の会話に対する様々な応答生成モデルが印象的な改善を達成しているが、より実用的で複雑な多者間の会話（MPC）にはあまり努力が払われていない。対話文脈が発話のシーケンスである二者間の会話と比較して、MPCの応答生成モデルを構築することはより困難である。なぜなら、複雑な文脈構造が存在し、生成された応答は発話者と受話者の両方と過去の発話に大きく依存するためである。これらの課題に対処するために、我々はHeterMPCを提案する。HeterMPCは、グラフ内の2種類のノードで同時に発話と発話者の意味をモデル化する異種グラフベースのニューラルネットワークであり、ノードエッジタイプ依存パラメータを持つ6種類のメタ関係を設計して、グラフ内の異種相互作用を特徴付ける。多段階更新を通じて、HeterMPCは会話の構造的知識を応答生成に十分に利用できる。Ubuntuインターネットリレーチャット（IRC）チャンネルベンチマークの実験結果は、HeterMPCがMPCの応答生成のための様々なベースラインモデルを上回ることを示している。"}
{"title": "The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature", "url": "https://aclanthology.org/2022.acl-long.350/", "abstract": "Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency. In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task. Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "患者は生きているよりも死んでいる方が多い：バイオメディカル文献のマルチドキュメント要約の現状を探る。", "jabstract": "バイオメディカル文献の多文書要約(MDS)は、最近注目を集めている非常に有用なタスクであるが、バイオメディカル要約の品質評価には一貫性と透明性が欠けている。本論文では、MDSタスクにおける課題の文脈で既存の評価手法の不備を理解するために、2つの現行モデルによって生成された要約を調査する。この分析に基づいて、人間による評価の新しいアプローチを提案し、効果的なバイオメディカルMDSシステムを開発するために克服しなければならないいくつかの課題を特定する。"}
{"title": "A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization", "url": "https://aclanthology.org/2022.acl-long.351/", "abstract": "Multi-document summarization (MDS) has made significant progress in recent years, in part facilitated by the availability of new, dedicated datasets and capacious language models. However, a standing limitation of these models is that they are trained against limited references and with plain maximum-likelihood objectives. As for many other generative tasks, reinforcement learning (RL) offers the potential to improve the training of MDS models; yet, it requires a carefully-designed reward that can ensure appropriate leverage of both the reference summaries and the input documents. For this reason, in this paper we propose fine-tuning an MDS baseline with a reward that balances a reference-based metric such as ROUGE with coverage of the input documents. To implement the approach, we utilize RELAX (Grathwohl et al., 2018), a contemporary gradient estimator which is both low-variance and unbiased, and we fine-tune the baseline in a few-shot style for both stability and computational efficiency. Experimental results over the Multi-News and WCEP MDS datasets show significant improvements of up to +0.95 pp average ROUGE score and +3.17 pp METEOR score over the baseline, and competitive results with the literature. In addition, they show that the coverage of the input documents is increased, and evenly across all documents.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「RELAXed Multi-Document Summarizationに対するマルチドキュメントカバレッジ報酬」についての論文の要約です。", "jabstract": "近年、新しい専用データセットや大容量の言語モデルの利用により、多文書要約(MDS)は大きな進歩を遂げてきた。しかし、これらのモデルの持つ制限の一つは、限られた参照文献と単純な最尤推定目的に対して訓練されていることである。多くの生成タスクと同様に、強化学習(RL)はMDSモデルの訓練を改善する可能性を持っているが、適切な報酬を設計する必要がある。このため、本論文では、ROUGEなどの参照ベースの評価指標と入力文書のカバレッジをバランスさせる報酬でMDSベースラインを微調整することを提案する。このアプローチを実装するために、低分散かつバイアスのない現代的な勾配推定器であるRELAX(Grathwohl et al.、2018)を利用し、ベースラインを安定性と計算効率のためにフューショットスタイルで微調整する。Multi-NewsとWCEP MDSデータセットに対する実験結果は、ベースラインに比べ平均ROUGEスコアが+0.95 pp、METEORスコアが+3.17 pp向上し、文献と競合する結果を示した。また、入力文書のカバレッジが向上し、すべての文書に均等に分散していることが示された。"}
{"title": "KNN-Contrastive Learning for Out-of-Domain Intent Classification", "url": "https://aclanthology.org/2022.acl-long.352/", "abstract": "The Out-of-Domain (OOD) intent classification is a basic and challenging task for dialogue systems. Previous methods commonly restrict the region (in feature space) of In-domain (IND) intent features to be compact or simply-connected implicitly, which assumes no OOD intents reside, to learn discriminative semantic features. Then the distribution of the IND intent features is often assumed to obey a hypothetical distribution (Gaussian mostly) and samples outside this distribution are regarded as OOD samples. In this paper, we start from the nature of OOD intent classification and explore its optimization objective. We further propose a simple yet effective method, named KNN-contrastive learning. Our approach utilizes k-nearest neighbors (KNN) of IND intents to learn discriminative semantic features that are more conducive to OOD detection.Notably, the density-based novelty detection algorithm is so well-grounded in the essence of our method that it is reasonable to use it as the OOD detection algorithm without making any requirements for the feature distribution.Extensive experiments on four public datasets show that our approach can not only enhance the OOD detection performance substantially but also improve the IND intent classification while requiring no restrictions on feature distribution.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KNN-対比学習によるドメイン外意図分類に関する論文の要旨です。", "jabstract": "Out-of-Domain（OOD）意図分類は、対話システムにとって基本的であり、かつ挑戦的なタスクです。以前の方法では、一般的にIn-domain（IND）意図特徴の領域（特徴空間内）をコンパクトまたは単純に接続されたものに制限し、OOD意図が存在しないと仮定して識別的な意味的特徴を学習することが想定されていました。その後、IND意図特徴の分布は、仮想的な分布（主にガウス分布）に従うと仮定され、この分布外のサンプルはOODサンプルと見なされます。本論文では、OOD意図分類の本質から出発し、その最適化目的を探求します。さらに、KNN-contrastive learningというシンプルで効果的な手法を提案します。当社のアプローチは、IND意図のk-nearest neighbors（KNN）を利用して、OOD検出により適した識別的な意味的特徴を学習します。特に、密度ベースの新規性検出アルゴリズムは、当社の手法の本質に非常に根付いているため、特徴分布に対する要件を一切設けずにOOD検出アルゴリズムとして使用することが合理的です。4つの公開データセットでの広範な実験により、当社のアプローチは、特徴分布に制限を設けることなく、OOD検出性能を大幅に向上させるだけでなく、IND意図分類を改善することができることが示されました。"}
{"title": "A Neural Network Architecture for Program Understanding Inspired by Human Behaviors", "url": "https://aclanthology.org/2022.acl-long.353/", "abstract": "Program understanding is a fundamental task in program language processing. Despite the success, existing works fail to take human behaviors as reference in understanding programs. In this paper, we consider human behaviors and propose the PGNN-EK model that consists of two main components. On the one hand, inspired by the “divide-and-conquer” reading behaviors of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes. On the other hand, to characterize human behaviors of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction. Finally, we combine the two embeddings generated from the two components to output code embeddings. We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks. In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community. Our codes and data are publicly available at https://github.com/RecklessRonan/PGNN-EK.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "人間の行動に着想を得たプログラム理解のためのニューラルネットワークアーキテクチャ\n\nAbstract:\nIn this paper, we propose a neural network architecture for program understanding inspired by human behaviors. The proposed architecture consists of two main components: a natural language processing module and a program analysis module. The natural language processing module is responsible for parsing the natural language descriptions of the program, while the program analysis module is responsible for analyzing the program code. We evaluate the proposed architecture on a dataset of Java programs and their corresponding natural language descriptions, and show that it outperforms existing approaches in terms of accuracy and efficiency. Our results demonstrate the potential of using neural networks for program understanding, and suggest directions for future research in this area.\n\n要約：\n本論文では、人間の行動に着想を得たプログラム理解のためのニューラルネットワークアーキテクチャを提案します。提案されたアーキテクチャは、自然言語処理モジュールとプログラム解析モジュールの2つの主要なコンポーネントで構成されています。自然言語処理モジュールは、プログラムの自然言語の説明を解析する責任があり、プログラム解析モジュールは、プログラムコードを解析する責任があります。私たちは、Javaプログラムとそれらに対応する自然言語の説明のデータセットで提案されたアーキテクチャを評価し、精度と効率の面で既存のアプローチを上回ることを示しました。私たちの結果は、ニューラルネットワークをプログラム理解に使用する可能性を示し、この分野の将来の研究の方向を示唆しています。", "jabstract": "プログラム理解は、プログラム言語処理における基本的なタスクです。これまでの研究では成功しているものの、既存の作品はプログラム理解において人間の行動を参考にすることに失敗しています。本論文では、人間の行動を考慮し、2つの主要なコンポーネントから構成されるPGNN-EKモデルを提案します。一方で、人間の「分割と征服」の読み取り行動に着想を得て、コードのアップグレードされたASTに基づく分割ベースのグラフニューラルネットワークモデルPGNNを提供します。他方で、コード理解を助けるために他のリソースに頼る人間の行動を特徴づけるために、外部知識で生のコードを変換し、情報抽出のための事前トレーニング技術を適用します。最後に、2つのコンポーネントから生成された2つの埋め込みを組み合わせて、コードの埋め込みを出力します。私たちは、PGNN-EKがコード要約とコードクローン検出のタスクにおいて優れた性能を発揮することを示すために、広範な実験を行いました。特に、私たちのモデルの汎化能力を示すために、コードクローン検出にとってより難しい新しいデータセットを公開し、コミュニティの発展を促進することができます。私たちのコードとデータは、https://github.com/RecklessRonan/PGNN-EKで公開されています。"}
{"title": "FaVIQ: FAct Verification from Information-seeking Questions", "url": "https://aclanthology.org/2022.acl-long.354/", "abstract": "Despite significant interest in developing general purpose fact checking models, it is challenging to construct a large-scale fact verification dataset with realistic real-world claims. Existing claims are either authored by crowdworkers, thereby introducing subtle biases thatare difficult to control for, or manually verified by professional fact checkers, causing them to be expensive and limited in scale. In this paper, we construct a large-scale challenging fact verification dataset called FAVIQ, consisting of 188k claims derived from an existing corpus of ambiguous information-seeking questions. The ambiguities in the questions enable automatically constructing true and false claims that reflect user confusions (e.g., the year of the movie being filmed vs. being released). Claims in FAVIQ are verified to be natural, contain little lexical bias, and require a complete understanding of the evidence for verification. Our experiments show that the state-of-the-art models are far from solving our new task. Moreover, training on our data helps in professional fact-checking, outperforming models trained on the widely used dataset FEVER or in-domain data by up to 17% absolute. Altogether, our data will serve as a challenging benchmark for natural language understanding and support future progress in professional fact checking.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nFaVIQ：情報収集に関する質問からの事実検証", "jabstract": "一般的な事実検証モデルの開発に関心が高まっているにもかかわらず、現実的な現実世界の主張を含む大規模な事実検証データセットを構築することは困難です。既存の主張は、クラウドワーカーによって作成されるため、微妙なバイアスが導入され、制御が困難であるか、または専門の事実チェック担当者によって手動で検証されるため、高価で規模が限られています。本論文では、曖昧な情報収集質問の既存のコーパスから派生した188kの主張から構成される大規模で難解な事実検証データセットであるFAVIQを構築します。質問の曖昧さにより、ユーザーの混乱を反映した真偽の主張を自動的に構築できます（例：映画の撮影年と公開年）。FAVIQの主張は自然であり、ほとんどの語彙的バイアスを含まず、検証には証拠の完全な理解が必要です。私たちの実験では、最先端のモデルが新しいタスクを解決するには遠いことが示されました。さらに、私たちのデータでのトレーニングは、広く使用されているデータセットFEVERまたはドメイン内データでトレーニングされたモデルを最大17％上回るプロの事実チェックに役立ちます。全体として、私たちのデータは自然言語理解の難解なベンチマークとして機能し、プロの事実チェックの将来の進歩を支援します。"}
{"title": "Simulating Bandit Learning from User Feedback for Extractive Question Answering", "url": "https://aclanthology.org/2022.acl-long.355/", "abstract": "We study learning from user feedback for extractive question answering by simulating feedback using supervised data. We cast the problem as contextual bandit learning, and analyze the characteristics of several learning scenarios with focus on reducing data annotation. We show that systems initially trained on few examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation effort, but instead improving the system on-the-fly via user feedback.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nユーザーフィードバックからバンディット学習をシミュレートして抽出型質問応答を行う。", "jabstract": "私たちは、教師ありデータを用いたフィードバックのシミュレーションによる抽出型質問応答の学習を研究しています。この問題を文脈バンディット学習として捉え、データ注釈を減らすことに焦点を当てたいくつかの学習シナリオの特性を分析します。私たちは、ユーザーからのフィードバックによってモデル予測された回答を改善することで、最初にわずかな例でトレーニングされたシステムが劇的に改善できることを示し、既存のデータセットを使用して、注釈の努力なしに新しいドメインにシステムを展開し、代わりにユーザーフィードバックによってシステムをオンザフライで改善できることを示します。"}
{"title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation", "url": "https://aclanthology.org/2022.acl-long.356/", "abstract": "Despite recent improvements in open-domain dialogue models, state of the art models are trained and evaluated on short conversations with little context. In contrast, the long-term conversation setting has hardly been studied. In this work we collect and release a human-human dataset consisting of multiple chat sessions whereby the speaking partners learn about each other’s interests and discuss the things they have learnt from past sessions. We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations, and we study long-context models that can perform much better. In particular, we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「金魚の記憶」を超えて：長期的なオープンドメインの会話", "jabstract": "最近のオープンドメインの対話モデルの改善にもかかわらず、最先端のモデルは短い会話に基づいて訓練および評価されており、文脈が少ない。これに対し、長期的な会話設定はほとんど研究されていない。本研究では、話し手がお互いの興味を学び、過去のセッションから学んだことを話し合う複数のチャットセッションからなる人間-人間のデータセットを収集および公開する。既存のデータセットで訓練された既存のモデルが、この長期的な会話設定で自動および人間の評価の両方で不十分であることを示し、長期的な文脈モデルがはるかに優れたパフォーマンスを発揮できることを研究する。特に、検索増強方法と、以前の会話を要約して記憶する能力を持つ方法が、現在最先端と考えられている標準のエンコーダー-デコーダーアーキテクチャを上回ることがわかった。"}
{"title": "ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension", "url": "https://aclanthology.org/2022.acl-long.357/", "abstract": "Training a referring expression comprehension (ReC) model for a new visual domain requires collecting referring expressions, and potentially corresponding bounding boxes, for images in the domain. While large-scale pre-trained models are useful for image classification across domains, it remains unclear if they can be applied in a zero-shot manner to more complex tasks like ReC. We present ReCLIP, a simple but strong zero-shot baseline that repurposes CLIP, a state-of-the-art large-scale model, for ReC. Motivated by the close connection between ReC and CLIP’s contrastive pre-training objective, the first component of ReCLIP is a region-scoring method that isolates object proposals via cropping and blurring, and passes them to CLIP. However, through controlled experiments on a synthetic dataset, we find that CLIP is largely incapable of performing spatial reasoning off-the-shelf. We reduce the gap between zero-shot baselines from prior work and supervised models by as much as 29% on RefCOCOg, and on RefGTA (video game imagery), ReCLIP’s relative improvement over supervised ReC models trained on real images is 8%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ReCLIP：指示表現理解の強力なゼロショットベースライン", "jabstract": "新しい視覚ドメインの指示表現理解（ReC）モデルのトレーニングには、ドメイン内の画像の指示表現、および可能であれば対応する境界ボックスを収集する必要があります。大規模な事前トレーニングモデルは、ドメインを横断した画像分類に役立ちますが、ReCのようなより複雑なタスクにゼロショットで適用できるかどうかはまだ不明です。私たちは、ReCLIPを提案します。これは、ReCのためにCLIPを再利用するシンプルで強力なゼロショットのベースラインです。ReCとCLIPの対比的な事前トレーニング目的の密接な関係に着想を得て、ReCLIPの最初のコンポーネントは、クロッピングとぼかしを介してオブジェクト提案を分離し、CLIPに渡す領域スコアリング方法です。しかし、合成データセットでの制御実験により、CLIPはオフシェルフで空間的推論を実行することがほとんどできないことがわかりました。私たちは、RefCOCOgで29％、RefGTA（ビデオゲーム画像）で、ReCLIPの相対的な改善率は、実際の画像でトレーニングされた監視されたReCモデルに比べて8％です。"}
{"title": "Dynamic Prefix-Tuning for Generative Template-based Event Extraction", "url": "https://aclanthology.org/2022.acl-long.358/", "abstract": "We consider event extraction in a generative manner with template-based conditional generation.Although there is a rising trend of casting the task of event extraction as a sequence generation problem with prompts, these generation-based methods have two significant challenges, including using suboptimal prompts and static event type information.In this paper, we propose a generative template-based event extraction method with dynamic prefix (GTEE-DynPref) by integrating context information with type-specific prefixes to learn a context-specific prefix for each context.Experimental results show that our model achieves competitive results with the state-of-the-art classification-based model OneIE on ACE 2005 and achieves the best performances on ERE.Additionally, our model is proven to be portable to new types of events effectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「生成テンプレートベースのイベント抽出のための動的プレフィックスチューニング」に関する論文の要約文を日本語に翻訳してください。", "jabstract": "私たちは、テンプレートベースの条件付き生成によるイベント抽出を考慮しています。イベント抽出のタスクをプロンプトを用いたシーケンス生成問題として捉える傾向があるが、これらの生成ベースの方法には、サブオプティマルなプロンプトの使用と静的なイベントタイプ情報の2つの重要な課題がある。本論文では、コンテキスト情報をタイプ固有のプレフィックスと統合し、各コンテキストに対してコンテキスト固有のプレフィックスを学習することで、動的プレフィックスを持つテンプレートベースのイベント抽出方法（GTEE-DynPref）を提案する。実験結果は、ACE 2005において最先端の分類ベースのモデルOneIEと競合する結果を達成し、EREにおいて最高の性能を発揮することが示された。さらに、我々のモデルは、新しいタイプのイベントに対して効果的に移植可能であることが証明されている。"}
{"title": "E-LANG: Energy-Based Joint Inferencing of Super and Swift Language Models", "url": "https://aclanthology.org/2022.acl-long.359/", "abstract": "Building huge and highly capable language models has been a trend in the past years. Despite their great performance, they incur high computational cost. A common solution is to apply model compression or choose light-weight architectures, which often need a separate fixed-size model for each desirable computational budget, and may lose performance in case of heavy compression. This paper proposes an effective dynamic inference approach, called E-LANG, which distributes the inference between large accurate Super-models and light-weight Swift models. To this end, a decision making module routes the inputs to Super or Swift models based on the energy characteristics of the representations in the latent space. This method is easily adoptable and architecture agnostic. As such, it can be applied to black-box pre-trained models without a need for architectural manipulations, reassembling of modules, or re-training. Unlike existing methods that are only applicable to encoder-only backbones and classification tasks, our method also works for encoder-decoder structures and sequence-to-sequence tasks such as translation. The E-LANG performance is verified through a set of experiments with T5 and BERT backbones on GLUE, SuperGLUE, and WMT. In particular, we outperform T5-11B with an average computations speed-up of 3.3X on GLUE and 2.9X on SuperGLUE. We also achieve BERT-based SOTA on GLUE with 3.2X less computations. Code and demo are available in supplementary materials.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "E-LANG: スーパーおよびスウィフト言語モデルのエネルギーベースの共同推論", "jabstract": "過去数年間、巨大で高性能な言語モデルの構築がトレンドとなっています。これらのモデルは優れた性能を発揮しますが、高い計算コストがかかります。一般的な解決策は、モデルの圧縮を適用するか、軽量なアーキテクチャを選択することですが、これらはしばしば望ましい計算予算ごとに別々の固定サイズのモデルが必要であり、重い圧縮の場合には性能が低下することがあります。本論文では、大規模で正確なスーパーモデルと軽量なスウィフトモデルの間で推論を分散する効果的な動的推論手法であるE-LANGを提案しています。このために、決定モジュールが潜在空間の表現のエネルギー特性に基づいて入力をスーパーまたはスウィフトモデルにルーティングします。この方法は採用が容易でアーキテクチャに依存しないため、アーキテクチャの操作、モジュールの再構築、または再トレーニングの必要がないブラックボックスの事前学習モデルに適用できます。エンコーダーのみのバックボーンと分類タスクにのみ適用可能な既存の方法とは異なり、本手法はエンコーダーデコーダー構造や翻訳などのシーケンスツーシーケンスタスクにも適用できます。E-LANGの性能は、GLUE、SuperGLUE、およびWMTでT5およびBERTバックボーンを用いた一連の実験によって検証されています。特に、GLUEで平均計算速度を3.3倍、SuperGLUEで2.9倍向上させ、T5-11Bを上回りました。また、GLUEでBERTベースのSOTAを3.2倍少ない計算で達成しました。コードとデモは補足資料で入手可能です。"}
{"title": "PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization", "url": "https://aclanthology.org/2022.acl-long.360/", "abstract": "We introduce PRIMERA, a pre-trained model for multi-document representation with a focus on summarization that reduces the need for dataset-specific architectures and large amounts of fine-tuning labeled data. PRIMERA uses our newly proposed pre-training objective designed to teach the model to connect and aggregate information across documents. It also uses efficient encoder-decoder transformers to simplify the processing of concatenated input documents. With extensive experiments on 6 multi-document summarization datasets from 3 different domains on zero-shot, few-shot and full-supervised settings, PRIMERA outperforms current state-of-the-art dataset-specific and pre-trained models on most of these settings with large margins.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "PRIMERA: マルチドキュメント要約のためのピラミッドベースのマスクされた文事前学習", "jabstract": "私たちは、PRIMERAというマルチドキュメント表現のための事前学習モデルを紹介します。このモデルは、サマリゼーションに焦点を当て、データセット固有のアーキテクチャや大量のラベル付きデータの微調整の必要性を減らすことを目的としています。PRIMERAは、ドキュメント間の情報の接続と集約をモデルに教えるために設計された新しい事前学習目的を使用しています。また、連結された入力ドキュメントの処理を簡素化するために、効率的なエンコーダー・デコーダー・トランスフォーマーを使用しています。3つの異なるドメインからの6つのマルチドキュメントサマリゼーションデータセットで、ゼロショット、フューショット、フルスーパーバイズドの設定で広範な実験を行った結果、PRIMERAは、大きなマージンで、ほとんどの設定で現在の最先端のデータセット固有のモデルや事前学習モデルを上回りました。"}
{"title": "Dynamic Global Memory for Document-level Argument Extraction", "url": "https://aclanthology.org/2022.acl-long.361/", "abstract": "Extracting informative arguments of events from news articles is a challenging problem in information extraction, which requires a global contextual understanding of each document. While recent work on document-level extraction has gone beyond single-sentence and increased the cross-sentence inference capability of end-to-end models, they are still restricted by certain input sequence length constraints and usually ignore the global context between events. To tackle this issue, we introduce a new global neural generation-based framework for document-level event argument extraction by constructing a document memory store to record the contextual event information and leveraging it to implicitly and explicitly help with decoding of arguments for later events. Empirical results show that our framework outperforms prior methods substantially and it is more robust to adversarially annotated examples with our constrained decoding design.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「文書レベルの議論抽出のためのダイナミックグローバルメモリ」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Dynamic Global Memory for Document-level Argument Extraction\n- 文書レベルの議論抽出のためのダイナミックグローバルメモリ", "jabstract": "ニュース記事からイベントの情報的な議論を抽出することは、情報抽出において課題となる問題であり、各文書のグローバルな文脈理解を必要とします。最近の文書レベルの抽出に関する研究は、単一文を超えてエンドツーエンドモデルのクロスセンテンス推論能力を向上させていますが、入力シーケンスの長さの制約に制限され、通常、イベント間のグローバルな文脈を無視しています。この問題に対処するために、私たちは、文書メモリストアを構築して文脈的なイベント情報を記録し、後のイベントの引数のデコードを暗黙的におよび明示的に支援するためにそれを活用する、新しいグローバルニューラル生成ベースのフレームワークを導入します。実験結果は、私たちのフレームワークが従来の方法よりも大幅に優れており、制約付きデコード設計により、敵対的に注釈された例に対してより堅牢であることを示しています。"}
{"title": "Measuring the Impact of (Psycho-)Linguistic and Readability Features and Their Spill Over Effects on the Prediction of Eye Movement Patterns", "url": "https://aclanthology.org/2022.acl-long.362/", "abstract": "There is a growing interest in the combined use of NLP and machine learning methods to predict gaze patterns during naturalistic reading. While promising results have been obtained through the use of transformer-based language models, little work has been undertaken to relate the performance of such models to general text characteristics. In this paper we report on experiments with two eye-tracking corpora of naturalistic reading and two language models (BERT and GPT-2). In all experiments, we test effects of a broad spectrum of features for predicting human reading behavior that fall into five categories (syntactic complexity, lexical richness, register-based multiword combinations, readability and psycholinguistic word properties). Our experiments show that both the features included and the architecture of the transformer-based language models play a role in predicting multiple eye-tracking measures during naturalistic reading. We also report the results of experiments aimed at determining the relative importance of features from different groups using SP-LIME.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「(心理)言語学的および読みやすさの特徴とその影響が、視線移動パターンの予測に及ぼす影響の測定」についての論文の要旨を翻訳します。", "jabstract": "自然言語処理と機械学習の組み合わせによる自然読解時の視線パターン予測に関心が高まっている。トランスフォーマーベースの言語モデルの使用により、有望な結果が得られているが、そのようなモデルの性能を一般的なテキスト特性と関連付ける研究はほとんど行われていない。本論文では、自然読解のアイ・トラッキングコーパスと2つの言語モデル（BERTとGPT-2）を用いた実験について報告する。すべての実験で、5つのカテゴリ（構文的複雑さ、語彙の豊かさ、登録ベースの複合語、読みやすさ、心理言語学的な単語特性）に分類される人間の読解行動を予測するための広範な特徴の効果をテストする。実験結果は、トランスフォーマーベースの言語モデルのアーキテクチャと含まれる特徴の両方が、自然読解時の複数のアイ・トラッキング測定値を予測する上で役割を果たすことを示している。また、SP-LIMEを使用して、異なるグループからの特徴の相対的な重要性を決定する実験の結果も報告する。"}
{"title": "Alternative Input Signals Ease Transfer in Multilingual Machine Translation", "url": "https://aclanthology.org/2022.acl-long.363/", "abstract": "Recent work in multilingual machine translation (MMT) has focused on the potential of positive transfer between languages, particularly cases where higher-resourced languages can benefit lower-resourced ones. While training an MMT model, the supervision signals learned from one language pair can be transferred to the other via the tokens shared by multiple source languages. However, the transfer is inhibited when the token overlap among source languages is small, which manifests naturally when languages use different writing systems. In this paper, we tackle inhibited transfer by augmenting the training data with alternative signals that unify different writing systems, such as phonetic, romanized, and transliterated input. We test these signals on Indic and Turkic languages, two language families where the writing systems differ but languages still share common features. Our results indicate that a straightforward multi-source self-ensemble – training a model on a mixture of various signals and ensembling the outputs of the same model fed with different signals during inference, outperforms strong ensemble baselines by 1.3 BLEU points on both language families. Further, we find that incorporating alternative inputs via self-ensemble can be particularly effective when training set is small, leading to +5 BLEU when only 5% of the total training data is accessible. Finally, our analysis demonstrates that including alternative signals yields more consistency and translates named entities more accurately, which is crucial for increased factuality of automated systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "代替入力信号は多言語機械翻訳における転移を容易にする", "jabstract": "最近の多言語機械翻訳（MMT）の研究は、高リソース言語が低リソース言語に利益をもたらす可能性に焦点を当てています。MMTモデルのトレーニング中、1つの言語ペアから学習した監視信号は、複数のソース言語で共有されるトークンを介して他の言語ペアに転送できます。ただし、トークンのオーバーラップが小さい場合、つまり言語が異なる書記体系を使用する場合、転送が妨げられます。本論文では、音声、ローマ字、転写入力など、異なる書記体系を統一する代替信号をトレーニングデータに追加することで、転送を阻害する問題に取り組みます。インド・トルコ語のように、書記体系が異なるが言語に共通の特徴がある2つの言語ファミリーでこれらの信号をテストします。結果、異なる信号の混合物でモデルをトレーニングし、推論中に異なる信号でフィードされた同じモデルの出力をアンサンブルする単純なマルチソースセルフアンサンブルは、強力なアンサンブルベースラインを1.3 BLEUポイント上回ります。さらに、セルフアンサンブルを介した代替入力の組み込みは、トレーニングセットが小さい場合に特に効果的であり、トレーニングデータの総量の5％しかアクセスできない場合でも+5 BLEUになります。最後に、代替信号を含めることで、より一貫性があり、名前付きエンティティをより正確に翻訳できることが分かり、自動化システムの事実性の向上に重要です。"}
{"title": "Phone-ing it in: Towards Flexible Multi-Modal Language Model Training by Phonetic Representations of Data", "url": "https://aclanthology.org/2022.acl-long.364/", "abstract": "Multi-modal techniques offer significant untapped potential to unlock improved NLP technology for local languages. However, many advances in language model pre-training are focused on text, a fact that only increases systematic inequalities in the performance of NLP tasks across the world’s languages. In this work, we propose a multi-modal approach to train language models using whatever text and/or audio data might be available in a language. Initial experiments using Swahili and Kinyarwanda data suggest the viability of the approach for downstream Named Entity Recognition (NER) tasks, with models pre-trained on phone data showing an improvement of up to 6% F1-score above models that are trained from scratch. Preprocessing and training code will be uploaded to https://github.com/sil-ai/phone-it-in.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Phone-ing it in: Towards Flexible Multi-Modal Language Model Training by Phonetic Representations of Data」という論文の要約文を日本語に翻訳してください。", "jabstract": "マルチモーダル技術は、地域言語の改善されたNLP技術を開発するために未開発の可能性を提供しています。しかし、言語モデルの事前学習における多くの進歩はテキストに焦点を当てており、これにより世界の言語におけるNLPタスクの性能の不平等が増大しています。本研究では、言語に使用可能なテキストと/またはオーディオデータを使用して言語モデルをマルチモーダルアプローチでトレーニングすることを提案します。スワヒリ語とキニャルワンダ語のデータを使用した初期実験では、電話データで事前トレーニングされたモデルが、ゼロからトレーニングされたモデルよりも最大6％のF1スコアの改善を示すことが示唆されました。前処理とトレーニングコードは、https://github.com/sil-ai/phone-it-inにアップロードされます。"}
{"title": "Noisy Channel Language Model Prompting for Few-Shot Text Classification", "url": "https://aclanthology.org/2022.acl-long.365/", "abstract": "We introduce a noisy channel approach for language model prompting in few-shot text classification. Instead of computing the likelihood of the label given the input (referred as direct models), channel models compute the conditional probability of the input given the label, and are thereby required to explain every word in the input. We use channel models for recently proposed few-shot learning methods with no or very limited updates to the language model parameters, via either in-context demonstration or prompt tuning. Our experiments show that, for both methods, channel models significantly outperform their direct counterparts, which we attribute to their stability, i.e., lower variance and higher worst-case accuracy. We also present extensive ablations that provide recommendations for when to use channel prompt tuning instead of other competitive models (e.g., direct head tuning): channel prompt tuning is preferred when the number of training examples is small, labels in the training data are imbalanced, or generalization to unseen labels is required.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ノイズチャネル言語モデルを用いたフューショットテキスト分類のためのプロンプト。", "jabstract": "我々は、少数派のテキスト分類における言語モデルのプロンプティングのためのノイズチャネルアプローチを紹介する。直接モデルと呼ばれる入力に対するラベルの尤度を計算する代わりに、チャネルモデルは入力に対するラベルの条件付き確率を計算し、入力のすべての単語を説明する必要がある。我々は、コンテキスト内デモンストレーションまたはプロンプトチューニングを介して、言語モデルパラメータの更新がないか非常に限られた少数派学習方法にチャネルモデルを使用する。我々の実験は、両方の方法において、チャネルモデルが直接モデルよりも優れていることを示しており、これは安定性、つまり分散が低く最悪の場合の精度が高いことに起因すると考えられる。また、チャネルプロンプトチューニングを他の競合モデル（例えば、直接ヘッドチューニング）よりも使用するタイミングについての推奨事項を提供する広範な実験を行っており、トレーニング例の数が少ない場合、トレーニングデータのラベルが不均衡な場合、または未知のラベルへの汎化が必要な場合には、チャネルプロンプトチューニングが好ましいとされている。"}
{"title": "Multilingual unsupervised sequence segmentation transfers to extremely low-resource languages", "url": "https://aclanthology.org/2022.acl-long.366/", "abstract": "We show that unsupervised sequence-segmentation performance can be transferred to extremely low-resource languages by pre-training a Masked Segmental Language Model (Downey et al., 2021) multilingually. Further, we show that this transfer can be achieved by training over a collection of low-resource languages that are typologically similar (but phylogenetically unrelated) to the target language. In our experiments, we transfer from a collection of 10 Indigenous American languages (AmericasNLP, Mager et al., 2021) to K’iche’, a Mayan language. We compare our multilingual model to a monolingual (from-scratch) baseline, as well as a model pre-trained on Quechua only. We show that the multilingual pre-trained approach yields consistent segmentation quality across target dataset sizes, exceeding the monolingual baseline in 6/10 experimental settings. Our model yields especially strong results at small target sizes, including a zero-shot performance of 20.6 F1. These results have promising implications for low-resource NLP pipelines involving human-like linguistic units, such as the sparse transcription framework proposed by Bird (2020).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語の非監視シーケンスセグメンテーションは、極めて低資源言語に転移可能である。\n\nA neural model for joint morphological segmentation and disambiguation of agglutinative languages is proposed. \n\n接着語言語の共同形態論的セグメンテーションと曖昧性解消のためのニューラルモデルが提案されている。", "jabstract": "本研究では、Masked Segmental Language Model（Downey et al.、2021）を多言語的に事前学習することで、非常に低資源言語における非監督的なシーケンス・セグメンテーションの性能を転移できることを示します。さらに、この転移は、ターゲット言語と系統的には無関係であるが、形態論的に類似した低資源言語のコレクションをトレーニングすることによって達成できることを示します。実験では、10の先住民アメリカン言語（AmericasNLP、Mager et al.、2021）からマヤ語のK’iche’に転移します。多言語モデルを単一言語（ゼロから）のベースライン、およびQuechuaのみで事前学習されたモデルと比較します。多言語事前学習アプローチは、ターゲットデータセットサイズに関係なく一貫したセグメンテーション品質を提供し、10の実験設定のうち6つで単一言語ベースラインを上回ることを示します。特に、ゼロショットの性能は20.6 F1であり、小規模なターゲットサイズで特に強力な結果を示します。これらの結果は、Bird（2020）が提唱するスパーストランスクリプションフレームワークなど、人間の言語単位を含む低資源NLPパイプラインに有望な示唆を与えます。"}
{"title": "KinyaBERT: a Morphology-aware Kinyarwanda Language Model", "url": "https://aclanthology.org/2022.acl-long.367/", "abstract": "Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks. However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages. Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities. We address these challenges by proposing a simple yet effective two-tier BERT architecture that leverages a morphological analyzer and explicitly represents morphological compositionality.Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages. We evaluate our proposed method on the low-resource morphologically rich Kinyarwanda language, naming the proposed model architecture KinyaBERT. A robust set of experimental results reveal that KinyaBERT outperforms solid baselines by 2% in F1 score on a named entity recognition task and by 4.3% in average score of a machine-translated GLUE benchmark. KinyaBERT fine-tuning has better convergence and achieves more robust results on multiple tasks even in the presence of translation noise.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KinyaBERT：形態論に精通したキニヤルワンダ語言語モデル", "jabstract": "BERTのような事前学習言語モデルは、多くの自然言語処理タスクに成功しています。しかし、これらのモデルで一般的に使用される非監督のサブワードトークナイズ方法（例：バイトペアエンコーディング-BPE）は、形態的に豊かな言語を扱うのに最適ではありません。形態素解析器があっても、形態素を標準的なBERTアーキテクチャに単純に並べることは、形態的な合成性を捉えることができず、単語相対的な構文的な規則性を表現することができません。私たちは、形態素解析器を活用し、形態的な合成性を明示的に表現するシンプルで効果的な2層のBERTアーキテクチャを提案することで、これらの課題に対処します。BERTの成功にもかかわらず、その評価のほとんどは高リソース言語で行われており、低リソース言語での適用性が不明瞭です。私たちは、低リソースの形態的に豊かなキニャルワンダ語で提案された方法を評価し、提案されたモデルアーキテクチャKinyaBERTと名付けました。堅牢な実験結果のセットにより、KinyaBERTは、名前エンティティ認識タスクのF1スコアで2％、機械翻訳GLUEベンチマークの平均スコアで4.3％の堅固なベースラインを上回ることがわかりました。 KinyaBERTの微調整は、翻訳ノイズが存在する場合でも、複数のタスクでより堅牢な結果を達成し、収束がより良くなります。"}
{"title": "On the Calibration of Pre-trained Language Models using Mixup Guided by Area Under the Margin and Saliency", "url": "https://aclanthology.org/2022.acl-long.368/", "abstract": "A well-calibrated neural model produces confidence (probability outputs) closely approximated by the expected accuracy. While prior studies have shown that mixup training as a data augmentation technique can improve model calibration on image classification tasks, little is known about using mixup for model calibration on natural language understanding (NLU) tasks. In this paper, we explore mixup for model calibration on several NLU tasks and propose a novel mixup strategy for pre-trained language models that improves model calibration further. Our proposed mixup is guided by both the Area Under the Margin (AUM) statistic (Pleiss et al., 2020) and the saliency map of each sample (Simonyan et al., 2013). Moreover, we combine our mixup strategy with model miscalibration correction techniques (i.e., label smoothing and temperature scaling) and provide detailed analyses of their impact on our proposed mixup. We focus on systematically designing experiments on three NLU tasks: natural language inference, paraphrase detection, and commonsense reasoning. Our method achieves the lowest expected calibration error compared to strong baselines on both in-domain and out-of-domain test samples while maintaining competitive accuracy.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Pre-trained Language ModelsのキャリブレーションにおけるMargin下の面積とSaliencyによってガイドされたMixupの使用についての論文の要約です。", "jabstract": "よくキャリブレーションされたニューラルモデルは、期待される精度に近い確信（確率出力）を生成します。以前の研究では、データ拡張技術としてのmixupトレーニングが画像分類タスクにおけるモデルのキャリブレーションを改善できることが示されていますが、自然言語理解（NLU）タスクにおけるモデルのキャリブレーションにmixupを使用することについてはほとんど知られていません。本論文では、複数のNLUタスクにおけるモデルのキャリブレーションのためのmixupを探求し、モデルのキャリブレーションをさらに改善する新しい事前学習言語モデルのmixup戦略を提案します。提案されたmixupは、各サンプルのマージン下の面積（AUM）統計量（Pleiss et al.、2020）とサンプルの重要度マップ（Simonyan et al.、2013）の両方によって誘導されます。さらに、ラベルスムージングと温度スケーリングというモデルのキャリブレーション補正技術と組み合わせ、提案されたmixupの影響について詳細な分析を提供します。我々は、自然言語推論、パラフレーズ検出、常識的推論という3つのNLUタスクについて、系統的に実験を設計しました。提案手法は、競合力のある精度を維持しながら、ドメイン内外のテストサンプルにおいて強力なベースラインよりも期待されるキャリブレーションエラーが最も低い結果を達成しました。"}
{"title": "IMPLI: Investigating NLI Models’ Performance on Figurative Language", "url": "https://aclanthology.org/2022.acl-long.369/", "abstract": "Natural language inference (NLI) has been widely used as a task to train and evaluate models for language understanding. However, the ability of NLI models to perform inferences requiring understanding of figurative language such as idioms and metaphors remains understudied. We introduce the IMPLI (Idiomatic and Metaphoric Paired Language Inference) dataset, an English dataset consisting of paired sentences spanning idioms and metaphors. We develop novel methods to generate 24k semiautomatic pairs as well as manually creating 1.8k gold pairs. We use IMPLI to evaluate NLI models based on RoBERTa fine-tuned on the widely used MNLI dataset. We then show that while they can reliably detect entailment relationship between figurative phrases with their literal counterparts, they perform poorly on similarly structured examples where pairs are designed to be non-entailing. This suggests the limits of current NLI models with regard to understanding figurative language and this dataset serves as a benchmark for future improvements in this direction.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "IMPLI：比喩的な言語に対するNLIモデルの性能を調査する", "jabstract": "自然言語推論（NLI）は、言語理解のモデルを訓練および評価するためのタスクとして広く使用されています。しかし、慣用句や比喩などの比喩的な言語を理解するために必要な推論能力については、まだ研究が不十分です。本研究では、慣用句や比喩を含むペアの英語文からなるIMPLI（Idiomatic and Metaphoric Paired Language Inference）データセットを紹介します。24,000の半自動ペアと1,800の手動ペアを生成するための新しい方法を開発しました。MNLIデータセットでファインチューニングされたRoBERTaに基づくNLIモデルをIMPLIで評価しました。その結果、比喩的なフレーズとその文字通りの対応物の間の含意関係を信頼性高く検出できる一方、同様の構造を持つペアが含意関係を持たないように設計された例では、性能が低下することがわかりました。これは、現在のNLIモデルが比喩的な言語を理解する能力についての限界を示しており、このデータセットは今後の改善のためのベンチマークとなります。"}
{"title": "QAConv: Question Answering on Informative Conversations", "url": "https://aclanthology.org/2022.acl-long.370/", "abstract": "This paper introduces QAConv, a new question answering (QA) dataset that uses conversations as a knowledge source. We focus on informative conversations, including business emails, panel discussions, and work channels. Unlike open-domain and task-oriented dialogues, these conversations are usually long, complex, asynchronous, and involve strong domain knowledge. In total, we collect 34,608 QA pairs from 10,259 selected conversations with both human-written and machine-generated questions. We use a question generator and a dialogue summarizer as auxiliary tools to collect and recommend questions. The dataset has two testing scenarios: chunk mode and full mode, depending on whether the grounded partial conversation is provided or retrieved. Experimental results show that state-of-the-art pretrained QA systems have limited zero-shot performance and tend to predict our questions as unanswerable. Our dataset provides a new training and evaluation testbed to facilitate QA on conversations research.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "QAConv：情報的な会話における質問応答", "jabstract": "この論文は、会話を知識源として使用する新しい質問応答（QA）データセットであるQAConvを紹介しています。私たちは、ビジネスのメール、パネルディスカッション、ワークチャネルなど、情報を含む会話に焦点を当てています。これらの会話は、オープンドメインやタスク指向の対話とは異なり、通常は長く、複雑で、非同期であり、強いドメイン知識が必要です。合計で、人間が書いた質問と機械生成の質問の両方を含む、10,259の選択された会話から34,608のQAペアを収集しました。質問ジェネレーターと対話要約器を補助ツールとして使用して、質問を収集し、推奨します。データセットには、部分的な会話が提供されるか、取得されるかに応じて、チャンクモードとフルモードの2つのテストシナリオがあります。実験結果は、最新の事前学習済みQAシステムが限られたゼロショット性能しか持たず、私たちの質問を回答不能と予測する傾向があることを示しています。私たちのデータセットは、会話に関するQAの研究を促進するための新しいトレーニングおよび評価テストベッドを提供します。"}
{"title": "Prix-LM: Pretraining for Multilingual Knowledge Base Construction", "url": "https://aclanthology.org/2022.acl-long.371/", "abstract": "Knowledge bases (KBs) contain plenty of structured world and commonsense knowledge. As such, they often complement distributional text-based information and facilitate various downstream tasks. Since their manual construction is resource- and time-intensive, recent efforts have tried leveraging large pretrained language models (PLMs) to generate additional monolingual knowledge facts for KBs. However, such methods have not been attempted for building and enriching multilingual KBs. Besides wider application, such multilingual KBs can provide richer combined knowledge than monolingual (e.g., English) KBs. Knowledge expressed in different languages may be complementary and unequally distributed: this implies that the knowledge available in high-resource languages can be transferred to low-resource ones. To achieve this, it is crucial to represent multilingual knowledge in a shared/unified space. To this end, we propose a unified representation model, Prix-LM, for multilingual KB construction and completion. We leverage two types of knowledge, monolingual triples and cross-lingual links, extracted from existing multilingual KBs, and tune a multilingual language encoder XLM-R via a causal language modeling objective. Prix-LM integrates useful multilingual and KB-based factual knowledge into a single model. Experiments on standard entity-related tasks, such as link prediction in multiple languages, cross-lingual entity linking and bilingual lexicon induction, demonstrate its effectiveness, with gains reported over strong task-specialised baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Prix-LM: 多言語知識ベース構築のための事前学習", "jabstract": "知識ベース（KB）には、構造化された世界的な共通知識が豊富に含まれています。そのため、分散テキストベースの情報を補完し、さまざまな下流タスクを促進することがよくあります。しかし、その手動構築はリソースと時間がかかるため、最近の取り組みでは、大規模な事前学習言語モデル（PLM）を活用して、KBの追加の単一言語の知識事実を生成することが試みられています。しかし、そのような方法は、多言語KBの構築と充実には試みられていません。広範な応用に加えて、このような多言語KBは、単一言語（例：英語）のKBよりも豊富な結合知識を提供できます。異なる言語で表現された知識は相補的であり、不均等に分布している場合があります。これは、高リソース言語で利用可能な知識が低リソース言語に転送できることを意味します。これを実現するには、多言語知識を共有/統一された空間で表現することが重要です。このため、私たちは、多言語KBの構築と完成のための統一表現モデル、Prix-LMを提案します。既存の多言語KBから抽出された単一言語のトリプルとクロスリンガルリンクの2種類の知識を活用し、因果言語モデリング目的を介して多言語言語エンコーダXLM-Rを調整します。Prix-LMは、有用な多言語およびKBベースの事実知識を単一のモデルに統合します。複数言語のリンク予測、クロスリンガルエンティティリンキング、バイリンガル語彙誘導などの標準的なエンティティ関連タスクにおける実験は、強力なタスク専用ベースラインに対する利益を報告し、その効果を示しています。"}
{"title": "Semantic Composition with PSHRG for Derivation Tree Reconstruction from Graph-Based Meaning Representations", "url": "https://aclanthology.org/2022.acl-long.372/", "abstract": "We introduce a data-driven approach to generating derivation trees from meaning representation graphs with probabilistic synchronous hyperedge replacement grammar (PSHRG). SHRG has been used to produce meaning representation graphs from texts and syntax trees, but little is known about its viability on the reverse. In particular, we experiment on Dependency Minimal Recursion Semantics (DMRS) and adapt PSHRG as a formalism that approximates the semantic composition of DMRS graphs and simultaneously recovers the derivations that license the DMRS graphs. Consistent results are obtained as evaluated on a collection of annotated corpora. This work reveals the ability of PSHRG in formalizing a syntax–semantics interface, modelling compositional graph-to-tree translations, and channelling explainability to surface realization.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "グラフベースの意味表現から導出木の再構築のためのPSHRGを用いた意味合成", "jabstract": "私たちは、確率的同期ハイパーエッジ置換文法（PSHRG）を用いて、意味表現グラフから導出木を生成するデータ駆動型アプローチを紹介する。SHRGは、テキストや構文木から意味表現グラフを生成するために使用されてきたが、その逆の可能性についてはほとんど知られていない。特に、私たちは依存最小再帰意味論（DMRS）に実験を行い、PSHRGをDMRSグラフの意味的合成を近似する形式化手法として適応し、同時にDMRSグラフを許可する導出を回復する。アノテーションされたコーパスのコレクションで評価された一貫した結果が得られた。この研究は、PSHRGが構文-意味インターフェースを形式化し、合成的なグラフから木への翻訳をモデル化し、表層表現に説明可能性を提供する能力を明らかにしている。"}
{"title": "HOLM: Hallucinating Objects with Language Models for Referring Expression Recognition in Partially-Observed Scenes", "url": "https://aclanthology.org/2022.acl-long.373/", "abstract": "AI systems embodied in the physical world face a fundamental challenge of partial observability; operating with only a limited view and knowledge of the environment. This creates challenges when AI systems try to reason about language and its relationship with the environment: objects referred to through language (e.g. giving many instructions) are not immediately visible. Actions by the AI system may be required to bring these objects in view. A good benchmark to study this challenge is Dynamic Referring Expression Recognition (dRER) task, where the goal is to find a target location by dynamically adjusting the field of view (FoV) in a partially observed 360 scenes. In this paper, we introduce HOLM, Hallucinating Objects with Language Models, to address the challenge of partial observability. HOLM uses large pre-trained language models (LMs) to infer object hallucinations for the unobserved part of the environment. Our core intuition is that if a pair of objects co-appear in an environment frequently, our usage of language should reflect this fact about the world. Based on this intuition, we prompt language models to extract knowledge about object affinities which gives us a proxy for spatial relationships of objects. Our experiments show that HOLM performs better than the state-of-the-art approaches on two datasets for dRER; allowing to study generalization for both indoor and outdoor settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "HOLM：部分的に観測されたシーンにおける言語モデルによる言及表現認識のための物体幻覚化", "jabstract": "物理的な世界に具現化されたAIシステムは、環境の限られた視野と知識だけで動作するという基本的な部分的観測の課題に直面しています。これにより、AIシステムが言語と環境の関係について推論しようとするときに課題が生じます。言語を通じて参照されるオブジェクト（例：多くの指示を与える）はすぐには見えません。AIシステムによるアクションが必要になる場合があります。この課題を研究するための良いベンチマークは、部分的に観測された360シーンで視野（FoV）を動的に調整してターゲットの場所を見つけるDynamic Referring Expression Recognition（dRER）タスクです。本論文では、部分的観測の課題に対処するために、言語モデルを使用したHOLM（Hallucinating Objects with Language Models）を紹介します。HOLMは、大規模な事前学習済み言語モデル（LM）を使用して、環境の未観測部分のオブジェクト幻覚を推論します。私たちの核心的な直感は、環境で頻繁に共起するオブジェクトのペアがある場合、言語の使用は世界に関するこの事実を反映するべきだということです。この直感に基づいて、言語モデルにオブジェクトの親和性に関する知識を抽出するよう促し、オブジェクトの空間的関係のプロキシを得ます。私たちの実験は、HOLMがdRERの2つのデータセットで最先端のアプローチよりも優れたパフォーマンスを発揮し、屋内外の両方の設定に対する一般化を研究することを可能にすることを示しています。"}
{"title": "Multi Task Learning For Zero Shot Performance Prediction of Multilingual Models", "url": "https://aclanthology.org/2022.acl-long.374/", "abstract": "Massively Multilingual Transformer based Language Models have been observed to be surprisingly effective on zero-shot transfer across languages, though the performance varies from language to language depending on the pivot language(s) used for fine-tuning. In this work, we build upon some of the existing techniques for predicting the zero-shot performance on a task, by modeling it as a multi-task learning problem. We jointly train predictive models for different tasks which helps us build more accurate predictors for tasks where we have test data in very few languages to measure the actual performance of the model. Our approach also lends us the ability to perform a much more robust feature selection, and identify a common set of features that influence zero-shot performance across a variety of tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語モデルのゼロショット性能予測のためのマルチタスク学習", "jabstract": "大規模多言語Transformerベースの言語モデルは、ピボット言語によって言語ごとに性能が異なるものの、ゼロショット転移において驚くほど効果的であることが観察されています。本研究では、既存のいくつかの技術を拡張し、マルチタスク学習問題としてモデル化することで、タスクのゼロショット性能を予測するための手法を構築しました。異なるタスクの予測モデルを共同でトレーニングすることで、テストデータが非常に少ない言語でモデルの実際の性能を測定することができるより正確な予測モデルを構築することができます。また、私たちのアプローチは、より堅牢な特徴選択を実行し、様々なタスクにおいてゼロショット性能に影響を与える共通の特徴を特定する能力も提供します。"}
{"title": "∞-former: Infinite Memory Transformer", "url": "https://aclanthology.org/2022.acl-long.375/", "abstract": "Transformers are unable to model long-term memories effectively, since the amount of computation they need to perform grows with the context length. While variations of efficient transformers have been proposed, they all have a finite memory capacity and are forced to drop old information. In this paper, we propose the ∞-former, which extends the vanilla transformer with an unbounded long-term memory. By making use of a continuous-space attention mechanism to attend over the long-term memory, the ∞-former’s attention complexity becomes independent of the context length, trading off memory length with precision.In order to control where precision is more important, ∞-former maintains “sticky memories,” being able to model arbitrarily long contexts while keeping the computation budget fixed.Experiments on a synthetic sorting task, language modeling, and document grounded dialogue generation demonstrate the ∞-former’s ability to retain information from long sequences.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "1. This paper proposes a new model for natural language processing called the ∞-former, which is an extension of the Transformer model.\nこの論文では、Transformerモデルの拡張である∞-formerという自然言語処理の新しいモデルを提案しています。\n\n2. The ∞-former introduces an infinite memory mechanism that allows the model to remember all previous inputs and their representations.\n∞-formerは、モデルがすべての前の入力とその表現を覚えることができる無限のメモリメカニズムを導入しています。\n\n3. This mechanism enables the model to better capture long-term dependencies in natural language sequences.\nこのメカニズムにより、モデルは自然言語シーケンスの長期的な依存関係をより正確に捉えることができます。\n\n4. The ∞-former achieves state-of-the-art performance on several natural language processing tasks, including language modeling and machine translation.\n∞-formerは、言語モデリングや機械翻訳などのいくつかの自然言語処理タスクで最先端の性能を発揮しています。", "jabstract": "トランスフォーマーは、コンテキストの長さに応じて必要な計算量が増加するため、長期的な記憶を効果的にモデル化することができません。効率的なトランスフォーマーの変種が提案されていますが、すべて有限のメモリ容量を持ち、古い情報を削除する必要があります。本論文では、∞-formerを提案し、無限の長期記憶を持つバニラトランスフォーマーを拡張します。長期記憶に対して連続空間のアテンションメカニズムを使用することで、∞-formerのアテンション複雑度はコンテキストの長さに依存しなくなり、メモリ長さと精度をトレードオフします。精度がより重要な場所を制御するために、∞-formerは「スティッキーメモリ」を維持し、計算予算を固定したまま任意の長いコンテキストをモデル化できます。合成ソートタスク、言語モデリング、および文書に基づく対話生成の実験により、∞-formerは長いシーケンスから情報を保持する能力を示しました。"}
{"title": "Systematic Inequalities in Language Technology Performance across the World’s Languages", "url": "https://aclanthology.org/2022.acl-long.376/", "abstract": "Natural language processing (NLP) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. While the performance of NLP methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world’s ≈6,500 languages. We introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in NLP. Our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as foundational NLP tasks (dependency parsing, morphological inflection). In the process, we (1) quantify disparities in the current state of NLP research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies. Data and code to reproduce the findings discussed in this paper areavailable on GitHub (https://github.com/neubig/globalutility).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "世界の言語における言語技術の性能における系統的な不平等性", "jabstract": "自然言語処理（NLP）システムは、コミュニケーション、教育、医療、人工知能、および多くの他の研究開発分野で中心的な技術となっています。過去10年間におけるNLP手法の性能向上は著しく、しかし、この進歩は世界の約6,500の言語の微小なサブセットに制限されています。本論文では、NLPの最近の出版物の包括的なスナップショットで明らかになる言語技術のグローバルな有用性を推定するためのフレームワークを紹介します。私たちの分析は、フィールド全体だけでなく、ユーザー向けの技術（機械翻訳、言語理解、質問応答、テキスト音声合成）および基礎的なNLPタスク（依存構造解析、形態論的屈折）についてもより詳細な研究を含みます。このプロセスで、私たちは（1）NLP研究の現状の不均衡を定量化し、（2）それに関連する社会的および学術的要因を探求し、（3）よりグローバルかつ公正な言語技術を促進するためのエビデンスに基づく政策提言を行います。本論文で議論された結果を再現するためのデータとコードは、GitHub（https://github.com/neubig/globalutility）で入手できます。"}
{"title": "CaMEL: Case Marker Extraction without Labels", "url": "https://aclanthology.org/2022.acl-long.377/", "abstract": "We introduce CaMEL (Case Marker Extraction without Labels), a novel and challenging task in computational morphology that is especially relevant for low-resource languages. We propose a first model for CaMEL that uses a massively multilingual corpus to extract case markers in 83 languages based only on a noun phrase chunker and an alignment system. To evaluate CaMEL, we automatically construct a silver standard from UniMorph. The case markers extracted by our model can be used to detect and visualise similarities and differences between the case systems of different languages as well as to annotate fine-grained deep cases in languages in which they are not overtly marked.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CaMEL: ラベルなしの格助詞抽出", "jabstract": "私たちは、自然言語処理に関する論文の要約文を以下に示します。これらを日本語に翻訳してください。\n\n私たちは、低資源言語に特に関連する、計算形態論における新しいかつ難解なタスクであるCaMEL（ラベルなしの格標識抽出）を紹介します。私たちは、名詞句チャンカーとアラインメントシステムのみを使用して、83の言語で格標識を抽出するための最初のモデルを提案します。CaMELを評価するために、私たちはUniMorphから自動的にシルバースタンダードを構築します。私たちのモデルによって抽出された格標識は、異なる言語の格システムの類似点と相違点を検出および視覚化するために使用できるだけでなく、明示的にマークされていない言語の細かい深い格を注釈するためにも使用できます。"}
{"title": "Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors", "url": "https://aclanthology.org/2022.acl-long.378/", "abstract": "Robustness of machine learning models on ever-changing real-world data is critical, especially for applications affecting human well-being such as content moderation. New kinds of abusive language continually emerge in online discussions in response to current events (e.g., COVID-19), and the deployed abuse detection systems should be updated regularly to remain accurate. In this paper, we show that general abusive language classifiers tend to be fairly reliable in detecting out-of-domain explicitly abusive utterances but fail to detect new types of more subtle, implicit abuse. Next, we propose an interpretability technique, based on the Testing Concept Activation Vector (TCAV) method from computer vision, to quantify the sensitivity of a trained model to the human-defined concepts of explicit and implicit abusive language, and use that to explain the generalizability of the model on new data, in this case, COVID-related anti-Asian hate speech. Extending this technique, we introduce a novel metric, Degree of Explicitness, for a single instance and show that the new metric is beneficial in suggesting out-of-domain unlabeled examples to effectively enrich the training data with informative, implicitly abusive texts.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「概念活性化ベクトルを用いた暗黙的な侮辱的言語検出における一般化性の向上」という論文の要約文を日本語に翻訳してください。", "jabstract": "機械学習モデルの堅牢性は、コンテンツモデレーションなど、人間の福祉に影響を与えるアプリケーションに特に重要であり、常に変化する現実世界のデータに対して堅牢であることが求められます。オンラインディスカッションにおいて、新しい種類の虐待的な言語が現れ続けており（例：COVID-19）、展開された虐待検出システムは正確性を維持するために定期的に更新される必要があります。本論文では、一般的な虐待的言語分類器は、ドメイン外の明示的な虐待的発言を検出するのにかなり信頼性があることを示しますが、より微妙で暗黙的な虐待の新しいタイプを検出することができません。次に、コンピュータビジョンのTesting Concept Activation Vector（TCAV）メソッドに基づく解釈可能性技術を提案し、トレーニングされたモデルの人間によって定義された明示的および暗黙的な虐待的言語の概念に対する感度を定量化し、新しいデータ（この場合、COVID関連の反アジア人憎悪スピーチ）におけるモデルの汎用性を説明するために使用します。この技術を拡張し、単一のインスタンスの明示性度という新しいメトリックを導入し、新しい情報を提供する暗黙的な虐待的テキストでトレーニングデータを効果的に豊富にするために、ドメイン外の未ラベル化された例を提案することが有益であることを示します。"}
{"title": "Reports of personal experiences and stories in argumentation: datasets and analysis", "url": "https://aclanthology.org/2022.acl-long.379/", "abstract": "Reports of personal experiences or stories can play a crucial role in argumentation, as they represent an immediate and (often) relatable way to back up one’s position with respect to a given topic. They are easy to understand and increase empathy: this makes them powerful in argumentation. The impact of personal reports and stories in argumentation has been studied in the Social Sciences, but it is still largely underexplored in NLP. Our work is the first step towards filling this gap: our goal is to develop robust classifiers to identify documents containing personal experiences and reports. The main challenge is the scarcity of annotated data: our solution is to leverage existing annotations to be able to scale-up the analysis. Our contribution is two-fold. First, we conduct a set of in-domain and cross-domain experiments involving three datasets (two from Argument Mining, one from the Social Sciences), modeling architectures, training setups and fine-tuning options tailored to the involved domains. We show that despite the differences among datasets and annotations, robust cross-domain classification is possible. Second, we employ linear regression for performance mining, identifying performance trends both for overall classification performance and individual classifier predictions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "個人的な経験や物語の報告における論証：データセットと分析", "jabstract": "個人的な経験や物語の報告は、与えられたトピックに関する立場を支持するための直接的かつ（しばしば）共感を呼び起こす方法として、論証において重要な役割を果たすことができます。それらは理解しやすく、共感を高めるため、論証において強力なものとなります。個人的な報告や物語の影響は社会科学で研究されていますが、NLPではまだ十分に探究されていません。私たちの仕事は、個人的な経験や報告を含む文書を識別するための堅牢な分類器を開発することです。主な課題は注釈付きデータの不足です。私たちの解決策は、分析を拡大するために既存の注釈を活用することです。私たちの貢献は2つあります。まず、3つのデータセット（Argument Miningから2つ、社会科学から1つ）を対象に、ドメイン内およびクロスドメインの実験を行い、関連するドメインに合わせたモデリングアーキテクチャ、トレーニングセットアップ、ファインチューニングオプションをモデル化します。データセットや注釈の違いにもかかわらず、堅牢なクロスドメイン分類が可能であることを示します。次に、線形回帰を使用してパフォーマンスマイニングを行い、全体的な分類パフォーマンスと個々の分類器の予測のパフォーマンストレンドを特定します。"}
{"title": "Non-neural Models Matter: a Re-evaluation of Neural Referring Expression Generation Systems", "url": "https://aclanthology.org/2022.acl-long.380/", "abstract": "In recent years, neural models have often outperformed rule-based and classic Machine Learning approaches in NLG. These classic approaches are now often disregarded, for example when new neural models are evaluated. We argue that they should not be overlooked, since, for some tasks, well-designed non-neural approaches achieve better performance than neural ones. In this paper, the task of generating referring expressions in linguistic context is used as an example. We examined two very different English datasets (WEBNLG and WSJ), and evaluated each algorithm using both automatic and human evaluations.Overall, the results of these evaluations suggest that rule-based systems with simple rule sets achieve on-par or better performance on both datasets compared to state-of-the-art neural REG systems. In the case of the more realistic dataset, WSJ, a machine learning-based system with well-designed linguistic features performed best. We hope that our work can encourage researchers to consider non-neural models in future.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "非ニューラルモデルは重要である：ニューラル言及表現生成システムの再評価", "jabstract": "近年、ニューラルモデルはNLGにおいて、ルールベースや古典的な機械学習アプローチよりも優れた性能を発揮することが多くなっています。これらの古典的なアプローチは、新しいニューラルモデルが評価される際にはしばしば無視されるようになっていますが、私たちは、いくつかのタスクにおいて、よく設計された非ニューラルアプローチがニューラルアプローチよりも優れた性能を発揮することがあるため、これらを見落とすべきではないと主張します。本論文では、言語的文脈における指示表現の生成タスクを例に挙げます。私たちは、2つの非常に異なる英語のデータセット（WEBNLGとWSJ）を調べ、各アルゴリズムを自動評価と人間の評価の両方で評価しました。全体的に、これらの評価の結果から、単純なルールセットを持つルールベースのシステムが、最新のニューラルREGシステムと比較して、両方のデータセットで同等またはより優れた性能を発揮することが示されました。より現実的なデータセットであるWSJの場合、よく設計された言語的特徴を持つ機械学習ベースのシステムが最も優れた性能を発揮しました。私たちは、今後の研究において非ニューラルモデルを考慮するよう研究者に呼びかけることができればと思っています。"}
{"title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion", "url": "https://aclanthology.org/2022.acl-long.381/", "abstract": "Text-to-SQL parsers map natural language questions to programs that are executable over tables to generate answers, and are typically evaluated on large-scale datasets like Spider (Yu et al., 2018). We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operation over columns. To study this problem, we first propose a synthetic dataset along with a re-purposed train/test split of the Squall dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations, and find existing state-of-the-art parsers struggle in these benchmarks. We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning. This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers’ overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new Squall data split.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「スキーマ拡張によるテキストからSQLへのパースにおける一般化ギャップの橋渡し」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion\n- テキストからSQLへのパースにおける一般化ギャップをスキーマ拡張によって橋渡しする\n", "jabstract": "テキストからSQLへのパーサーは、自然言語の質問をテーブル上で実行可能なプログラムにマッピングして回答を生成し、通常はSpider（Yu et al.、2018）などの大規模なデータセットで評価されます。我々は、既存のベンチマークが、ドメイン固有のフレーズを列の複合操作にマッチングするという、実用上重要な特定のドメイン外汎化問題を捉えきれていないと主張します。この問題を研究するために、まず、Squallデータセット（Shi et al.、2020）の再利用可能なトレイン/テスト分割とともに、合成データセットを提案し、列操作のドメイン汎化を定量化する新しいベンチマークを提供します。そして、既存の最先端のパーサーがこれらのベンチマークで苦戦していることを発見します。我々は、テーブルスキーマの前処理に先行するドメイン知識を組み込むことによって、この問題に対処することを提案し、スキーマ拡張とスキーマ剪定の2つのコンポーネントから構成される方法を設計します。この方法は、複数の既存のベースパーサーに簡単に適用でき、このドメイン汎化問題でベースパーサーの全体的な性能を最大13.8％の相対精度向上（5.1％の絶対値）で向上させることを示します。"}
{"title": "Predicate-Argument Based Bi-Encoder for Paraphrase Identification", "url": "https://aclanthology.org/2022.acl-long.382/", "abstract": "Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a bi-encoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "述語-項目ベースのバイエンコーダーによる同義語同定", "jabstract": "言語処理に関する論文の要約を日本語に翻訳してください。\n\n言い換えの識別は、2つの文が同じまたは類似した意味を表しているかどうかを識別することを意味します。クロスエンコーダは、いくつかのベンチマークで高い性能を発揮していますが、SBERTなどのバイエンコーダは文のペアタスクに広く適用されています。彼らは計算複雑性が大幅に低く、対称的なタスクに適しています。本研究では、言い換えの識別タスクにバイエンコーダアプローチを採用し、SBERTに述語-引数情報を重み付け集約することで明示的に組み込む影響を調査します。6つの言い換え識別データセットでの実験は、パラメータの最小限の増加で、提案されたモデルがSBERT / SRoBERTaを大幅に上回ることを示しています。さらに、削除実験の結果、述語-引数ベースのコンポーネントが性能向上に重要な役割を果たしていることが明らかになりました。"}
{"title": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective", "url": "https://aclanthology.org/2022.acl-long.383/", "abstract": "NER model has achieved promising performance on standard NER benchmarks. However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary(OOV) entity recognition. In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective. The proposed approach contains two mutual information based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rotate memorizing entity names or exploiting biased cues in data. Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MINER：情報理論的観点から見た語彙外の固有表現認識の改善", "jabstract": "NERモデルは、標準のNERベンチマークで有望なパフォーマンスを達成しています。しかし、最近の研究では、以前のアプローチがエンティティメンション情報に過度に依存しているため、語彙外のエンティティ認識のパフォーマンスが低下することが示されています。本研究では、情報理論的な観点からこの問題を解決するために、MINERという新しいNER学習フレームワークを提案します。提案されたアプローチには、相互情報量に基づく2つのトレーニング目標が含まれます。i）一般化情報最大化は、文脈とエンティティ表面形式の深い理解によって表現を強化します。ii）余分な情報最小化は、エンティティ名の回転的な記憶やデータ内のバイアスのある手がかりを利用した表現を抑制します。さまざまな設定とデータセットでの実験により、OOVエンティティの予測においてより優れたパフォーマンスを発揮することが示されています。"}
{"title": "Leveraging Wikipedia article evolution for promotional tone detection", "url": "https://aclanthology.org/2022.acl-long.384/", "abstract": "Detecting biased language is useful for a variety of applications, such as identifying hyperpartisan news sources or flagging one-sided rhetoric. In this work we introduce WikiEvolve, a dataset for document-level promotional tone detection. Unlike previously proposed datasets, WikiEvolve contains seven versions of the same article from Wikipedia, from different points in its revision history; one with promotional tone, and six without it. This allows for obtaining more precise training signal for learning models from promotional tone detection. We adapt the previously proposed gradient reversal layer framework to encode two article versions simultaneously and thus leverage this additional training signal. In our experiments, our proposed adaptation of gradient reversal improves the accuracy of four different architectures on both in-domain and out-of-domain evaluation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ウィキペディア記事の進化を活用した宣伝的トーン検出のための自然言語処理に関する論文の要約です。", "jabstract": "バイアスのある言語を検出することは、ハイパーパーティザンなニュースソースの特定や片寄ったレトリックのフラッグ付けなど、さまざまなアプリケーションに役立ちます。本研究では、文書レベルのプロモーション音の検出のためのデータセットであるWikiEvolveを紹介します。以前提案されたデータセットとは異なり、WikiEvolveには、Wikipediaの同じ記事の7つのバージョンが含まれており、異なる改訂履歴のポイントから1つはプロモーション音を含み、6つは含まれていません。これにより、プロモーション音検出の学習モデルからより正確なトレーニングシグナルを取得できます。我々は、以前提案された勾配反転層フレームワークを適応して、2つの記事バージョンを同時にエンコードし、この追加のトレーニングシグナルを活用します。実験では、勾配反転の提案された適応は、4つの異なるアーキテクチャの正確さを、ドメイン内外の評価の両方で向上させます。"}
{"title": "From text to talk: Harnessing conversational corpora for humane and diversity-aware language technology", "url": "https://aclanthology.org/2022.acl-long.385/", "abstract": "Informal social interaction is the primordial home of human language. Linguistically diverse conversational corpora are an important and largely untapped resource for computational linguistics and language technology. Through the efforts of a worldwide language documentation movement, such corpora are increasingly becoming available. We show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action, with implications for language technology, natural language understanding, and the design of conversational interfaces. Harnessing linguistically diverse conversational corpora will provide the empirical foundations for flexible, localizable, humane language technologies of the future.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストから話し言葉へ：人道的かつ多様性に配慮した言語技術のための会話コーパスの活用", "jabstract": "非公式な社交的相互作用は、人間の言語の原初的な発生場所です。言語的に多様な会話コーパスは、計算言語学や言語技術にとって重要であり、ほとんど活用されていない資源です。世界的な言語文書化運動の努力により、このようなコーパスがますます利用可能になっています。我々は、63の言語（26の系統）からの相互作用データが、ターンテイキング、タイミング、シーケンシャル構造、社会的行動に関する洞察を提供し、言語技術、自然言語理解、会話インタフェースの設計に影響を与えることを示します。言語的に多様な会話コーパスを活用することで、将来的に柔軟でローカライズ可能で人間らしい言語技術の実証的な基盤が提供されます。"}
{"title": "Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning", "url": "https://aclanthology.org/2022.acl-long.386/", "abstract": "Adversarial robustness has attracted much attention recently, and the mainstream solution is adversarial training. However, the tradition of generating adversarial perturbations for each input embedding (in the settings of NLP) scales up the training computational complexity by the number of gradient steps it takes to obtain the adversarial samples. To address this problem, we leverage Flooding method which primarily aims at better generalization and we find promising in defending adversarial attacks. We further propose an effective criterion to bring hyper-parameter-dependent flooding into effect with a narrowed-down search space by measuring how the gradient steps taken within one epoch affect the loss of each batch. Our approach requires zero adversarial sample for training, and its time consumption is equivalent to fine-tuning, which can be 2-15 times faster than standard adversarial training. We experimentally show that our method improves BERT’s resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Flooding-X：損失制限された微調整によるBERTの敵対的攻撃に対する耐性の向上", "jabstract": "最近、敵対的な堅牢性に注目が集まっており、主流の解決策は敵対的なトレーニングです。しかし、NLPの設定では、各入力埋め込みに対して敵対的な摂動を生成する伝統的な方法は、敵対的なサンプルを取得するために必要な勾配ステップの数によってトレーニングの計算複雑性がスケールアップします。この問題に対処するために、私たちは主に汎化を改善することを目的としたFlooding法を活用し、敵対的な攻撃に対する有望な防御策として見つけました。さらに、1エポック内に取られた勾配ステップが各バッチの損失にどのように影響するかを測定することにより、ハイパーパラメータに依存するFloodingを効果的に実現するための効果的な基準を提案します。私たちのアプローチは、トレーニングに敵対的なサンプルを必要とせず、時間の消費量はファインチューニングと同等であり、標準的な敵対的なトレーニングよりも2〜15倍高速です。私たちは実験的に、私たちの方法がBERTのテキスト敵対的攻撃に対する耐性を大幅に向上させ、さまざまなテキスト分類およびGLUEタスクで最新の堅牢性の高い精度を達成することを示しました。"}
{"title": "RoMe: A Robust Metric for Evaluating Natural Language Generation", "url": "https://aclanthology.org/2022.acl-long.387/", "abstract": "Evaluating Natural Language Generation (NLG) systems is a challenging task. Firstly, the metric should ensure that the generated hypothesis reflects the reference’s semantics. Secondly, it should consider the grammatical quality of the generated sentence. Thirdly, it should be robust enough to handle various surface forms of the generated sentence. Thus, an effective evaluation metric has to be multifaceted. In this paper, we propose an automatic evaluation metric incorporating several core aspects of natural language understanding (language competence, syntactic and semantic variation). Our proposed metric, RoMe, is trained on language features such as semantic similarity combined with tree edit distance and grammatical acceptability, using a self-supervised neural network to assess the overall quality of the generated sentence. Moreover, we perform an extensive robustness analysis of the state-of-the-art methods and RoMe. Empirical results suggest that RoMe has a stronger correlation to human judgment over state-of-the-art metrics in evaluating system-generated sentences across several NLG tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "RoMe：自然言語生成を評価するための堅牢なメトリック", "jabstract": "自然言語生成（NLG）システムの評価は困難な課題である。まず、評価指標は生成された仮説が参照の意味を反映していることを保証する必要がある。次に、生成された文の文法的な品質を考慮する必要がある。第三に、生成された文のさまざまな表面形式を処理するために堅牢である必要がある。したがって、効果的な評価指標は多面的である必要がある。本論文では、自然言語理解のいくつかの核心的な側面（言語能力、構文および意味の変化）を組み込んだ自動評価指標を提案する。提案された指標であるRoMeは、意味的類似性と木構造編集距離、文法的受容性などの言語特徴を組み合わせた自己教示型ニューラルネットワークを使用して、生成された文の全体的な品質を評価する。さらに、最新の手法とRoMeの堅牢性分析を行う。実験結果は、RoMeが複数のNLGタスクでシステム生成の文を評価する際に、最新の評価指標よりも人間の判断とより強い相関関係を持つことを示唆している。"}
{"title": "Finding Structural Knowledge in Multimodal-BERT", "url": "https://aclanthology.org/2022.acl-long.388/", "abstract": "In this work, we investigate the knowledge learned in the embeddings of multimodal-BERT models. More specifically, we probe their capabilities of storing the grammatical structure of linguistic data and the structure learned over objects in visual data. To reach that goal, we first make the inherent structure of language and visuals explicit by a dependency parse of the sentences that describe the image and by the dependencies between the object regions in the image, respectively. We call this explicit visual structure the scene tree, that is based on the dependency tree of the language description. Extensive probing experiments show that the multimodal-BERT models do not encode these scene trees.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Multimodal-BERT」における構造的知識の発見", "jabstract": "この論文では、多様なモーダルBERTモデルの埋め込みで学習された知識を調査します。具体的には、言語データの文法的構造と視覚データのオブジェクトに関する学習された構造を格納する能力を調べます。この目標を達成するために、まず、画像を説明する文の依存構造解析と、画像内のオブジェクト領域間の依存関係によって、言語と視覚の固有の構造を明示的にします。これを明示的な視覚構造と呼び、言語説明の依存構造に基づくシーンツリーに基づいています。広範なプロービング実験により、多様なモーダルBERTモデルはこれらのシーンツリーをエンコードしないことが示されました。"}
{"title": "Fully Hyperbolic Neural Networks", "url": "https://aclanthology.org/2022.acl-long.389/", "abstract": "Hyperbolic neural networks have shown great potential for modeling complex data. However, existing hyperbolic networks are not completely hyperbolic, as they encode features in the hyperbolic space yet formalize most of their operations in the tangent space (a Euclidean subspace) at the origin of the hyperbolic model. This hybrid method greatly limits the modeling ability of networks. In this paper, we propose a fully hyperbolic framework to build hyperbolic networks based on the Lorentz model by adapting the Lorentz transformations (including boost and rotation) to formalize essential operations of neural networks. Moreover, we also prove that linear transformation in tangent spaces used by existing hyperbolic networks is a relaxation of the Lorentz rotation and does not include the boost, implicitly limiting the capabilities of existing hyperbolic networks. The experimental results on four NLP tasks show that our method has better performance for building both shallow and deep networks. Our code will be released to facilitate follow-up research.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n完全に双曲的なニューラルネットワーク", "jabstract": "双曲線型ニューラルネットワークは、複雑なデータのモデリングにおいて大きな可能性を示しています。しかし、既存の双曲線型ネットワークは完全に双曲線型ではなく、双曲線空間で特徴をエンコードしながら、ほとんどの操作を双曲線モデルの原点にある接線空間（ユークリッド部分空間）で形式化しています。このハイブリッド手法は、ネットワークのモデリング能力を大きく制限しています。本論文では、ローレンツモデルに基づいて、ローレンツ変換（ブーストと回転を含む）を適応してニューラルネットワークの必要な操作を形式化することで、完全に双曲線型のフレームワークを提案します。さらに、既存の双曲線型ネットワークで使用される接線空間の線形変換が、ローレンツ回転の緩和であり、ブーストを含まないことを証明し、既存の双曲線型ネットワークの能力を暗黙的に制限していることを示します。4つのNLPタスクの実験結果は、浅いネットワークと深いネットワークの両方を構築するための私たちの方法がより優れたパフォーマンスを持つことを示しています。私たちのコードは、後続の研究を促進するためにリリースされます。"}
{"title": "Neural Machine Translation with Phrase-Level Universal Visual Representations", "url": "https://aclanthology.org/2022.acl-long.390/", "abstract": "Multimodal machine translation (MMT) aims to improve neural machine translation (NMT) with additional visual information, but most existing MMT methods require paired input of source sentence and image, which makes them suffer from shortage of sentence-image pairs. In this paper, we propose a phrase-level retrieval-based method for MMT to get visual information for the source input from existing sentence-image data sets so that MMT can break the limitation of paired sentence-image input. Our method performs retrieval at the phrase level and hence learns visual information from pairs of source phrase and grounded region, which can mitigate data sparsity. Furthermore, our method employs the conditional variational auto-encoder to learn visual representations which can filter redundant visual information and only retain visual information related to the phrase. Experiments show that the proposed method significantly outperforms strong baselines on multiple MMT datasets, especially when the textual context is limited.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「フレーズレベルのユニバーサルビジュアル表現を用いたニューラル機械翻訳」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Neural Machine Translation with Phrase-Level Universal Visual Representations\n- フレーズレベルのユニバーサルビジュアル表現を用いたニューラル機械翻訳", "jabstract": "多様なモーダル機械翻訳（MMT）は、追加の視覚情報によってニューラル機械翻訳（NMT）を改善することを目的としていますが、ほとんどの既存のMMT方法は、ソース文と画像のペア入力が必要であり、文-画像のペアが不足しているため、苦しんでいます。本論文では、既存の文-画像データセットからソース入力の視覚情報を取得するためのフレーズレベルの検索ベースのMMT方法を提案し、MMTがペアの文-画像入力の制限を破ることができます。私たちの方法はフレーズレベルで検索を実行し、ソースフレーズと接地領域のペアから視覚情報を学習するため、データのまばらさを緩和できます。さらに、私たちの方法は条件付き変分オートエンコーダを使用して視覚表現を学習し、冗長な視覚情報をフィルタリングし、フレーズに関連する視覚情報のみを保持できます。実験結果は、提案された方法が複数のMMTデータセットで強力なベースラインを大幅に上回り、特にテキストコンテキストが限られている場合に優れていることを示しています。"}
{"title": "M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database", "url": "https://aclanthology.org/2022.acl-long.391/", "abstract": "The emotional state of a speaker can be influenced by many different factors in dialogues, such as dialogue scene, dialogue topic, and interlocutor stimulus. The currently available data resources to support such multimodal affective analysis in dialogues are however limited in scale and diversity. In this work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue dataset, M3ED, which contains 990 dyadic emotional dialogues from 56 different TV series, a total of 9,082 turns and 24,449 utterances. M3ED is annotated with 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and neutral) at utterance level, and encompasses acoustic, visual, and textual modalities. To the best of our knowledge, M3ED is the first multimodal emotional dialogue dataset in Chinese.It is valuable for cross-culture emotion analysis and recognition. We apply several state-of-the-art methods on the M3ED dataset to verify the validity and quality of the dataset. We also propose a general Multimodal Dialogue-aware Interaction framework, MDI, to model the dialogue context for emotion recognition, which achieves comparable performance to the state-of-the-art methods on the M3ED. The full dataset and codes are available.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "M3ED：マルチモーダル・マルチシーン・マルチラベルの感情的な対話データベース", "jabstract": "話者の感情状態は、対話の場面、話題、相手の刺激など、多様な要因によって影響を受ける。しかしながら、現在利用可能なデータリソースは、対話における多様な感情分析をサポートするには規模や多様性が限られている。本研究では、56の異なるテレビシリーズから990の二人対話を含む、合計9,082のターンと24,449の発話を収録した、マルチモーダル・マルチシーン・マルチラベル感情対話データセット（M3ED）を提案する。M3EDは、発話レベルで7つの感情カテゴリ（喜び、驚き、悲しみ、嫌悪、怒り、恐れ、中立）を注釈として持ち、音声、視覚、テキストのモダリティを含む。M3EDは、中国語における初めてのマルチモーダル感情対話データセットであり、異文化間の感情分析と認識に貴重なものである。我々は、M3EDデータセットに対していくつかの最先端の手法を適用し、データセットの妥当性と品質を検証する。また、対話文脈をモデル化するための一般的なマルチモーダル対話認識フレームワーク（MDI）を提案し、M3EDにおいて最先端の手法と同等の性能を達成する。全データセットとコードは利用可能である。"}
{"title": "Few-shot Named Entity Recognition with Self-describing Networks", "url": "https://aclanthology.org/2022.acl-long.392/", "abstract": "Few-shot NER needs to effectively capture information from limited instances and transfer useful knowledge from external resources. In this paper, we propose a self-describing mechanism for few-shot NER, which can effectively leverage illustrative instances and precisely transfer knowledge from external resources by describing both entity types and mentions using a universal concept set. Specifically, we design Self-describing Networks (SDNet), a Seq2Seq generation model which can universally describe mentions using concepts, automatically map novel entity types to concepts, and adaptively recognize entities on-demand. We pre-train SDNet with large-scale corpus, and conduct experiments on 8 benchmarks from different domains. Experiments show that SDNet achieves competitive performances on all benchmarks and achieves the new state-of-the-art on 6 benchmarks, which demonstrates its effectiveness and robustness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己記述ネットワークを用いた少数派の固有表現認識", "jabstract": "Few-shot NERは、限られたインスタンスから情報を効果的に捕捉し、外部リソースから有用な知識を転送する必要があります。本論文では、普遍的な概念セットを使用してエンティティタイプとメンションの両方を記述することにより、説明的なインスタンスを効果的に活用し、外部リソースから知識を正確に転送する自己記述メカニズムを提案します。具体的には、Self-describing Networks（SDNet）と呼ばれるSeq2Seq生成モデルを設計し、概念を使用してメンションを普遍的に記述し、新しいエンティティタイプを自動的に概念にマッピングし、必要に応じてエンティティを適応的に認識します。我々は、大規模なコーパスでSDNetを事前学習し、異なるドメインからの8つのベンチマークで実験を行いました。実験結果は、SDNetがすべてのベンチマークで競争力のある性能を発揮し、6つのベンチマークで新しい最高性能を達成したことを示し、その有効性と堅牢性を証明しています。"}
{"title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing", "url": "https://aclanthology.org/2022.acl-long.393/", "abstract": "Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained natural language processing models, we propose a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. After preprocessing the input speech/text through the pre-nets, the shared encoder-decoder network models the sequence-to-sequence transformation, and then the post-nets generate the output in the speech/text modality based on the output of the decoder. Leveraging large-scale unlabeled speech and text data, we pre-train SpeechT5 to learn a unified-modal representation, hoping to improve the modeling capability for both speech and text. To align the textual and speech information into this unified semantic space, we propose a cross-modal vector quantization approach that randomly mixes up speech/text states with latent units as the interface between encoder and decoder. Extensive evaluations show the superiority of the proposed SpeechT5 framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SpeechT5：音声言語処理のための統合モーダルエンコーダーデコーダープリトレーニング", "jabstract": "T5（Text-To-Text Transfer Transformer）の成功に刺激を受け、自己教師あり音声/テキスト表現学習のためのエンコーダ・デコーダの事前学習を探求する統合モーダルSpeechT5フレームワークを提案する。SpeechT5フレームワークは、共有エンコーダ・デコーダネットワークと6つのモーダル固有（音声/テキスト）のプレ/ポストネットワークで構成されている。入力音声/テキストをプレネットで前処理した後、共有エンコーダ・デコーダネットワークはシーケンス-シーケンス変換をモデル化し、その後、ポストネットはデコーダの出力に基づいて音声/テキストモダリティの出力を生成する。大規模な未ラベル化音声/テキストデータを活用して、SpeechT5を事前学習して統合モーダル表現を学習し、音声とテキストのモデリング能力を向上させることを期待している。テキスト情報と音声情報をこの統合された意味空間に整列させるために、エンコーダとデコーダのインターフェースとして、音声/テキスト状態を潜在ユニットとランダムに混合するクロスモーダルベクトル量子化アプローチを提案する。広範な評価により、自動音声認識、音声合成、音声翻訳、音声変換、音声強調、話者識別などの様々な話し言葉処理タスクにおいて、提案されたSpeechT5フレームワークの優越性が示された。"}
{"title": "Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation", "url": "https://aclanthology.org/2022.acl-long.394/", "abstract": "In recent years, machine learning models have rapidly become better at generating clinical consultation notes; yet, there is little work on how to properly evaluate the generated consultation notes to understand the impact they may have on both the clinician using them and the patient’s clinical safety.To address this we present an extensive human evaluation study of consultation notes where 5 clinicians (i) listen to 57 mock consultations, (ii) write their own notes, (iii) post-edit a number of automatically generated notes, and (iv) extract all the errors, both quantitative and qualitative. We then carry out a correlation study with 18 automatic quality metrics and the human judgements. We find that a simple, character-based Levenshtein distance metric performs on par if not better than common model-based metrics like BertScore. All our findings and annotations are open-sourced.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「診察ノート生成における人間評価と自動評価指標との相関」に関する論文の要約です。", "jabstract": "近年、機械学習モデルは臨床相談ノートの生成において急速に向上してきたが、生成された相談ノートを適切に評価し、それが医師や患者の臨床的安全性に与える影響を理解するための研究はほとんど行われていない。この問題に対処するために、我々は5人の医師が（i）57件の模擬相談を聞き、（ii）自分自身でノートを書き、（iii）自動生成されたノートのいくつかをポスト編集し、（iv）すべての定量的および定性的なエラーを抽出する、広範な人間評価研究を行った。その後、18の自動品質メトリックと人間の判断との相関研究を行った。我々は、単純な文字ベースのレーベンシュタイン距離メトリックが、BertScoreなどの一般的なモデルベースのメトリックよりも同等かそれ以上の性能を発揮することを発見した。すべての結果と注釈はオープンソースである。"}
{"title": "Unified Structure Generation for Universal Information Extraction", "url": "https://aclanthology.org/2022.acl-long.395/", "abstract": "Information extraction suffers from its varying targets, heterogeneous structures, and demand-specific schemas. In this paper, we propose a unified text-to-structure generation framework, namely UIE, which can universally model different IE tasks, adaptively generate targeted structures, and collaboratively learn general IE abilities from different knowledge sources. Specifically, UIE uniformly encodes different extraction structures via a structured extraction language, adaptively generates target extractions via a schema-based prompt mechanism – structural schema instructor, and captures the common IE abilities via a large-scale pretrained text-to-structure model. Experiments show that UIE achieved the state-of-the-art performance on 4 IE tasks, 13 datasets, and on all supervised, low-resource, and few-shot settings for a wide range of entity, relation, event and sentiment extraction tasks and their unification. These results verified the effectiveness, universality, and transferability of UIE.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "普遍的な情報抽出のための統一された構造生成", "jabstract": "情報抽出は、その対象の多様性、異種構造、および需要に応じたスキーマに苦しんでいます。本論文では、異なるIEタスクを普遍的にモデル化し、ターゲット構造を適応的に生成し、異なる知識源から一般的なIE能力を共同学習する統一されたテキスト-構造生成フレームワークであるUIEを提案します。具体的には、UIEは、構造化抽出言語を介して異なる抽出構造を均一に符号化し、スキーマベースのプロンプトメカニズムである構造スキーマインストラクタによってターゲット抽出を適応的に生成し、大規模な事前学習済みテキスト-構造モデルを介して共通のIE能力を捉えます。実験の結果、UIEは、広範なエンティティ、関係、イベント、および感情抽出タスクとその統合のための監視された、低リソース、およびフューショット設定のすべてのIEタスク、13のデータセットで最先端のパフォーマンスを達成しました。これらの結果は、UIEの効果的で普遍的で移植可能であることを確認しました。"}
{"title": "Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering", "url": "https://aclanthology.org/2022.acl-long.396/", "abstract": "Recent works on knowledge base question answering (KBQA) retrieve subgraphs for easier reasoning. The desired subgraph is crucial as a small one may exclude the answer but a large one might introduce more noises. However, the existing retrieval is either heuristic or interwoven with the reasoning, causing reasoning on the partial subgraphs, which increases the reasoning bias when the intermediate supervision is missing. This paper proposes a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive experiments demonstrate SR achieves significantly better retrieval and QA performance than existing retrieval methods. Via weakly supervised pre-training as well as the end-to-end fine-tuning, SR achieves new state-of-the-art performance when combined with NSM (He et al., 2021), a subgraph-oriented reasoner, for embedding-based KBQA methods. Codes and datasets are available online (https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA)", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多段階知識ベース質問応答のためのサブグラフ検索強化モデル", "jabstract": "知識ベース質問応答（KBQA）に関する最近の研究では、より簡単な推論のためにサブグラフを取得することが行われています。望ましいサブグラフは、小さいものでは回答を除外する可能性があり、大きいものではより多くのノイズを導入する可能性があるため、重要です。しかし、既存の取得方法は、ヒューリスティックまたは推論と絡み合っているため、中間監視が欠落している場合には部分的なサブグラフでの推論が増加し、推論バイアスが増加します。本論文では、後続の推論プロセスから分離された訓練可能なサブグラフ取得器（SR）を提案し、任意のサブグラフ指向KBQAモデルを強化するためのプラグアンドプレイフレームワークを実現します。広範な実験により、SRが既存の取得方法よりも優れた取得およびQAパフォーマンスを達成することが示されています。弱く監視された事前トレーニングとエンドツーエンドのファインチューニングを通じて、SRは、埋め込みベースのKBQA方法のサブグラフ指向の推論器であるNSM（He et al.、2021）と組み合わせた場合に、新しい最先端のパフォーマンスを達成します。コードとデータセットはオンラインで利用可能です（https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA）。"}
{"title": "Pre-training to Match for Unified Low-shot Relation Extraction", "url": "https://aclanthology.org/2022.acl-long.397/", "abstract": "Low-shot relation extraction (RE) aims to recognize novel relations with very few or even no samples, which is critical in real scenario application. Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem to be with similar target but require totally different underlying abilities. In this paper, we propose Multi-Choice Matching Networks to unify low-shot relation extraction. To fill in the gap between zero-shot and few-shot RE, we propose the triplet-paraphrase meta-training, which leverages triplet paraphrase to pre-train zero-shot label matching ability and uses meta-learning paradigm to learn few-shot instance summarizing ability. Experimental results on three different low-shot RE tasks show that the proposed method outperforms strong baselines by a large margin, and achieve the best performance on few-shot RE leaderboard.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n統一された低ショット関係抽出のための事前学習", "jabstract": "低ショット関係抽出（RE）は、非常に少数またはまったくサンプルがない状況で新しい関係を認識することを目的としており、実際のシナリオアプリケーションにおいて重要です。フューショットおよびゼロショットREは、類似したターゲットを持つように見えますが、完全に異なる基盤能力を必要とします。本論文では、マルチチョイスマッチングネットワークを提案し、低ショット関係抽出を統一します。ゼロショットとフューショットREのギャップを埋めるために、トリプレットパラフレーズメタトレーニングを提案し、トリプレットパラフレーズを活用してゼロショットラベルマッチング能力を事前学習し、メタラーニングパラダイムを使用してフューショットインスタンス要約能力を学習します。3つの異なる低ショットREタスクの実験結果は、提案手法が強力なベースラインを大幅に上回り、フューショットREリーダーボードで最高のパフォーマンスを達成したことを示しています。"}
{"title": "Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View", "url": "https://aclanthology.org/2022.acl-long.398/", "abstract": "Prompt-based probing has been widely used in evaluating the abilities of pretrained language models (PLMs). Unfortunately, recent studies have discovered such an evaluation may be inaccurate, inconsistent and unreliable. Furthermore, the lack of understanding its inner workings, combined with its wide applicability, has the potential to lead to unforeseen risks for evaluating and applying PLMs in real-world applications. To discover, understand and quantify the risks, this paper investigates the prompt-based probing from a causal view, highlights three critical biases which could induce biased results and conclusions, and proposes to conduct debiasing via causal intervention. This paper provides valuable insights for the design of unbiased datasets, better probing frameworks and more reliable evaluations of pretrained language models. Furthermore, our conclusions also echo that we need to rethink the criteria for identifying better pretrained language models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Prompt Probe Pretrained Language Modelsは可能か？因果的視点から見た見えないリスクの理解", "jabstract": "プロンプトベースのプロービングは、事前学習言語モデル（PLM）の能力を評価するために広く使用されています。残念ながら、最近の研究では、この評価が不正確で一貫性がなく信頼性がないことが発見されています。さらに、その内部機能の理解の欠如と広範な適用性が組み合わされると、PLMの評価と適用に予期しないリスクが生じる可能性があります。この論文では、因果関係の観点からプロンプトベースのプロービングを調査し、バイアスのある結果と結論を導く可能性がある3つの重要なバイアスを強調し、因果関係の介入によるデバイアスを行うことを提案しています。この論文は、バイアスのないデータセット、より良いプロービングフレームワーク、より信頼性の高い事前学習言語モデルの評価の設計について貴重な洞察を提供します。さらに、私たちの結論は、より良い事前学習言語モデルを特定するための基準を再考する必要があることを示しています。"}
{"title": "Evaluating Extreme Hierarchical Multi-label Classification", "url": "https://aclanthology.org/2022.acl-long.399/", "abstract": "Several natural language processing (NLP) tasks are defined as a classification problem in its most complex form: Multi-label Hierarchical Extreme classification, in which items may be associated with multiple classes from a set of thousands of possible classes organized in a hierarchy and with a highly unbalanced distribution both in terms of class frequency and the number of labels per item. We analyze the state of the art of evaluation metrics based on a set of formal properties and we define an information theoretic based metric inspired by the Information Contrast Model (ICM). Experiments on synthetic data and a case study on real data show the suitability of the ICM for such scenarios.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n極端な階層的多ラベル分類の評価", "jabstract": "自然言語処理（NLP）のいくつかのタスクは、最も複雑な形式の分類問題として定義されます。多ラベル階層的極端分類として、アイテムは、階層的に組織化された数千の可能なクラスのセットから複数のクラスに関連付けられ、クラスの頻度とアイテムあたりのラベル数の両方において高度に不均衡な分布を示します。私たちは、一連の形式的な特性に基づく評価メトリックの最新の状況を分析し、情報対比モデル（ICM）に着想を得た情報理論に基づくメトリックを定義します。合成データ上の実験と実データのケーススタディにより、ICMがこのようなシナリオに適していることが示されます。"}
{"title": "What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels", "url": "https://aclanthology.org/2022.acl-long.400/", "abstract": "We present a complete pipeline to extract characters in a novel and link them to their direct-speech utterances. Our model is divided into three independent components: extracting direct-speech, compiling a list of characters, and attributing those characters to their utterances. Although we find that existing systems can perform the first two tasks accurately, attributing characters to direct speech is a challenging problem due to the narrator’s lack of explicit character mentions, and the frequent use of nominal and pronominal coreference when such explicit mentions are made. We adapt the progress made on Dialogue State Tracking to tackle a new problem: attributing speakers to dialogues. This is the first application of deep learning to speaker attribution, and it shows that is possible to overcome the need for the hand-crafted features and rules used in the past. Our full pipeline improves the performance of state-of-the-art models by a relative 50% in F1-score.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "海は岸に何を語りかけるのか？小説における話者と対話の帰属をBERTベースのDSTスタイルアプローチによって解決する。", "jabstract": "私たちは小説からキャラクターを抽出し、それらを直接話し言葉にリンクする完全なパイプラインを提供します。私たちのモデルは3つの独立したコンポーネントに分かれています：直接話し言葉の抽出、キャラクターのリストの編集、そしてそれらのキャラクターを彼らの発言に帰属させること。既存のシステムが最初の2つのタスクを正確に実行できることがわかりましたが、直接話し言葉にキャラクターを帰属させることは、ナレーターが明示的なキャラクターの言及を欠いていること、そしてそのような明示的な言及がある場合には名詞的および代名詞的な共参照の頻繁な使用のため、課題となります。私たちは、対話状態追跡で進展したことを適応して、新しい問題である話者の帰属を解決するために取り組んでいます。これは話者の帰属に深層学習を適用する最初のアプリケーションであり、過去に使用された手作りの特徴量やルールの必要性を克服できることを示しています。私たちの完全なパイプラインは、F1スコアで最先端のモデルの性能を相対的に50％向上させます。"}
{"title": "Measuring Fairness of Text Classifiers via Prediction Sensitivity", "url": "https://aclanthology.org/2022.acl-long.401/", "abstract": "With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions. Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. In this work, we propose a new formulation – accumulated prediction sensitivity, which measures fairness in machine learning models based on the model’s prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group. We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans’ perception of fairness. We conduct experiments on two text classification datasets – Jigsaw Toxicity, and Bias in Bios, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n予測感度を通じたテキスト分類器の公平性の測定", "jabstract": "言語処理アプリケーションの急速な成長に伴い、データ駆動型の解決策において公平性が重要な考慮事項として浮上しています。最近の文献では、様々な公平性の定義が探求されていますが、どの指標がシステムの公平性を最も正確に反映するかについては合意が得られていません。本研究では、入力特徴量の摂動に対するモデルの予測感度に基づいて機械学習モデルの公平性を測定する新しい公式「累積予測感度」を提案します。この指標は、保護された属性が個人の保護グループのメンバーシップ状態をエンコードする場合に、単一の予測が保護された属性に依存する程度を定量化しようとします。この指標は、特定のグループ公平性（統計的公平性）と個人公平性の特定の概念と理論的に関連付けることができます。また、人間の公平性の認識とも良く相関します。Jigsaw ToxicityとBias in Biosの2つのテキスト分類データセットで実験を行い、モデルが公平な結果を出したかどうかに関する手動注釈と指標の相関を評価しました。予測感度に基づく提案された公平性指標は、既存の因果公平性指標よりも人間の注釈と統計的に有意に相関することが観察されました。"}
{"title": "RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion", "url": "https://aclanthology.org/2022.acl-long.402/", "abstract": "Temporal factors are tied to the growth of facts in realistic applications, such as the progress of diseases and the development of political situation, therefore, research on Temporal Knowledge Graph (TKG) attracks much attention. In TKG, relation patterns inherent with temporality are required to be studied for representation learning and reasoning across temporal facts. However, existing methods can hardly model temporal relation patterns, nor can capture the intrinsic connections between relations when evolving over time, lacking of interpretability. In this paper, we propose a novel temporal modeling method which represents temporal entities as Rotations in Quaternion Vector Space (RotateQVS) and relations as complex vectors in Hamilton’s quaternion space. We demonstrate our method can model key patterns of relations in TKG, such as symmetry, asymmetry, inverse, and can capture time-evolved relations by theory. And empirically, we show that our method can boost the performance of link prediction tasks over four temporal knowledge graph benchmarks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "RotateQVS：時間的知識グラフの完成のために、時間情報を四元数ベクトル空間内の回転として表現する。", "jabstract": "現実的なアプリケーションにおいて、疾患の進行や政治情勢の発展など、時間的要因は事実の成長に関連しており、そのため、時間的知識グラフ（TKG）に関する研究が注目を集めています。TKGでは、時間性に固有の関係パターンを研究し、時間的事実を跨いで表現学習と推論を行う必要があります。しかし、既存の方法では時間的関係パターンをモデル化することができず、時間の経過に伴う関係間の本質的なつながりを捉えることができず、解釈可能性に欠けています。本論文では、時間的エンティティを四元数ベクトル空間で回転として表現し、関係をハミルトンの四元数空間の複素ベクトルとして表現する新しい時間モデリング方法を提案します。我々の方法は、対称性、非対称性、逆関係など、TKGの主要な関係パターンをモデル化でき、理論によって時間的に進化する関係を捉えることができます。また、実証的に、我々の方法は、4つの時間的知識グラフベンチマークにおけるリンク予測タスクの性能を向上させることができることを示します。"}
{"title": "Feeding What You Need by Understanding What You Learned", "url": "https://aclanthology.org/2022.acl-long.403/", "abstract": "Machine Reading Comprehension (MRC) reveals the ability to understand a given text passage and answer questions based on it. Existing research works in MRC rely heavily on large-size models and corpus to improve the performance evaluated by metrics such as Exact Match (EM) and F1. However, such a paradigm lacks sufficient interpretation to model capability and can not efficiently train a model with a large corpus. In this paper, we argue that a deep understanding of model capabilities and data properties can help us feed a model with appropriate training data based on its learning status. Specifically, we design an MRC capability assessment framework that assesses model capabilities in an explainable and multi-dimensional manner. Based on it, we further uncover and disentangle the connections between various data properties and model performance. Finally, to verify the effectiveness of the proposed MRC capability assessment framework, we incorporate it into a curriculum learning pipeline and devise a Capability Boundary Breakthrough Curriculum (CBBC) strategy, which performs a model capability-based training to maximize the data value and improve training efficiency. Extensive experiments demonstrate that our approach significantly improves performance, achieving up to an 11.22% / 8.71% improvement of EM / F1 on MRC tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "学んだことを理解して必要なものを提供することによるフィードバック", "jabstract": "マシンリーディングコンプリヘンション（MRC）は、与えられたテキストパッセージを理解し、それに基づいて質問に答える能力を示します。MRCに関する既存の研究は、Exact Match（EM）およびF1などのメトリックによって評価されるパフォーマンスを向上させるために、大規模なモデルとコーパスに重点を置いています。しかし、そのようなパラダイムには、モデルの能力をモデル化するための十分な解釈が欠けており、大規模なコーパスで効率的にモデルをトレーニングすることができません。本論文では、モデルの能力とデータの特性についての深い理解が、学習状況に基づいて適切なトレーニングデータをモデルに供給するのに役立つことを主張します。具体的には、モデルの能力を説明可能で多次元的に評価するMRC能力評価フレームワークを設計します。これに基づいて、さまざまなデータ特性とモデルパフォーマンスの関係を明らかにし、提案されたMRC能力評価フレームワークの効果を検証するために、カリキュラム学習パイプラインに組み込み、能力境界突破カリキュラム（CBBC）戦略を考案します。これにより、モデルの能力に基づいたトレーニングを実行し、データの価値を最大化し、トレーニング効率を改善します。広範な実験により、提案手法がパフォーマンスを大幅に改善し、MRCタスクでEM / F1の最大11.22％/ 8.71％の改善を達成することが示されました。"}
{"title": "Probing Simile Knowledge from Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.404/", "abstract": "Simile interpretation (SI) and simile generation (SG) are challenging tasks for NLP because models require adequate world knowledge to produce predictions. Previous works have employed many hand-crafted resources to bring knowledge-related into models, which is time-consuming and labor-intensive. In recent years, pre-trained language models (PLMs) based approaches have become the de-facto standard in NLP since they learn generic knowledge from a large corpus. The knowledge embedded in PLMs may be useful for SI and SG tasks. Nevertheless, there are few works to explore it. In this paper, we probe simile knowledge from PLMs to solve the SI and SG tasks in the unified framework of simile triple completion for the first time. The backbone of our framework is to construct masked sentences with manual patterns and then predict the candidate words in the masked position. In this framework, we adopt a secondary training process (Adjective-Noun mask Training) with the masked language model (MLM) loss to enhance the prediction diversity of candidate words in the masked position. Moreover, pattern ensemble (PE) and pattern search (PS) are applied to improve the quality of predicted words. Finally, automatic and human evaluations demonstrate the effectiveness of our framework in both SI and SG tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルからの比喩知識の探索", "jabstract": "類比解釈（SI）と類比生成（SG）は、NLPにとって適切な世界知識が必要であるため、困難なタスクである。従来の研究では、モデルに知識をもたらすために多くの手作業リソースが使用されており、時間と労力がかかっていた。近年、大規模なコーパスから一般的な知識を学習するための事前学習言語モデル（PLMs）ベースのアプローチがNLPのデファクトスタンダードとなっている。PLMsに埋め込まれた知識は、SIおよびSGタスクに有用である可能性がある。しかし、それを探求する研究はほとんどない。本論文では、類比トリプル完了の統一フレームワークで、PLMsから類比知識を探求し、SIおよびSGタスクを解決する。フレームワークのバックボーンは、手動パターンを使用してマスクされた文を構築し、マスクされた位置の候補単語を予測することである。このフレームワークでは、マスクされた言語モデル（MLM）損失を使用した二次トレーニングプロセス（形容詞-名詞マスクトレーニング）を採用して、マスクされた位置の候補単語の予測多様性を強化する。さらに、パターンアンサンブル（PE）とパターンサーチ（PS）を適用して、予測された単語の品質を向上させる。最後に、自動評価と人間の評価により、SIおよびSGタスクの両方でフレームワークの有効性が示された。"}
{"title": "An Effective and Efficient Entity Alignment Decoding Algorithm via Third-Order Tensor Isomorphism", "url": "https://aclanthology.org/2022.acl-long.405/", "abstract": "Entity alignment (EA) aims to discover the equivalent entity pairs between KGs, which is a crucial step for integrating multi-source KGs.For a long time, most researchers have regarded EA as a pure graph representation learning task and focused on improving graph encoders while paying little attention to the decoding process.In this paper, we propose an effective and efficient EA Decoding Algorithm via Third-order Tensor Isomorphism (DATTI).Specifically, we derive two sets of isomorphism equations: (1) Adjacency tensor isomorphism equations and (2) Gramian tensor isomorphism equations.By combining these equations, DATTI could effectively utilize the adjacency and inner correlation isomorphisms of KGs to enhance the decoding process of EA.Extensive experiments on public datasets indicate that our decoding algorithm can deliver significant performance improvements even on the most advanced EA methods, while the extra required time is less than 3 seconds.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "第三階テンソル同型を介した効果的かつ効率的なエンティティアラインメントデコーディングアルゴリズム", "jabstract": "エンティティアラインメント（EA）は、複数の知識グラフを統合するための重要なステップである、知識グラフ間の同等なエンティティペアを発見することを目的としています。長い間、ほとんどの研究者はEAを純粋なグラフ表現学習タスクと見なし、グラフエンコーダーの改善に焦点を当ててきましたが、デコーディングプロセスにはほとんど注意を払っていませんでした。本論文では、第三階テンソル同型性を利用した効果的かつ効率的なEAデコーディングアルゴリズム（DATTI）を提案します。具体的には、2つの同型性方程式を導出します：（1）隣接テンソル同型性方程式と（2）グラミアンテンソル同型性方程式。これらの方程式を組み合わせることで、DATTIはKGの隣接および内部相関同型性を効果的に利用してEAのデコーディングプロセスを強化することができます。公開データセットでの広範な実験により、最も高度なEA方法でも、追加の必要時間が3秒未満であっても、デコーディングアルゴリズムが大幅な性能向上をもたらすことが示されました。"}
{"title": "Entailment Graph Learning with Textual Entailment and Soft Transitivity", "url": "https://aclanthology.org/2022.acl-long.406/", "abstract": "Typed entailment graphs try to learn the entailment relations between predicates from text and model them as edges between predicate nodes. The construction of entailment graphs usually suffers from severe sparsity and unreliability of distributional similarity. We propose a two-stage method, Entailment Graph with Textual Entailment and Transitivity (EGT2). EGT2 learns the local entailment relations by recognizing the textual entailment between template sentences formed by typed CCG-parsed predicates. Based on the generated local graph, EGT2 then uses three novel soft transitivity constraints to consider the logical transitivity in entailment structures. Experiments on benchmark datasets show that EGT2 can well model the transitivity in entailment graph to alleviate the sparsity, and leads to signifcant improvement over current state-of-the-art methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「テキストの含意とソフトトランジティブを用いた含意グラフ学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Entailment Graph Learning with Textual Entailment and Soft Transitivity\n- テキストの含意とソフトトランジティブを用いた含意グラフ学習", "jabstract": "タイプ付き含意グラフは、テキストから述語間の含意関係を学習し、述語ノード間のエッジとしてモデル化することを試みます。含意グラフの構築は、通常、分布類似性の深刻な疎密性と信頼性の欠如に苦しんでいます。我々は、テキスト含意と推移性を持つ含意グラフ（EGT2）という2段階の方法を提案します。EGT2は、タイプ付きCCG解析述語によって形成されたテンプレート文間のテキスト含意を認識することによって、ローカルな含意関係を学習します。生成されたローカルグラフに基づいて、EGT2は、3つの新しいソフト推移性制約を使用して、含意構造の論理的推移性を考慮します。ベンチマークデータセット上の実験結果は、EGT2が含意グラフの推移性をうまくモデル化して疎密性を緩和し、現在の最先端の方法よりも大幅に改善することを示しています。"}
{"title": "Logic Traps in Evaluating Attribution Scores", "url": "https://aclanthology.org/2022.acl-long.407/", "abstract": "Modern deep learning models are notoriously opaque, which has motivated the development of methods for interpreting how deep models predict.This goal is usually approached with attribution method, which assesses the influence of features on model predictions. As an explanation method, the evaluation criteria of attribution methods is how accurately it reflects the actual reasoning process of the model (faithfulness). Meanwhile, since the reasoning process of deep models is inaccessible, researchers design various evaluation methods to demonstrate their arguments.However, some crucial logic traps in these evaluation methods are ignored in most works, causing inaccurate evaluation and unfair comparison.This paper systematically reviews existing methods for evaluating attribution scores and summarizes the logic traps in these methods.We further conduct experiments to demonstrate the existence of each logic trap.Through both theoretical and experimental analysis, we hope to increase attention on the inaccurate evaluation of attribution scores. Moreover, with this paper, we suggest stopping focusing on improving performance under unreliable evaluation systems and starting efforts on reducing the impact of proposed logic traps.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n属性スコアの評価における論理トラップ", "jabstract": "現代の深層学習モデルは、通常、予測の深層モデルの解釈方法の開発を促進する不透明性がある。この目標は、通常、モデル予測に対する特徴の影響を評価する帰属方法でアプローチされる。説明方法として、帰属方法の評価基準は、モデルの実際の推論プロセスをどの程度正確に反映するか（忠実度）である。一方、深層モデルの推論プロセスが不可視であるため、研究者は、自分たちの主張を示すためにさまざまな評価方法を設計している。しかし、これらの評価方法には、多くの作品で無視されている重要な論理トラップがあり、不正確な評価と不公平な比較を引き起こしている。本論文では、帰属スコアを評価するための既存の方法を体系的にレビューし、これらの方法の論理トラップをまとめる。さらに、各論理トラップの存在を実験で示す。理論的および実験的分析を通じて、帰属スコアの不正確な評価に対する注意を高めることを目的としています。さらに、本論文により、信頼性の低い評価システムの下でのパフォーマンスの改善に焦点を当てるのをやめ、提案された論理トラップの影響を減らす努力を開始することを提案します。"}
{"title": "Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network", "url": "https://aclanthology.org/2022.acl-long.408/", "abstract": "In this paper, we study how to continually pre-train language models for improving the understanding of math problems. Specifically, we focus on solving a fundamental challenge in modeling math problems, how to fuse the semantics of textual description and formulas, which are highly different in essence. To address this issue, we propose a new approach called COMUS to continually pre-train language models for math problem understanding with syntax-aware memory network. In this approach, we first construct the math syntax graph to model the structural semantic information, by combining the parsing trees of the text and formulas, and then design the syntax-aware memory networks to deeply fuse the features from the graph and text. With the help of syntax relations, we can model the interaction between the token from the text and its semantic-related nodes within the formulas, which is helpful to capture fine-grained semantic correlations between texts and formulas. Besides, we devise three continual pre-training tasks to further align and fuse the representations of the text and math syntax graph. Experimental results on four tasks in the math domain demonstrate the effectiveness of our approach. Our code and data are publicly available at the link: bluehttps://github.com/RUCAIBox/COMUS.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n構文意識メモリネットワークを用いた数学問題理解のための言語モデルの継続的事前学習", "jabstract": "本論文では、数学問題の理解を改善するために、言語モデルを継続的に事前学習する方法を研究します。具体的には、数式とテキストの意味を融合するという、数学問題モデリングにおける基本的な課題を解決することに焦点を当てます。この問題に対処するために、我々は、構文に注意したメモリネットワークを用いた数学問題理解のための言語モデルの継続的な事前学習を提案するCOMUSという新しいアプローチを提案します。このアプローチでは、まず、テキストと数式の構文木を組み合わせて数学構文グラフを構築し、その後、構文に注意したメモリネットワークを設計して、グラフとテキストからの特徴を深く融合します。構文関係の助けを借りて、テキストからのトークンと数式内の意味関連ノードとの相互作用をモデル化することができ、テキストと数式の微細な意味的相関を捉えるのに役立ちます。さらに、テキストと数学構文グラフの表現をさらに整列・融合するための3つの継続的な事前学習タスクを考案しました。数学領域の4つのタスクでの実験結果は、我々のアプローチの有効性を示しています。我々のコードとデータは、以下のリンクから公開されています：bluehttps://github.com/RUCAIBox/COMUS。"}
{"title": "Multitasking Framework for Unsupervised Simple Definition Generation", "url": "https://aclanthology.org/2022.acl-long.409/", "abstract": "The definition generation task can help language learners by providing explanations for unfamiliar words. This task has attracted much attention in recent years. We propose a novel task of Simple Definition Generation (SDG) to help language learners and low literacy readers. A significant challenge of this task is the lack of learner’s dictionaries in many languages, and therefore the lack of data for supervised training. We explore this task and propose a multitasking framework SimpDefiner that only requires a standard dictionary with complex definitions and a corpus containing arbitrary simple texts. We disentangle the complexity factors from the text by carefully designing a parameter sharing scheme between two decoders. By jointly training these components, the framework can generate both complex and simple definitions simultaneously. We demonstrate that the framework can generate relevant, simple definitions for the target words through automatic and manual evaluations on English and Chinese datasets. Our method outperforms the baseline model by a 1.77 SARI score on the English dataset, and raises the proportion of the low level (HSK level 1-3) words in Chinese definitions by 3.87%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「無監視の簡単な定義生成のためのマルチタスクフレームワーク」", "jabstract": "定義生成タスクは、未知の単語の説明を提供することで言語学習者を支援することができます。このタスクは近年注目を集めています。我々は、言語学習者や低識字読者を支援するためのSimple Definition Generation（SDG）という新しいタスクを提案します。このタスクの重要な課題は、多くの言語における学習者用辞書の不足と、教師あり学習のためのデータの不足です。我々はこのタスクを探求し、複雑な定義を持つ標準的な辞書と任意の簡単なテキストを含むコーパスのみを必要とするマルチタスキングフレームワークSimpDefinerを提案します。2つのデコーダー間のパラメータ共有スキームを注意深く設計することで、テキストから複雑な要因を分離します。これらのコンポーネントを共同でトレーニングすることにより、フレームワークは複雑な定義と簡単な定義を同時に生成することができます。英語と中国語のデータセットでの自動評価と手動評価により、フレームワークが対象単語の関連する簡単な定義を生成できることを示します。我々の手法は、英語のデータセットで1.77のSARIスコアでベースラインモデルを上回り、中国語の定義における低レベル（HSKレベル1-3）の単語の割合を3.87％増加させます。"}
{"title": "Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction", "url": "https://aclanthology.org/2022.acl-long.410/", "abstract": "Solving math word problems requires deductive reasoning over the quantities in the text. Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context. While empirically effective, such approaches typically do not provide explanations for the generated expressions. In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation. Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines. We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "演繹的推論を学ぶ：複雑な関係抽出としての数学のワード問題の解決", "jabstract": "数学の文章問題を解くには、文章中の数量に対する演繹的推論が必要です。最近の研究では、主にシーケンス・トゥ・シーケンスまたはシーケンス・トゥ・ツリー・モデルを用いて、与えられた文脈内の数量の関係を明示的に推論することなく、数式を生成することが多かった。これらの手法は実証的に効果的であるが、生成された式の説明を提供することはできない。本研究では、このタスクを複雑な関係抽出問題と見なし、目標式を反復的に構築するための説明可能な演繹的推論手順を提案する。各ステップは、与えられた文脈内の2つの数量の関係を定義する2つの数量に対する原始的な操作を含みます。4つのベンチマークデータセットでの広範な実験により、提案されたモデルが既存の強力なベースラインを大幅に上回ることを示しました。さらに、演繹的手順はより説明可能なステップを提供するだけでなく、より複雑な推論が必要な質問に対してより正確な予測を可能にすることを示しました。"}
{"title": "When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues", "url": "https://aclanthology.org/2022.acl-long.411/", "abstract": "Indirect speech such as sarcasm achieves a constellation of discourse goals in human communication. While the indirectness of figurative language warrants speakers to achieve certain pragmatic goals, it is challenging for AI agents to comprehend such idiosyncrasies of human communication. Though sarcasm identification has been a well-explored topic in dialogue analysis, for conversational systems to truly grasp a conversation’s innate meaning and generate appropriate responses, simply detecting sarcasm is not enough; it is vital to explain its underlying sarcastic connotation to capture its true essence. In this work, we study the discourse structure of sarcastic conversations and propose a novel task – Sarcasm Explanation in Dialogue (SED). Set in a multimodal and code-mixed setting, the task aims to generate natural language explanations of satirical conversations. To this end, we curate WITS, a new dataset to support our task. We propose MAF (Modality Aware Fusion), a multimodal context-aware attention and global information fusion module to capture multimodality and use it to benchmark WITS. The proposed attention module surpasses the traditional multimodal fusion baselines and reports the best performance on almost all metrics. Lastly, we carry out detailed analysis both quantitatively and qualitatively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「いつからそんなに賢くなったのですか、お賢者様？！マルチモーダルマルチパーティダイアログにおける皮肉の説明」", "jabstract": "間接話法、例えば皮肉などは、人間のコミュニケーションにおいて多様な談話目標を達成する。比喩的な言語の間接性は、話者が特定の実用的な目標を達成することを保証するが、AIエージェントが人間のコミュニケーションのこのような特異性を理解することは困難である。皮肉の識別は、対話分析においてよく研究されたトピックであるが、会話の本来の意味を理解し、適切な応答を生成するためには、単に皮肉を検出するだけでは不十分であり、その真の本質を捉えるためにその根底にある皮肉の意味を説明することが重要である。本研究では、皮肉的な会話の談話構造を研究し、対話における皮肉の説明という新しいタスクを提案する。多様なモーダルとコードミックスの設定で行われるこのタスクは、風刺的な会話の自然言語の説明を生成することを目的としている。このために、私たちはWITSという新しいデータセットを作成し、私たちのタスクをサポートする。私たちは、多様なモーダルに対応したコンテキストに注意を払い、グローバル情報の融合モジュールであるMAF（Modality Aware Fusion）を提案し、これを使用してWITSをベンチマークに使用する。提案された注意モジュールは、従来の多様なモーダル融合のベースラインを超え、ほとんどすべてのメトリックで最高のパフォーマンスを報告する。最後に、私たちは定量的および定性的な詳細な分析を実施する。"}
{"title": "Toward Interpretable Semantic Textual Similarity via Optimal Transport-based Contrastive Sentence Learning", "url": "https://aclanthology.org/2022.acl-long.412/", "abstract": "Recently, finetuning a pretrained language model to capture the similarity between sentence embeddings has shown the state-of-the-art performance on the semantic textual similarity (STS) task. However, the absence of an interpretation method for the sentence similarity makes it difficult to explain the model output. In this work, we explicitly describe the sentence distance as the weighted sum of contextualized token distances on the basis of a transportation problem, and then present the optimal transport-based distance measure, named RCMD; it identifies and leverages semantically-aligned token pairs. In the end, we propose CLRCMD, a contrastive learning framework that optimizes RCMD of sentence pairs, which enhances the quality of sentence similarity and their interpretation. Extensive experiments demonstrate that our learning framework outperforms other baselines on both STS and interpretable-STS benchmarks, indicating that it computes effective sentence similarity and also provides interpretation consistent with human judgement.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "最適輸送ベースの対照的文学習を通じた解釈可能な意味的テキスト類似性に向けて", "jabstract": "最近、事前学習された言語モデルをファインチューニングして文の埋め込みの類似性を捉えることが、意味的テキスト類似性（STS）タスクにおいて最先端の性能を示すことが示されています。しかし、文の類似性の解釈方法がないため、モデルの出力を説明することが困難です。本研究では、輸送問題に基づいて文脈化されたトークンの距離の重み付き和として文の距離を明示的に説明し、意味的に整列したトークンペアを特定して活用する最適輸送ベースの距離尺度であるRCMDを提案します。最後に、文のペアのRCMDを最適化する対照的学習フレームワークであるCLRCMDを提案し、文の類似性とその解釈の品質を向上させます。広範な実験により、学習フレームワークがSTSおよび解釈可能なSTSベンチマークの両方で他のベースラインを上回り、効果的な文の類似性を計算し、人間の判断と一致する解釈を提供することが示されました。"}
{"title": "Pre-training and Fine-tuning Neural Topic Model: A Simple yet Effective Approach to Incorporating External Knowledge", "url": "https://aclanthology.org/2022.acl-long.413/", "abstract": "Recent years have witnessed growing interests in incorporating external knowledge such as pre-trained word embeddings (PWEs) or pre-trained language models (PLMs) into neural topic modeling. However, we found that employing PWEs and PLMs for topic modeling only achieved limited performance improvements but with huge computational overhead. In this paper, we propose a novel strategy to incorporate external knowledge into neural topic modeling where the neural topic model is pre-trained on a large corpus and then fine-tuned on the target dataset. Experiments have been conducted on three datasets and results show that the proposed approach significantly outperforms both current state-of-the-art neural topic models and some topic modeling approaches enhanced with PWEs or PLMs. Moreover, further study shows that the proposed approach greatly reduces the need for the huge size of training data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n事前学習と微調整を行ったニューラルトピックモデル：外部知識を組み込むためのシンプルで効果的なアプローチ", "jabstract": "近年、事前学習された単語埋め込み（PWE）や事前学習された言語モデル（PLM）などの外部知識をニューラルトピックモデリングに組み込むことに関心が高まっています。しかし、PWEやPLMをトピックモデリングに使用することは、計算オーバーヘッドが大きく、限定的な性能向上しか得られないことがわかりました。本論文では、ニューラルトピックモデリングに外部知識を組み込む新しい戦略を提案し、ニューラルトピックモデルを大規模なコーパスで事前学習し、その後、ターゲットデータセットで微調整することを提案します。3つのデータセットで実験を行い、提案手法が現在の最先端のニューラルトピックモデルやPWEやPLMを使用したトピックモデリング手法を大幅に上回ることが示されました。さらに、さらなる研究により、提案手法が大量のトレーニングデータの必要性を大幅に減らすことがわかりました。"}
{"title": "Multi-View Document Representation Learning for Open-Domain Dense Retrieval", "url": "https://aclanthology.org/2022.acl-long.414/", "abstract": "Dense retrieval has achieved impressive advances in first-stage retrieval from a large-scale document collection, which is built on bi-encoder architecture to produce single vector representation of query and document. However, a document can usually answer multiple potential queries from different views. So the single vector representation of a document is hard to match with multi-view queries, and faces a semantic mismatch problem. This paper proposes a multi-view document representation learning framework, aiming to produce multi-view embeddings to represent documents and enforce them to align with different queries. First, we propose a simple yet effective method of generating multiple embeddings through viewers. Second, to prevent multi-view embeddings from collapsing to the same one, we further propose a global-local loss with annealed temperature to encourage the multiple viewers to better align with different potential queries. Experiments show our method outperforms recent works and achieves state-of-the-art results.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オープンドメインの密な検索のためのマルチビュードキュメント表現学習", "jabstract": "密集検索は、大規模文書コレクションからの第1段階の検索において、バイエンコーダーアーキテクチャに基づいてクエリと文書の単一ベクトル表現を生成することで、印象的な進歩を達成しています。しかし、文書は通常、異なる視点から複数の潜在的なクエリに答えることができます。したがって、文書の単一ベクトル表現は、マルチビュークエリと一致させるのが難しく、意味的な不一致の問題に直面します。本論文では、マルチビュードキュメント表現学習フレームワークを提案し、ドキュメントを表現するためのマルチビュー埋め込みを生成し、それらを異なるクエリに合わせることを目的としています。まず、ビューアを介して複数の埋め込みを生成するための単純で効果的な方法を提案します。次に、マルチビュー埋め込みが同じものに収束するのを防ぐために、アニール温度を持つグローバルローカル損失をさらに提案し、複数のビューアが異なる潜在的なクエリによりよく合わせるようにします。実験結果は、当社の方法が最近の作品を上回り、最先端の結果を達成していることを示しています。"}
{"title": "Graph Pre-training for AMR Parsing and Generation", "url": "https://aclanthology.org/2022.acl-long.415/", "abstract": "Abstract meaning representation (AMR) highlights the core semantic information of text in a graph structure.Recently, pre-trained language models (PLMs) have advanced tasks of AMR parsing and AMR-to-text generation, respectively.However, PLMs are typically pre-trained on textual data, thus are sub-optimal for modeling structural knowledge.To this end, we investigate graph self-supervised training to improve the structure awareness of PLMs over AMR graphs.In particular, we introduce two graph auto-encoding strategies for graph-to-graph pre-training and four tasks to integrate text and graph information during pre-training.We further design a unified framework to bridge the gap between pre-training and fine-tuning tasks.Experiments on both AMR parsing and AMR-to-text generation show the superiority of our model.To our knowledge, we are the first to consider pre-training on semantic graphs.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AMR解析と生成のためのグラフ事前学習", "jabstract": "抽象意味表現（AMR）は、テキストの中心的な意味情報をグラフ構造で強調します。最近、事前学習言語モデル（PLMs）は、それぞれAMR解析とAMR-to-text生成のタスクを進化させています。しかし、PLMsは通常、テキストデータで事前学習されるため、構造的な知識をモデル化するのに最適ではありません。このため、私たちはグラフ自己教師付き学習を調査し、AMRグラフ上のPLMsの構造認識を改善することを目的としています。特に、グラフ間事前学習のための2つのグラフ自己符号化戦略と、事前学習中のテキストとグラフ情報の統合のための4つのタスクを紹介します。さらに、事前学習とファインチューニングタスクのギャップを埋めるための統一されたフレームワークを設計します。AMR解析とAMR-to-text生成の両方の実験により、私たちのモデルの優越性が示されました。私たちは、意味グラフでの事前学習を考慮する最初の人々であると思われます。"}
{"title": "Turning Tables: Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills", "url": "https://aclanthology.org/2022.acl-long.416/", "abstract": "Models pre-trained with a language modeling objective possess ample world knowledge and language skills, but are known to struggle in tasks that require reasoning. In this work, we propose to leverage semi-structured tables, and automatically generate at scale question-paragraph pairs, where answering the question requires reasoning over multiple facts in the paragraph. We add a pre-training step over this synthetic data, which includes examples that require 16 different reasoning skills such as number comparison, conjunction, and fact composition. To improve data efficiency, we sample examples from reasoning skills where the model currently errs. We evaluate our approach on three reasoning-focused reading comprehension datasets, and show that our model, PReasM, substantially outperforms T5, a popular pre-trained encoder-decoder model. Moreover, sampling examples based on model errors leads to faster training and higher performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "半構造化テーブルから例を生成し、言語モデルに推論スキルを与えるための論文の要旨です。", "jabstract": "言語モデル目的で事前学習されたモデルは、豊富な世界知識と言語スキルを持っていますが、推論を必要とするタスクに苦戦することが知られています。本研究では、半構造化テーブルを活用し、自動的に問題-段落ペアを大量生成し、問題に答えるためには段落内の複数の事実に対する推論が必要な例を含む合成データに対して事前学習ステップを追加します。この例には、数字の比較、接続詞、事実の構成など、16種類の推論スキルが必要なものが含まれます。モデルが現在エラーを起こしている推論スキルから例をサンプリングすることで、データ効率を改善します。我々は、3つの推論に焦点を当てた読解データセットでアプローチを評価し、PReasMというモデルが、人気のある事前学習エンコーダー・デコーダーモデルであるT5を大幅に上回ることを示しました。さらに、モデルのエラーに基づいて例をサンプリングすることで、より速いトレーニングと高いパフォーマンスが得られます。"}
{"title": "RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering", "url": "https://aclanthology.org/2022.acl-long.417/", "abstract": "Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-of-the-art results on GrailQA and WebQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GrailQA leaderboard. In addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "RNG-KBQA: 知識ベース質問応答のための生成増強反復ランキング", "jabstract": "既存のKBQAアプローチは、i.i.d.テストデータで強力なパフォーマンスを達成しているにもかかわらず、未知のKBスキーマ項目を含む質問に対して一般化することがしばしば困難です。従来のランキングベースのアプローチは一般化に成功しているものの、カバレッジの問題に苦しんでいます。本論文では、ランクアンドジェネレートアプローチを用いたKBQAのRnG-KBQAを提案し、一般化能力を保持しながら生成モデルによってカバレッジの問題を解決します。本アプローチは、まず知識グラフを検索して得られた候補論理式のセットをランク付けするために対比ランカーを使用します。次に、質問とトップランクの候補に基づいて調整された生成モデルを導入して、最終的な論理式を構成します。GrailQAとWebQSPデータセットで新しい最高性能を達成しました。特に、GrailQAリーダーボードで従来の最高性能を大幅に上回りました。さらに、RnG-KBQAは、オラクルエンティティリンキングを使用するものを含め、すべての従来のアプローチを上回り、人気のあるWebQSPベンチマークでも最高のパフォーマンスを発揮しました。実験結果は、ランキングと生成の相互作用の効果を示し、特にゼロショット一般化において強力な改善をもたらす提案手法の優れたパフォーマンスを示しています。"}
{"title": "Rethinking Self-Supervision Objectives for Generalizable Coherence Modeling", "url": "https://aclanthology.org/2022.acl-long.418/", "abstract": "Given the claims of improved text generation quality across various pre-trained neural models, we consider the coherence evaluation of machine generated text to be one of the principal applications of coherence models that needs to be investigated. Prior work in neural coherence modeling has primarily focused on devising new architectures for solving the permuted document task. We instead use a basic model architecture and show significant improvements over state of the art within the same training regime. We then design a harder self-supervision objective by increasing the ratio of negative samples within a contrastive learning setup, and enhance the model further through automatic hard negative mining coupled with a large global negative queue encoded by a momentum encoder. We show empirically that increasing the density of negative samples improves the basic model, and using a global negative queue further improves and stabilizes the model while training with hard negative samples. We evaluate the coherence model on task-independent test sets that resemble real-world applications and show significant improvements in coherence evaluations of downstream tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "一般化可能な一貫性モデリングのための自己監督目標の再考\n\nIn this paper, we propose a new self-supervision objective for coherence modeling that is designed to improve generalization to unseen domains. \n\n本論文では、未知のドメインに対する一般化を改善するために設計された、一貫性モデリングのための新しい自己監督目標を提案します。\n\nOur approach leverages a pre-trained language model to generate synthetic coherence judgments that are used to train a coherence model. \n\n当社のアプローチは、事前にトレーニングされた言語モデルを活用して、一貫性モデルをトレーニングするために使用される合成一貫性判断を生成することによって行われます。\n\nWe show that our approach outperforms existing self-supervision objectives on a range of coherence modeling tasks, including domain adaptation and cross-lingual coherence modeling. \n\n当社のアプローチは、ドメイン適応やクロスリンガル一貫性モデリングを含む一連の一貫性モデリングタスクで、既存の自己監督目標を上回ることを示します。", "jabstract": "様々な事前学習済みニューラルモデルによるテキスト生成品質の向上に関する主張を考慮すると、機械生成テキストの一貫性評価は、調和モデルの主要な応用の1つであると考えられます。ニューラル調和モデリングに関する以前の研究は、主に順列ドキュメントタスクを解決するための新しいアーキテクチャの開発に焦点を当てていました。代わりに、基本的なモデルアーキテクチャを使用し、同じトレーニングレジメン内で最新技術に対して重要な改善を示します。その後、コントラスティブラーニングのセットアップ内で負のサンプルの比率を増やすことにより、より困難な自己監督目標を設計し、モデルを自動的にハードネガティブマイニングと大規模なグローバルネガティブキューによってエンコードされたモーメンタムエンコーダと組み合わせてさらに強化します。負のサンプルの密度を増やすことが基本モデルを改善し、ハードネガティブサンプルでトレーニングする間にグローバルネガティブキューを使用することで、モデルをさらに改善し安定化することを実証的に示します。私たちは、現実世界のアプリケーションに似たタスク非依存のテストセットで調和モデルを評価し、下流タスクの一貫性評価において重要な改善を示します。"}
{"title": "Just Rank: Rethinking Evaluation with Word and Sentence Similarities", "url": "https://aclanthology.org/2022.acl-long.419/", "abstract": "Word and sentence embeddings are useful feature representations in natural language processing. However, intrinsic evaluation for embeddings lags far behind, and there has been no significant update since the past decade. Word and sentence similarity tasks have become the de facto evaluation method. It leads models to overfit to such evaluations, negatively impacting embedding models’ development. This paper first points out the problems using semantic similarity as the gold standard for word and sentence embedding evaluations. Further, we propose a new intrinsic evaluation method called EvalRank, which shows a much stronger correlation with downstream tasks. Extensive experiments are conducted based on 60+ models and popular datasets to certify our judgments. Finally, the practical evaluation toolkit is released for future benchmarking purposes.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Just Rank：単語と文の類似性を用いた評価の再考」は、自然言語処理に関する論文の要約です。", "jabstract": "単語と文の埋め込みは、自然言語処理において有用な特徴表現である。しかし、埋め込みの内在的評価は遅れており、過去10年間に重要な更新はなかった。単語と文の類似性タスクが事実上の評価方法となっており、モデルがこのような評価に過剰適合することで、埋め込みモデルの開発に悪影響を与えている。本論文では、単語と文の埋め込み評価において意味的類似性を基準とする問題点を指摘する。さらに、EvalRankという新しい内在的評価方法を提案し、下流タスクとの相関がより強いことを示す。60以上のモデルと人気のあるデータセットに基づく広範な実験を行い、私たちの判断を証明する。最後に、将来のベンチマーク目的のために実用的な評価ツールキットをリリースする。"}
{"title": "MarkupLM: Pre-training of Text and Markup Language for Visually Rich Document Understanding", "url": "https://aclanthology.org/2022.acl-long.420/", "abstract": "Multimodal pre-training with text, layout, and image has made significant progress for Visually Rich Document Understanding (VRDU), especially the fixed-layout documents such as scanned document images. While, there are still a large number of digital documents where the layout information is not fixed and needs to be interactively and dynamically rendered for visualization, making existing layout-based pre-training approaches not easy to apply. In this paper, we propose MarkupLM for document understanding tasks with markup languages as the backbone, such as HTML/XML-based documents, where text and markup information is jointly pre-trained. Experiment results show that the pre-trained MarkupLM significantly outperforms the existing strong baseline models on several document understanding tasks. The pre-trained model and code will be publicly available at https://aka.ms/markuplm.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MarkupLM：視覚的に豊かなドキュメント理解のためのテキストとマークアップ言語の事前トレーニング", "jabstract": "テキスト、レイアウト、画像を用いたマルチモーダルな事前学習は、特にスキャンされた文書画像などの固定レイアウト文書において、視覚的に豊かな文書理解（VRDU）において重要な進展を遂げています。しかし、レイアウト情報が固定されていない多数のデジタル文書があり、視覚化のために相互作用的かつ動的にレンダリングする必要があるため、既存のレイアウトベースの事前学習手法を適用することは容易ではありません。本論文では、HTML/XMLベースの文書など、マークアップ言語をバックボーンとする文書理解タスクにMarkupLMを提案し、テキストとマークアップ情報を共同で事前学習します。実験結果は、事前学習されたMarkupLMがいくつかの文書理解タスクにおいて既存の強力なベースラインモデルを大幅に上回ることを示しています。事前学習されたモデルとコードは、https://aka.ms/markuplmで公開されます。"}
{"title": "CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment", "url": "https://aclanthology.org/2022.acl-long.421/", "abstract": "CLIP has shown a remarkable zero-shot capability on a wide range of vision tasks. Previously, CLIP is only regarded as a powerful visual encoder. However, after being pre-trained by language supervision from a large amount of image-caption pairs, CLIP itself should also have acquired some few-shot abilities for vision-language tasks. In this work, we empirically show that CLIP can be a strong vision-language few-shot learner by leveraging the power of language. We first evaluate CLIP’s zero-shot performance on a typical visual question answering task and demonstrate a zero-shot cross-modality transfer capability of CLIP on the visual entailment task. Then we propose a parameter-efficient fine-tuning strategy to boost the few-shot performance on the vqa task. We achieve competitive zero/few-shot results on the visual question answering and visual entailment tasks without introducing any additional pre-training procedure.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CLIPモデルはフューショット学習者である：VQAと視覚的帰結に関する経験的研究", "jabstract": "CLIPは、広範なビジョンタスクにおいて驚異的なゼロショット能力を示しています。以前は、CLIPは強力なビジュアルエンコーダーとしてしか認識されていませんでした。しかし、大量の画像キャプションペアからの言語監督による事前学習を受けた後、CLIP自体もビジョン言語タスクのフューショット能力をいくつか獲得しているはずです。本研究では、言語の力を活用して、CLIPが強力なビジョン言語フューショット学習者であることを実証的に示します。まず、CLIPのゼロショット性能を典型的なビジュアル質問応答タスクで評価し、ビジュアル含意タスクにおけるクロスモダリティ転送能力を示します。次に、パラメータ効率の良いファインチューニング戦略を提案し、vqaタスクのフューショット性能を向上させます。追加の事前学習手順を導入せずに、ビジュアル質問応答およびビジュアル含意タスクにおいて競争力のあるゼロ/フューショット結果を達成します。"}
{"title": "KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base", "url": "https://aclanthology.org/2022.acl-long.422/", "abstract": "Complex question answering over knowledge base (Complex KBQA) is challenging because it requires various compositional reasoning capabilities, such as multi-hop inference, attribute comparison, set operation, etc. Existing benchmarks have some shortcomings that limit the development of Complex KBQA: 1) they only provide QA pairs without explicit reasoning processes; 2) questions are poor in diversity or scale. To this end, we introduce KQA Pro, a dataset for Complex KBQA including around 120K diverse natural language questions. We introduce a compositional and interpretable programming language KoPL to represent the reasoning process of complex questions. For each question, we provide the corresponding KoPL program and SPARQL query, so that KQA Pro can serve for both KBQA and semantic parsing tasks. Experimental results show that state-of-the-art KBQA methods cannot achieve promising results on KQA Pro as on current datasets, which suggests that KQA Pro is challenging and Complex KBQA requires further research efforts. We also treat KQA Pro as a diagnostic dataset for testing multiple reasoning skills, conduct a thorough evaluation of existing models and discuss further directions for Complex KBQA. Our codes and datasets can be obtained from https://github.com/shijx12/KQAPro_Baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "KQA Pro: 知識ベース上の複雑な質問応答のための明示的な構成プログラムを持つデータセット\n\nWe present KQA Pro, a new dataset for complex question answering over knowledge bases that includes explicit compositional programs. \n\n明示的な構成プログラムを含む、知識ベース上の複雑な質問応答のための新しいデータセットであるKQA Proを提供する。\n\nThe dataset consists of 5,047 questions and their corresponding programs, covering a wide range of question types and knowledge domains. \n\nこのデータセットには、広範な質問タイプと知識ドメインをカバーする5,047の質問とそれに対応するプログラムが含まれています。\n\nWe also propose a new model, Compositional Program Learning Network (CPLN), that learns to generate programs from natural language questions and their answers. \n\nまた、自然言語の質問とその回答からプログラムを生成することを学習する新しいモデルである「Compositional Program Learning Network (CPLN)」を提案します。", "jabstract": "知識ベース上の複雑な質問応答（Complex KBQA）は、多段推論、属性比較、集合演算などの様々な合成推論能力を必要とするため、困難である。既存のベンチマークにはいくつかの欠点があり、Complex KBQAの開発を制限している。1）明示的な推論プロセスのないQAペアのみを提供する。2）質問が多様性やスケールに乏しい。このため、私たちはKQA Proという、約120Kの多様な自然言語質問を含むComplex KBQAのデータセットを紹介する。複雑な質問の推論プロセスを表現するために、合成的で解釈可能なプログラミング言語KoPLを紹介する。各質問に対して、対応するKoPLプログラムとSPARQLクエリを提供することで、KQA ProはKBQAと意味解析の両方のタスクに役立つ。実験結果は、最新のKBQA方法が現在のデータセットと同様にKQA Proで有望な結果を得られないことを示しており、KQA Proが挑戦的であり、Complex KBQAにはさらなる研究が必要であることを示唆している。私たちはまた、KQA Proを複数の推論スキルをテストする診断データセットとして扱い、既存のモデルの徹底的な評価を行い、Complex KBQAのさらなる方向性について議論する。私たちのコードとデータセットは、https://github.com/shijx12/KQAPro_Baselinesから入手できる。"}
{"title": "Debiased Contrastive Learning of Unsupervised Sentence Representations", "url": "https://aclanthology.org/2022.acl-long.423/", "abstract": "Recently, contrastive learning has been shown to be effective in improving pre-trained language models (PLM) to derive high-quality sentence representations. It aims to pull close positive examples to enhance the alignment while push apart irrelevant negatives for the uniformity of the whole representation space.However, previous works mostly adopt in-batch negatives or sample from training data at random. Such a way may cause the sampling bias that improper negatives (false negatives and anisotropy representations) are used to learn sentence representations, which will hurt the uniformity of the representation space.To address it, we present a new framework DCLR (Debiased Contrastive Learning of unsupervised sentence Representations) to alleviate the influence of these improper negatives.In DCLR, we design an instance weighting method to punish false negatives and generate noise-based negatives to guarantee the uniformity of the representation space.Experiments on seven semantic textual similarity tasks show that our approach is more effective than competitive baselines. Our code and data are publicly available at the link: bluehttps://github.com/RUCAIBox/DCLR.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n非監督学習による文の表現のための偏りのない対照的学習", "jabstract": "最近、対照学習は、事前学習言語モデル（PLM）を改善し、高品質の文表現を導出するために効果的であることが示されています。対照学習は、正の例を引き寄せて整列を強化し、不要な負の例を遠ざけて表現空間全体の均一性を高めることを目的としています。しかし、以前の研究では、主にバッチ内の負の例を採用するか、ランダムにトレーニングデータからサンプリングする方法を採用しています。このような方法は、不適切な負の例（偽の負の例や異方性表現）が文表現を学習するために使用されるサンプリングバイアスを引き起こす可能性があり、表現空間の均一性に悪影響を与えます。これを解決するために、私たちは、不適切な負の影響を軽減するための新しいフレームワークDCLR（非監督学習文表現のバイアスのない対照学習）を提案します。DCLRでは、偽の負の例を罰するインスタンスの重み付け方法を設計し、表現空間の均一性を保証するためにノイズベースの負の例を生成します。7つの意味的テキスト類似性タスクでの実験結果は、私たちのアプローチが競合するベースラインよりも効果的であることを示しています。私たちのコードとデータは、リンク：bluehttps://github.com/RUCAIBox/DCLRで公開されています。"}
{"title": "MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators", "url": "https://aclanthology.org/2022.acl-long.424/", "abstract": "Prompting has recently been shown as a promising approach for applying pre-trained language models to perform downstream tasks. We present Multi-Stage Prompting, a simple and automatic approach for leveraging pre-trained language models to translation tasks. To better mitigate the discrepancy between pre-training and translation, MSP divides the translation process via pre-trained language models into three separate stages: the encoding stage, the re-encoding stage, and the decoding stage. During each stage, we independently apply different continuous prompts for allowing pre-trained language models better shift to translation tasks. We conduct extensive experiments on three translation tasks. Experiments show that our method can significantly improve the translation performance of pre-trained language models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MSP：事前学習済み言語モデルをより優れた翻訳者にするためのマルチステージプロンプティング", "jabstract": "最近、プロンプティングは、事前学習された言語モデルを下流タスクに適用する有望な手法として示されています。本論文では、事前学習された言語モデルを翻訳タスクに活用するための簡単で自動的なアプローチであるMulti-Stage Promptingを提案します。MSPは、事前学習と翻訳の間の不一致をより良く緩和するために、事前学習された言語モデルによる翻訳プロセスをエンコーディングステージ、再エンコーディングステージ、デコーディングステージの3つの別々のステージに分割します。各ステージでは、事前学習された言語モデルが翻訳タスクに適応するために異なる連続的なプロンプトを独立して適用します。我々は3つの翻訳タスクで広範な実験を行いました。実験の結果、我々の手法は事前学習された言語モデルの翻訳性能を大幅に改善することができることが示されました。"}
{"title": "SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues", "url": "https://aclanthology.org/2022.acl-long.425/", "abstract": "Dialogue systems are usually categorized into two types, open-domain and task-oriented. The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue. The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, playing a song. These two directions have been studied separately due to their different purposes. However, how to smoothly transition from social chatting to task-oriented dialogues is important for triggering the business opportunities, and there is no any public data focusing on such scenarios. Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to task-oriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction. To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful open-domain dialogue generation model can be easily leveraged. The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities. Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SalesBot：チットチャットからタスク指向の対話への移行", "jabstract": "対話システムは通常、オープンドメイン型とタスク指向型の2つに分類されます。前者はユーザーとのチャットや会話を重視し、適切なトピックを選択して対話コンテキストに合わせることが成功の鍵となります。後者は、カジュアルな会話ではなく、特定のタスクに焦点を当てます。例えば、金曜日の夜に映画を見つけたり、曲を再生したりすることです。これら2つの方向は、異なる目的を持つため、別々に研究されてきました。しかし、社交的なチャットからタスク指向の対話にスムーズに移行する方法は、ビジネスの機会を引き起こすために重要であり、そのようなシナリオに焦点を当てた公開データはありません。したがって、本論文では、オープンドメインの社交的なチャットから始まり、徐々にタスク指向の目的に移行する会話を調査し、この研究方向を促進するための詳細な注釈付きの大規模データセットを公開することに焦点を当てています。この目標を達成するために、本論文では、人間の関与なしに多数の対話を自動生成するフレームワークを提案し、強力なオープンドメインの対話生成モデルを簡単に活用できるようにしています。人間の評価により、私たちが生成した対話データは自然な流れを持ち、合理的な品質を示しており、私たちが公開したデータは将来の研究方向や商業活動を指導する大きな可能性を持っていることが示されました。さらに、公開されたモデルにより、研究者はターゲットシナリオで無制限の対話を自動生成できるため、半教師ありおよび非教師ありアプローチに大きな利益をもたらすことができます。"}
{"title": "UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining", "url": "https://aclanthology.org/2022.acl-long.426/", "abstract": "High-quality phrase representations are essential to finding topics and related terms in documents (a.k.a. topic mining). Existing phrase representation learning methods either simply combine unigram representations in a context-free manner or rely on extensive annotations to learn context-aware knowledge. In this paper, we propose UCTopic, a novel unsupervised contrastive learning framework for context-aware phrase representations and topic mining. UCTopic is pretrained in a large scale to distinguish if the contexts of two phrase mentions have the same semantics. The key to the pretraining is positive pair construction from our phrase-oriented assumptions. However, we find traditional in-batch negatives cause performance decay when finetuning on a dataset with small topic numbers. Hence, we propose cluster-assisted contrastive learning (CCL) which largely reduces noisy negatives by selecting negatives from clusters and further improves phrase representations for topics accordingly. UCTopic outperforms the state-of-the-art phrase representation model by 38.2% NMI in average on four entity clustering tasks. Comprehensive evaluation on topic mining shows that UCTopic can extract coherent and diverse topical phrases.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "この論文は、自然言語処理に関するものであり、フレーズ表現とトピックマイニングのための非監督学習の対比学習について述べています。", "jabstract": "高品質のフレーズ表現は、ドキュメント内のトピックや関連用語を見つけるために不可欠です（トピックマイニングとも呼ばれます）。既存のフレーズ表現学習方法は、単語表現を単純にコンテキストフリーに組み合わせるか、コンテキストに関する知識を学習するために広範な注釈に依存しています。本論文では、コンテキストに関するフレーズ表現とトピックマイニングのための革新的な非監督対比学習フレームワークであるUCTopicを提案します。UCTopicは、2つのフレーズメンションのコンテキストが同じ意味を持つかどうかを区別するために、大規模に事前学習されます。事前学習の鍵は、フレーズ指向の仮定からの正のペア構築です。しかし、トピック数が少ないデータセットでの微調整時に、従来のバッチ内ネガティブは性能低下を引き起こすことがわかりました。そのため、クラスタ支援対比学習（CCL）を提案し、クラスタからネガティブを選択することでノイズを大幅に減らし、トピックに対するフレーズ表現をさらに改善します。UCTopicは、4つのエンティティクラスタリングタスクの平均で、最先端のフレーズ表現モデルよりも38.2％ NMIで優れた性能を発揮します。トピックマイニングの包括的な評価により、UCTopicは、一貫性のある多様なトピックフレーズを抽出できることが示されています。"}
{"title": "XLM-E: Cross-lingual Language Model Pre-training via ELECTRA", "url": "https://aclanthology.org/2022.acl-long.427/", "abstract": "In this paper, we introduce ELECTRA-style tasks to cross-lingual language model pre-training. Specifically, we present two pre-training tasks, namely multilingual replaced token detection, and translation replaced token detection. Besides, we pretrain the model, named as XLM-E, on both multilingual and parallel corpora. Our model outperforms the baseline models on various cross-lingual understanding tasks with much less computation cost. Moreover, analysis shows that XLM-E tends to obtain better cross-lingual transferability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "XLM-E: ELECTRAを介したクロスリンガル言語モデルの事前学習", "jabstract": "この論文では、ELECTRAスタイルのタスクをクロスリンガル言語モデルの事前学習に導入します。具体的には、多言語置換トークン検出と翻訳置換トークン検出の2つの事前学習タスクを提供します。さらに、多言語および並列コーパスの両方でXLM-Eというモデルを事前学習します。我々のモデルは、より少ない計算コストでさまざまなクロスリンガル理解タスクでベースラインモデルを上回る性能を発揮します。さらに、分析により、XLM-Eがより優れたクロスリンガル転移性を獲得する傾向があることが示されます。"}
{"title": "Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing", "url": "https://aclanthology.org/2022.acl-long.428/", "abstract": "Nested named entity recognition (NER) has been receiving increasing attention. Recently, Fu et al. (2020) adapt a span-based constituency parser to tackle nested NER. They treat nested entities as partially-observed constituency trees and propose the masked inside algorithm for partial marginalization. However, their method cannot leverage entity heads, which have been shown useful in entity mention detection and entity typing. In this work, we resort to more expressive structures, lexicalized constituency trees in which constituents are annotated by headwords, to model nested entities. We leverage the Eisner-Satta algorithm to perform partial marginalization and inference efficiently.In addition, we propose to use (1) a two-stage strategy (2) a head regularization loss and (3) a head-aware labeling loss in order to enhance the performance. We make a thorough ablation study to investigate the functionality of each component. Experimentally, our method achieves the state-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive performance on GENIA, and meanwhile has a fast inference speed.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ネストされた固有表現認識は、潜在的な語彙化構成解析として行われる。", "jabstract": "ネスト型の固有表現認識（NER）は、ますます注目されています。最近、Fuら（2020）は、スパンベースの構成解析器を適応して、ネスト型NERに対処しました。彼らは、ネスト型のエンティティを部分的に観測された構成木として扱い、部分的マージナライゼーションのためのマスクされたインサイドアルゴリズムを提案しました。しかし、彼らの方法は、エンティティのヘッドを活用することができず、エンティティの言及検出やエンティティのタイピングに有用であることが示されています。本研究では、より表現力の高い構造、ヘッドワードで注釈付けされたレキシカル化された構成木を使用して、ネスト型エンティティをモデル化します。部分的マージナライゼーションと推論を効率的に行うために、Eisner-Sattaアルゴリズムを活用します。さらに、パフォーマンスを向上させるために、（1）2段階の戦略、（2）ヘッド正則化損失、および（3）ヘッドに関するラベリング損失を使用することを提案します。各コンポーネントの機能を調べるために、徹底的なアブレーション研究を行います。実験的に、当社の方法は、ACE2004、ACE2005、およびNNEで最先端のパフォーマンスを達成し、GENIAでは競争力のあるパフォーマンスを発揮し、同時に高速な推論速度を持っています。"}
{"title": "Can Explanations Be Useful for Calibrating Black Box Models?", "url": "https://aclanthology.org/2022.acl-long.429/", "abstract": "NLP practitioners often want to take existing trained models and apply them to data from new domains. While fine-tuning or few-shot learning can be used to adapt a base model, there is no single recipe for making these techniques work; moreover, one may not have access to the original model weights if it is deployed as a black box. We study how to improve a black box model’s performance on a new domain by leveraging explanations of the model’s behavior. Our approach first extracts a set of features combining human intuition about the task with model attributions generated by black box interpretation techniques, then uses a simple calibrator, in the form of a classifier, to predict whether the base model was correct or not. We experiment with our method on two tasks, extractive question answering and natural language inference, covering adaptation from several pairs of domains with limited target-domain data. The experimental results across all the domain pairs show that explanations are useful for calibrating these models, boosting accuracy when predictions do not have to be returned on every example. We further show that the calibration model transfers to some extent between tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「説明はブラックボックスモデルのキャリブレーションに役立つ可能性があるか？」", "jabstract": "自然言語処理の研究者は、既存のトレーニング済みモデルを取り、新しいドメインのデータに適用したいと考えることがよくある。ベースモデルを適応させるためにファインチューニングやフューショット学習を使用できるが、これらの技術を動作させるための単一のレシピは存在せず、また、ブラックボックスとして展開されている場合、元のモデルの重みにアクセスできない場合がある。本研究では、モデルの振る舞いの説明を活用して、ブラックボックスモデルの新しいドメインでのパフォーマンスを向上させる方法を研究する。我々のアプローチは、まず、人間の直感とブラックボックス解釈技術によって生成されたモデルの属性を組み合わせた特徴量のセットを抽出し、次に、分類器としての単純なキャリブレータを使用して、ベースモデルが正しいかどうかを予測する。我々は、抽出型質問応答と自然言語推論の2つのタスクで、限られたターゲットドメインデータからの適応をカバーするいくつかのドメインペアで、我々の方法を実験した。すべてのドメインペアにわたる実験結果は、説明がこれらのモデルのキャリブレーションに役立つことを示し、予測がすべての例に返される必要がない場合には、精度を向上させる。さらに、キャリブレーションモデルがある程度タスク間で転移することを示す。"}
{"title": "OIE@OIA: an Adaptable and Efficient Open Information Extraction Framework", "url": "https://aclanthology.org/2022.acl-long.430/", "abstract": "Different Open Information Extraction (OIE) tasks require different types of information, so the OIE field requires strong adaptability of OIE algorithms to meet different task requirements. This paper discusses the adaptability problem in existing OIE systems and designs a new adaptable and efficient OIE system - OIE@OIA as a solution. OIE@OIA follows the methodology of Open Information eXpression (OIX): parsing a sentence to an Open Information Annotation (OIA) Graph and then adapting the OIA graph to different OIE tasks with simple rules. As the core of our OIE@OIA system, we implement an end-to-end OIA generator by annotating a dataset (we make it open available) and designing an efficient learning algorithm for the complex OIA graph. We easily adapt the OIE@OIA system to accomplish three popular OIE tasks. The experimental show that our OIE@OIA achieves new SOTA performances on these tasks, showing the great adaptability of our OIE@OIA system. Furthermore, compared to other end-to-end OIE baselines that need millions of samples for training, our OIE@OIA needs much fewer training samples (12K), showing a significant advantage in terms of efficiency.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "OIE@OIA：適応性が高く効率的なオープン情報抽出フレームワーク", "jabstract": "異なるオープン情報抽出（OIE）タスクには異なる情報が必要であり、OIEフィールドには異なるタスク要件を満たすためのOIEアルゴリズムの強い適応性が必要です。本論文では、既存のOIEシステムの適応性問題について議論し、新しい適応性の高い効率的なOIEシステムであるOIE@OIAを解決策として設計します。OIE@OIAは、Open Information eXpression（OIX）の方法論に従って、文をOpen Information Annotation（OIA）グラフに解析し、簡単なルールでOIAグラフを異なるOIEタスクに適応させます。OIE@OIAシステムのコアとして、データセットを注釈付けして（オープンに利用可能にします）、複雑なOIAグラフのための効率的な学習アルゴリズムを設計することで、エンドツーエンドのOIAジェネレータを実装します。私たちは、OIE@OIAシステムを簡単に適応させて、3つの人気のあるOIEタスクを達成します。実験結果は、私たちのOIE@OIAがこれらのタスクで新しいSOTAパフォーマンスを達成し、私たちのOIE@OIAシステムの大きな適応性を示しています。さらに、数百万のサンプルを必要とする他のエンドツーエンドのOIEベースラインと比較して、私たちのOIE@OIAははるかに少ないトレーニングサンプル（12K）を必要とするため、効率的な点で大きな利点があります。"}
{"title": "ReACC: A Retrieval-Augmented Code Completion Framework", "url": "https://aclanthology.org/2022.acl-long.431/", "abstract": "Code completion, which aims to predict the following code token(s) according to the code context, can improve the productivity of software development. Recent work has proved that statistical language modeling with transformers can greatly improve the performance in the code completion task via learning from large-scale source code datasets. However, current approaches focus only on code context within the file or project, i.e. internal context. Our distinction is utilizing ”external” context, inspired by human behaviors of copying from the related code snippets when writing code. Specifically, we propose a retrieval-augmented code completion framework, leveraging both lexical copying and referring to code with similar semantics by retrieval. We adopt a stage-wise training approach that combines a source code retriever and an auto-regressive language model for programming language. We evaluate our approach in the code completion task in Python and Java programming languages, achieving a state-of-the-art performance on CodeXGLUE benchmark.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ReACC：検索補完フレームワークによるコード補完", "jabstract": "コード補完は、コードの文脈に基づいて次のコードトークンを予測することを目的としており、ソフトウェア開発の生産性を向上させることができます。最近の研究により、トランスフォーマーを用いた統計的言語モデリングにより、大規模なソースコードデータセットから学習することで、コード補完タスクのパフォーマンスを大幅に向上させることができることが証明されています。しかし、現在のアプローチは、ファイルやプロジェクト内のコード文脈にのみ焦点を当てています。すなわち、内部文脈に限定されています。私たちの独自性は、コードを書く際に関連するコードスニペットからコピーする人間の行動に着想を得て、「外部」文脈を利用することです。具体的には、レキシカルコピーと検索による類似した意味を持つコードの参照を両方活用する検索増強型コード補完フレームワークを提案します。プログラミング言語のソースコードリトリーバーと自己回帰言語モデルを組み合わせた段階的なトレーニングアプローチを採用しています。PythonおよびJavaプログラミング言語のコード補完タスクで私たちのアプローチを評価し、CodeXGLUEベンチマークで最先端のパフォーマンスを達成しました。"}
{"title": "Does Recommend-Revise Produce Reliable Annotations? An Analysis on Missing Instances in DocRED", "url": "https://aclanthology.org/2022.acl-long.432/", "abstract": "DocRED is a widely used dataset for document-level relation extraction. In the large-scale annotation, a recommend-revise scheme is adopted to reduce the workload. Within this scheme, annotators are provided with candidate relation instances from distant supervision, and they then manually supplement and remove relational facts based on the recommendations. However, when comparing DocRED with a subset relabeled from scratch, we find that this scheme results in a considerable amount of false negative samples and an obvious bias towards popular entities and relations. Furthermore, we observe that the models trained on DocRED have low recall on our relabeled dataset and inherit the same bias in the training data. Through the analysis of annotators’ behaviors, we figure out the underlying reason for the problems above: the scheme actually discourages annotators from supplementing adequate instances in the revision phase. We appeal to future research to take into consideration the issues with the recommend-revise scheme when designing new models and annotation schemes. The relabeled dataset is released at https://github.com/AndrewZhe/Revisit-DocRED, to serve as a more reliable test set of document RE models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Recommend-Revise」は信頼性の高い注釈を生成するか？DocREDにおける欠落インスタンスの分析", "jabstract": "DocREDは、文書レベルの関係抽出のために広く使用されているデータセットです。大規模な注釈付けでは、作業量を減らすために推奨-修正スキームが採用されています。このスキームでは、注釈付け者に遠隔監視からの候補関係インスタンスが提供され、彼らは推奨に基づいて関係的な事実を手動で補足および削除します。しかし、スクラッチから再ラベル化されたサブセットと比較すると、このスキームはかなりの量の偽陰性サンプルと人気のあるエンティティと関係に対する明らかなバイアスを引き起こすことがわかります。さらに、DocREDで訓練されたモデルは、再ラベル化されたデータセットで低い再現率を示し、訓練データの同じバイアスを引き継ぎます。注釈付け者の行動の分析により、上記の問題の根本的な原因を把握しました。スキームは、実際には修正フェーズで十分なインスタンスを補足することを注釈付け者に妨げているのです。新しいモデルや注釈スキームを設計する際に、推奨-修正スキームの問題を考慮するように将来の研究に呼びかけます。再ラベル化されたデータセットは、https://github.com/AndrewZhe/Revisit-DocREDで公開されており、文書REモデルのより信頼性の高いテストセットとして役立ちます。"}
{"title": "UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning", "url": "https://aclanthology.org/2022.acl-long.433/", "abstract": "Recent parameter-efficient language model tuning (PELT) methods manage to match the performance of fine-tuning with much fewer trainable parameters and perform especially well when training data is limited. However, different PELT methods may perform rather differently on the same task, making it nontrivial to select the most appropriate method for a specific task, especially considering the fast-growing number of new PELT methods and tasks. In light of model diversity and the difficulty of model selection, we propose a unified framework, UniPELT, which incorporates different PELT methods as submodules and learns to activate the ones that best suit the current data or task setup via gating mechanism. On the GLUE benchmark, UniPELT consistently achieves 1 4% gains compared to the best individual PELT method that it incorporates and even outperforms fine-tuning under different setups. Moreover, UniPELT generally surpasses the upper bound that takes the best performance of all its submodules used individually on each task, indicating that a mixture of multiple PELT methods may be inherently more effective than single methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "UniPELT：パラメータ効率の高い言語モデルの調整のための統一フレームワーク", "jabstract": "最近のパラメータ効率的言語モデル調整（PELT）手法は、訓練データが限られている場合でも、はるかに少ない訓練可能なパラメータで微調整の性能に匹敵することができる。しかし、異なるPELT手法は同じタスクでかなり異なるパフォーマンスを発揮するため、特定のタスクに最適な方法を選択することは容易ではなく、新しいPELT手法とタスクの急速な増加を考慮すると特に困難である。モデルの多様性とモデル選択の難しさを考慮して、私たちは統一されたフレームワーク、UniPELTを提案する。UniPELTは、異なるPELT手法をサブモジュールとして組み込み、ゲーティングメカニズムを介して現在のデータまたはタスクのセットアップに最適なものをアクティブに学習する。GLUEベンチマークでは、UniPELTは、組み込まれた最良の個々のPELT手法と比較して一貫して14％の利益を上げ、異なるセットアップで微調整を上回る性能を発揮する。さらに、UniPELTは、個々のタスクで個別に使用されるすべてのサブモジュールの最高性能を取り上げた上限を上回ることが一般的であり、複数のPELT手法の混合が単一の手法よりも本質的に効果的である可能性があることを示している。"}
{"title": "An Empirical Study of Memorization in NLP", "url": "https://aclanthology.org/2022.acl-long.434/", "abstract": "A recent study by Feldman (2020) proposed a long-tail theory to explain the memorization behavior of deep learning models. However, memorization has not been empirically verified in the context of NLP, a gap addressed by this work. In this paper, we use three different NLP tasks to check if the long-tail theory holds. Our experiments demonstrate that top-ranked memorized training instances are likely atypical, and removing the top-memorized training instances leads to a more serious drop in test accuracy compared with removing training instances randomly. Furthermore, we develop an attribution method to better understand why a training instance is memorized. We empirically show that our memorization attribution method is faithful, and share our interesting finding that the top-memorized parts of a training instance tend to be features negatively correlated with the class label.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理における記憶の経験的研究", "jabstract": "Feldman（2020）による最近の研究では、深層学習モデルの記憶行動を説明するために長尾理論が提案されました。しかし、自然言語処理の文脈での記憶は実証的に検証されていません。本研究では、このギャップを埋めるために、3つの異なる自然言語処理タスクを使用して長尾理論が成立するかどうかを確認します。実験結果は、上位ランクの記憶されたトレーニングインスタンスが典型的でない可能性が高く、上位の記憶されたトレーニングインスタンスを削除すると、ランダムにトレーニングインスタンスを削除するよりもテスト精度がより大幅に低下することを示しています。さらに、私たちはトレーニングインスタンスがなぜ記憶されるのかをよりよく理解するための帰属方法を開発しました。私たちは、私たちの記憶帰属方法が忠実であることを実証し、トレーニングインスタンスの上位の記憶された部分がクラスラベルと負の相関がある特徴である傾向があるという興味深い発見を共有します。"}
{"title": "AmericasNLI: Evaluating Zero-shot Natural Language Understanding of Pretrained Multilingual Models in Truly Low-resource Languages", "url": "https://aclanthology.org/2022.acl-long.435/", "abstract": "Pretrained multilingual models are able to perform cross-lingual transfer in a zero-shot setting, even for languages unseen during pretraining. However, prior work evaluating performance on unseen languages has largely been limited to low-level, syntactic tasks, and it remains unclear if zero-shot learning of high-level, semantic tasks is possible for unseen languages. To explore this question, we present AmericasNLI, an extension of XNLI (Conneau et al., 2018) to 10 Indigenous languages of the Americas. We conduct experiments with XLM-R, testing multiple zero-shot and translation-based approaches. Additionally, we explore model adaptation via continued pretraining and provide an analysis of the dataset by considering hypothesis-only models. We find that XLM-R’s zero-shot performance is poor for all 10 languages, with an average performance of 38.48%. Continued pretraining offers improvements, with an average accuracy of 43.85%. Surprisingly, training on poorly translated data by far outperforms all other methods with an accuracy of 49.12%.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "アメリカNLI：事前に学習された多言語モデルのゼロショット自然言語理解を真に低資源言語で評価する。", "jabstract": "事前学習された多言語モデルは、事前学習中に見たことのない言語に対しても、ゼロショット設定でクロスリンガル転送を実行できます。しかし、これまでの研究では、未知の言語に対するパフォーマンスの評価は、主に低レベルの構文タスクに限定されており、高レベルの意味タスクに対するゼロショット学習が未知の言語に対して可能かどうかは不明のままです。この問題を探るために、私たちはAmericasNLIを提案します。これは、XNLI（Conneau et al.、2018）をアメリカ先住民の10の言語に拡張したものです。私たちは、XLM-Rで実験を行い、複数のゼロショットおよび翻訳ベースのアプローチをテストしました。さらに、継続的な事前学習によるモデルの適応性を探求し、仮説のみのモデルを考慮してデータセットを分析します。私たちは、XLM-Rのゼロショットのパフォーマンスが10の言語すべてにおいて低く、平均パフォーマンスが38.48％であることを発見しました。継続的な事前学習により、平均精度は43.85％に向上します。驚くべきことに、翻訳が不十分なデータでのトレーニングは、すべての他の方法よりも優れた精度（49.12％）を示しました。"}
{"title": "Towards Learning (Dis)-Similarity of Source Code from Program Contrasts", "url": "https://aclanthology.org/2022.acl-long.436/", "abstract": "Understanding the functional (dis)-similarity of source code is significant for code modeling tasks such as software vulnerability and code clone detection. We present DISCO (DIS-similarity of COde), a novel self-supervised model focusing on identifying (dis)similar functionalities of source code. Different from existing works, our approach does not require a huge amount of randomly collected datasets. Rather, we design structure-guided code transformation algorithms to generate synthetic code clones and inject real-world security bugs, augmenting the collected datasets in a targeted way. We propose to pre-train the Transformer model with such automatically generated program contrasts to better identify similar code in the wild and differentiate vulnerable programs from benign ones. To better capture the structural features of source code, we propose a new cloze objective to encode the local tree-based context (e.g., parents or sibling nodes). We pre-train our model with a much smaller dataset, the size of which is only 5% of the state-of-the-art models’ training datasets, to illustrate the effectiveness of our data augmentation and the pre-training approach. The evaluation shows that, even with much less data, DISCO can still outperform the state-of-the-art models in vulnerability and code clone detection tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プログラムの対比からソースコードの(非)類似性を学習する方向性", "jabstract": "ソースコードの機能的（非）類似性を理解することは、ソフトウェアの脆弱性やコードクローン検出などのコードモデリングタスクにとって重要です。本論文では、ソースコードの（非）類似機能を特定することに焦点を当てた新しい自己教師モデルであるDISCO（DIS-similarity of COde）を提案します。既存の研究とは異なり、我々のアプローチはランダムに収集された大量のデータセットを必要としません。代わりに、構造に基づくコード変換アルゴリズムを設計して、合成コードクローンを生成し、実世界のセキュリティバグを注入し、収集されたデータセットをターゲットに拡張します。我々は、このように自動生成されたプログラムの対比を用いてTransformerモデルを事前学習し、野生の類似コードをよりよく特定し、脆弱なプログラムと無害なプログラムを区別することを提案します。ソースコードの構造的特徴をよりよく捉えるために、親ノードや兄弟ノードなどのローカルツリーベースのコンテキストをエンコードする新しいクローズ目的を提案します。我々は、データ拡張と事前学習アプローチの効果を示すために、最新のモデルのトレーニングデータセットのわずか5％のサイズのデータセットでモデルを事前学習します。評価により、DISCOは、はるかに少ないデータでも、脆弱性とコードクローン検出のタスクで最新のモデルを上回ることが示されました。"}
{"title": "Guided Attention Multimodal Multitask Financial Forecasting with Inter-Company Relationships and Global and Local News", "url": "https://aclanthology.org/2022.acl-long.437/", "abstract": "Most works on financial forecasting use information directly associated with individual companies (e.g., stock prices, news on the company) to predict stock returns for trading. We refer to such company-specific information as local information. Stock returns may also be influenced by global information (e.g., news on the economy in general), and inter-company relationships. Capturing such diverse information is challenging due to the low signal-to-noise ratios, different time-scales, sparsity and distributions of global and local information from different modalities. In this paper, we propose a model that captures both global and local multimodal information for investment and risk management-related forecasting tasks. Our proposed Guided Attention Multimodal Multitask Network (GAME) model addresses these challenges by using novel attention modules to guide learning with global and local information from different modalities and dynamic inter-company relationship networks. Our extensive experiments show that GAME outperforms other state-of-the-art models in several forecasting tasks and important real-world application case studies.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「企業間関係とグローバル・ローカルニュースを用いたガイド付きアテンションマルチモーダルマルチタスク金融予測」", "jabstract": "金融予測に関する多くの研究は、株価や企業のニュースなど、個々の企業に直接関連する情報（ローカル情報）を使用して、株式のリターンを予測するために行われています。株式のリターンは、一般的な経済に関するニュースなどのグローバル情報や、企業間の関係によっても影響を受ける可能性があります。このような多様な情報を捉えることは、異なる時間スケール、スパース性、および異なるモダリティからのグローバルおよびローカル情報の分布による低信号対ノイズ比のために困難です。本論文では、投資およびリスク管理に関連する予測タスクのために、グローバルおよびローカルのマルチモーダル情報を両方捉えるモデルを提案します。提案されたGuided Attention Multimodal Multitask Network（GAME）モデルは、新しいアテンションモジュールを使用して、異なるモダリティおよび動的な企業間関係ネットワークからのグローバルおよびローカル情報を学習するためにガイドを行います。広範な実験により、GAMEがいくつかの予測タスクおよび重要な実世界の応用事例において、他の最先端モデルを上回ることが示されました。"}
{"title": "On Vision Features in Multimodal Machine Translation", "url": "https://aclanthology.org/2022.acl-long.438/", "abstract": "Previous work on multimodal machine translation (MMT) has focused on the way of incorporating vision features into translation but little attention is on the quality of vision models. In this work, we investigate the impact of vision models on MMT. Given the fact that Transformer is becoming popular in computer vision, we experiment with various strong models (such as Vision Transformer) and enhanced features (such as object-detection and image captioning). We develop a selective attention model to study the patch-level contribution of an image in MMT. On detailed probing tasks, we find that stronger vision models are helpful for learning translation from the visual modality. Our results also suggest the need of carefully examining MMT models, especially when current benchmarks are small-scale and biased.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "多言語機械翻訳における視覚特徴についての論文の要旨です。", "jabstract": "多言語機械翻訳（MMT）に関する以前の研究は、ビジョン機能を翻訳に組み込む方法に焦点を当ててきましたが、ビジョンモデルの品質にはほとんど注意が払われていません。本研究では、ビジョンモデルがMMTに与える影響を調査しました。Transformerがコンピュータビジョンで人気を博していることを考慮して、私たちはさまざまな強力なモデル（Vision Transformerなど）と強化された機能（オブジェクト検出や画像キャプションなど）で実験を行いました。私たちは、選択的注意モデルを開発して、MMTにおける画像のパッチレベルの貢献を研究しました。詳細なプロービングタスクで、より強力なビジョンモデルが視覚モダリティからの翻訳学習に役立つことがわかりました。私たちの結果は、現在のベンチマークが小規模で偏っている場合、特にMMTモデルを注意深く検討する必要があることを示唆しています。"}
{"title": "CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning", "url": "https://aclanthology.org/2022.acl-long.439/", "abstract": "Named Entity Recognition (NER) in Few-Shot setting is imperative for entity tagging in low resource domains. Existing approaches only learn class-specific semantic features and intermediate representations from source domains. This affects generalizability to unseen target domains, resulting in suboptimal performances. To this end, we present CONTaiNER, a novel contrastive learning technique that optimizes the inter-token distribution distance for Few-Shot NER. Instead of optimizing class-specific attributes, CONTaiNER optimizes a generalized objective of differentiating between token categories based on their Gaussian-distributed embeddings. This effectively alleviates overfitting issues originating from training domains. Our experiments in several traditional test domains (OntoNotes, CoNLL’03, WNUT ‘17, GUM) and a new large scale Few-Shot NER dataset (Few-NERD) demonstrate that on average, CONTaiNER outperforms previous methods by 3%-13% absolute F1 points while showing consistent performance trends, even in challenging scenarios where previous approaches could not achieve appreciable performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CONTaiNER：対照学習によるフューショット名前付きエンティティ認識", "jabstract": "Few-Shot設定におけるNamed Entity Recognition（NER）は、低リソースドメインにおけるエンティティタグ付けに必要不可欠です。既存のアプローチは、ソースドメインからクラス固有の意味的特徴と中間表現のみを学習します。これは、未知のターゲットドメインに対する汎用性に影響を与え、最適なパフォーマンスを発揮できなくなります。このため、我々は、Few-Shot NERの間トークン分布距離を最適化する新しい対照的学習技術であるCONTaiNERを提案します。CONTaiNERは、クラス固有の属性を最適化するのではなく、ガウス分布埋め込みに基づいてトークンカテゴリを区別するための一般化された目的を最適化します。これにより、トレーニングドメインから起因する過学習問題が効果的に緩和されます。OntoNotes、CoNLL'03、WNUT'17、GUMなどのいくつかの従来のテストドメインと、新しい大規模Few-Shot NERデータセット（Few-NERD）での実験により、CONTaiNERが平均で以前の方法よりも3％〜13％の絶対F1ポイントで優れたパフォーマンスを発揮し、一貫したパフォーマンス傾向を示すことが示されました。さらに、以前のアプローチでは適切なパフォーマンスを発揮できなかった困難なシナリオでも、一貫したパフォーマンスを示しました。"}
{"title": "Cree Corpus: A Collection of nêhiyawêwin Resources", "url": "https://aclanthology.org/2022.acl-long.440/", "abstract": "Plains Cree (nêhiyawêwin) is an Indigenous language that is spoken in Canada and the USA. It is the most widely spoken dialect of Cree and a morphologically complex language that is polysynthetic, highly inflective, and agglutinative. It is an extremely low resource language, with no existing corpus that is both available and prepared for supporting the development of language technologies. To support nêhiyawêwin revitalization and preservation, we developed a corpus covering diverse genres, time periods, and texts for a variety of intended audiences. The data has been verified and cleaned; it is ready for use in developing language technologies for nêhiyawêwin. The corpus includes the corresponding English phrases or audio files where available. We demonstrate the utility of the corpus through its community use and its use to build language technologies that can provide the types of support that community members have expressed are desirable. The corpus is available for public use.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Cree Corpus：nêhiyawêwinリソースのコレクション」という論文の要約文です。日本語に翻訳すると以下のようになります。\n\n- Cree Corpusは、nêhiyawêwinリソースのコレクションです。\n", "jabstract": "プレーンズ・クリー語（nêhiyawêwin）は、カナダとアメリカで話されている先住民族の言語であり、クリー語の中で最も広く話されている方言であり、形態複雑な言語であり、多合成的で高度に屈折的で接着的です。これは、非常に低資源言語であり、言語技術の開発を支援するために利用可能で準備されたコーパスが存在しない言語です。nêhiyawêwinの復興と保存を支援するために、私たちは多様なジャンル、時代、および対象読者のテキストをカバーするコーパスを開発しました。データは検証され、クリーンアップされ、nêhiyawêwinの言語技術の開発に使用する準備ができています。コーパスには、英語のフレーズまたは音声ファイルがある場合はそれに対応するものが含まれています。私たちは、コミュニティの使用と、コミュニティメンバーが望む種類のサポートを提供できる言語技術の構築によって、コーパスの有用性を示しています。コーパスは一般に公開されています。"}
{"title": "Learning to Rank Visual Stories From Human Ranking Data", "url": "https://aclanthology.org/2022.acl-long.441/", "abstract": "Visual storytelling (VIST) is a typical vision and language task that has seen extensive development in the natural language generation research domain. However, it remains unclear whether conventional automatic evaluation metrics for text generation are applicable on VIST. In this paper, we present the VHED (VIST Human Evaluation Data) dataset, which first re-purposes human evaluation results for automatic evaluation; hence we develop Vrank (VIST Ranker), a novel reference-free VIST metric for story evaluation. We first show that the results from commonly adopted automatic metrics for text generation have little correlation with those obtained from human evaluation, which motivates us to directly utilize human evaluation results to learn the automatic evaluation model. In the experiments, we evaluate the generated texts to predict story ranks using our model as well as other reference-based and reference-free metrics. Results show that Vrank prediction is significantly more aligned to human evaluation than other metrics with almost 30% higher accuracy when ranking story pairs. Moreover, we demonstrate that only Vrank shows human-like behavior in its strong ability to find better stories when the quality gap between two stories is high. Finally, we show the superiority of Vrank by its generalizability to pure textual stories, and conclude that this reuse of human evaluation results puts Vrank in a strong position for continued future advances.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "人間のランキングデータからビジュアルストーリーをランク付けすることを学ぶ", "jabstract": "ビジュアルストーリーテリング（VIST）は、自然言語生成研究領域で広く開発されてきた典型的なビジョン・ランゲージ・タスクです。しかし、テキスト生成の従来の自動評価メトリックがVISTに適用可能かどうかはまだ不明です。本論文では、自動評価のために人間の評価結果を再利用するVHED（VIST Human Evaluation Data）データセットを提供し、ストーリー評価のための新しいリファレンスフリーVISTメトリックであるVrank（VIST Ranker）を開発します。まず、テキスト生成の一般的に採用されている自動メトリックの結果が人間の評価結果とほとんど相関しないことを示し、自動評価モデルを学習するために直接人間の評価結果を利用することを動機付けます。実験では、モデルを使用して生成されたテキストを評価し、他のリファレンスベースおよびリファレンスフリーメトリックとともにストーリーランクを予測します。結果は、Vrank予測が他のメトリックよりも人間の評価により合致しており、ストーリーペアのランキング時に約30％の高い精度を示していることを示しています。さらに、Vrankだけが、2つのストーリーの品質差が大きい場合により良いストーリーを見つける強い能力を持つ人間らしい行動を示すことを示します。最後に、純粋なテキストストーリーに対するVrankの汎用性を示し、人間の評価結果の再利用により、Vrankが今後の進歩に向けて強い立場にあることを結論付けます。"}
{"title": "Universal Conditional Masked Language Pre-training for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.442/", "abstract": "Pre-trained sequence-to-sequence models have significantly improved Neural Machine Translation (NMT). Different from prior works where pre-trained models usually adopt an unidirectional decoder, this paper demonstrates that pre-training a sequence-to-sequence model but with a bidirectional decoder can produce notable performance gains for both Autoregressive and Non-autoregressive NMT. Specifically, we propose CeMAT, a conditional masked language model pre-trained on large-scale bilingual and monolingual corpora in many languages. We also introduce two simple but effective methods to enhance the CeMAT, aligned code-switching & masking and dynamic dual-masking. We conduct extensive experiments and show that our CeMAT can achieve significant performance improvement for all scenarios from low- to extremely high-resource languages, i.e., up to +14.4 BLEU on low resource and +7.9 BLEU improvements on average for Autoregressive NMT. For Non-autoregressive NMT, we demonstrate it can also produce consistent performance gains, i.e., up to +5.3 BLEU. To the best of our knowledge, this is the first work to pre-train a unified model for fine-tuning on both NMT tasks. Code, data, and pre-trained models are available at https://github.com/huawei-noah/Pretrained-Language-Model/CeMAT", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル機械翻訳のための普遍的な条件付きマスク言語事前学習", "jabstract": "事前学習されたシーケンス・ツー・シーケンスモデルは、ニューラル機械翻訳（NMT）を大幅に改善しています。従来の作業とは異なり、事前学習モデルは通常、単方向デコーダを採用していましたが、本論文では、双方向デコーダを使用してシーケンス・ツー・シーケンスモデルを事前学習することで、自己回帰型および非自己回帰型NMTの両方に対して注目すべき性能向上が得られることを示しています。具体的には、多言語の大規模なバイリンガルおよびモノリンガルコーパスで事前学習された条件付きマスク言語モデルであるCeMATを提案します。また、CeMATを強化するための2つのシンプルで効果的な方法、アラインドコードスイッチング＆マスキングおよびダイナミックデュアルマスキングを紹介します。私たちは広範な実験を行い、CeMATが低から極めて高いリソース言語までのすべてのシナリオで有意な性能向上を達成できることを示しました。自己回帰型NMTの場合、低リソースで+14.4 BLEU、平均で+7.9 BLEUの改善があります。非自己回帰型NMTの場合、一貫した性能向上が得られることも示しており、最大+5.3 BLEUの改善があります。私たちの知る限り、これはNMTタスクの両方に微調整するための統一されたモデルを事前学習する最初の作業です。コード、データ、および事前学習モデルは、https://github.com/huawei-noah/Pretrained-Language-Model/CeMATで利用可能です。"}
{"title": "CARETS: A Consistency And Robustness Evaluative Test Suite for VQA", "url": "https://aclanthology.org/2022.acl-long.443/", "abstract": "We introduce CARETS, a systematic test suite to measure consistency and robustness of modern VQA models through a series of six fine-grained capability tests. In contrast to existing VQA test sets, CARETS features balanced question generation to create pairs of instances to test models, with each pair focusing on a specific capability such as rephrasing, logical symmetry or image obfuscation. We evaluate six modern VQA systems on CARETS and identify several actionable weaknesses in model comprehension, especially with concepts such as negation, disjunction, or hypernym invariance. Interestingly, even the most sophisticated models are sensitive to aspects such as swapping the order of terms in a conjunction or varying the number of answer choices mentioned in the question. We release CARETS to be used as an extensible tool for evaluating multi-modal model robustness.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CARETS: VQAの一貫性と堅牢性を評価するためのテストスイート", "jabstract": "私たちは、CARETSというシステムテストスイートを紹介し、6つの細かい能力テストを通じて現代のVQAモデルの一貫性と堅牢性を測定することを提案します。既存のVQAテストセットとは異なり、CARETSはバランスの取れた質問生成を特徴とし、モデルをテストするためのインスタンスのペアを作成し、それぞれのペアは再表現、論理的対称性、または画像の曖昧さなどの特定の能力に焦点を当てます。私たちは、CARETSで6つの現代的なVQAシステムを評価し、否定、論理和、または上位語の不変性などの概念に特に弱点があることを特定しました。興味深いことに、最も洗練されたモデルでさえ、接続詞の順序を入れ替えたり、質問に言及される回答選択肢の数を変えたりするという点に敏感です。私たちは、CARETSをマルチモーダルモデルの堅牢性を評価するための拡張可能なツールとしてリリースします。"}
{"title": "Phrase-aware Unsupervised Constituency Parsing", "url": "https://aclanthology.org/2022.acl-long.444/", "abstract": "Recent studies have achieved inspiring success in unsupervised grammar induction using masked language modeling (MLM) as the proxy task. Despite their high accuracy in identifying low-level structures, prior arts tend to struggle in capturing high-level structures like clauses, since the MLM task usually only requires information from local context. In this work, we revisit LM-based constituency parsing from a phrase-centered perspective. Inspired by the natural reading process of human, we propose to regularize the parser with phrases extracted by an unsupervised phrase tagger to help the LM model quickly manage low-level structures. For a better understanding of high-level structures, we propose a phrase-guided masking strategy for LM to emphasize more on reconstructing non-phrase words. We show that the initial phrase regularization serves as an effective bootstrap, and phrase-guided masking improves the identification of high-level structures. Experiments on the public benchmark with two different backbone models demonstrate the effectiveness and generality of our method.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「フレーズに注意を払った教師なし構文解析」に関する論文の要約文です。以下、日本語に翻訳します。\n\nPhrase-aware Unsupervised Constituency Parsing", "jabstract": "最近の研究では、マスクされた言語モデリング（MLM）をプロキシタスクとして使用して、教師なしの文法誘導においてインスピレーションを与える成功を収めています。低レベルの構造を識別する高い精度を持つにもかかわらず、先行研究は、MLMタスクが通常ローカルコンテキストからの情報のみを必要とするため、節などの高レベルの構造を捉えるのに苦労する傾向があります。本研究では、句中心の観点からLMベースの構成解析を再検討します。人間の自然な読み取りプロセスに着想を得て、教師なしの句タガーによって抽出された句でパーサーを正規化し、LMモデルが低レベルの構造を迅速に処理するのを支援することを提案します。高レベルの構造をよりよく理解するために、非句単語の再構築に重点を置く句案内のマスキング戦略を提案します。初期の句の正規化が効果的なブートストラップとして機能し、句案内のマスキングが高レベルの構造の識別を改善することを示します。2つの異なるバックボーンモデルを使用した公開ベンチマークの実験により、当社の手法の有効性と汎用性が示されました。"}
{"title": "Achieving Reliable Human Assessment of Open-Domain Dialogue Systems", "url": "https://aclanthology.org/2022.acl-long.445/", "abstract": "Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed. Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results. This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation. Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost. Self-replication experiments reveal almost perfectly repeatable results with a correlation of r=0.969. Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests. Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed. We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics. Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オープンドメインの対話システムの信頼性の高い人間評価の達成", "jabstract": "オープンドメインの対話システムの評価は非常に困難であり、より良い技術の開発が切望されていることが何度も強調されています。最近の競技会で信頼性の高いライブ評価を実施するための大規模な取り組みが行われてきましたが、注釈は放棄され、合理的な結果を生み出すにはあまりにも信頼性が低いと報告されています。これは深刻な問題であり、自動メトリックが高品質の会話を示すかどうかを示す良い指標ではないことが知られているためです。対話においてより良い評価技術が緊急に必要であると強調された競技会の救援要請に応えて、私たちは高信頼性でありながら実現可能かつ低コストな人間評価の成功した開発を提案します。自己複製実験により、相関係数r=0.969でほぼ完全に繰り返し可能な結果が得られました。さらに、統計的有意性テストの適切な方法がないため、対話評価においてシステムの潜在的な改善の可能性が偶然によって引き起こされることはめったに考慮されておらず、私たちが提案する評価は標準的なテストの適用を容易にします。高信頼性の評価方法を開発したため、システムのパフォーマンスに関する新しい洞察が明らかになります。したがって、私たちは、(i) 人格を持つ場合と持たない場合の最新のモデルの比較、および(ii) 指定されたトピックと自由に選択されたトピックの比較を含め、会話品質への人格の貢献を測定するための比較を行います。人格に関しては、結果は期待されたように、人格が会話品質に肯定的に貢献するわけではないことを示しています。"}
{"title": "Updated Headline Generation: Creating Updated Summaries for Evolving News Stories", "url": "https://aclanthology.org/2022.acl-long.446/", "abstract": "We propose the task of updated headline generation, in which a system generates a headline for an updated article, considering both the previous article and headline. The system must identify the novel information in the article update, and modify the existing headline accordingly. We create data for this task using the NewsEdits corpus by automatically identifying contiguous article versions that are likely to require a substantive headline update. We find that models conditioned on the prior headline and body revisions produce headlines judged by humans to be as factual as gold headlines while making fewer unnecessary edits compared to a standard headline generation model. Our experiments establish benchmarks for this new contextual summarization task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n進化するニュースストーリーに対して更新された要約を作成するための最新のヘッドライン生成。", "jabstract": "私たちは、自然言語処理に関する論文の要約文を以下に示します。 \n\n私たちは、更新された記事に対して、以前の記事と見出しを考慮しながら、システムが見出しを生成するタスクを提案します。システムは、記事の更新における新しい情報を特定し、既存の見出しを適宜修正する必要があります。私たちは、NewsEditsコーパスを使用して、実質的な見出しの更新が必要であると思われる連続した記事のバージョンを自動的に特定することで、このタスクのためのデータを作成します。私たちは、以前の見出しと本文の改訂に基づくモデルが、標準的な見出し生成モデルと比較して、不必要な編集を少なくしながら、人間によって事実と判断される見出しを生成することを発見しました。私たちの実験は、この新しい文脈に基づく要約タスクのベンチマークを確立します。"}
{"title": "SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures", "url": "https://aclanthology.org/2022.acl-long.447/", "abstract": "Current open-domain conversational models can easily be made to talk in inadequate ways. Online learning from conversational feedback given by the conversation partner is a promising avenue for a model to improve and adapt, so as to generate fewer of these safety failures. However, current state-of-the-art models tend to react to feedback with defensive or oblivious responses. This makes for an unpleasant experience and may discourage conversation partners from giving feedback in the future. This work proposes SaFeRDialogues, a task and dataset of graceful responses to conversational feedback about safety failures.We collect a dataset of 8k dialogues demonstrating safety failures, feedback signaling them, and a response acknowledging the feedback. We show how fine-tuning on this dataset results in conversations that human raters deem considerably more likely to lead to a civil conversation, without sacrificing engagingness or general conversational ability.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SaFeRDialogues：会話の安全性の失敗後に優雅にフィードバックを受け取る\n\nNote: As an AI language model, I cannot provide a full translation of the paper without access to the original text. The above sentence is the title and subtitle of the paper.", "jabstract": "現在のオープンドメインの会話モデルは、不適切な方法で話すことが容易です。会話相手からの会話フィードバックによるオンライン学習は、モデルが改善し適応するための有望な手段であり、これによりこれらの安全性の失敗を少なく生成することができます。しかし、現在の最先端のモデルは、フィードバックに対して防御的または無頓着な反応を示す傾向があります。これは不快な体験をもたらし、将来的には会話相手がフィードバックを与えることを躊躇する可能性があります。本研究では、SaFeRDialoguesという、安全性の失敗に関する会話フィードバックに対する優雅な応答のタスクとデータセットを提案します。私たちは、安全性の失敗を示すフィードバックと、フィードバックを認める応答を示す8,000の対話のデータセットを収集します。このデータセットでの微調整が、人間の評価者が文明的な会話につながる可能性が高く、魅力的で一般的な会話能力を犠牲にすることなく、会話を生成することを示します。"}
{"title": "Compositional Generalization in Dependency Parsing", "url": "https://aclanthology.org/2022.acl-long.448/", "abstract": "Compositionality— the ability to combine familiar units like words into novel phrases and sentences— has been the focus of intense interest in artificial intelligence in recent years. To test compositional generalization in semantic parsing, Keysers et al. (2020) introduced Compositional Freebase Queries (CFQ). This dataset maximizes the similarity between the test and train distributions over primitive units, like words, while maximizing the compound divergence: the dissimilarity between test and train distributions over larger structures, like phrases. Dependency parsing, however, lacks a compositional generalization benchmark. In this work, we introduce a gold-standard set of dependency parses for CFQ, and use this to analyze the behaviour of a state-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset. We find that increasing compound divergence degrades dependency parsing performance, although not as dramatically as semantic parsing performance. Additionally, we find the performance of the dependency parser does not uniformly degrade relative to compound divergence, and the parser performs differently on different splits with the same compound divergence. We explore a number of hypotheses for what causes the non-uniform degradation in dependency parsing performance, and identify a number of syntactic structures that drive the dependency parser’s lower performance on the most challenging splits.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "依存構文解析における構成的一般化", "jabstract": "近年、人工知能において、単語などの既知の単位を新しいフレーズや文に組み合わせる能力である合成性が注目されている。Keysersら（2020）は、意味解析における合成的一般化をテストするために、Compositional Freebase Queries（CFQ）を導入した。このデータセットは、単語などの原始的な単位に関するテストとトレーニングの分布の類似性を最大化しながら、フレーズなどのより大きな構造に関するテストとトレーニングの分布の相違を最大化する。しかし、依存解析には合成的一般化のベンチマークが欠けている。本研究では、CFQの依存解析のゴールドスタンダードセットを導入し、これを使用して最新の依存解析器（Qiら、2020）のCFQデータセットにおける動作を分析する。我々は、複合的な分岐が増加すると依存解析の性能が低下することを発見したが、意味解析の性能ほど劇的には低下しないことも明らかにした。さらに、依存解析器の性能は複合的な分岐に対して一様に低下せず、同じ複合的な分岐を持つ異なる分割で異なる動作をすることがわかった。我々は、依存解析性能の非一様な低下の原因についていくつかの仮説を探求し、最も困難な分割における依存解析器の低い性能を引き起こすいくつかの構文構造を特定した。"}
{"title": "ASPECTNEWS: Aspect-Oriented Summarization of News Documents", "url": "https://aclanthology.org/2022.acl-long.449/", "abstract": "Generic summaries try to cover an entire document and query-based summaries try to answer document-specific questions. But real users’ needs often fall in between these extremes and correspond to aspects, high-level topics discussed among similar types of documents. In this paper, we collect a dataset of realistic aspect-oriented summaries, AspectNews, which covers different subtopics about articles in news sub-domains. We annotate data across two domains of articles, earthquakes and fraud investigations, where each article is annotated with two distinct summaries focusing on different aspects for each domain. A system producing a single generic summary cannot concisely satisfy both aspects. Our focus in evaluation is how well existing techniques can generalize to these domains without seeing in-domain training data, so we turn to techniques to construct synthetic training data that have been used in query-focused summarization work. We compare several training schemes that differ in how strongly keywords are used and how oracle summaries are extracted. Our evaluation shows that our final approach yields (a) focused summaries, better than those from a generic summarization system or from keyword matching; (b) a system sensitive to the choice of keywords.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ASPECTNEWS：ニュース文書のアスペクト指向要約", "jabstract": "一般的な要約は文書全体をカバーし、クエリベースの要約は文書固有の質問に答えようとする。しかし、実際のユーザーのニーズはしばしばこれらの極端の間にあり、類似した種類の文書で議論される高レベルのトピックに対応する。本論文では、ニュースのサブドメインの記事に関する異なるサブトピックをカバーする現実的なアスペクト指向の要約のデータセットであるAspectNewsを収集する。我々は、地震と詐欺調査の2つのドメインの記事にわたってデータを注釈し、各記事についてドメインごとに異なるアスペクトに焦点を当てた2つの異なる要約を注釈する。単一の一般的な要約を生成するシステムは、両方のアスペクトを簡潔に満たすことができない。我々の評価の焦点は、ドメイン内のトレーニングデータを見ずに既存の技術がこれらのドメインに一般化できるかどうかであり、クエリに焦点を当てた要約作業で使用された合成トレーニングデータを構築する技術に注目する。我々は、キーワードの使用の強さとオラクル要約の抽出方法が異なるいくつかのトレーニングスキームを比較する。我々の評価は、(a)一般的な要約システムやキーワードマッチングからより優れたフォーカスされた要約を生み出す; (b)キーワードの選択に敏感なシステムを生み出すことを示している。"}
{"title": "MemSum: Extractive Summarization of Long Documents Using Multi-Step Episodic Markov Decision Processes", "url": "https://aclanthology.org/2022.acl-long.450/", "abstract": "We introduce MemSum (Multi-step Episodic Markov decision process extractive SUMmarizer), a reinforcement-learning-based extractive summarizer enriched at each step with information on the current extraction history. When MemSum iteratively selects sentences into the summary, it considers a broad information set that would intuitively also be used by humans in this task: 1) the text content of the sentence, 2) the global text context of the rest of the document, and 3) the extraction history consisting of the set of sentences that have already been extracted. With a lightweight architecture, MemSum obtains state-of-the-art test-set performance (ROUGE) in summarizing long documents taken from PubMed, arXiv, and GovReport. Ablation studies demonstrate the importance of local, global, and history information. A human evaluation confirms the high quality and low redundancy of the generated summaries, stemming from MemSum’s awareness of extraction history.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「MemSum：多段階エピソードマルコフ決定過程を用いた長文書の抽出的要約」は、長い文書の要約を抽出するための新しい手法を提案する。この手法は、マルコフ決定過程を使用して、文書の重要な情報を抽出するために複数のステップを実行する。この手法は、自然言語処理の分野での重要な進歩を示している。", "jabstract": "私たちは、MemSum（Multi-step Episodic Markov decision process extractive SUMmarizer）を紹介します。これは、現在の抽出履歴に関する情報を各ステップで豊富に取り入れた強化学習ベースの抽出型要約器です。MemSumが要約に文を反復的に選択する際には、人間がこのタスクで直感的に使用する広範な情報セットを考慮します。1）文のテキスト内容、2）ドキュメントの残りの部分のグローバルなテキストコンテキスト、3）すでに抽出された文のセットで構成される抽出履歴です。軽量なアーキテクチャを持つMemSumは、PubMed、arXiv、GovReportから取得した長い文書を要約する際に、最新のテストセットパフォーマンス（ROUGE）を達成します。削除研究により、ローカル、グローバル、および履歴情報の重要性が示されます。人間の評価により、MemSumの抽出履歴に関する認識から生じる高品質かつ低冗長性の要約の高品質が確認されました。"}
{"title": "CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations", "url": "https://aclanthology.org/2022.acl-long.451/", "abstract": "Supervised learning has traditionally focused on inductive learning by observing labeled examples of a task. In contrast, a hallmark of human intelligence is the ability to learn new concepts purely from language. Here, we explore training zero-shot classifiers for structured data purely from language. For this, we introduce CLUES, a benchmark for Classifier Learning Using natural language ExplanationS, consisting of a range of classification tasks over structured data along with natural language supervision in the form of explanations. CLUES consists of 36 real-world and 144 synthetic classification tasks. It contains crowdsourced explanations describing real-world tasks from multiple teachers and programmatically generated explanations for the synthetic tasks. To model the influence of explanations in classifying an example, we develop ExEnt, an entailment-based model that learns classifiers using explanations. ExEnt generalizes up to 18% better (relative) on novel tasks than a baseline that does not use explanations. We delineate key challenges for automated learning from explanations, addressing which can lead to progress on CLUES in the future. Code and datasets are available at: https://clues-benchmark.github.io.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CLUES: 自然言語説明を用いた分類器学習のためのベンチマーク\n\n1. This paper presents CLUES, a benchmark for learning classifiers using natural language explanations.\nこの論文では、自然言語説明を用いた分類器学習のためのベンチマークであるCLUESを提案する。\n\n2. CLUES consists of a dataset of explanations and a set of evaluation metrics.\nCLUESは、説明のデータセットと評価指標のセットから構成されています。\n\n3. The dataset contains examples from various domains, including image classification and sentiment analysis.\nデータセットには、画像分類や感情分析など、さまざまなドメインの例が含まれています。\n\n4. The evaluation metrics measure the accuracy of the classifiers and the quality of the explanations.\n評価指標は、分類器の正確性と説明の品質を測定します。", "jabstract": "従来の教師あり学習は、タスクのラベル付き例を観察することによる帰納学習に焦点を当ててきた。一方、人間の知能の特徴は、言語だけから新しい概念を学ぶ能力である。ここでは、言語だけから構造化データのゼロショット分類器をトレーニングすることを探求する。そのために、分類タスクと自然言語による説明の形での教育を含む、Classifier Learning Using natural language ExplanationS（CLUES）のベンチマークを紹介する。CLUESには、36の実世界の分類タスクと144の合成分類タスクが含まれている。それは、複数の教師からの実世界のタスクを説明するクラウドソーシングされた説明と、合成タスクのためのプログラム生成された説明を含んでいます。例を分類するための説明の影響をモデル化するために、説明を使用しないベースラインよりも18％以上一般化するExEntというエンテイルメントベースのモデルを開発する。説明からの自動学習の主要な課題を明確にし、将来的にCLUESで進展することができる。コードとデータセットは、https://clues-benchmark.github.ioで利用可能です。"}
{"title": "Substructure Distribution Projection for Zero-Shot Cross-Lingual Dependency Parsing", "url": "https://aclanthology.org/2022.acl-long.452/", "abstract": "We present substructure distribution projection (SubDP), a technique that projects a distribution over structures in one domain to another, by projecting substructure distributions separately. Models for the target domain can then be trained, using the projected distributions as soft silver labels. We evaluate SubDP on zero shot cross-lingual dependency parsing, taking dependency arcs as substructures: we project the predicted dependency arc distributions in the source language(s) to target language(s), and train a target language parser on the resulting distributions. Given an English tree bank as the only source of human supervision, SubDP achieves better unlabeled attachment score than all prior work on the Universal Dependencies v2.2 (Nivre et al., 2020) test set across eight diverse target languages, as well as the best labeled attachment score on six languages. In addition, SubDP improves zero shot cross-lingual dependency parsing with very few (e.g., 50) supervised bitext pairs, across a broader range of target languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ゼロショットクロスリンガル依存解析のためのサブストラクチャ分布射影」に関する論文の要約文です。", "jabstract": "私たちは、サブストラクチャ分布射影（SubDP）という技術を提案します。これは、サブストラクチャ分布を別々に射影することにより、あるドメインの構造の分布を別のドメインに射影する技術です。射影された分布をソフトシルバーラベルとして使用して、ターゲットドメインのモデルをトレーニングすることができます。私たちは、依存構造をサブストラクチャとして扱い、ゼロショットクロスリンガル依存解析にSubDPを適用しました。つまり、ソース言語の予測された依存構造の分布をターゲット言語に射影し、その分布を用いてターゲット言語のパーサをトレーニングしました。英語のツリーバンクを唯一の人間の監督情報として使用した場合、SubDPは、8つの異なるターゲット言語において、Universal Dependencies v2.2（Nivre et al.、2020）のテストセットにおいて、すべての先行研究よりも優れた未ラベル付きアタッチメントスコアを達成し、6つの言語においては最高のラベル付きアタッチメントスコアを達成しました。さらに、SubDPは、わずか50の監督ビットキストペアを使用して、より広範なターゲット言語において、ゼロショットクロスリンガル依存解析を改善します。"}
{"title": "Multilingual Detection of Personal Employment Status on Twitter", "url": "https://aclanthology.org/2022.acl-long.453/", "abstract": "Detecting disclosures of individuals’ employment status on social media can provide valuable information to match job seekers with suitable vacancies, offer social protection, or measure labor market flows. However, identifying such personal disclosures is a challenging task due to their rarity in a sea of social media content and the variety of linguistic forms used to describe them. Here, we examine three Active Learning (AL) strategies in real-world settings of extreme class imbalance, and identify five types of disclosures about individuals’ employment status (e.g. job loss) in three languages using BERT-based classification models. Our findings show that, even under extreme imbalance settings, a small number of AL iterations is sufficient to obtain large and significant gains in precision, recall, and diversity of results compared to a supervised baseline with the same number of labels. We also find that no AL strategy consistently outperforms the rest. Qualitative analysis suggests that AL helps focus the attention mechanism of BERT on core terms and adjust the boundaries of semantic expansion, highlighting the importance of interpretable models to provide greater control and visibility into this dynamic learning process.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Twitter上での個人の雇用状況の多言語検出", "jabstract": "ソーシャルメディア上で個人の雇用状況の開示を検出することは、求職者と適切な求人をマッチングするための貴重な情報を提供し、社会保護を提供するか、労働市場の流れを測定することができます。しかし、そのような個人的な開示を特定することは、社会メディアのコンテンツの海の中での稀少性と、それらを説明するために使用される言語形式の多様性のために、困難な課題です。ここでは、極端なクラスの不均衡の現実世界の設定で3つのアクティブラーニング（AL）戦略を検討し、BERTベースの分類モデルを使用して3つの言語で個人の雇用状況に関する5つの開示タイプ（例：雇用喪失）を特定します。私たちの調査結果は、極端な不均衡設定でも、同じラベル数を持つ監視されたベースラインと比較して、わずかなAL反復が精度、再現率、および結果の多様性の大きなかつ有意な利益を得るのに十分であることを示しています。また、どのAL戦略も一貫して他を上回るわけではないことがわかりました。質的分析は、ALがBERTの注意メカニズムをコア用語に集中させ、意味的拡張の境界を調整するのに役立つことを示唆し、解釈可能なモデルがこの動的な学習プロセスに対するより大きな制御と可視性を提供する重要性を強調しています。"}
{"title": "MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data", "url": "https://aclanthology.org/2022.acl-long.454/", "abstract": "Numerical reasoning over hybrid data containing both textual and tabular content (e.g., financial reports) has recently attracted much attention in the NLP community. However, existing question answering (QA) benchmarks over hybrid data only include a single flat table in each document and thus lack examples of multi-step numerical reasoning across multiple hierarchical tables. To facilitate data analytical progress, we construct a new large-scale benchmark, MultiHiertt, with QA pairs over Multi Hierarchical Tabular and Textual data. MultiHiertt is built from a wealth of financial reports and has the following unique characteristics: 1) each document contain multiple tables and longer unstructured texts; 2) most of tables contained are hierarchical; 3) the reasoning process required for each question is more complex and challenging than existing benchmarks; and 4) fine-grained annotations of reasoning processes and supporting facts are provided to reveal complex numerical reasoning. We further introduce a novel QA model termed MT2Net, which first applies facts retrieving to extract relevant supporting facts from both tables and text and then uses a reasoning module to perform symbolic reasoning over retrieved facts. We conduct comprehensive experiments on various baselines. The experimental results show that MultiHiertt presents a strong challenge for existing baselines whose results lag far behind the performance of human experts. The dataset and code are publicly available at https://github.com/psunlpgroup/MultiHiertt.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MultiHiertt: 多層階層的な表形式およびテキストデータに対する数値推論", "jabstract": "テキストと表形式の両方のデータを含むハイブリッドデータ上での数値推論（例：財務報告書）は、最近NLPコミュニティで注目を集めています。しかし、既存のハイブリッドデータ上の質問応答（QA）ベンチマークは、各ドキュメントに単一のフラットテーブルしか含まれておらず、複数の階層的テーブルを跨いだ多段階の数値推論の例が欠けています。データ分析の進展を促進するために、私たちはMulti Hierarchical Tabular and Textualデータ上のQAペアを持つ新しい大規模ベンチマーク、MultiHierttを構築しました。MultiHierttは、豊富な財務報告書から構築され、以下のユニークな特徴を持っています：1）各ドキュメントには複数のテーブルと長い非構造化テキストが含まれています。2）ほとんどのテーブルは階層的です。3）各質問に必要な推論プロセスは、既存のベンチマークよりも複雑で挑戦的です。4）複雑な数値推論を明らかにするために、推論プロセスとサポートファクトの細かい注釈が提供されます。さらに、MT2Netという新しいQAモデルを紹介し、まず事実検索を適用して、テーブルとテキストから関連するサポートファクトを抽出し、その後、抽出された事実に対してシンボリック推論を実行する推論モジュールを使用します。さまざまなベースラインで包括的な実験を行いました。実験結果は、MultiHierttが既存のベースラインにとって強力な課題を提供し、その結果が人間の専門家のパフォーマンスを大きく下回っていることを示しています。データセットとコードは、https://github.com/psunlpgroup/MultiHierttで公開されています。"}
{"title": "Transformers in the loop: Polarity in neural models of language", "url": "https://aclanthology.org/2022.acl-long.455/", "abstract": "Representation of linguistic phenomena in computational language models is typically assessed against the predictions of existing linguistic theories of these phenomena. Using the notion of polarity as a case study, we show that this is not always the most adequate set-up. We probe polarity via so-called ‘negative polarity items’ (in particular, English ‘any’) in two pre-trained Transformer-based models (BERT and GPT-2). We show that – at least for polarity – metrics derived from language models are more consistent with data from psycholinguistic experiments than linguistic theory predictions. Establishing this allows us to more adequately evaluate the performance of language models and also to use language models to discover new insights into natural language grammar beyond existing linguistic theories. This work contributes to establishing closer ties between psycholinguistic experiments and experiments with language models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "処理言語のニューラルモデルにおける極性：ループ内のトランスフォーマー", "jabstract": "計算言語モデルにおける言語現象の表現は、通常、これらの現象の既存の言語理論の予測と比較して評価されます。極性を事例として使用し、これが常に最適な設定ではないことを示します。私たちは、負の極性項目（特に英語の「any」）を介して極性を探求し、2つの事前トレーニング済みTransformerベースのモデル（BERTとGPT-2）で行います。私たちは、少なくとも極性については、言語モデルから導出されたメトリックが、言語理論の予測よりも心理言語学的実験のデータとより一致していることを示します。これにより、言語モデルのパフォーマンスをより適切に評価し、既存の言語理論を超えた自然言語文法の新しい洞察を発見するために言語モデルを使用することができます。この研究は、心理言語学的実験と言語モデルの実験との間のより密接な関係を確立するのに貢献します。"}
{"title": "Bridging the Data Gap between Training and Inference for Unsupervised Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.456/", "abstract": "Back-translation is a critical component of Unsupervised Neural Machine Translation (UNMT), which generates pseudo parallel data from target monolingual data. A UNMT model is trained on the pseudo parallel data with \\bf translated source, and translates \\bf natural source sentences in inference. The source discrepancy between training and inference hinders the translation performance of UNMT models. By carefully designing experiments, we identify two representative characteristics of the data gap in source: (1) style gap (i.e., translated vs. natural text style) that leads to poor generalization capability; (2) content gap that induces the model to produce hallucination content biased towards the target language. To narrow the data gap, we propose an online self-training approach, which simultaneously uses the pseudo parallel data {natural source, translated target} to mimic the inference scenario. Experimental results on several widely-used language pairs show that our approach outperforms two strong baselines (XLM and MASS) by remedying the style and content gaps.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己教師なしニューラル機械翻訳におけるトレーニングと推論の間のデータギャップを埋めるための取り組み", "jabstract": "バックトランスレーションは、ターゲット単一言語データから疑似並列データを生成するUnsupervised Neural Machine Translation（UNMT）の重要なコンポーネントです。 UNMTモデルは、翻訳されたソースを使用して疑似並列データでトレーニングされ、推論で自然なソース文を翻訳します。トレーニングと推論の間のソースの不一致は、UNMTモデルの翻訳性能を妨げます。実験を慎重に設計することで、ソースのデータギャップの2つの代表的な特徴を特定しました：（1）スタイルギャップ（つまり、翻訳されたテキストスタイルと自然なテキストスタイル）は、一般化能力が低下する原因となります。 （2）コンテンツギャップは、モデルがターゲット言語に偏った幻覚コンテンツを生成する原因となります。データギャップを狭めるために、オンライン自己トレーニングアプローチを提案し、疑似並列データ{自然なソース、翻訳されたターゲット}を同時に使用して推論シナリオを模倣します。いくつかの広く使用されている言語ペアでの実験結果は、スタイルとコンテンツのギャップを修正することにより、アプローチが2つの強力なベースライン（XLMおよびMASS）を上回ることを示しています。"}
{"title": "SDR: Efficient Neural Re-ranking using Succinct Document Representation", "url": "https://aclanthology.org/2022.acl-long.457/", "abstract": "BERT based ranking models have achieved superior performance on various information retrieval tasks. However, the large number of parameters and complex self-attention operations come at a significant latency overhead. To remedy this, recent works propose late-interaction architectures, which allow pre-computation of intermediate document representations, thus reducing latency. Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limit their adoption in real-life production systems.In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue. Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document’s textual content in both the encoding and decoding phases. After this token encoding step, we further reduce the size of the document representations using modern quantization techniques. Evaluation on MSMARCO’s passage re-reranking task show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x–11.6x higher compression rates for the same ranking quality. Similarly, on the TREC CAR dataset, we achieve 7.7x higher compression rate for the same ranking quality.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SDR：簡潔な文書表現を使用した効率的なニューラル再ランキング", "jabstract": "BERTベースのランキングモデルは、さまざまな情報検索タスクで優れたパフォーマンスを発揮しています。しかし、大量のパラメータと複雑な自己注意操作は、著しいレイテンシーオーバーヘッドを伴います。この問題を解決するために、最近の研究では、中間ドキュメント表現の事前計算を許可する遅延相互作用アーキテクチャが提案されており、レイテンシーを低減しています。しかし、即座のレイテンシー問題を解決した後、これらの方法はストレージコストとネットワーク取得レイテンシーを導入し、実際のプロダクションシステムでの採用を制限します。本研究では、高度に圧縮された中間ドキュメント表現を計算するSuccinct Document Representation（SDR）スキームを提案し、ストレージ/ネットワークの問題を緩和します。我々のアプローチは、まず、ドキュメントのテキストコンテンツをエンコードおよびデコードフェーズの両方で使用する新しいオートエンコーダーアーキテクチャを使用して、トークン表現の次元を削減します。このトークンエンコーディングステップの後、現代の量子化技術を使用して、ドキュメント表現のサイズをさらに縮小します。MSMARCOのパッセージ再ランキングタスクでの評価では、圧縮されたドキュメント表現を使用する既存のアプローチと比較して、同じランキング品質の場合、我々の方法は非常に効率的であり、4倍から11.6倍の高い圧縮率を達成しています。同様に、TREC CARデータセットでは、同じランキング品質の場合、7.7倍の高い圧縮率を達成しています。"}
{"title": "The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications", "url": "https://aclanthology.org/2022.acl-long.458/", "abstract": "Task-oriented dialogue systems are increasingly prevalent in healthcare settings, and have been characterized by a diverse range of architectures and objectives. Although these systems have been surveyed in the medical community from a non-technical perspective, a systematic review from a rigorous computational perspective has to date remained noticeably absent. As a result, many important implementation details of healthcare-oriented dialogue systems remain limited or underspecified, slowing the pace of innovation in this area. To fill this gap, we investigated an initial pool of 4070 papers from well-known computer science, natural language processing, and artificial intelligence venues, identifying 70 papers discussing the system-level implementation of task-oriented dialogue systems for healthcare applications. We conducted a comprehensive technical review of these papers, and present our key findings including identified gaps and corresponding recommendations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AIドクターが登場：医療アプリケーションのためのタスク指向型対話システムの調査", "jabstract": "タスク指向型の対話システムは、医療現場でますます普及しており、多様なアーキテクチャや目的で特徴付けられています。これらのシステムは、医療コミュニティから非技術的な観点で調査されてきましたが、厳密な計算的観点からの体系的なレビューは、今まで著しく欠落していました。その結果、医療に特化した対話システムの重要な実装の詳細は限られており、この分野のイノベーションのペースが遅れています。このギャップを埋めるために、私たちは、よく知られたコンピュータサイエンス、自然言語処理、人工知能の会場からの初期の4070本の論文を調査し、医療アプリケーションのためのタスク指向型対話システムのシステムレベルの実装について70本の論文を特定しました。これらの論文を包括的に技術的にレビューし、特定されたギャップとそれに対応する推奨事項を含む主要な調査結果を提示します。"}
{"title": "SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher", "url": "https://aclanthology.org/2022.acl-long.459/", "abstract": "Even though several methods have proposed to defend textual neural network (NN) models against black-box adversarial attacks, they often defend against a specific text perturbation strategy and/or require re-training the models from scratch. This leads to a lack of generalization in practice and redundant computation. In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources. By borrowing an idea from software engineering, in order to address these limitations, we propose a novel algorithm, SHIELD, which modifies and re-trains only the last layer of a textual NN, and thus it “patches” and “transforms” the NN into a stochastic weighted ensemble of multi-expert prediction heads. Considering that most of current black-box attacks rely on iterative search mechanisms to optimize their adversarial perturbations, SHIELD confuses the attackers by automatically utilizing different weighted ensembles of predictors depending on the input. In other words, SHIELD breaks a fundamental assumption of the attack, which is a victim NN model remains constant during an attack. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative enhancement of 15%–70% in accuracy on average against 14 different black-box attacks, outperforming 6 defensive baselines across 3 public datasets. All codes are to be released.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SHIELD：確率的なマルチエキスパートパッチャを用いた複数のブラックボックス攻撃に対するテキストニューラルネットワークの防御", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nテキストニューラルネットワーク（NN）モデルをブラックボックス攻撃から守るために提案されたいくつかの手法があるにもかかわらず、それらはしばしば特定のテキスト摂動戦略に対して防御し、またはモデルをゼロから再トレーニングする必要があります。これにより、実践において一般化が不足し、冗長な計算が発生します。特に、最先端のトランスフォーマーモデル（例：BERT、RoBERTa）は、大量の時間と計算リソースを必要とします。これらの制限に対処するために、ソフトウェアエンジニアリングからアイデアを借りて、テキストNNの最後のレイヤーのみを修正および再トレーニングする新しいアルゴリズムであるSHIELDを提案します。これにより、NNを多数の専門家予測ヘッドの確率的加重アンサンブルに「パッチ」および「変換」します。現在のほとんどのブラックボックス攻撃が、敵対的な摂動を最適化するための反復的な検索メカニズムに依存していることを考慮すると、SHIELDは、入力に応じて異なる加重予測器のアンサンブルを自動的に利用することで攻撃者を混乱させます。つまり、SHIELDは攻撃の基本的な仮定である、被害者NNモデルが攻撃中に一定であるという仮定を破ります。包括的な実験を実施することにより、SHIELDによってパッチされたCNN、RNN、BERT、およびRoBERTaベースのテキストNNは、14種類の異なるブラックボックス攻撃に対して平均15％〜70％の相対的な精度向上を示し、3つの公開データセット全体で6つの防御ベースラインを上回ります。すべてのコードは公開されます。"}
{"title": "Accurate Online Posterior Alignments for Principled Lexically-Constrained Decoding", "url": "https://aclanthology.org/2022.acl-long.460/", "abstract": "Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded. Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model. We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods. Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms. On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates. When deployed on seven lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "原則に基づく語彙制約デコーディングのための正確なオンライン事後アラインメント", "jabstract": "機械翻訳におけるオンラインアラインメントとは、ターゲットシーケンスが部分的にデコードされた場合に、ターゲット単語をソース単語にアラインするタスクを指します。良好なオンラインアラインメントは、ユーザー定義の辞書を使用して翻訳モデルに語彙制約を注入するレキシカル制約翻訳などの重要なアプリケーションを容易にします。我々は、既存の方法と比較してアラインメントエラー率が優れている真にオンラインの事後アラインメント技術を提案します。我々の提案する推論技術は、アラインメントとトークン確率を原理的に共同考慮し、既存の制約付きビームサーチデコーディングアルゴリズムにシームレスに統合できます。2つの遠隔言語ペアを含む5つの言語ペアで、アラインメントエラー率の一貫した低下を達成しました。7つのレキシカル制約翻訳タスクに展開された場合、制約位置周辺のBLEUに特に改善が見られました。"}
{"title": "Leveraging Task Transferability to Meta-learning for Clinical Section Classification with Limited Data", "url": "https://aclanthology.org/2022.acl-long.461/", "abstract": "Identifying sections is one of the critical components of understanding medical information from unstructured clinical notes and developing assistive technologies for clinical note-writing tasks. Most state-of-the-art text classification systems require thousands of in-domain text data to achieve high performance. However, collecting in-domain and recent clinical note data with section labels is challenging given the high level of privacy and sensitivity. The present paper proposes an algorithmic way to improve the task transferability of meta-learning-based text classification in order to address the issue of low-resource target data. Specifically, we explore how to make the best use of the source dataset and propose a unique task transferability measure named Normalized Negative Conditional Entropy (NNCE). Leveraging the NNCE, we develop strategies for selecting clinical categories and sections from source task data to boost cross-domain meta-learning accuracy. Experimental results show that our task selection strategies improve section classification accuracy significantly compared to meta-learning algorithms.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "限られたデータでの臨床セクション分類のためのメタ学習におけるタスク転移の活用", "jabstract": "セクションの特定は、非構造化の臨床ノートから医療情報を理解し、臨床ノート作成タスクの支援技術を開発する上で、重要な要素の1つです。最新のテキスト分類システムのほとんどは、高い性能を達成するために、数千のドメイン内テキストデータが必要です。しかし、プライバシーと機密性の高い問題があるため、ドメイン内で最近の臨床ノートデータを収集することは困難です。本論文では、低リソースのターゲットデータの問題に対処するために、メタ学習ベースのテキスト分類のタスク転移性を改善するアルゴリズム的な方法を提案します。具体的には、ソースデータセットを最大限活用する方法を探求し、ノーマライズされた負の条件付きエントロピー（NNCE）という独自のタスク転移性尺度を提案します。NNCEを活用して、ソースタスクデータから臨床カテゴリとセクションを選択する戦略を開発し、クロスドメインのメタ学習精度を向上させます。実験結果は、タスク選択戦略がメタ学習アルゴリズムに比べてセクション分類の精度を大幅に改善することを示しています。"}
{"title": "Reinforcement Guided Multi-Task Learning Framework for Low-Resource Stereotype Detection", "url": "https://aclanthology.org/2022.acl-long.462/", "abstract": "As large Pre-trained Language Models (PLMs) trained on large amounts of data in an unsupervised manner become more ubiquitous, identifying various types of bias in the text has come into sharp focus. Existing ‘Stereotype Detection’ datasets mainly adopt a diagnostic approach toward large PLMs. Blodgett et. al. (2021) show that there are significant reliability issues with the existing benchmark datasets. Annotating a reliable dataset requires a precise understanding of the subtle nuances of how stereotypes manifest in text. In this paper, we annotate a focused evaluation set for ‘Stereotype Detection’ that addresses those pitfalls by de-constructing various ways in which stereotypes manifest in text. Further, we present a multi-task model that leverages the abundance of data-rich neighboring tasks such as hate speech detection, offensive language detection, misogyny detection, etc., to improve the empirical performance on ‘Stereotype Detection’. We then propose a reinforcement-learning agent that guides the multi-task learning model by learning to identify the training examples from the neighboring tasks that help the target task the most. We show that the proposed models achieve significant empirical gains over existing baselines on all the tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "低リソースのステレオタイプ検出のための強化ガイドマルチタスク学習フレームワーク", "jabstract": "大量のデータを非監視学習でトレーニングされた大規模な事前学習言語モデル（PLM）が普及するにつれて、テキスト内のさまざまな種類のバイアスを特定することが注目されるようになってきました。既存の「ステレオタイプ検出」データセットは、主に大規模なPLMに対する診断的アプローチを採用しています。Blodgettら（2021）は、既存のベンチマークデータセットには重大な信頼性の問題があることを示しています。信頼性の高いデータセットを注釈するには、ステレオタイプがテキストでどのように現れるかの微妙なニュアンスを正確に理解する必要があります。本論文では、ステレオタイプがテキストでどのように現れるかを分解することによって、これらの落とし穴に対処する「ステレオタイプ検出」のための注目評価セットを注釈します。さらに、ヘイトスピーチ検出、攻撃的言語検出、女性嫌悪検出などのデータ豊富な隣接タスクを活用して、多目的モデルを提供します。これにより、「ステレオタイプ検出」の経験的パフォーマンスを向上させます。次に、強化学習エージェントを提案し、目標タスクに最も役立つ隣接タスクのトレーニング例を特定することを学習することにより、マルチタスク学習モデルをガイドします。提案されたモデルがすべてのタスクで既存のベースラインよりも重要な経験的利益をもたらすことを示します。"}
{"title": "Letters From the Past: Modeling Historical Sound Change Through Diachronic Character Embeddings", "url": "https://aclanthology.org/2022.acl-long.463/", "abstract": "While a great deal of work has been done on NLP approaches to lexical semantic change detection, other aspects of language change have received less attention from the NLP community. In this paper, we address the detection of sound change through historical spelling. We propose that a sound change can be captured by comparing the relative distance through time between the distributions of the characters involved before and after the change has taken place. We model these distributions using PPMI character embeddings. We verify this hypothesis in synthetic data and then test the method’s ability to trace the well-known historical change of lenition of plosives in Danish historical sources. We show that the models are able to identify several of the changes under consideration and to uncover meaningful contexts in which they appeared. The methodology has the potential to contribute to the study of open questions such as the relative chronology of sound shifts and their geographical distribution.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "過去からの手紙：歴史的音響変化をダイアクロニックな文字埋め込みを通じてモデリングする\n\nIn this paper, we propose a novel approach to modeling historical sound change using diachronic character embeddings. \n本論文では、ダイアクロニックな文字埋め込みを使用して歴史的音響変化をモデリングする新しいアプローチを提案します。\n\nOur method involves training a neural network to predict the phonetic representation of a character given its diachronic context. \n当社の方法は、ダイアクロニックな文脈が与えられた場合に文字の音声表現を予測するためにニューラルネットワークをトレーニングすることを含みます。\n\nWe evaluate our approach on a dataset of Old English and Middle English texts and show that our model outperforms existing methods for modeling historical sound change. \n私たちは、古英語と中英語のテキストのデータセットで私たちのアプローチを評価し、私たちのモデルが歴史的音響変化をモデリングするための既存の方法を上回ることを示します。", "jabstract": "自然言語処理における語彙意味変化検出のNLPアプローチに関する多くの研究が行われてきたが、言語変化の他の側面はNLPコミュニティからはあまり注目されていない。本論文では、歴史的な綴りを通じた音韻変化の検出に取り組む。我々は、音韻変化が、変化前後の文字の分布の相対的な時間的距離を比較することによって捉えられると提案する。我々は、PPMI文字埋め込みを用いてこれらの分布をモデル化する。我々は、合成データでこの仮説を検証し、その後、デンマークの歴史的な文献における子音の緩和というよく知られた歴史的変化を追跡する方法の能力をテストする。我々は、モデルがいくつかの変化を識別し、それらが現れた意味のある文脈を明らかにすることができることを示す。この方法論は、音韻変化の相対的な年代順序と地理的分布などの未解決の問題の研究に貢献する可能性がある。"}
{"title": "A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation", "url": "https://aclanthology.org/2022.acl-long.464/", "abstract": "Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications. Existing work usually attempts to detect these hallucinations based on a corresponding oracle reference at a sentence or document level. However ground-truth references may not be readily available for many free-form text generation applications, and sentence- or document-level detection may fail to provide the fine-grained signals that would prevent fallacious content in real time. As a first step to addressing these issues, we propose a novel token-level, reference-free hallucination detection task and an associated annotated dataset named HaDeS (HAllucination DEtection dataSet). To create this dataset, we first perturb a large number of text segments extracted from English language Wikipedia, and then verify these with crowd-sourced annotations. To mitigate label imbalance during annotation, we utilize an iterative model-in-loop strategy. We conduct comprehensive data analyses and create multiple baseline models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自由形式テキスト生成のためのトークンレベルの参照不要幻覚検出ベンチマーク\n\nAbstract:\n本論文では、自由形式テキスト生成における幻覚検出のためのトークンレベルの参照不要なベンチマークを提案する。我々は、自然言語処理における幻覚検出の重要性を説明し、既存のベンチマークの問題点を指摘する。提案されたベンチマークは、参照不要であり、トークンレベルでの評価を可能にする。我々は、提案されたベンチマークを使用して、幻覚検出の性能を評価し、既存の手法と比較する。結果は、提案されたベンチマークが有用であることを示している。", "jabstract": "GPT-3のような大規模な事前学習生成モデルは、非存在または不正確なコンテンツを幻覚することがよくあり、これは実際のアプリケーションでの潜在的な利点を損なう。既存の研究では、通常、文または文書レベルの対応するオラクルリファレンスに基づいてこれらの幻覚を検出しようとする。しかし、自由形式のテキスト生成アプリケーションでは、グラウンドトゥルースのリファレンスがすぐに利用できない場合があり、文または文書レベルの検出ではリアルタイムで誤ったコンテンツを防止するための細かい信号を提供できない場合がある。これらの問題に対処するための第一歩として、我々は新しいトークンレベル、リファレンスフリーの幻覚検出タスクと、関連する注釈付きデータセットであるHaDeS（HAllucination DEtection dataSet）を提案する。このデータセットを作成するために、まず英語のWikipediaから抽出した大量のテキストセグメントを変形させ、クラウドソーシングされた注釈で検証する。注釈付け中のラベルの不均衡を緩和するために、反復的なモデルインループ戦略を利用する。我々は包括的なデータ分析を実施し、複数のベースラインモデルを作成する。"}
{"title": "Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice", "url": "https://aclanthology.org/2022.acl-long.465/", "abstract": "Classifiers in natural language processing (NLP) often have a large number of output classes. For example, neural language models (LMs) and machine translation (MT) models both predict tokens from a vocabulary of thousands. The Softmax output layer of these models typically receives as input a dense feature representation, which has much lower dimensionality than the output. In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models (Demeter et al., 2020). In this paper we ask whether it can happen in practical large language models and translation models. To do so, we develop algorithms to detect such unargmaxable tokens in public models. We find that 13 out of 150 models do indeed have such tokens; however, they are very infrequent and unlikely to impact model quality. We release our algorithms and code to the public.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "低ランクソフトマックスは理論上はアンアーグマックス可能なクラスを持つことができますが、実際にはまれです。", "jabstract": "自然言語処理（NLP）における分類器は、しばしば多数の出力クラスを持っています。例えば、ニューラル言語モデル（LM）や機械翻訳（MT）モデルは、共に数千の語彙からトークンを予測します。これらのモデルのSoftmax出力層は、通常、低次元の密な特徴表現を入力として受け取りますが、出力よりもはるかに低い次元数です。理論的には、入力特徴に関係なく、いくつかの単語はargmaxを介して予測することが不可能であるため、小規模な言語モデルでは（Demeter et al.、2020）、経験的にもそのようなことが起こることがあるという証拠があります。本論文では、実用的な大規模言語モデルや翻訳モデルでもこのようなことが起こる可能性があるかどうかを調べます。そのために、公開されているモデルでこのようなargmax不可能なトークンを検出するアルゴリズムを開発しました。150のモデルのうち13つがこのようなトークンを持っていることがわかりましたが、非常にまれであり、モデルの品質に影響を与える可能性は低いです。私たちは、アルゴリズムとコードを公開します。"}
{"title": "Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction", "url": "https://aclanthology.org/2022.acl-long.466/", "abstract": "In this paper, we propose an effective yet efficient model PAIE for both sentence-level and document-level Event Argument Extraction (EAE), which also generalizes well when there is a lack of training data. On the one hand, PAIE utilizes prompt tuning for extractive objectives to take the best advantages of Pre-trained Language Models (PLMs). It introduces two span selectors based on the prompt to select start/end tokens among input texts for each role. On the other hand, it captures argument interactions via multi-role prompts and conducts joint optimization with optimal span assignments via a bipartite matching loss. Also, with a flexible prompt design, PAIE can extract multiple arguments with the same role instead of conventional heuristic threshold tuning. We have conducted extensive experiments on three benchmarks, including both sentence- and document-level EAE. The results present promising improvements from PAIE (3.5% and 2.3% F1 gains in average on three benchmarks, for PAIE-base and PAIE-large respectively). Further analysis demonstrates the efficiency, generalization to few-shot settings, and effectiveness of different extractive prompt tuning strategies. Our code is available at https://github.com/mayubo2333/PAIE.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「抽出のためのプロンプト？PAIE：イベント引数抽出のためのプロンプト引き起こし引数相互作用」という論文の要約です。", "jabstract": "本論文では、トレーニングデータが不足している場合でも汎用性が高く、文レベルおよび文書レベルのイベント引数抽出（EAE）に効果的かつ効率的なモデルPAIEを提案します。一方、PAIEは、抽出目的のためのプロンプトチューニングを利用して、事前学習言語モデル（PLM）の最大の利点を活用します。それは、各役割の入力テキストから開始/終了トークンを選択するためのプロンプトに基づく2つのスパンセレクタを導入します。他方、マルチロールプロンプトを介して引数の相互作用を捕捉し、二部マッチング損失を介した最適スパン割り当てとの共同最適化を実行します。また、柔軟なプロンプト設計により、従来のヒューリスティックな閾値チューニングではなく、同じ役割を持つ複数の引数を抽出できます。我々は、文レベルおよび文書レベルのEAEを含む3つのベンチマークで広範な実験を行いました。その結果、PAIE（PAIE-baseおよびPAIE-largeの平均で3.5％および2.3％のF1ゲイン）から有望な改善が示されました。さらに、抽出プロンプトチューニング戦略の効率性、少数ショット設定への汎用性、および効果を示すさまざまな分析を行いました。我々のコードはhttps://github.com/mayubo2333/PAIEで利用可能です。"}
{"title": "Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework", "url": "https://aclanthology.org/2022.acl-long.467/", "abstract": "Simultaneous machine translation (SiMT) starts translating while receiving the streaming source inputs, and hence the source sentence is always incomplete during translating. Different from the full-sentence MT using the conventional seq-to-seq architecture, SiMT often applies prefix-to-prefix architecture, which forces each target word to only align with a partial source prefix to adapt to the incomplete source in streaming inputs. However, the source words in the front positions are always illusoryly considered more important since they appear in more prefixes, resulting in position bias, which makes the model pay more attention on the front source positions in testing. In this paper, we first analyze the phenomenon of position bias in SiMT, and develop a Length-Aware Framework to reduce the position bias by bridging the structural gap between SiMT and full-sentence MT. Specifically, given the streaming inputs, we first predict the full-sentence length and then fill the future source position with positional encoding, thereby turning the streaming inputs into a pseudo full-sentence. The proposed framework can be integrated into most existing SiMT methods to further improve performance. Experiments on two representative SiMT methods, including the state-of-the-art adaptive policy, show that our method successfully reduces the position bias and thereby achieves better SiMT performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「長さに注意したフレームワークを用いた同時機械翻訳における位置バイアスの削減」に関する論文の要約です。", "jabstract": "同時機械翻訳（SiMT）は、ストリーミングソース入力を受け取りながら翻訳を開始するため、翻訳中にソース文が常に不完全な状態になります。従来のseq-to-seqアーキテクチャを使用した完全文MTとは異なり、SiMTはしばしば接頭辞から接頭辞へのアーキテクチャを適用し、各ターゲット単語が不完全なソースに適応するために部分的なソース接頭辞にのみアラインメントされるようにします。しかし、前方のソース単語は常に重要視されるため、位置バイアスが生じ、モデルがテスト中に前方のソース位置により多くの注意を払うことになります。本論文では、SiMTにおける位置バイアス現象を分析し、SiMTと完全文MTの構造的なギャップを埋めることで位置バイアスを減らすための長さに配慮したフレームワークを開発します。具体的には、ストリーミング入力を与えた後、完全文の長さを予測し、将来のソース位置に位置符号化を埋め込むことで、ストリーミング入力を疑似完全文に変換します。提案されたフレームワークは、既存のほとんどのSiMT方法に統合することができ、さらなる性能向上を実現します。最新の適応ポリシーを含む2つの代表的なSiMT方法に対する実験結果は、本手法が位置バイアスを成功裏に減らし、より良いSiMT性能を実現することを示しています。"}
{"title": "A Statutory Article Retrieval Dataset in French", "url": "https://aclanthology.org/2022.acl-long.468/", "abstract": "Statutory article retrieval is the task of automatically retrieving law articles relevant to a legal question. While recent advances in natural language processing have sparked considerable interest in many legal tasks, statutory article retrieval remains primarily untouched due to the scarcity of large-scale and high-quality annotated datasets. To address this bottleneck, we introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which consists of 1,100+ French native legal questions labeled by experienced jurists with relevant articles from a corpus of 22,600+ Belgian law articles. Using BSARD, we benchmark several state-of-the-art retrieval approaches, including lexical and dense architectures, both in zero-shot and supervised setups. We find that fine-tuned dense retrieval models significantly outperform other systems. Our best performing baseline achieves 74.8% R@100, which is promising for the feasibility of the task and indicates there is still room for improvement. By the specificity of the domain and addressed task, BSARD presents a unique challenge problem for future research on legal information retrieval. Our dataset and source code are publicly available.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "フランス語の法令記事検索データセット", "jabstract": "法的質問に関連する法律条文を自動的に取得することを法的条文検索という。自然言語処理の最近の進歩により、多くの法的タスクに関心が集まっているが、大規模で高品質な注釈付きデータセットが不足しているため、法的条文検索は主に未開拓のままである。このボトルネックに対処するために、私たちはベルギー法的条文検索データセット（BSARD）を導入しました。これは、22,600以上のベルギー法律条文のコーパスから関連する条文を経験豊富な法律家によってラベル付けされた1,100以上のフランス語の法的質問から構成されています。BSARDを使用して、ゼロショットおよび監視されたセットアップの両方で、レキシカルおよび密なアーキテクチャを含むいくつかの最新の検索アプローチをベンチマークします。私たちは、ファインチューニングされた密な検索モデルが他のシステムよりも優れていることを発見しました。最も優れたベースラインは、74.8％のR@100を達成し、タスクの実現可能性に向けた有望な成果を示し、改善の余地があることを示しています。BSARDは、ドメインの特異性と対象タスクにより、法的情報検索の将来の研究におけるユニークな課題問題を提供します。私たちのデータセットとソースコードは公開されています。"}
{"title": "ParaDetox: Detoxification with Parallel Data", "url": "https://aclanthology.org/2022.acl-long.469/", "abstract": "We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task.We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ParaDetox：並列データによる解毒作用", "jabstract": "私たちは、解毒タスクのための並列データ収集のための新しいパイプラインを提案します。私たちは、10,000以上の英語の有害な文に対して非有害な言い換えを収集します。また、このパイプラインを使用して、大規模な既存の言い換えコーパスを蒸留して、有害-中立の文のペアを得ることができることを示します。私たちは、解毒モデルのトレーニングに使用できる2つの並列コーパスをリリースします。私たちの知る限り、これらはこのタスクの最初の並列データセットです。私たちは、パイプラインを詳細に説明し、新しい言語やドメインに対して簡単に設定できるようにすることで、新しい並列リソースのより速く、簡単な開発に貢献します。私たちは、収集したデータでいくつかの解毒モデルをトレーニングし、いくつかのベースラインと最先端の非監視アプローチと比較します。自動評価と手動評価の両方を実施します。並列データでトレーニングされたすべてのモデルは、最先端の非監視モデルを大幅に上回ります。これは、私たちの新しいデータセットが解毒システムの性能を向上させることができることを示唆しています。"}
{"title": "Interpreting Character Embeddings With Perceptual Representations: The Case of Shape, Sound, and Color", "url": "https://aclanthology.org/2022.acl-long.470/", "abstract": "Character-level information is included in many NLP models, but evaluating the information encoded in character representations is an open issue. We leverage perceptual representations in the form of shape, sound, and color embeddings and perform a representational similarity analysis to evaluate their correlation with textual representations in five languages. This cross-lingual analysis shows that textual character representations correlate strongly with sound representations for languages using an alphabetic script, while shape correlates with featural scripts.We further develop a set of probing classifiers to intrinsically evaluate what phonological information is encoded in character embeddings. Our results suggest that information on features such as voicing are embedded in both LSTM and transformer-based representations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「知覚表現を用いた文字埋め込みの解釈：形状、音、色の場合」", "jabstract": "多くのNLPモデルには文字レベルの情報が含まれていますが、文字表現にエンコードされた情報を評価することは未解決の問題です。私たちは、形状、音、色の埋め込みという知覚的な表現を活用し、表現の類似性分析を実行して、5つの言語でのテキスト表現との相関を評価します。このクロスリンガル分析は、アルファベットスクリプトを使用する言語では、テキスト文字表現が音声表現と強く相関する一方、形状は特徴スクリプトと相関することを示しています。さらに、文字埋め込みにエンコードされた音韻情報を内在的に評価するための一連のプロービング分類器を開発しました。私たちの結果は、声調などの特徴情報がLSTMとトランスフォーマーベースの表現に埋め込まれていることを示唆しています。"}
{"title": "Fine-Grained Controllable Text Generation Using Non-Residual Prompting", "url": "https://aclanthology.org/2022.acl-long.471/", "abstract": "The introduction of immensely large Causal Language Models (CLMs) has rejuvenated the interest in open-ended text generation. However, controlling the generative process for these Transformer-based models is at large an unsolved problem. Earlier work has explored either plug-and-play decoding strategies, or more powerful but blunt approaches such as prompting. There hence currently exists a trade-off between fine-grained control, and the capability for more expressive high-level instructions. To alleviate this trade-off, we propose an encoder-decoder architecture that enables intermediate text prompts at arbitrary time steps. We propose a resource-efficient method for converting a pre-trained CLM into this architecture, and demonstrate its potential on various experiments, including the novel task of contextualized word inclusion. Our method provides strong results on multiple experimental settings, proving itself to be both expressive and versatile.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「非残差プロンプティングを使用した細かい制御可能なテキスト生成」に関する論文の要約文です。\n\n- Fine-Grained Controllable Text Generation: 細かい制御可能なテキスト生成\n- Using Non-Residual Prompting: 非残差プロンプティングを使用した", "jabstract": "極めて大きな因果言語モデル（CLM）の導入により、オープンエンドのテキスト生成に対する関心が再び高まっています。ただし、これらのTransformerベースのモデルの生成プロセスを制御することは、大きな未解決の問題です。以前の研究では、プラグアンドプレイのデコーディング戦略またはプロンプトなど、より強力であるが鈍いアプローチが探求されてきました。したがって、細かい制御とより表現力の高い高レベルの指示の能力との間には、現在、トレードオフが存在しています。このトレードオフを緩和するために、任意の時間ステップで中間テキストプロンプトを可能にするエンコーダーデコーダーアーキテクチャを提案します。事前にトレーニングされたCLMをこのアーキテクチャに変換するためのリソース効率の高い方法を提案し、文脈に基づいた単語の含有の新しいタスクを含むさまざまな実験でその可能性を示します。私たちの方法は、複数の実験設定で強力な結果を提供し、表現力と多目的性の両方を証明しています。"}
{"title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features", "url": "https://aclanthology.org/2022.acl-long.472/", "abstract": "While neural text-to-speech systems perform remarkably well in high-resource scenarios, they cannot be applied to the majority of the over 6,000 spoken languages in the world due to a lack of appropriate training data. In this work, we use embeddings derived from articulatory vectors rather than embeddings derived from phoneme identities to learn phoneme representations that hold across languages. In conjunction with language agnostic meta learning, this enables us to fine-tune a high-quality text-to-speech model on just 30 minutes of data in a previously unseen language spoken by a previously unseen speaker.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "言語に依存しないメタ学習を用いた、発音特徴を持つ低リソースのテキスト音声変換についての論文の要旨です。", "jabstract": "ニューラルテキスト・トゥ・スピーチシステムは、高リソースのシナリオでは驚くほど優れた性能を発揮しますが、適切なトレーニングデータがないため、世界で6,000以上の話されている言語の大多数には適用できません。本研究では、音素のアイデンティティから派生した埋め込みではなく、口腔運動ベクトルから派生した埋め込みを使用して、言語を超えて音素表現を学習します。言語に依存しないメタ学習と組み合わせることで、以前に見たことのない話者が話す以前に見たことのない言語で、わずか30分のデータで高品質のテキスト・トゥ・スピーチモデルを微調整することができます。"}
{"title": "TwittIrish: A Universal Dependencies Treebank of Tweets in Modern Irish", "url": "https://aclanthology.org/2022.acl-long.473/", "abstract": "Modern Irish is a minority language lacking sufficient computational resources for the task of accurate automatic syntactic parsing of user-generated content such as tweets. Although language technology for the Irish language has been developing in recent years, these tools tend to perform poorly on user-generated content. As with other languages, the linguistic style observed in Irish tweets differs, in terms of orthography, lexicon, and syntax, from that of standard texts more commonly used for the development of language models and parsers. We release the first Universal Dependencies treebank of Irish tweets, facilitating natural language processing of user-generated content in Irish. In this paper, we explore the differences between Irish tweets and standard Irish text, and the challenges associated with dependency parsing of Irish tweets. We describe our bootstrapping method of treebank development and report on preliminary parsing experiments.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「TwittIrish：現代アイルランド語のツイートのUniversal Dependencies Treebank」", "jabstract": "現代アイルランド語は、ツイートなどのユーザー生成コンテンツの正確な自動構文解析のための十分な計算リソースを欠いている少数派言語である。アイルランド語の言語技術は近年発展してきたが、これらのツールはユーザー生成コンテンツに対しては性能が低い傾向がある。他の言語と同様に、アイルランド語のツイートで観察される言語スタイルは、正書法、語彙、構文の面で、言語モデルやパーサーの開発によく使われる標準テキストと異なる。本論文では、アイルランド語ツイートと標準アイルランド語テキストの違いと、アイルランド語ツイートの依存解析に関連する課題について探究し、アイルランド語ユーザー生成コンテンツの自然言語処理を可能にする初めてのアイルランド語ツイートのUniversal Dependencies treebankを公開する。また、treebankの開発のブートストラップ方法を説明し、初期の解析実験について報告する。"}
{"title": "Length Control in Abstractive Summarization by Pretraining Information Selection", "url": "https://aclanthology.org/2022.acl-long.474/", "abstract": "Previous length-controllable summarization models mostly control lengths at the decoding stage, whereas the encoding or the selection of information from the source document is not sensitive to the designed length. They also tend to generate summaries as long as those in the training data. In this paper, we propose a length-aware attention mechanism (LAAM) to adapt the encoding of the source based on the desired length. Our approach works by training LAAM on a summary length balanced dataset built from the original training data, and then fine-tuning as usual. Results show that this approach is effective in generating high-quality summaries with desired lengths and even those short lengths never seen in the original training set.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「事前学習情報選択による抽象的要約における長さ制御」についての論文の要約です。", "jabstract": "従来の長さ制御可能な要約モデルは、デコード段階で長さを制御することが多く、ソースドキュメントからのエンコーディングや情報の選択は設計された長さに敏感ではありませんでした。また、トレーニングデータと同じ長さの要約を生成する傾向がありました。本論文では、望ましい長さに基づいてソースのエンコーディングを適応させる長さに注意したメカニズム（LAAM）を提案します。このアプローチは、元のトレーニングデータから構築された要約長バランスの取れたデータセットでLAAMをトレーニングし、通常通りファインチューニングすることで機能します。結果は、このアプローチが望ましい長さで高品質な要約を生成するのに効果的であり、元のトレーニングセットにはなかった短い長さの要約を生成することもできることを示しています。"}
{"title": "CQG: A Simple and Effective Controlled Generation Framework for Multi-hop Question Generation", "url": "https://aclanthology.org/2022.acl-long.475/", "abstract": "Multi-hop question generation focuses on generating complex questions that require reasoning over multiple pieces of information of the input passage. Current models with state-of-the-art performance have been able to generate the correct questions corresponding to the answers. However, most models can not ensure the complexity of generated questions, so they may generate shallow questions that can be answered without multi-hop reasoning. To address this challenge, we propose the CQG, which is a simple and effective controlled framework. CQG employs a simple method to generate the multi-hop questions that contain key entities in multi-hop reasoning chains, which ensure the complexity and quality of the questions. In addition, we introduce a novel controlled Transformer-based decoder to guarantee that key entities appear in the questions. Experiment results show that our model greatly improves performance, which also outperforms the state-of-the-art model about 25% by 5 BLEU points on HotpotQA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CQG：マルチホップ質問生成のためのシンプルで効果的な制御生成フレームワーク", "jabstract": "マルチホップ質問生成は、入力パッセージの複数の情報を推論することを必要とする複雑な質問を生成することに焦点を当てています。最新の性能を持つ現在のモデルは、答えに対応する正しい質問を生成することができました。しかし、ほとんどのモデルは生成された質問の複雑さを保証できないため、マルチホップ推論なしで回答できる浅い質問を生成する可能性があります。この課題に対処するために、私たちはシンプルで効果的な制御フレームワークであるCQGを提案します。CQGは、マルチホップ推論チェーン内のキーとなるエンティティを含むマルチホップ質問を生成するためのシンプルな方法を採用し、質問の複雑さと品質を保証します。さらに、キーとなるエンティティが質問に現れるようにするための新しい制御Transformerベースのデコーダを導入します。実験結果は、私たちのモデルが性能を大幅に向上させ、HotpotQAで最新のモデルを5 BLEUポイントで25％上回ることを示しています。"}
{"title": "Word Order Does Matter and Shuffled Language Models Know It", "url": "https://aclanthology.org/2022.acl-long.476/", "abstract": "Recent studies have shown that language models pretrained and/or fine-tuned on randomly permuted sentences exhibit competitive performance on GLUE, putting into question the importance of word order information. Somewhat counter-intuitively, some of these studies also report that position embeddings appear to be crucial for models’ good performance with shuffled text. We probe these language models for word order information and investigate what position embeddings learned from shuffled text encode, showing that these models retain a notion of word order information. We show this is in part due to a subtlety in how shuffling is implemented in previous work – before rather than after subword segmentation. Surprisingly, we find even Language models trained on text shuffled after subword segmentation retain some semblance of information about word order because of the statistical dependencies between sentence length and unigram probabilities. Finally, we show that beyond GLUE, a variety of language understanding tasks do require word order information, often to an extent that cannot be learned through fine-tuning.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "単語の順序は重要であり、シャッフルされた言語モデルはそれを知っています。", "jabstract": "最近の研究により、ランダムに並べ替えられた文章に事前学習および/または微調整された言語モデルがGLUEで競争力のあるパフォーマンスを発揮することが示され、単語順序情報の重要性に疑問が投げかけられています。これらの研究の中には、位置エンベッディングがシャッフルされたテキストのモデルの良好なパフォーマンスに重要であるように見えると報告するものもあり、やや直感に反する結果となっています。我々はこれらの言語モデルを単語順序情報について調査し、シャッフルされたテキストから学習された位置エンベッディングが何をエンコードしているかを調べ、これらのモデルが単語順序情報の概念を保持していることを示します。これは、以前の研究でシャッフルがサブワード分割の前に行われていたという微妙な点によるものの一部です。驚くべきことに、サブワード分割後にシャッフルされたテキストで訓練された言語モデルでも、文の長さとユニグラム確率の統計的依存関係のために、単語順序情報の情報が一部残っていることがわかりました。最後に、GLUEを超えて、様々な言語理解タスクには単語順序情報が必要であり、微調整では学習できない程度に必要であることを示します。"}
{"title": "An Empirical Study on Explanations in Out-of-Domain Settings", "url": "https://aclanthology.org/2022.acl-long.477/", "abstract": "Recent work in Natural Language Processing has focused on developing approaches that extract faithful explanations, either via identifying the most important tokens in the input (i.e. post-hoc explanations) or by designing inherently faithful models that first select the most important tokens and then use them to predict the correct label (i.e. select-then-predict models). Currently, these approaches are largely evaluated on in-domain settings. Yet, little is known about how post-hoc explanations and inherently faithful models perform in out-of-domain settings. In this paper, we conduct an extensive empirical study that examines: (1) the out-of-domain faithfulness of post-hoc explanations, generated by five feature attribution methods; and (2) the out-of-domain performance of two inherently faithful models over six datasets. Contrary to our expectations, results show that in many cases out-of-domain post-hoc explanation faithfulness measured by sufficiency and comprehensiveness is higher compared to in-domain. We find this misleading and suggest using a random baseline as a yardstick for evaluating post-hoc explanation faithfulness. Our findings also show that select-then predict models demonstrate comparable predictive performance in out-of-domain settings to full-text trained models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ドメイン外の設定における説明に関する実証的研究」についての要約です。", "jabstract": "自然言語処理における最近の研究は、入力内の最も重要なトークンを特定することによって忠実な説明を抽出するアプローチを開発することに焦点を当てています（つまり、事後説明）または最も重要なトークンを最初に選択し、それらを使用して正しいラベルを予測することができる本質的に忠実なモデルを設計することによって（つまり、選択して予測するモデル）。現在、これらのアプローチは主にドメイン内の設定で評価されています。しかし、事後説明と本質的に忠実なモデルがドメイン外の設定でどのように機能するかはほとんど知られていません。本論文では、5つの特徴の帰属方法によって生成されたドメイン外の事後説明の十分性と包括性を評価するとともに、6つのデータセット上で2つの本質的に忠実なモデルのドメイン外の性能を評価する、広範な実証的研究を行います。私たちの期待に反して、結果は、多くの場合、ドメイン外の事後説明の忠実性が、十分性と包括性によって測定された場合、ドメイン内よりも高いことを示しています。これは誤解を招くものであり、事後説明の忠実性を評価する基準としてランダムベースラインを使用することを提案します。また、私たちの調査結果は、選択して予測するモデルが、フルテキストトレーニングモデルと同等の予測性能をドメイン外の設定で示すことを示しています。"}
{"title": "MILIE: Modular & Iterative Multilingual Open Information Extraction", "url": "https://aclanthology.org/2022.acl-long.478/", "abstract": "Open Information Extraction (OpenIE) is the task of extracting (subject, predicate, object) triples from natural language sentences. Current OpenIE systems extract all triple slots independently. In contrast, we explore the hypothesis that it may be beneficial to extract triple slots iteratively: first extract easy slots, followed by the difficult ones by conditioning on the easy slots, and therefore achieve a better overall extraction.Based on this hypothesis, we propose a neural OpenIE system, MILIE, that operates in an iterative fashion. Due to the iterative nature, the system is also modularit is possible to seamlessly integrate rule based extraction systems with a neural end-to-end system, thereby allowing rule based systems to supply extraction slots which MILIE can leverage for extracting the remaining slots. We confirm our hypothesis empirically: MILIE outperforms SOTA systems on multiple languages ranging from Chinese to Arabic. Additionally, we are the first to provide an OpenIE test dataset for Arabic and Galician.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "MILIE: モジュラー＆反復的な多言語オープン情報抽出", "jabstract": "オープン情報抽出（OpenIE）は、自然言語文から（主語、述語、目的語）トリプルを抽出するタスクです。現在のOpenIEシステムは、すべてのトリプルスロットを独立して抽出します。それに対して、私たちは、簡単なスロットを最初に抽出し、簡単なスロットに基づいて難しいスロットを抽出することが有益である可能性があるという仮説を探求しています。この仮説に基づいて、私たちは、イテレーション方式で動作するニューラルOpenIEシステム、MILIEを提案します。イテレーションの性質により、システムはモジュール化されます。ルールベースの抽出システムをニューラルエンドツーエンドシステムにシームレスに統合することができるため、ルールベースのシステムが抽出スロットを提供し、MILIEが残りのスロットを抽出するために活用できます。私たちは、MILIEが中国語からアラビア語までの複数の言語でSOTAシステムを上回ることを実証しました。さらに、私たちは、アラビア語とガリシア語のOpenIEテストデータセットを提供する最初の人です。"}
{"title": "What Makes Reading Comprehension Questions Difficult?", "url": "https://aclanthology.org/2022.acl-long.479/", "abstract": "For a natural language understanding benchmark to be useful in research, it has to consist of examples that are diverse and difficult enough to discriminate among current and near-future state-of-the-art systems. However, we do not yet know how best to select text sources to collect a variety of challenging examples. In this study, we crowdsource multiple-choice reading comprehension questions for passages taken from seven qualitatively distinct sources, analyzing what attributes of passages contribute to the difficulty and question types of the collected examples. To our surprise, we find that passage source, length, and readability measures do not significantly affect question difficulty. Through our manual annotation of seven reasoning types, we observe several trends between passage sources and reasoning types, e.g., logical reasoning is more often required in questions written for technical passages. These results suggest that when creating a new benchmark dataset, selecting a diverse set of passages can help ensure a diverse range of question types, but that passage difficulty need not be a priority.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "読解問題を難しくする要因は何ですか？", "jabstract": "自然言語理解のベンチマークが研究に役立つためには、現在の最先端システムと近い将来のシステムを区別するのに十分多様で難しい例から構成されている必要があります。しかし、どのようにして多様な難しい例を収集するためのテキストソースを選択するのが最適かはまだわかっていません。本研究では、7つの質的に異なるソースから抜粋された文章に対して、クラウドソーシングによる多肢選択式読解問題を収集し、収集された例の難易度と問題タイプに寄与する文章の属性を分析しました。驚くべきことに、文章のソース、長さ、読みやすさの指標は問題の難易度にほとんど影響しないことがわかりました。7つの推論タイプを手動で注釈付けした結果、文章のソースと推論タイプの間にいくつかの傾向が観察されました。例えば、技術的な文章に書かれた問題では論理的な推論がより頻繁に必要とされます。これらの結果から、新しいベンチマークデータセットを作成する際には、多様な文章を選択することで多様な問題タイプを確保できることが示唆されますが、文章の難易度は優先される必要はないということがわかります。"}
{"title": "From Simultaneous to Streaming Machine Translation by Leveraging Streaming History", "url": "https://aclanthology.org/2022.acl-long.480/", "abstract": "Simultaneous machine translation has recently gained traction thanks to significant quality improvements and the advent of streaming applications. Simultaneous translation systems need to find a trade-off between translation quality and response time, and with this purpose multiple latency measures have been proposed. However, latency evaluations for simultaneous translation are estimated at the sentence level, not taking into account the sequential nature of a streaming scenario. Indeed, these sentence-level latency measures are not well suited for continuous stream translation, resulting in figures that are not coherent with the simultaneous translation policy of the system being assessed. This work proposes a stream-level adaptation of the current latency measures based on a re-segmentation approach applied to the output translation, that is successfully evaluated on streaming conditions for a reference IWSLT task", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n「ストリーミング履歴を活用した同時からストリーミング機械翻訳への移行」", "jabstract": "最近、同時機械翻訳は品質の大幅な向上とストリーミングアプリケーションの登場により注目を集めています。同時翻訳システムは翻訳品質と応答時間のトレードオフを見つける必要があり、この目的のために複数のレイテンシー測定が提案されています。しかし、同時翻訳のレイテンシー評価は文レベルで推定され、ストリーミングシナリオの連続性を考慮していません。実際、これらの文レベルのレイテンシー測定は、連続ストリーム翻訳には適しておらず、評価されるシステムの同時翻訳方針と一致しない数字を示します。本研究では、出力翻訳に適用される再セグメンテーションアプローチに基づく現在のレイテンシー測定のストリームレベルの適応を提案し、参照IWSLTタスクのストリーミング条件で成功裏に評価されました。"}
{"title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning", "url": "https://aclanthology.org/2022.acl-long.481/", "abstract": "We present a novel rational-centric framework with human-in-the-loop – Rationales-centric Double-robustness Learning (RDL) – to boost model out-of-distribution performance in few-shot learning scenarios. By using static semi-factual generation and dynamic human-intervened correction, RDL, acting like a sensible “inductive bias”, exploits rationales (i.e. phrases that cause the prediction), human interventions and semi-factual augmentations to decouple spurious associations and bias models towards generally applicable underlying distributions, which enables fast and accurate generalisation. Experimental results show that RDL leads to significant prediction benefits on both in-distribution and out-of-distribution tests, especially for few-shot learning scenarios, compared to many state-of-the-art benchmarks. We also perform extensive ablation studies to support in-depth analyses of each component in our framework.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨を日本語に翻訳します。\n\n人間と機械学習のための合理的中心的フレームワーク", "jabstract": "私たちは、人間を含めた合理的な中心のフレームワークである「Rationales-centric Double-robustness Learning（RDL）」を提案し、モデルのアウトオブディストリビューションパフォーマンスをフューショット学習シナリオで向上させます。静的な半事実的生成と動的な人間介入により、RDLは合理的な「帰納的バイアス」のように作用し、理由（つまり、予測を引き起こすフレーズ）、人間の介入、および半事実的な拡張を利用して、偽の関連性を分離し、モデルを一般的に適用可能な基礎分布にバイアスをかけ、迅速かつ正確な一般化を可能にします。実験結果は、RDLが、多くの最新のベンチマークに比べて、インディストリビューションテストとアウトオブディストリビューションテストの両方で、特にフューショット学習シナリオで、重要な予測の利点をもたらすことを示しています。また、フレームワークの各コンポーネントの詳細な分析をサポートするために、包括的な除去研究を実施しています。"}
{"title": "Challenges and Strategies in Cross-Cultural NLP", "url": "https://aclanthology.org/2022.acl-long.482/", "abstract": "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "クロスカルチャーNLPにおける課題と戦略", "jabstract": "自然言語処理（NLP）コミュニティでは、言語の多様性に対応し、多言語話者にサービスを提供するための様々な取り組みが行われています。しかし、言語と文化は密接に関連しているものの、話者と彼らが生産し必要とするコンテンツは、言語だけでなく文化によっても異なることを認識することが重要です。クロスリンガルおよびマルチリンガルNLPに類似して、クロスカルチャーおよびマルチカルチャーNLPは、これらの違いを考慮してNLPシステムのユーザーにより良いサービスを提供するために検討されます。我々は、これらの取り組みを枠組みとする原則的なフレームワークを提案し、既存および潜在的な戦略を調査します。"}
{"title": "Prototypical Verbalizer for Prompt-based Few-shot Tuning", "url": "https://aclanthology.org/2022.acl-long.483/", "abstract": "Prompt-based tuning for pre-trained language models (PLMs) has shown its effectiveness in few-shot learning. Typically, prompt-based tuning wraps the input text into a cloze question. To make predictions, the model maps the output words to labels via a verbalizer, which is either manually designed or automatically built. However, manual verbalizers heavily depend on domain-specific prior knowledge and human efforts, while finding appropriate label words automatically still remains challenging.In this work, we propose the prototypical verbalizer (ProtoVerb) which is built directly from training data. Specifically, ProtoVerb learns prototype vectors as verbalizers by contrastive learning. In this way, the prototypes summarize training instances and are able to enclose rich class-level semantics. We conduct experiments on both topic classification and entity typing tasks, and the results demonstrate that ProtoVerb significantly outperforms current automatic verbalizers, especially when training data is extremely scarce. More surprisingly, ProtoVerb consistently boosts prompt-based tuning even on untuned PLMs, indicating an elegant non-tuning way to utilize PLMs. Our codes are avaliable at https://github.com/thunlp/OpenPrompt.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "プロンプトベースのフューショットチューニングのための典型的な言語処理システム", "jabstract": "事前学習言語モデル（PLMs）のプロンプトベースの調整は、フューショット学習においてその効果を示しています。通常、プロンプトベースの調整は、入力テキストをクローズ質問にラップします。予測を行うために、モデルは出力単語をラベルにマッピングするためのバーバライザを使用します。このバーバライザは、手動で設計されるか、自動的に構築されます。しかし、手動バーバライザは、ドメイン固有の事前知識と人間の努力に大きく依存しており、適切なラベル単語を自動的に見つけることはまだ困難です。本研究では、トレーニングデータから直接構築されたプロトタイプバーバライザ（ProtoVerb）を提案します。具体的には、ProtoVerbは対比学習によってバーバライザとしてプロトタイプベクトルを学習します。この方法により、プロトタイプはトレーニングインスタンスを要約し、豊富なクラスレベルの意味を包含することができます。トピック分類およびエンティティタイピングタスクの両方で実験を行い、結果は、ProtoVerbが現在の自動バーバライザよりも優れており、特にトレーニングデータが極端に少ない場合に顕著であることを示しています。さらに驚くべきことに、ProtoVerbは、調整されていないPLMsでもプロンプトベースの調整を一貫して向上させるため、PLMsを利用するためのエレガントな非調整方法を示唆しています。私たちのコードはhttps://github.com/thunlp/OpenPromptで利用可能です。"}
{"title": "Clickbait Spoiling via Question Answering and Passage Retrieval", "url": "https://aclanthology.org/2022.acl-long.484/", "abstract": "We introduce and study the task of clickbait spoiling: generating a short text that satisfies the curiosity induced by a clickbait post. Clickbait links to a web page and advertises its contents by arousing curiosity instead of providing an informative summary. Our contributions are approaches to classify the type of spoiler needed (i.e., a phrase or a passage), and to generate appropriate spoilers. A large-scale evaluation and error analysis on a new corpus of 5,000 manually spoiled clickbait posts—the Webis Clickbait Spoiling Corpus 2022—shows that our spoiler type classifier achieves an accuracy of 80%, while the question answering model DeBERTa-large outperforms all others in generating spoilers for both types.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nクリックベイトの台無しになる質問応答とパッセージ検索", "jabstract": "私たちは、クリックベイトの台頭によって引き起こされる好奇心を満たす短いテキストを生成するタスクである「クリックベイトスポイリング」を紹介し、研究しました。クリックベイトは、情報的な要約を提供する代わりに好奇心をかき立てることで、ウェブページへのリンクを宣伝します。私たちの貢献は、必要なスポイラーのタイプ（フレーズまたはパッセージ）を分類するアプローチと、適切なスポイラーを生成するアプローチです。新しいコーパスである「Webis Clickbait Spoiling Corpus 2022」の5,000件の手動スポイリングされたクリックベイト投稿に対する大規模な評価とエラー分析により、スポイラータイプ分類器は80％の精度を達成し、質問応答モデルであるDeBERTa-largeは、両方のタイプのスポイラーを生成するために他のすべてを上回る性能を発揮しました。"}
{"title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning", "url": "https://aclanthology.org/2022.acl-long.485/", "abstract": "We present Knowledge Distillation with Meta Learning (MetaDistil), a simple yet effective alternative to traditional knowledge distillation (KD) methods where the teacher model is fixed during training. We show the teacher network can learn to better transfer knowledge to the student network (i.e., learning to teach) with the feedback from the performance of the distilled student network in a meta learning framework. Moreover, we introduce a pilot update mechanism to improve the alignment between the inner-learner and meta-learner in meta learning algorithms that focus on an improved inner-learner. Experiments on various benchmarks show that MetaDistil can yield significant improvements compared with traditional KD algorithms and is less sensitive to the choice of different student capacity and hyperparameters, facilitating the use of KD on different tasks and models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "BERTが教えることを学ぶ：メタ学習による知識蒸留", "jabstract": "私たちは、メタ学習を用いた知識蒸留（MetaDistil）を提案し、従来の知識蒸留（KD）手法の代替として、教師モデルがトレーニング中に固定されることがないようにします。私たちは、メタ学習フレームワークで蒸留された学生ネットワークのパフォーマンスに対するフィードバックを用いて、教師ネットワークが知識をより効果的に転移することができることを示します。さらに、改善された内部学習者に焦点を当てたメタ学習アルゴリズムにおいて、内部学習者とメタ学習者の整合性を改善するためのパイロット更新メカニズムを導入します。様々なベンチマーク実験により、MetaDistilは従来のKDアルゴリズムと比較して、有意な改善をもたらすことができ、異なるタスクやモデルでKDを使用することを容易にすることができることが示されました。"}
{"title": "STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation", "url": "https://aclanthology.org/2022.acl-long.486/", "abstract": "How to learn a better speech representation for end-to-end speech-to-text translation (ST) with limited labeled data? Existing techniques often attempt to transfer powerful machine translation (MT) capabilities to ST, but neglect the representation discrepancy across modalities. In this paper, we propose the Speech-TExt Manifold Mixup (STEMM) method to calibrate such discrepancy. Specifically, we mix up the representation sequences of different modalities, and take both unimodal speech sequences and multimodal mixed sequences as input to the translation model in parallel, and regularize their output predictions with a self-learning framework. Experiments on MuST-C speech translation benchmark and further analysis show that our method effectively alleviates the cross-modal representation discrepancy, and achieves significant improvements over a strong baseline on eight translation directions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "STEMM：音声翻訳のための音声テキストマニフォールドミックスアップによる自己学習", "jabstract": "限られたラベル付きデータでエンドツーエンドの音声からテキストへの翻訳（ST）のためにより良い音声表現を学ぶ方法は何ですか？既存の技術はしばしば強力な機械翻訳（MT）の能力をSTに転送しようとしますが、モダリティ間の表現の不一致を無視します。本論文では、Speech-TExt Manifold Mixup（STEMM）方法を提案し、このような不一致を調整します。具体的には、異なるモダリティの表現シーケンスを混ぜ合わせ、単一モーダル音声シーケンスと多モーダル混合シーケンスの両方を並列に翻訳モデルの入力として取り、自己学習フレームワークで出力予測を正則化します。MuST-C音声翻訳ベンチマークでの実験とさらなる分析により、当社の方法はクロスモーダル表現の不一致を効果的に緩和し、8つの翻訳方向で強力なベースラインに比べて有意な改善を実現していることが示されました。"}
{"title": "Integrating Vectorized Lexical Constraints for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.487/", "abstract": "Lexically constrained neural machine translation (NMT), which controls the generation of NMT models with pre-specified constraints, is important in many practical scenarios. Due to the representation gap between discrete constraints and continuous vectors in NMT models, most existing works choose to construct synthetic data or modify the decoding algorithm to impose lexical constraints, treating the NMT model as a black box. In this work, we propose to open this black box by directly integrating the constraints into NMT models. Specifically, we vectorize source and target constraints into continuous keys and values, which can be utilized by the attention modules of NMT models. The proposed integration method is based on the assumption that the correspondence between keys and values in attention modules is naturally suitable for modeling constraint pairs. Experimental results show that our method consistently outperforms several representative baselines on four language pairs, demonstrating the superiority of integrating vectorized lexical constraints.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約の以下の文を日本語に翻訳してください。\n\nベクトル化された語彙制約をニューラル機械翻訳に統合する", "jabstract": "単語制約を持つニューラル機械翻訳（NMT）は、事実上の多くのシナリオで重要である。NMTモデルの離散制約と連続ベクトルの表現ギャップのため、既存の多くの研究では、合成データを構築するか、デコーディングアルゴリズムを変更して、NMTモデルをブラックボックスとして扱い、単語制約を課している。本研究では、制約を直接NMTモデルに統合することで、このブラックボックスを開くことを提案する。具体的には、ソースとターゲットの制約を連続的なキーと値にベクトル化し、NMTモデルのアテンションモジュールで利用できるようにする。提案された統合方法は、アテンションモジュール内のキーと値の対応が制約ペアのモデリングに自然に適しているという仮定に基づいています。実験結果は、ベクトル化された単語制約を統合する優位性を示し、4つの言語ペアでいくつかの代表的なベースラインを一貫して上回ることを示しています。"}
{"title": "MPII: Multi-Level Mutual Promotion for Inference and Interpretation", "url": "https://aclanthology.org/2022.acl-long.488/", "abstract": "In order to better understand the rationale behind model behavior, recent works have exploited providing interpretation to support the inference prediction. However, existing methods tend to provide human-unfriendly interpretation, and are prone to sub-optimal performance due to one-side promotion, i.e. either inference promotion with interpretation or vice versa. In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII). Specifically, from the model-level, we propose a Step-wise Integration Mechanism to jointly perform and deeply integrate inference and interpretation in an autoregressive manner. From the optimization-level, we propose an Adversarial Fidelity Regularization to improve the fidelity between inference and interpretation with the Adversarial Mutual Information training strategy. Extensive experiments on NLI and CQA tasks reveal that the proposed MPII approach can significantly outperform baseline models for both the inference performance and the interpretation quality.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nMPII：推論と解釈のための多レベル相互促進", "jabstract": "最近の研究では、モデルの振る舞いの理論をより理解するために、推論予測をサポートする解釈を提供することが試みられています。しかし、既存の方法は人間にとって不親切な解釈を提供する傾向があり、推論促進と解釈促進のどちらか一方に偏りがちであるため、最適なパフォーマンスを発揮することができません。本論文では、自己進化型推論と文レベル解釈のための多レベル相互促進メカニズム（MPII）を提案します。具体的には、モデルレベルから、ステップワイズ統合メカニズムを提案し、自己回帰的に推論と解釈を深く統合します。最適化レベルからは、敵対的相互情報学習戦略を用いた敵対的忠実度正則化を提案し、推論と解釈の忠実度を向上させます。NLIとCQAタスクでの広範な実験により、提案されたMPIIアプローチが、推論パフォーマンスと解釈品質の両方においてベースラインモデルを大幅に上回ることが示されました。"}
{"title": "StableMoE: Stable Routing Strategy for Mixture of Experts", "url": "https://aclanthology.org/2022.acl-long.489/", "abstract": "The Mixture-of-Experts (MoE) technique can scale up the model size of Transformers with an affordable computational overhead. We point out that existing learning-to-route MoE methods suffer from the routing fluctuation issue, i.e., the target expert of the same input may change along with training, but only one expert will be activated for the input during inference. The routing fluctuation tends to harm sample efficiency because the same input updates different experts but only one is finally used. In this paper, we propose StableMoE with two training stages to address the routing fluctuation problem. In the first training stage, we learn a balanced and cohesive routing strategy and distill it into a lightweight router decoupled from the backbone model. In the second training stage, we utilize the distilled router to determine the token-to-expert assignment and freeze it for a stable routing strategy. We validate our method on language modeling and multilingual machine translation. The results show that StableMoE outperforms existing MoE methods in terms of both convergence speed and performance.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "StableMoE: 専門家の混合物の安定したルーティング戦略", "jabstract": "Mixture-of-Experts（MoE）技術は、手頃な計算オーバーヘッドでTransformersのモデルサイズを拡大できます。既存の学習ルートMoE方法は、ルーティングの変動問題、つまり、同じ入力のターゲットエキスパートがトレーニングに従って変化するが、推論中には入力に対して1つのエキスパートのみがアクティブになるため、問題があることを指摘します。ルーティングの変動は、同じ入力が異なるエキスパートを更新するが、最終的には1つしか使用されないため、サンプル効率に悪影響を与える傾向があります。本論文では、ルーティングの変動問題に対処するために、2つのトレーニングステージを持つStableMoEを提案します。最初のトレーニングステージでは、バランスの取れた結束したルーティング戦略を学習し、バックボーンモデルから切り離された軽量ルーターに蒸留します。2番目のトレーニングステージでは、蒸留されたルーターを利用してトークンからエキスパートへの割り当てを決定し、安定したルーティング戦略に凍結します。言語モデリングと多言語機械翻訳で私たちの方法を検証します。結果は、StableMoEが収束速度とパフォーマンスの両方の面で既存のMoE方法を上回ることを示しています。"}
{"title": "Boundary Smoothing for Named Entity Recognition", "url": "https://aclanthology.org/2022.acl-long.490/", "abstract": "Neural named entity recognition (NER) models may easily encounter the over-confidence issue, which degrades the performance and calibration. Inspired by label smoothing and driven by the ambiguity of boundary annotation in NER engineering, we propose boundary smoothing as a regularization technique for span-based neural NER models. It re-assigns entity probabilities from annotated spans to the surrounding ones. Built on a simple but strong baseline, our model achieves results better than or competitive with previous state-of-the-art systems on eight well-known NER benchmarks. Further empirical analysis suggests that boundary smoothing effectively mitigates over-confidence, improves model calibration, and brings flatter neural minima and more smoothed loss landscapes.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n固有表現認識のための境界スムージング", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nニューラルネットワークを用いた固有表現認識（NER）モデルは、過信の問題に直面することがあり、性能やキャリブレーションが低下する可能性があります。ラベルスムージングに着想を得て、NERエンジニアリングにおける境界注釈の曖昧さに駆られ、スパンベースのニューラルNERモデルの正則化技術として、バウンダリースムージングを提案します。これにより、注釈付きスパンから周囲のスパンにエンティティの確率を再割り当てします。シンプルで強力なベースラインに基づいて構築された当社のモデルは、8つのよく知られたNERベンチマークで、以前の最先端システムと同等またはそれ以上の結果を達成しています。さらなる実証分析により、バウンダリースムージングは過信を効果的に緩和し、モデルのキャリブレーションを改善し、より平らなニューラルミニマとよりスムーズな損失ランドスケープをもたらすことが効果的であることが示されています。"}
{"title": "Incorporating Hierarchy into Text Encoder: a Contrastive Learning Approach for Hierarchical Text Classification", "url": "https://aclanthology.org/2022.acl-long.491/", "abstract": "Hierarchical text classification is a challenging subtask of multi-label classification due to its complex label hierarchy. Existing methods encode text and label hierarchy separately and mix their representations for classification, where the hierarchy remains unchanged for all input text. Instead of modeling them separately, in this work, we propose Hierarchy-guided Contrastive Learning (HGCLR) to directly embed the hierarchy into a text encoder. During training, HGCLR constructs positive samples for input text under the guidance of the label hierarchy. By pulling together the input text and its positive sample, the text encoder can learn to generate the hierarchy-aware text representation independently. Therefore, after training, the HGCLR enhanced text encoder can dispense with the redundant hierarchy. Extensive experiments on three benchmark datasets verify the effectiveness of HGCLR.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストエンコーダーに階層を組み込む：階層的テキスト分類のための対比学習アプローチ", "jabstract": "階層的なテキスト分類は、複雑なラベル階層のため、マルチラベル分類の難しいサブタスクです。既存の方法では、テキストとラベル階層を別々にエンコードし、分類のためにそれらの表現を混合します。ここでは、階層をすべての入力テキストに対して変更せずに、それらを別々にモデル化する代わりに、Hierarchy-guided Contrastive Learning（HGCLR）を提案します。トレーニング中、HGCLRはラベル階層のガイダンスの下で入力テキストの正のサンプルを構築します。入力テキストとその正のサンプルを引き合わせることで、テキストエンコーダは階層に注意したテキスト表現を独立して生成することを学ぶことができます。したがって、トレーニング後、HGCLR強化されたテキストエンコーダは冗長な階層を省略できます。3つのベンチマークデータセットでの広範な実験により、HGCLRの効果が検証されました。"}
{"title": "Signal in Noise: Exploring Meaning Encoded in Random Character Sequences with Character-Aware Language Models", "url": "https://aclanthology.org/2022.acl-long.492/", "abstract": "Natural language processing models learn word representations based on the distributional hypothesis, which asserts that word context (e.g., co-occurrence) correlates with meaning. We propose that n-grams composed of random character sequences, or garble, provide a novel context for studying word meaning both within and beyond extant language. In particular, randomly generated character n-grams lack meaning but contain primitive information based on the distribution of characters they contain. By studying the embeddings of a large corpus of garble, extant language, and pseudowords using CharacterBERT, we identify an axis in the model’s high-dimensional embedding space that separates these classes of n-grams. Furthermore, we show that this axis relates to structure within extant language, including word part-of-speech, morphology, and concept concreteness. Thus, in contrast to studies that are mainly limited to extant language, our work reveals that meaning and primitive information are intrinsically linked.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ノイズの中のシグナル：文字認識言語モデルを用いたランダム文字列にエンコードされた意味の探索", "jabstract": "自然言語処理モデルは、単語の文脈（例：共起）が意味と相関するという分布仮説に基づいて単語表現を学習します。私たちは、ランダムな文字列のn-gram、またはgarbleから構成されるものが、既存の言語内外で単語の意味を研究するための新しい文脈を提供すると提案します。特に、ランダムに生成された文字n-gramには意味はありませんが、含まれる文字の分布に基づく原始的な情報が含まれています。CharacterBERTを使用して、garble、既存の言語、および疑似単語の大規模なコーパスの埋め込みを研究することにより、これらのn-gramのクラスを分離するモデルの高次元埋め込み空間の軸を特定します。さらに、この軸が、単語の品詞、形態論、および概念の具体性など、既存の言語内の構造に関連していることを示します。したがって、既存の言語に主に限定された研究とは対照的に、私たちの研究は、意味と原始的な情報が本質的に関連していることを明らかにします。"}
{"title": "Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering", "url": "https://aclanthology.org/2022.acl-long.493/", "abstract": "To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR). However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement. To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents. We demonstrate that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval. We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multi-hop, and out-of-domain scenarios. The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by more than 10 points in terms of top-20 retrieval accuracy under the zero-shot scenario. Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "オープンドメインの質問応答におけるパッセージ検索のためのハイパーリンク誘発プレトレーニング", "jabstract": "質問応答システムのトレーニングにおけるデータ不足問題を緩和するため、最近の研究では、密なパッセージ検索のための追加の中間プレトレーニングが提案されている。しかし、上流の信号と下流の質問-パッセージの関連性の間には依然として大きな乖離があり、改善が少なくなる。このギャップを埋めるために、我々はHyperLink-induced Pre-training (HLP)を提案する。これは、Webドキュメント内のハイパーリンクベースのトポロジーによって誘発されるテキストの関連性を用いて、密なリトリーバーをプレトレーニングする方法である。デュアルリンクと共起のハイパーリンクベースの構造が、ダウンストリームのパッセージ検索をより効果的に促進する大規模なプレトレーニングのための効果的な関連性信号を提供できることを示す。我々は、ゼロショット、フューショット、マルチホップ、およびアウトオブドメインのシナリオにおける広範なオープンドメインQAデータセットでのアプローチの効果を調査する。実験結果は、ゼロショットシナリオにおいて、HLPがBM25を最大7ポイント上回り、トップ20のリトリーバル精度に関して他のプレトレーニング方法を10ポイント以上上回ることを示している。さらに、HLPは他のシナリオでも他のプレトレーニング方法を大幅に上回る。"}
{"title": "AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension", "url": "https://aclanthology.org/2022.acl-long.494/", "abstract": "Recent machine reading comprehension datasets such as ReClor and LogiQA require performing logical reasoning over text. Conventional neural models are insufficient for logical reasoning, while symbolic reasoners cannot directly apply to text. To meet the challenge, we present a neural-symbolic approach which, to predict an answer, passes messages over a graph representing logical relations between text units. It incorporates an adaptive logic graph network (AdaLoGN) which adaptively infers logical relations to extend the graph and, essentially, realizes mutual and iterative reinforcement between neural and symbolic reasoning. We also implement a novel subgraph-to-node message passing mechanism to enhance context-option interaction for answering multiple-choice questions. Our approach shows promising results on ReClor and LogiQA.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "AdaLoGN：推論に基づく機械読解のための適応的論理グラフネットワーク", "jabstract": "最近の機械読解データセットであるReClorとLogiQAは、テキスト上で論理的推論を行う必要があります。従来のニューラルモデルは論理的推論に不十分であり、一方、記号的推論者は直接テキストに適用することができません。この課題に対応するため、我々はニューラル-記号的アプローチを提案します。このアプローチは、テキストユニット間の論理関係を表すグラフ上でメッセージを送信して回答を予測します。アダプティブ論理グラフネットワーク（AdaLoGN）を組み込み、グラフを拡張するために論理的関係を適応的に推論し、本質的にニューラルと記号的推論の相互および反復的な強化を実現します。また、複数選択問題に答えるために、新しいサブグラフからノードへのメッセージパッシングメカニズムを実装して、コンテキスト-オプションの相互作用を強化します。我々のアプローチは、ReClorとLogiQAで有望な結果を示しています。"}
{"title": "CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing", "url": "https://aclanthology.org/2022.acl-long.495/", "abstract": "Model ensemble is a popular approach to produce a low-variance and well-generalized model. However, it induces large memory and inference costs, which is often not affordable for real-world deployment. Existing work has resorted to sharing weights among models. However, when increasing the proportion of the shared weights, the resulting models tend to be similar, and the benefits of using model ensemble diminish. To retain ensemble benefits while maintaining a low memory cost, we propose a consistency-regularized ensemble learning approach based on perturbed models, named CAMERO. Specifically, we share the weights of bottom layers across all models and apply different perturbations to the hidden representations for different models, which can effectively promote the model diversity. Meanwhile, we apply a prediction consistency regularizer across the perturbed models to control the variance due to the model diversity. Our experiments using large language models demonstrate that CAMERO significantly improves the generalization performance of the ensemble model. Specifically, CAMERO outperforms the standard ensemble of 8 BERT-base models on the GLUE benchmark by 0.7 with a significantly smaller model size (114.2M vs. 880.6M).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CAMERO：重み共有を伴う摂動言語モデルの一貫性正則化アンサンブル", "jabstract": "モデルアンサンブルは、低分散かつよく一般化されたモデルを生成するための人気のある手法です。しかし、それは大きなメモリと推論コストを引き起こし、現実世界での展開にはしばしば手が届かないことがあります。既存の研究は、モデル間で重みを共有することに頼っています。しかし、共有される重みの割合を増やすと、生成されるモデルは類似しており、モデルアンサンブルの利点が減少する傾向があります。低メモリコストを維持しながらアンサンブルの利点を保持するために、私たちは摂動モデルに基づく一貫性正則化アンサンブル学習アプローチを提案します。具体的には、すべてのモデルで下層の重みを共有し、異なるモデルに対して異なる摂動を隠れた表現に適用することで、モデルの多様性を効果的に促進します。同時に、摂動モデル間で予測の一貫性正則化を適用して、モデル多様性による分散を制御します。大規模言語モデルを使用した実験により、CAMEROがアンサンブルモデルの一般化性能を大幅に改善することが示されました。具体的には、CAMEROは、標準的な8つのBERT-baseモデルのアンサンブルに比べて、モデルサイズが大幅に小さい（114.2M vs. 880.6M）GLUEベンチマークで0.7を上回ります。"}
{"title": "Interpretability for Language Learners Using Example-Based Grammatical Error Correction", "url": "https://aclanthology.org/2022.acl-long.496/", "abstract": "Grammatical Error Correction (GEC) should not focus only on high accuracy of corrections but also on interpretability for language learning.However, existing neural-based GEC models mainly aim at improving accuracy, and their interpretability has not been explored.A promising approach for improving interpretability is an example-based method, which uses similar retrieved examples to generate corrections. In addition, examples are beneficial in language learning, helping learners understand the basis of grammatically incorrect/correct texts and improve their confidence in writing.Therefore, we hypothesize that incorporating an example-based method into GEC can improve interpretability as well as support language learners.In this study, we introduce an Example-Based GEC (EB-GEC) that presents examples to language learners as a basis for a correction result.The examples consist of pairs of correct and incorrect sentences similar to a given input and its predicted correction.Experiments demonstrate that the examples presented by EB-GEC help language learners decide to accept or refuse suggestions from the GEC output.Furthermore, the experiments also show that retrieved examples improve the accuracy of corrections.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "例ベースの文法エラー訂正を用いた言語学習者の解釈可能性", "jabstract": "文法エラー訂正（GEC）は、言語学習のための解釈可能性にも焦点を当てる必要がある。しかし、既存のニューラルベースのGECモデルは主に精度の向上を目的としており、解釈可能性は未だに探求されていない。解釈可能性を向上させる有望なアプローチは、類似の検索例を使用して訂正を生成する例ベースの方法である。また、例は言語学習において有益であり、文法的に正しくない/正しいテキストの基礎を理解し、自信を持って文章を書くことができるように支援する。したがって、我々は、例ベースの方法をGECに組み込むことで、解釈可能性を向上させると同時に言語学習者を支援できると仮説を立てた。本研究では、言語学習者に訂正結果の基礎となる例を提示するExample-Based GEC（EB-GEC）を紹介する。例は、与えられた入力と予測された訂正に類似した正しい文と誤った文のペアで構成される。実験は、EB-GECによって提示された例が、言語学習者がGECの出力から提案を受け入れるか拒否するかを決定するのに役立つことを示している。さらに、実験は、検索された例が訂正の精度を向上させることも示している。"}
{"title": "Rethinking Negative Sampling for Handling Missing Entity Annotations", "url": "https://aclanthology.org/2022.acl-long.497/", "abstract": "Negative sampling is highly effective in handling missing annotations for named entity recognition (NER). One of our contributions is an analysis on how it makes sense through introducing two insightful concepts: missampling and uncertainty. Empirical studies show low missampling rate and high uncertainty are both essential for achieving promising performances with negative sampling. Based on the sparsity of named entities, we also theoretically derive a lower bound for the probability of zero missampling rate, which is only relevant to sentence length. The other contribution is an adaptive and weighted sampling distribution that further improves negative sampling via our former analysis. Experiments on synthetic datasets and well-annotated datasets (e.g., CoNLL-2003) show that our proposed approach benefits negative sampling in terms of F1 score and loss convergence. Besides, models with improved negative sampling have achieved new state-of-the-art results on real-world datasets (e.g., EC).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n欠落したエンティティ注釈を処理するためのネガティブサンプリングの再考", "jabstract": "ネームドエンティティ認識（NER）の欠損注釈を処理するために、ネガティブサンプリングは非常に効果的である。私たちの貢献の1つは、ミスサンプリングと不確実性という2つの洞察的な概念を導入することによって、どのように意味を成すかについての分析である。実証研究により、低いミスサンプリング率と高い不確実性の両方が、ネガティブサンプリングで有望なパフォーマンスを達成するために不可欠であることが示されている。また、ネームドエンティティの疎らさに基づいて、ミスサンプリング率がゼロである確率の下限を理論的に導出し、これは文の長さにのみ関連する。もう1つの貢献は、以前の分析を通じてネガティブサンプリングをさらに改善する適応的で重み付けされたサンプリング分布である。合成データセットやよく注釈されたデータセット（例：CoNLL-2003）での実験により、提案されたアプローチがF1スコアと損失収束の観点でネガティブサンプリングを改善することが示されている。さらに、改善されたネガティブサンプリングを備えたモデルは、実世界のデータセット（例：EC）で新しい最高の結果を達成している。"}
{"title": "Distantly Supervised Named Entity Recognition via Confidence-Based Multi-Class Positive and Unlabeled Learning", "url": "https://aclanthology.org/2022.acl-long.498/", "abstract": "In this paper, we study the named entity recognition (NER) problem under distant supervision. Due to the incompleteness of the external dictionaries and/or knowledge bases, such distantly annotated training data usually suffer from a high false negative rate. To this end, we formulate the Distantly Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU) learning and propose a theoretically and practically novel CONFidence-based MPU (Conf-MPU) approach. To handle the incomplete annotations, Conf-MPU consists of two steps. First, a confidence score is estimated for each token of being an entity token. Then, the proposed Conf-MPU risk estimation is applied to train a multi-class classifier for the NER task. Thorough experiments on two benchmark datasets labeled by various external knowledge demonstrate the superiority of the proposed Conf-MPU over existing DS-NER methods. Our code is available at Github.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「信頼度に基づく多クラス陽性・未ラベル学習を用いた遠隔監視された固有表現認識」に関する論文の要約文です。", "jabstract": "本論文では、遠隔監視下での固有表現認識（NER）問題を研究します。外部辞書や知識ベースの不完全性により、このような遠隔監視下で注釈付けされたトレーニングデータは、通常、高い偽陰性率に苦しんでいます。このため、Multi-class Positive and Unlabeled（MPU）学習を介してDistantly Supervised NER（DS-NER）問題を定式化し、理論的にも実用的にも新しいCONFidence-based MPU（Conf-MPU）アプローチを提案します。不完全な注釈を処理するために、Conf-MPUは2つのステップで構成されています。まず、各トークンがエンティティトークンである可能性の信頼スコアが推定されます。次に、提案されたConf-MPUリスク推定を使用して、NERタスクのマルチクラス分類器をトレーニングします。さまざまな外部知識によってラベル付けされた2つのベンチマークデータセットでの徹底的な実験により、提案されたConf-MPUが既存のDS-NER方法よりも優れていることが示されました。私たちのコードはGithubで利用可能です。"}
{"title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation", "url": "https://aclanthology.org/2022.acl-long.499/", "abstract": "Pre-trained models for programming languages have recently demonstrated great success on code intelligence. To support both code-related understanding and generation tasks, recent works attempt to pre-train unified encoder-decoder models. However, such encoder-decoder framework is sub-optimal for auto-regressive tasks, especially code completion that requires a decoder-only manner for efficient inference. In this paper, we present UniXcoder, a unified cross-modal pre-trained model for programming language. The model utilizes mask attention matrices with prefix adapters to control the behavior of the model and leverages cross-modal contents like AST and code comment to enhance code representation. To encode AST that is represented as a tree in parallel, we propose a one-to-one mapping method to transform AST in a sequence structure that retains all structural information from the tree. Furthermore, we propose to utilize multi-modal contents to learn representation of code fragment with contrastive learning, and then align representations among programming languages using a cross-modal generation task. We evaluate UniXcoder on five code-related tasks over nine datasets. To further evaluate the performance of code fragment representation, we also construct a dataset for a new task, called zero-shot code-to-code search. Results show that our model achieves state-of-the-art performance on most tasks and analysis reveals that comment and AST can both enhance UniXcoder.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "UniXcoder：コード表現のための統一されたクロスモーダル事前学習", "jabstract": "プログラミング言語の事前学習済みモデルは、コードインテリジェンスにおいて最近大きな成功を収めている。コード関連の理解と生成の両方をサポートするために、最近の研究では、統合エンコーダ・デコーダモデルを事前学習する試みが行われている。しかし、このようなエンコーダ・デコーダフレームワークは、特にデコーダのみを使用して効率的な推論を行うコード補完などの自己回帰タスクにおいては、サブオプティマルである。本論文では、プログラミング言語のための統合クロスモーダル事前学習モデルであるUniXcoderを提案する。モデルは、マスクアテンション行列とプレフィックスアダプタを使用してモデルの動作を制御し、ASTやコードコメントなどのクロスモーダルコンテンツを活用してコード表現を強化する。木構造で表現されるASTを並列にエンコードするために、ASTを木からすべての構造情報を保持するシーケンス構造に変換する1対1のマッピング方法を提案する。さらに、コントラスティブ学習を用いてコードフラグメントの表現を学習し、クロスモーダル生成タスクを使用してプログラミング言語間の表現を整列させることを提案する。UniXcoderを9つのデータセット上の5つのコード関連タスクで評価する。さらに、コードフラグメントの表現の性能を評価するために、ゼロショットコード検索という新しいタスクのためのデータセットを構築する。結果は、ほとんどのタスクで最先端の性能を発揮し、コメントとASTの両方がUniXcoderを強化することが分かった。"}
{"title": "One Country, 700+ Languages: NLP Challenges for Underrepresented Languages and Dialects in Indonesia", "url": "https://aclanthology.org/2022.acl-long.500/", "abstract": "NLP research is impeded by a lack of resources and awareness of the challenges presented by underrepresented languages and dialects. Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia’s 700+ languages. We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems. Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia but also other underrepresented languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "1. インドネシア：700以上の言語を持つ国におけるNLPの課題\n2. インドネシアの未代表言語や方言に対するNLPの課題", "jabstract": "自然言語処理の研究は、資源の不足と、代表的でない言語や方言が抱える課題に対する認識の欠如によって妨げられています。インドネシアで話されている言語に焦点を当て、世界で2番目に言語が多様で、4番目に人口の多い国であるインドネシアの700以上の言語に対する現在の自然言語処理の状況を概観します。インドネシアの自然言語処理における課題と、これらが現在の自然言語処理システムの性能にどのように影響するかを強調します。最後に、インドネシアの言語だけでなく、他の代表的でない言語の自然言語処理技術の開発を支援するための一般的な推奨事項を提供します。"}
{"title": "Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text", "url": "https://aclanthology.org/2022.acl-long.501/", "abstract": "Modern neural language models can produce remarkably fluent and grammatical text. So much, in fact, that recent work by Clark et al. (2021) has reported that conventional crowdsourcing can no longer reliably distinguish between machine-authored (GPT-3) and human-authored writing. As errors in machine generations become ever subtler and harder to spot, it poses a new challenge to the research community for robust machine text evaluation.We propose a new framework called Scarecrow for scrutinizing machine text via crowd annotation. To support the broad range of real machine errors that can be identified by laypeople, the ten error categories of Scarecrow—such as redundancy, commonsense errors, and incoherence—are identified through several rounds of crowd annotation experiments without a predefined ontology.We then use Scarecrow to collect over 41k error spans in human-written and machine-generated paragraphs of English language news text. We isolate factors for detailed analysis, including parameter count, training data, and various decoding-time configurations. Our approach successfully quantifies measurable gaps between human authored text and generations from models of several sizes, including fourteen configurations of GPT-3. In addition, our analysis unveils new insights, with detailed rationales provided by laypeople, e.g., that the commonsense capabilities have been improving with larger models while math capabilities have not, and that the choices of simple decoding hyperparameters can make remarkable differences on the perceived quality of machine text. We release our training material, annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "GPT-3のテキストは人間のテキストと区別できないのか？Scarecrow：機械テキストを検証するためのフレームワーク", "jabstract": "現代のニューラル言語モデルは、驚くほど流暢で文法的に優れたテキストを生成することができます。実際、Clarkらの最近の研究（2021）によると、従来のクラウドソーシングでは、機械生成（GPT-3）と人間による執筆を信頼性をもって区別することができなくなっています。機械生成のエラーがますます微妙で見つけにくくなるにつれ、堅牢な機械テキスト評価のための新たな課題が研究コミュニティに課せられています。本論文では、クラウドアノテーションを用いた機械テキストの厳密な検証のための新しいフレームワーク「Scarecrow」を提案します。Scarecrowは、事前定義されたオントロジーなしに、冗長性、常識的なエラー、不一致などの10のエラーカテゴリを、複数のラウンドのクラウドアノテーション実験によって特定することで、一般の人々によって特定できる幅広い実際の機械エラーをサポートします。その後、Scarecrowを使用して、英語のニューステキストの人間による執筆と機械生成の段落から、41,000以上のエラースパンを収集します。パラメータ数、トレーニングデータ、およびさまざまなデコード時間の構成など、詳細な分析のための要因を分離します。私たちのアプローチは、GPT-3の14の構成を含む複数のサイズのモデルの生成物と人間による執筆テキストの間の測定可能なギャップを成功裏に定量化します。さらに、私たちの分析は、大きなモデルでは常識的な能力が向上している一方で、数学的な能力は向上していないこと、そして単純なデコードハイパーパラメータの選択が機械テキストの知覚される品質に著しい違いをもたらすことなど、新しい洞察を明らかにします。私たちは、https://yao-dou.github.io/scarecrow/で私たちのトレーニング資料、アノテーションツールキット、およびデータセットを公開しています。"}
{"title": "Transkimmer: Transformer Learns to Layer-wise Skim", "url": "https://aclanthology.org/2022.acl-long.502/", "abstract": "Transformer architecture has become the de-facto model for many machine learning tasks from natural language processing and computer vision. As such, improving its computational efficiency becomes paramount. One of the major computational inefficiency of Transformer based models is that they spend the identical amount of computation throughout all layers. Prior works have proposed to augment the Transformer model with the capability of skimming tokens to improve its computational efficiency. However, they suffer from not having effectual and end-to-end optimization of the discrete skimming predictor. To address the above limitations, we propose the Transkimmer architecture, which learns to identify hidden state tokens that are not required by each layer. The skimmed tokens are then forwarded directly to the final output, thus reducing the computation of the successive layers. The key idea in Transkimmer is to add a parameterized predictor before each layer that learns to make the skimming decision. We also propose to adopt reparameterization trick and add skim loss for the end-to-end training of Transkimmer. Transkimmer achieves 10.97x average speedup on GLUE benchmark compared with vanilla BERT-base baseline with less than 1% accuracy degradation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nTranskimmer：トランスフォーマーが層ごとにスキムを学習する", "jabstract": "トランスフォーマーアーキテクチャは、自然言語処理やコンピュータビジョンなどの多くの機械学習タスクにおいて、デファクトモデルとなっています。そのため、その計算効率の改善は極めて重要です。トランスフォーマーベースのモデルの主要な計算効率の問題の1つは、すべてのレイヤーで同じ量の計算を行うことです。これに対処するために、トークンをスキミングする機能をトランスフォーマーモデルに追加することが提案されてきました。しかし、これらは離散的なスキミング予測子の効果的でエンドツーエンドの最適化を持たないため、問題があります。これらの制限に対処するために、私たちはTranskimmerアーキテクチャを提案します。これは、各レイヤーで必要ない隠れ状態トークンを特定することを学習するものです。スキミングされたトークンは、直接最終出力に転送され、その後続レイヤーの計算を減らします。Transkimmerのキーとなるアイデアは、スキミング決定を行うためのパラメータ化された予測子を各レイヤーの前に追加することです。また、再パラメータ化トリックを採用し、Transkimmerのエンドツーエンドトレーニングのためにスキミング損失を追加することを提案します。Transkimmerは、1％未満の精度低下で、GLUEベンチマークにおいて、バニラBERT-baseベースラインに比べて10.97倍の平均高速化を実現します。"}
{"title": "SkipBERT: Efficient Inference with Shallow Layer Skipping", "url": "https://aclanthology.org/2022.acl-long.503/", "abstract": "In this paper, we propose SkipBERT to accelerate BERT inference by skipping the computation of shallow layers. To achieve this, our approach encodes small text chunks into independent representations, which are then materialized to approximate the shallow representation of BERT. Since the use of such approximation is inexpensive compared with transformer calculations, we leverage it to replace the shallow layers of BERT to skip their runtime overhead. With off-the-shelf early exit mechanisms, we also skip redundant computation from the highest few layers to further improve inference efficiency. Results on GLUE show that our approach can reduce latency by 65% without sacrificing performance. By using only two-layer transformer calculations, we can still maintain 95% accuracy of BERT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SkipBERT：浅いレイヤースキップによる効率的な推論", "jabstract": "本論文では、浅いレイヤーの計算をスキップすることでBERTの推論を加速するSkipBERTを提案する。このために、我々のアプローチは小さなテキストチャンクを独立した表現にエンコードし、それらを実現してBERTの浅い表現を近似する。このような近似の使用はトランスフォーマーの計算に比べて安価であるため、BERTの浅いレイヤーを置き換えてランタイムオーバーヘッドをスキップするためにそれを活用する。また、早期終了メカニズムを使用して、最上位の数層から冗長な計算をスキップして推論効率をさらに改善する。GLUEの結果から、我々のアプローチは性能を犠牲にすることなくレイテンシを65％削減できることが示された。2層のトランスフォーマー計算のみを使用しても、BERTの95％の精度を維持できる。"}
{"title": "Pretraining with Artificial Language: Studying Transferable Knowledge in Language Models", "url": "https://aclanthology.org/2022.acl-long.504/", "abstract": "We investigate what kind of structural knowledge learned in neural network encoders is transferable to processing natural language.We design artificial languages with structural properties that mimic natural language, pretrain encoders on the data, and see how much performance the encoder exhibits on downstream tasks in natural language.Our experimental results show that pretraining with an artificial language with a nesting dependency structure provides some knowledge transferable to natural language.A follow-up probing analysis indicates that its success in the transfer is related to the amount of encoded contextual information and what is transferred is the knowledge of position-aware context dependence of language.Our results provide insights into how neural network encoders process human languages and the source of cross-lingual transferability of recent multilingual language models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "人工言語による事前学習：言語モデルにおける転移可能な知識の研究", "jabstract": "私たちは、ニューラルネットワークエンコーダーで学習されたどのような構造的知識が自然言語処理に転移可能かを調査しました。私たちは、自然言語を模倣する構造的特性を持つ人工言語を設計し、そのデータでエンコーダーを事前学習し、エンコーダーが自然言語の下流タスクでどの程度の性能を発揮するかを調べました。実験結果は、入れ子の依存構造を持つ人工言語での事前学習が、自然言語に転移可能な知識を提供することを示しています。追加のプロービング分析により、転移の成功はエンコードされた文脈情報の量に関連しており、転移されるのは言語の位置に応じた文脈依存性の知識です。私たちの結果は、ニューラルネットワークエンコーダーが人間の言語をどのように処理するか、そして最近の多言語言語モデルの言語間転移可能性の源についての洞察を提供します。"}
{"title": "mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models", "url": "https://aclanthology.org/2022.acl-long.505/", "abstract": "Recent studies have shown that multilingual pretrained language models can be effectively improved with cross-lingual alignment information from Wikipedia entities.However, existing methods only exploit entity information in pretraining and do not explicitly use entities in downstream tasks.In this study, we explore the effectiveness of leveraging entity representations for downstream cross-lingual tasks.We train a multilingual language model with 24 languages with entity representations and showthe model consistently outperforms word-based pretrained models in various cross-lingual transfer tasks.We also analyze the model and the key insight is that incorporating entity representations into the input allows us to extract more language-agnostic features.We also evaluate the model with a multilingual cloze prompt task with the mLAMA dataset.We show that entity-based prompt elicits correct factual knowledge more likely than using only word representations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "mLUKE：多言語事前学習言語モデルにおけるエンティティ表現の力", "jabstract": "最近の研究により、多言語事前学習言語モデルは、Wikipediaエンティティからのクロスリンガルアラインメント情報を効果的に活用することができることが示されています。しかし、既存の方法は、事前学習時にエンティティ情報のみを利用し、ダウンストリームタスクでは明示的にエンティティを使用していません。本研究では、エンティティ表現を活用したダウンストリームクロスリンガルタスクの効果を探究しました。24言語の多言語言語モデルをエンティティ表現でトレーニングし、モデルが様々なクロスリンガル転移タスクで単語ベースの事前学習モデルよりも一貫して優れた性能を発揮することを示しました。また、モデルを分析し、エンティティ表現を入力に組み込むことで、より言語に依存しない特徴を抽出できることが重要な洞察であることを示しました。さらに、mLAMAデータセットを用いた多言語クローズプロンプトタスクでモデルを評価しました。エンティティベースのプロンプトを使用することで、単語表現のみを使用するよりも正確な事実知識を引き出すことができることを示しました。"}
{"title": "Evaluating Factuality in Text Simplification", "url": "https://aclanthology.org/2022.acl-long.506/", "abstract": "Automated simplification models aim to make input texts more readable. Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader. However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information. Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all. The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated. We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs. We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要旨を以下に示します。日本語に翻訳してください。\n\nテキスト簡素化における事実性の評価", "jabstract": "自動簡素化モデルは、入力テキストをより読みやすくすることを目的としています。このような方法は、複雑な情報を広い層にアクセス可能にする可能性があります。例えば、一般読者には理解不能な最新の医学文献にアクセスできるようにすることができます。しかし、このようなモデルは、自動的に簡素化されたテキストに、対応する元のテキストに支持されていない文を挿入することや、重要な情報を省略することによって、誤りを導入するリスクがあります。読みやすくなったが不正確なテキストを提供することは、多くの場合、全くアクセスを提供しないよりも悪い場合があります。事実の正確性（または不正確性）の問題は、要約モデルの文脈で高い関心を集めていますが、自動的に簡素化されたテキストの事実性は調査されていません。我々は、既存の簡素化データセットから引用されたものと最新のモデルの出力の両方を分析するために使用するエラーの分類法を紹介します。我々は、既存の評価メトリックに捉えられていないエラーが両方に頻繁に現れることを発見し、自動簡素化モデルの事実性を保証するための研究の必要性を促しています。"}
{"title": "Requirements and Motivations of Low-Resource Speech Synthesis for Language Revitalization", "url": "https://aclanthology.org/2022.acl-long.507/", "abstract": "This paper describes the motivation and development of speech synthesis systems for the purposes of language revitalization. By building speech synthesis systems for three Indigenous languages spoken in Canada, Kanien’kéha, Gitksan & SENĆOŦEN, we re-evaluate the question of how much data is required to build low-resource speech synthesis systems featuring state-of-the-art neural models. For example, preliminary results with English data show that a FastSpeech2 model trained with 1 hour of training data can produce speech with comparable naturalness to a Tacotron2 model trained with 10 hours of data. Finally, we motivate future research in evaluation and classroom integration in the field of speech synthesis for language revitalization.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "言語復興のための低資源音声合成の要件と動機", "jabstract": "本論文は、言語復興のための音声合成システムの動機と開発について説明しています。カナダで話される3つの先住民族言語、カニエンケハ語、ギトクサン語、センチョーテン語の音声合成システムを構築することで、最新のニューラルモデルを搭載した低リソース音声合成システムを構築するために必要なデータ量について再評価します。例えば、英語のデータを用いた予備的な結果では、1時間のトレーニングデータでトレーニングされたFastSpeech2モデルは、10時間のデータでトレーニングされたTacotron2モデルと同等の自然さを持つ音声を生成できることが示されました。最後に、言語復興のための音声合成の分野における評価と教室での統合に向けた将来の研究を動機付けます。"}
{"title": "Sharpness-Aware Minimization Improves Language Model Generalization", "url": "https://aclanthology.org/2022.acl-long.508/", "abstract": "The allure of superhuman-level capabilities has led to considerable interest in language models like GPT-3 and T5, wherein the research has, by and large, revolved around new model architectures, training tasks, and loss objectives, along with substantial engineering efforts to scale up model capacity and dataset size. Comparatively little work has been done to improve the generalization of these models through better optimization. In this work, we show that Sharpness-Aware Minimization (SAM), a recently proposed optimization procedure that encourages convergence to flatter minima, can substantially improve the generalization of language models without much computational overhead. We show that SAM is able to boost performance on SuperGLUE, GLUE, Web Questions, Natural Questions, Trivia QA, and TyDiQA, with particularly large gains when training data for these tasks is limited.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "シャープネスに敏感な最小化は、言語モデルの汎化性能を向上させます。", "jabstract": "超人的な能力に魅了されたことから、GPT-3やT5のような言語モデルに対する関心が高まっており、研究は主に新しいモデルアーキテクチャ、トレーニングタスク、損失目的、モデル容量およびデータセットサイズの拡大に向けた大規模なエンジニアリング努力に焦点を当ててきた。これに比べ、これらのモデルの汎化性能を改善するための研究はほとんど行われていない。本研究では、収束をより平坦な最小値に促す最近提案された最適化手法であるSharpness-Aware Minimization（SAM）が、計算オーバーヘッドをほとんど増やすことなく、言語モデルの汎化性能を大幅に改善できることを示す。SuperGLUE、GLUE、Web Questions、Natural Questions、Trivia QA、TyDiQAのパフォーマンスを向上させることができ、特にこれらのタスクのトレーニングデータが限られている場合に大きな利益をもたらすことを示す。"}
{"title": "Adversarial Authorship Attribution for Deobfuscation", "url": "https://aclanthology.org/2022.acl-long.509/", "abstract": "Recent advances in natural language processing have enabled powerful privacy-invasive authorship attribution. To counter authorship attribution, researchers have proposed a variety of rule-based and learning-based text obfuscation approaches. However, existing authorship obfuscation approaches do not consider the adversarial threat model. Specifically, they are not evaluated against adversarially trained authorship attributors that are aware of potential obfuscation. To fill this gap, we investigate the problem of adversarial authorship attribution for deobfuscation. We show that adversarially trained authorship attributors are able to degrade the effectiveness of existing obfuscators from 20-30% to 5-10%. We also evaluate the effectiveness of adversarial training when the attributor makes incorrect assumptions about whether and which obfuscator was used. While there is a a clear degradation in attribution accuracy, it is noteworthy that this degradation is still at or above the attribution accuracy of the attributor that is not adversarially trained at all. Our results motivate the need to develop authorship obfuscation approaches that are resistant to deobfuscation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nDeobfuscationのための敵対的な著者特定", "jabstract": "自然言語処理の最近の進歩により、強力なプライバシー侵害の著者特定が可能になりました。著者特定に対抗するため、研究者は様々なルールベースと学習ベースのテキスト曖昧化アプローチを提案しています。しかし、既存の著者曖昧化アプローチは敵対的脅威モデルを考慮していません。具体的には、潜在的な曖昧化を認識している敵対的にトレーニングされた著者特定者に対して評価されていません。このギャップを埋めるために、我々は敵対的著者特定のための曖昧化解除の問題を調査します。我々は、敵対的にトレーニングされた著者特定者が、既存の曖昧化器の効果を20-30％から5-10％に低下させることができることを示します。また、特定者が使用された曖昧化器について正しい仮定をしているかどうかを評価した場合の敵対的トレーニングの効果も評価します。正確性には明らかな低下がありますが、この低下はまだ全く敵対的にトレーニングされていない特定者の特定精度以上であることに注意すべきです。我々の結果は、曖昧化解除に耐性のある著者曖昧化アプローチを開発する必要性を促します。"}
{"title": "Weakly Supervised Word Segmentation for Computational Language Documentation", "url": "https://aclanthology.org/2022.acl-long.510/", "abstract": "Word and morpheme segmentation are fundamental steps of language documentation as they allow to discover lexical units in a language for which the lexicon is unknown. However, in most language documentation scenarios, linguists do not start from a blank page: they may already have a pre-existing dictionary or have initiated manual segmentation of a small part of their data. This paper studies how such a weak supervision can be taken advantage of in Bayesian non-parametric models of segmentation. Our experiments on two very low resource languages (Mboshi and Japhug), whose documentation is still in progress, show that weak supervision can be beneficial to the segmentation quality. In addition, we investigate an incremental learning scenario where manual segmentations are provided in a sequential manner. This work opens the way for interactive annotation tools for documentary linguists.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "計算言語学の文書化のための弱監督単語分割", "jabstract": "単語と形態素の分割は、語彙が不明な言語において、言語文書化の基本的なステップであり、言語内の語彙単位を発見することができます。しかし、ほとんどの言語文書化のシナリオでは、言語学者は白紙の状態から始めるわけではありません。彼らはすでに既存の辞書を持っているか、またはデータの一部を手動で分割を開始している場合があります。本論文では、ベイズ非パラメトリックモデルの分割において、このような弱い監視がどのように活用できるかを研究しています。私たちの実験は、まだ進行中の非常に低資源言語（MboshiとJaphug）において、弱い監視が分割の品質に有益であることを示しています。さらに、手動分割が順次提供されるインクリメンタル学習シナリオについても調査しています。この研究は、文書化言語学者のためのインタラクティブ注釈ツールの可能性を開くものです。"}
{"title": "SciNLI: A Corpus for Natural Language Inference on Scientific Text", "url": "https://aclanthology.org/2022.acl-long.511/", "abstract": "Existing Natural Language Inference (NLI) datasets, while being instrumental in the advancement of Natural Language Understanding (NLU) research, are not related to scientific text. In this paper, we introduce SciNLI, a large dataset for NLI that captures the formality in scientific text and contains 107,412 sentence pairs extracted from scholarly papers on NLP and computational linguistics. Given that the text used in scientific literature differs vastly from the text used in everyday language both in terms of vocabulary and sentence structure, our dataset is well suited to serve as a benchmark for the evaluation of scientific NLU models. Our experiments show that SciNLI is harder to classify than the existing NLI datasets. Our best performing model with XLNet achieves a Macro F1 score of only 78.18% and an accuracy of 78.23% showing that there is substantial room for improvement.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SciNLI: 科学的テキストにおける自然言語推論のためのコーパス", "jabstract": "既存の自然言語推論（NLI）データセットは、自然言語理解（NLU）研究の進歩に重要な役割を果たしている一方、科学的なテキストに関連していません。本論文では、NLPと計算言語学に関する学術論文から抽出された107,412の文のペアを含む、科学的なテキストの形式を捉えた大規模なNLIデータセットであるSciNLIを紹介します。科学文献で使用されるテキストは、語彙や文構造の面で日常語で使用されるテキストと大きく異なるため、当社のデータセットは科学的NLUモデルの評価のためのベンチマークとして適しています。私たちの実験は、SciNLIが既存のNLIデータセットよりも分類が難しいことを示しています。XLNetを使用した最高のパフォーマンスを発揮するモデルは、マクロF1スコアがわずか78.18％、精度が78.23％であり、改善の余地が十分にあることを示しています。"}
{"title": "Neural reality of argument structure constructions", "url": "https://aclanthology.org/2022.acl-long.512/", "abstract": "In lexicalist linguistic theories, argument structure is assumed to be predictable from the meaning of verbs. As a result, the verb is the primary determinant of the meaning of a clause. In contrast, construction grammarians propose that argument structure is encoded in constructions (or form-meaning pairs) that are distinct from verbs. Two decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view. Here we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformer-based language models (LMs). First, using a sentence sorting experiment, we find that sentences sharing the same construction are closer in embedding space than sentences sharing the same verb. Furthermore, LMs increasingly prefer grouping by construction with more input data, mirroring the behavior of non-native language learners. Second, in a “Jabberwocky” priming-based experiment, we find that LMs associate ASCs with meaning, even in semantically nonsensical sentences. Our work offers the first evidence for ASCs in LMs and highlights the potential to devise novel probing methods grounded in psycholinguistic research.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「論証構造構築の神経的現実性」に関する論文の要約文です。\n\n1. This paper investigates the neural reality of argument structure constructions in natural language processing.\n→ この論文は、自然言語処理における論証構造構築の神経的現実性を調査しています。\n\n2. The study uses fMRI data to examine the neural activation patterns associated with argument structure constructions.\n→ この研究では、fMRIデータを使用して、論証構造構築に関連する神経活性化パターンを調べています。\n\n3. The results suggest that argument structure constructions are processed in a distributed network of brain regions.\n→ 結果から、論証構造構築は、脳の分散ネットワークで処理されることが示唆されています。", "jabstract": "レキシカリスト言語学理論では、動詞の意味から引数構造が予測されると仮定されています。その結果、動詞は節の意味の主要な決定要因となります。一方、構文学者は、引数構造が動詞とは異なる構成物（または形式-意味ペア）にエンコードされると提唱しています。20年にわたる心理言語学的研究により、構成物の視点が支持される実証的な証拠が蓄積されています。本稿では、心理言語学的研究を適応して、Transformerベースの言語モデル（LM）に引数構造構成物（ASC）が存在するかどうかを調べます。まず、文のソート実験を使用して、同じ構成物を共有する文は同じ動詞を共有する文よりも埋め込み空間で近くなることを発見します。さらに、LMは、より多くの入力データによって構成物によるグループ化を好むようになり、非母語話者の行動を反映します。第二に、「ジャバウォッキー」プライミングベースの実験では、LMが、意味的に意味のない文でもASCを意味に関連付けることがわかりました。本研究は、LMにおけるASCの最初の証拠を提供し、心理言語学的研究に基づく新しいプロービング方法の可能性を示しています。"}
{"title": "On the Robustness of Offensive Language Classifiers", "url": "https://aclanthology.org/2022.acl-long.513/", "abstract": "Social media platforms are deploying machine learning based offensive language classification systems to combat hateful, racist, and other forms of offensive speech at scale. However, despite their real-world deployment, we do not yet comprehensively understand the extent to which offensive language classifiers are robust against adversarial attacks. Prior work in this space is limited to studying robustness of offensive language classifiers against primitive attacks such as misspellings and extraneous spaces. To address this gap, we systematically analyze the robustness of state-of-the-art offensive language classifiers against more crafty adversarial attacks that leverage greedy- and attention-based word selection and context-aware embeddings for word replacement. Our results on multiple datasets show that these crafty adversarial attacks can degrade the accuracy of offensive language classifiers by more than 50% while also being able to preserve the readability and meaning of the modified text.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nOffensive Language Classifiersの堅牢性について", "jabstract": "ソーシャルメディアプラットフォームは、機械学習に基づく攻撃的な言語分類システムを展開し、悪意のある、人種差別的な、その他の攻撃的なスピーチに対処しています。しかし、実際に展開されているにもかかわらず、攻撃的な言語分類器が敵対的攻撃に対してどの程度堅牢であるかはまだ包括的に理解されていません。この領域の先行研究は、つづりの誤りや余分なスペースなどの原始的な攻撃に対する攻撃的な言語分類器の堅牢性を研究することに限定されています。このギャップに対処するために、我々は、貪欲な単語選択や文脈に敏感な埋め込みを利用した巧妙な敵対的攻撃に対する最先端の攻撃的な言語分類器の堅牢性を系統的に分析します。複数のデータセットにおける結果は、これらの巧妙な敵対的攻撃が、修正されたテキストの可読性と意味を保持しながら、攻撃的な言語分類器の精度を50％以上低下させることができることを示しています。"}
{"title": "Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings", "url": "https://aclanthology.org/2022.acl-long.514/", "abstract": "Style transfer is the task of rewriting a sentence into a target style while approximately preserving content. While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al. 2021) has attempted “few-shot” style transfer using only 3-10 sentences at inference for style extraction. In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim. We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages. Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob. We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model. Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages. To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "低リソース多言語環境におけるフューショット制御可能なスタイル転送", "jabstract": "スタイル転送は、コンテンツをほぼ保持しながら、文を目標のスタイルに書き換えるタスクです。以前の文献のほとんどは、大規模なスタイルラベル付きコーパスにアクセスできることを前提としていますが、最近の研究（Riley et al. 2021）では、スタイル抽出のために推論時に3〜10の文のみを使用する「few-shot」スタイル転送を試みています。本研究では、スタイルラベル付きコーパスが存在しない言語のスタイル転送という関連する低リソース設定を研究しています。既存のfew-shot方法は、入力をそのままコピーすることが多く、このタスクを不十分に実行します。我々は、パラフレーズ間のスタイルの違いをモデル化する新しい方法でfew-shotスタイル転送の最先端を推し進めます。従来の研究と比較して、我々のモデルは、7つの言語でフォーマリティ転送とコードミキシング追加において2〜3倍の性能を発揮します。さらに、我々の方法は、入力スカラーノブを使用してスタイル転送の強度をより制御することができます。我々は、モデルを再トレーニングすることなく、感情転送、簡素化、ジェンダーニュートラル化、テキスト匿名化などのいくつかの属性転送タスクについて有望な定性的結果を報告しています。最後に、多くの言語に対してデータセットやメトリックが不足しているため、モデルの評価が困難であることがわかりました。今後の研究を促進するために、我々は4つのインド系言語の4000の文のペアについてフォーマリティ注釈をクラウドソーシングし、このデータを使用して自動評価を設計しました。"}
{"title": "ABC: Attention with Bounded-memory Control", "url": "https://aclanthology.org/2022.acl-long.515/", "abstract": "Transformer architectures have achieved state- of-the-art results on a variety of natural language processing (NLP) tasks. However, their attention mechanism comes with a quadratic complexity in sequence lengths, making the computational overhead prohibitive, especially for long sequences. Attention context can be seen as a random-access memory with each token taking a slot. Under this perspective, the memory size grows linearly with the sequence length, and so does the overhead of reading from it. One way to improve the efficiency is to bound the memory size. We show that disparate approaches can be subsumed into one abstraction, attention with bounded-memory control (ABC), and they vary in their organization of the memory. ABC reveals new, unexplored possibilities. First, it connects several efficient attention variants that would otherwise seem apart. Second, this abstraction gives new insights—an established approach (Wang et al., 2020b) previously thought to not be applicable in causal attention, actually is. Last, we present a new instance of ABC, which draws inspiration from existing ABC approaches, but replaces their heuristic memory-organizing functions with a learned, contextualized one. Our experiments on language modeling, machine translation, and masked language model finetuning show that our approach outperforms previous efficient attention models; compared to the strong transformer baselines, it significantly improves the inference time and space efficiency with no or negligible accuracy loss.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ABC: 限定メモリ制御によるアテンション", "jabstract": "トランスフォーマーアーキテクチャは、さまざまな自然言語処理（NLP）タスクで最先端の結果を達成しています。しかし、そのアテンションメカニズムは、シーケンス長に対して二次的な複雑性を持ち、特に長いシーケンスに対して計算オーバーヘッドが禁止されるため、効率が悪いです。アテンションコンテキストは、各トークンがスロットを占有するランダムアクセスメモリと見なすことができます。この観点から、メモリサイズはシーケンス長に比例して増加し、それに伴って読み取りのオーバーヘッドも増加します。効率を改善する方法の1つは、メモリサイズを制限することです。我々は、異なるアプローチが1つの抽象化で包括されることができることを示し、境界付きメモリ制御を持つアテンション（ABC）という抽象化があり、それらはメモリの組織によって異なります。 ABCは、新しい、未開拓の可能性を示します。まず、いくつかの効率的なアテンション変種を接続し、それ以外には別のように見えることができます。第二に、この抽象化は、確定的なアテンションに適用できないと以前に考えられていた確立されたアプローチ（Wang et al.、2020b）が実際に適用できることを示します。最後に、我々は、既存のABCアプローチからインスピレーションを得て、ヒューリスティックなメモリ組織関数を学習されたコンテキストに置き換えた新しいABCのインスタンスを提示します。言語モデリング、機械翻訳、およびマスクされた言語モデルの微調整に関する私たちの実験は、私たちのアプローチが以前の効率的なアテンションモデルを上回ることを示しています。強力なトランスフォーマーベースラインと比較して、推論時間とスペース効率を大幅に改善し、精度の損失がないか無視できる程度に改善します。"}
{"title": "The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP Systems Fail", "url": "https://aclanthology.org/2022.acl-long.516/", "abstract": "Researchers in NLP often frame and discuss research results in ways that serve to deemphasize the field’s successes, often in response to the field’s widespread hype. Though well-meaning, this has yielded many misleading or false claims about the limits of our best technology. This is a problem, and it may be more serious than it looks: It harms our credibility in ways that can make it harder to mitigate present-day harms, like those involving biased systems for content moderation or resume screening. It also limits our ability to prepare for the potentially enormous impacts of more distant future advances. This paper urges researchers to be careful about these claims and suggests some research directions and communication strategies that will make it easier to avoid or rebut them.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nアンダークレーミングの危険性：NLPシステムの失敗を報告する際の注意点の理由", "jabstract": "自然言語処理（NLP）の研究者は、しばしば、広く言われる熱狂的な期待に対応して、分野の成功を軽視するような研究結果の枠組みや議論を行っています。これは善意から来るものですが、最高技術の限界に関する誤解や虚偽の主張を多数生み出しています。これは問題であり、それは見かけよりも深刻かもしれません。なぜなら、これはバイアスのあるコンテンツモデレーションや履歴書のスクリーニングなど、現在の害を軽減するのがより困難になることで信頼性に損害を与えるからです。また、より遠い未来の進歩の可能性に対する影響を準備する能力も制限されます。この論文は、研究者がこれらの主張に注意を払い、それらを回避または反論するための研究方向とコミュニケーション戦略を提案しています。"}
{"title": "RELiC: Retrieving Evidence for Literary Claims", "url": "https://aclanthology.org/2022.acl-long.517/", "abstract": "Humanities scholars commonly provide evidence for claims that they make about a work of literature (e.g., a novel) in the form of quotations from the work. We collect a large-scale dataset (RELiC) of 78K literary quotations and surrounding critical analysis and use it to formulate the novel task of literary evidence retrieval, in which models are given an excerpt of literary analysis surrounding a masked quotation and asked to retrieve the quoted passage from the set of all passages in the work. Solving this retrieval task requires a deep understanding of complex literary and linguistic phenomena, which proves challenging to methods that overwhelmingly rely on lexical and semantic similarity matching. We implement a RoBERTa-based dense passage retriever for this task that outperforms existing pretrained information retrieval baselines; however, experiments and analysis by human domain experts indicate that there is substantial room for improvement.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nRELiC：文学的主張の証拠の検索", "jabstract": "人文学者は、文学作品（例えば小説）に関する主張を引用形式で証拠を提供することが一般的です。本研究では、78,000の文学引用とその周辺の批評分析からなる大規模なデータセット（RELiC）を収集し、小説の証拠検索という新しいタスクを定式化します。このタスクでは、モデルにマスクされた引用文を含む文学分析の抜粋が与えられ、作品中のすべての文章から引用された部分を検索するように求めます。この検索タスクを解決するには、語彙的および意味的類似性マッチングに圧倒的に依存する方法にとって、複雑な文学的および言語現象の深い理解が必要であり、困難を伴います。本研究では、このタスクのためにRoBERTaベースの密なパッセージ検索器を実装し、既存の事前学習済み情報検索ベースラインを上回る性能を発揮しました。しかし、人間のドメイン専門家による実験と分析により、改善の余地があることが示されました。"}
{"title": "Analyzing Generalization of Vision and Language Navigation to Unseen Outdoor Areas", "url": "https://aclanthology.org/2022.acl-long.518/", "abstract": "Vision and language navigation (VLN) is a challenging visually-grounded language understanding task. Given a natural language navigation instruction, a visual agent interacts with a graph-based environment equipped with panorama images and tries to follow the described route. Most prior work has been conducted in indoor scenarios where best results were obtained for navigation on routes that are similar to the training routes, with sharp drops in performance when testing on unseen environments. We focus on VLN in outdoor scenarios and find that in contrast to indoor VLN, most of the gain in outdoor VLN on unseen data is due to features like junction type embedding or heading delta that are specific to the respective environment graph, while image information plays a very minor role in generalizing VLN to unseen outdoor areas. These findings show a bias to specifics of graph representations of urban environments, demanding that VLN tasks grow in scale and diversity of geographical environments.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n未知の屋外エリアへのビジョンと言語ナビゲーションの一般化を分析する", "jabstract": "ビジョンと言語ナビゲーション（VLN）は、視覚的に基盤となる言語理解の課題であり、自然言語のナビゲーション指示に従って、視覚エージェントがパノラマ画像を備えたグラフベースの環境と相互作用し、指示されたルートに従おうとします。これまでのほとんどの研究は、トレーニングルートに似たルートでのナビゲーションに最も優れた結果が得られ、未知の環境でのテストでは性能が急激に低下する屋内シナリオで行われてきました。私たちは屋外シナリオでのVLNに焦点を当て、屋外VLNでは、屋内VLNとは対照的に、ジャンクションタイプの埋め込みやヘッディングデルタなどの特定の環境グラフに固有の特徴が未知のデータに対する屋外VLNのほとんどの利益をもたらすことを発見しました。一般的に、画像情報は未知の屋外エリアにVLNを一般化するために非常に小さな役割を果たします。これらの結果は、都市環境のグラフ表現の特定に偏りがあることを示しており、VLNタスクが地理的環境の規模と多様性を増やす必要があることを要求しています。"}
{"title": "Adapting Coreference Resolution Models through Active Learning", "url": "https://aclanthology.org/2022.acl-long.519/", "abstract": "Neural coreference resolution models trained on one dataset may not transfer to new, low-resource domains. Active learning mitigates this problem by sampling a small subset of data for annotators to label. While active learning is well-defined for classification tasks, its application to coreference resolution is neither well-defined nor fully understood. This paper explores how to actively label coreference, examining sources of model uncertainty and document reading costs. We compare uncertainty sampling strategies and their advantages through thorough error analysis. In both synthetic and human experiments, labeling spans within the same document is more effective than annotating spans across documents. The findings contribute to a more realistic development of coreference resolution models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nアクティブラーニングを通じて共参照解決モデルを適応すること", "jabstract": "1つのデータセットでトレーニングされたニューラル共参照解決モデルは、新しい低リソースドメインに転送できない場合があります。アクティブラーニングは、アノテーターがラベルを付けるために小さなデータサブセットをサンプリングすることによって、この問題を緩和します。アクティブラーニングは分類タスクに対してよく定義されていますが、共参照解決に対するその適用は、十分に定義されていないか、または完全に理解されていません。本論文では、モデルの不確実性とドキュメントの読み取りコストのソースを調べ、どのように共参照をアクティブにラベル付けするかを探求します。私たちは、不確実性サンプリング戦略とその利点を徹底的なエラー分析を通じて比較します。合成実験と人間の実験の両方で、同じドキュメント内のスパンにラベルを付けることが、ドキュメント間のスパンに注釈を付けるよりも効果的であることがわかりました。この研究成果は、より現実的な共参照解決モデルの開発に貢献します。"}
{"title": "An Imitation Learning Curriculum for Text Editing with Non-Autoregressive Models", "url": "https://aclanthology.org/2022.acl-long.520/", "abstract": "We propose a framework for training non-autoregressive sequence-to-sequence models for editing tasks, where the original input sequence is iteratively edited to produce the output. We show that the imitation learning algorithms designed to train such models for machine translation introduces mismatches between training and inference that lead to undertraining and poor generalization in editing scenarios. We address this issue with two complementary strategies: 1) a roll-in policy that exposes the model to intermediate training sequences that it is more likely to encounter during inference, 2) a curriculum that presents easy-to-learn edit operations first, gradually increasing the difficulty of training samples as the model becomes competent. We show the efficacy of these strategies on two challenging English editing tasks: controllable text simplification and abstractive summarization. Our approach significantly improves output quality on both tasks and controls output complexity better on the simplification task.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "非自己回帰モデルを用いたテキスト編集のための模倣学習カリキュラム", "jabstract": "私たちは、編集タスクのための非自己回帰シーケンス・トゥ・シーケンス・モデルのトレーニングのためのフレームワークを提案します。元の入力シーケンスを編集して出力を生成するために反復的に編集されます。機械翻訳のために設計された模倣学習アルゴリズムが、トレーニングと推論の間に不一致を導入し、編集シナリオでの過少トレーニングと一般化の悪さを引き起こすことを示します。私たちは、この問題に対して2つの補完的な戦略で対処します。1つは、モデルを推論中により頻繁に遭遇する可能性のある中間トレーニングシーケンスにさらすロールインポリシーです。2つ目は、簡単に学習できる編集操作を最初に提示し、モデルが能力を獲得するにつれてトレーニングサンプルの難易度を徐々に上げるカリキュラムです。私たちは、2つの難しい英語編集タスク、制御可能なテキスト簡素化と抽象的要約において、これらの戦略の有効性を示します。私たちのアプローチは、両方のタスクで出力品質を大幅に改善し、簡素化タスクでは出力の複雑さをより制御します。"}
{"title": "Memorisation versus Generalisation in Pre-trained Language Models", "url": "https://aclanthology.org/2022.acl-long.521/", "abstract": "State-of-the-art pre-trained language models have been shown to memorise facts and perform well with limited amounts of training data. To gain a better understanding of how these models learn, we study their generalisation and memorisation capabilities in noisy and low-resource scenarios. We find that the training of these models is almost unaffected by label noise and that it is possible to reach near-optimal results even on extremely noisy datasets. However, our experiments also show that they mainly learn from high-frequency patterns and largely fail when tested on low-resource tasks such as few-shot learning and rare entity recognition. To mitigate such limitations, we propose an extension based on prototypical networks that improves performance in low-resource named entity recognition tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習された言語モデルにおける記憶と一般化の比較", "jabstract": "最新の事前学習言語モデルは、事実を記憶し、限られたトレーニングデータでも優れたパフォーマンスを発揮することが示されています。これらのモデルがどのように学習するかをよりよく理解するために、我々はノイズの多い低リソースシナリオでの一般化と記憶能力を研究しました。我々は、これらのモデルのトレーニングがラベルノイズにほとんど影響を受けないことを発見し、非常にノイズの多いデータセットでもほぼ最適な結果を得ることができることを示しました。しかし、我々の実験は、これらのモデルが主に高頻度のパターンから学習し、フューショット学習やレアエンティティ認識などの低リソースタスクでテストされた場合には大きく失敗することを示しています。このような制限を緩和するために、我々はプロトタイプネットワークに基づく拡張を提案し、低リソースの固有名詞認識タスクでのパフォーマンスを改善します。"}
{"title": "ChatMatch: Evaluating Chatbots by Autonomous Chat Tournaments", "url": "https://aclanthology.org/2022.acl-long.522/", "abstract": "Existing automatic evaluation systems of chatbots mostly rely on static chat scripts as ground truth, which is hard to obtain, and requires access to the models of the bots as a form of “white-box testing”. Interactive evaluation mitigates this problem but requires human involvement. In our work, we propose an interactive chatbot evaluation framework in which chatbots compete with each other like in a sports tournament, using flexible scoring metrics. This framework can efficiently rank chatbots independently from their model architectures and the domains for which they are trained.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ChatMatch：自律チャットトーナメントによるチャットボットの評価", "jabstract": "チャットボットの既存の自動評価システムは、主に静的なチャットスクリプトを基準としており、入手が困難であり、「ホワイトボックステスト」としてボットのモデルにアクセスする必要があります。対話型評価はこの問題を緩和しますが、人間の関与が必要です。本研究では、柔軟なスコアリングメトリックを使用して、チャットボットがスポーツトーナメントのように競い合うインタラクティブなチャットボット評価フレームワークを提案します。このフレームワークは、モデルアーキテクチャやトレーニングされたドメインに関係なく、チャットボットを効率的にランク付けすることができます。"}
{"title": "Do self-supervised speech models develop human-like perception biases?", "url": "https://aclanthology.org/2022.acl-long.523/", "abstract": "Self-supervised models for speech processing form representational spaces without using any external labels. Increasingly, they appear to be a feasible way of at least partially eliminating costly manual annotations, a problem of particular concern for low-resource languages. But what kind of representational spaces do these models construct?Human perception specializes to the sounds of listeners’ native languages. Does the same thing happen in self-supervised models? We examine the representational spaces of three kinds of state of the art self-supervised models: wav2vec, HuBERT and contrastive predictive coding (CPC), and compare them with the perceptual spaces of French-speaking and English-speaking human listeners, both globally and taking account of the behavioural differences between the two language groups. We show that the CPC model shows a small native language effect, but that wav2vec and HuBERT seem to develop a universal speech perception space which is not language specific. A comparison against the predictions of supervised phone recognisers suggests that all three self-supervised models capture relatively fine-grained perceptual phenomena, while supervised models are better at capturing coarser, phone-level effects, and effects of listeners’ native language, on perception.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己教育音声モデルは、人間の知覚バイアスを開発するのか？", "jabstract": "音声処理のための自己教師ありモデルは、外部のラベルを使用せずに表現空間を形成します。これらのモデルは、低資源言語に特に関心がある問題である高価な手動注釈を少なくとも部分的に排除することができる可能性があります。しかし、これらのモデルはどのような表現空間を構築するのでしょうか？人間の知覚は、聴衆の母語の音に特化しています。自己教師ありモデルでも同じことが起こるのでしょうか？私たちは、wav2vec、HuBERT、および対比的予測符号化（CPC）の3種類の最新の自己教師ありモデルの表現空間を調べ、フランス語を話す人と英語を話す人の知覚空間と比較します。両言語グループの行動的な違いを考慮して、グローバルに比較します。CPCモデルは小さな母語効果を示しますが、wav2vecとHuBERTは言語に特化しない普遍的な音声知覚空間を開発するようです。教師ありの音素認識器の予測との比較から、3つの自己教師ありモデルは比較的細かい知覚現象を捉える一方、教師ありモデルは粗い音素レベルの効果や聴衆の母語の影響をよりよく捉えることができます。"}
{"title": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions", "url": "https://aclanthology.org/2022.acl-long.524/", "abstract": "A long-term goal of AI research is to build intelligent agents that can communicate with humans in natural language, perceive the environment, and perform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental and interdisciplinary research topic towards this goal, and receives increasing attention from natural language processing, computer vision, robotics, and machine learning communities. In this paper, we review contemporary studies in the emerging field of VLN, covering tasks, evaluation metrics, methods, etc. Through structured analysis of current progress and challenges, we also highlight the limitations of current VLN and opportunities for future work. This paper serves as a thorough reference for the VLN research community.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions」という論文の要約文を日本語に翻訳してください。", "jabstract": "AI研究の長期的な目標の1つは、自然言語で人間とコミュニケーションを取り、環境を認識し、現実世界のタスクを実行できる知的エージェントを構築することです。ビジョン・アンド・ランゲージ・ナビゲーション（VLN）は、この目標に向けた基本的で学際的な研究トピックであり、自然言語処理、コンピュータビジョン、ロボット工学、機械学習のコミュニティからますます注目を集めています。本論文では、VLNの新興分野におけるタスク、評価指標、手法などをカバーした現代の研究をレビューします。現在の進歩と課題の構造化された分析を通じて、現在のVLNの限界と将来の研究の機会を強調します。本論文は、VLN研究コミュニティの包括的な参照資料として役立ちます。"}
{"title": "Learning to Generate Programs for Table Fact Verification via Structure-Aware Semantic Parsing", "url": "https://aclanthology.org/2022.acl-long.525/", "abstract": "Table fact verification aims to check the correctness of textual statements based on given semi-structured data. Most existing methods are devoted to better comprehending logical operations and tables, but they hardly study generating latent programs from statements, with which we can not only retrieve evidences efficiently but also explain reasons behind verifications naturally. However, it is challenging to get correct programs with existing weakly supervised semantic parsers due to the huge search space with lots of spurious programs. In this paper, we address the challenge by leveraging both lexical features and structure features for program generation. Through analyzing the connection between the program tree and the dependency tree, we define a unified concept, operation-oriented tree, to mine structure features, and introduce Structure-Aware Semantic Parsing to integrate structure features into program generation. Moreover, we design a refined objective function with lexical features and violation punishments to further avoid spurious programs. Experimental results show that our proposed method generates programs more accurately than existing semantic parsers, and achieves comparable performance to the SOTA on the large-scale benchmark TABFACT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「構造に注意を払った意味解析を通じた表ファクト検証のためのプログラム生成の学習」についての論文の要約です。", "jabstract": "テーブル事実検証は、与えられた半構造化データに基づいて、テキスト文の正確性を確認することを目的としています。既存の多くの手法は、論理演算とテーブルをより理解することに専念していますが、文から潜在的なプログラムを生成することにはほとんど取り組んでおらず、これにより、証拠を効率的に取得するだけでなく、検証の理由を自然に説明することができます。しかし、既存の弱く監視された意味解析器では、多数の誤ったプログラムが存在する巨大な検索空間のため、正しいプログラムを取得することは困難です。本論文では、プログラム生成のために語彙的特徴と構造的特徴の両方を活用することで、この課題に取り組みます。プログラムツリーと依存ツリーの接続を分析することにより、操作指向ツリーという統一的な概念を定義し、構造的特徴を採掘するための構造的意味解析を導入します。さらに、語彙的特徴と違反罰則を組み合わせた洗練された目的関数を設計し、誤ったプログラムをさらに回避します。実験結果は、提案された手法が既存の意味解析器よりも正確にプログラムを生成し、大規模なベンチマークTABFACTでSOTAと同等の性能を発揮することを示しています。"}
{"title": "Cluster & Tune: Boost Cold Start Performance in Text Classification", "url": "https://aclanthology.org/2022.acl-long.526/", "abstract": "In real-world scenarios, a text classification task often begins with a cold start, when labeled data is scarce. In such cases, the common practice of fine-tuning pre-trained models, such as BERT, for a target classification task, is prone to produce poor performance. We suggest a method to boost the performance of such models by adding an intermediate unsupervised classification task, between the pre-training and fine-tuning phases. As such an intermediate task, we perform clustering and train the pre-trained model on predicting the cluster labels.We test this hypothesis on various data sets, and show that this additional classification phase can significantly improve performance, mainly for topical classification tasks, when the number of labeled instances available for fine-tuning is only a couple of dozen to a few hundred.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "クラスター＆チューン：テキスト分類におけるコールドスタート性能を向上させる", "jabstract": "現実世界のシナリオでは、ラベル付きデータが不足している場合、テキスト分類タスクはしばしばコールドスタートで始まります。そのような場合、BERTなどの事前学習済みモデルをファインチューニングするという一般的な方法は、パフォーマンスが低下する可能性があります。我々は、事前学習とファインチューニングの間に、中間の非監視分類タスクを追加することで、そのようなモデルのパフォーマンスを向上させる方法を提案します。この中間タスクとして、クラスタリングを実行し、事前学習済みモデルをクラスタラベルの予測にトレーニングします。我々は、さまざまなデータセットでこの仮説をテストし、ファインチューニングに利用可能なラベル付きインスタンスの数が数十から数百に限定される場合、この追加の分類フェーズが主にトピック分類タスクのパフォーマンスを大幅に改善できることを示します。"}
{"title": "Overcoming a Theoretical Limitation of Self-Attention", "url": "https://aclanthology.org/2022.acl-long.527/", "abstract": "Although transformers are remarkably effective for many tasks, there are some surprisingly easy-looking regular languages that they struggle with. Hahn shows that for languages where acceptance depends on a single input symbol, a transformer’s classification decisions get closer and closer to random guessing (that is, a cross-entropy of 1) as input strings get longer and longer. We examine this limitation using two languages: PARITY, the language of bit strings with an odd number of 1s, and FIRST, the language of bit strings starting with a 1. We demonstrate three ways of overcoming the limitation implied by Hahn’s lemma. First, we settle an open question by constructing a transformer that recognizes PARITY with perfect accuracy, and similarly for FIRST. Second, we use layer normalization to bring the cross-entropy of both models arbitrarily close to zero. Third, when transformers need to focus on a single position, as for FIRST, we find that they can fail to generalize to longer strings; we offer a simple remedy to this problem that also improves length generalization in machine translation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己注意の理論的制限の克服", "jabstract": "トランスフォーマーは多くのタスクに対して非常に効果的であるが、驚くほど簡単に見える正則言語には苦戦する。Hahnは、入力記号が1つに依存する言語では、入力文字列が長くなるにつれてトランスフォーマーの分類決定がランダムな推測に近づくことを示している（つまり、クロスエントロピーが1になる）。本稿では、PARITY（1の数が奇数のビット列の言語）とFIRST（1で始まるビット列の言語）の2つの言語を用いて、Hahnの補題によって示される制限を3つの方法で克服することを示す。第1に、PARITYとFIRSTを完全に正確に認識するトランスフォーマーを構築することで、未解決の問題を解決する。第2に、レイヤー正規化を使用して、両モデルのクロスエントロピーを任意の値に近づける。第3に、FIRSTのようにトランスフォーマーが単一の位置に焦点を当てる必要がある場合、長い文字列に一般化できなくなることがある。この問題に対する簡単な解決策を提供し、機械翻訳における長さの一般化も改善する。"}
{"title": "Prediction Difference Regularization against Perturbation for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.528/", "abstract": "Regularization methods applying input perturbation have drawn considerable attention and have been frequently explored for NMT tasks in recent years. Despite their simplicity and effectiveness, we argue that these methods are limited by the under-fitting of training data. In this paper, we utilize prediction difference for ground-truth tokens to analyze the fitting of token-level samples and find that under-fitting is almost as common as over-fitting. We introduce prediction difference regularization (PD-R), a simple and effective method that can reduce over-fitting and under-fitting at the same time. For all token-level samples, PD-R minimizes the prediction difference between the original pass and the input-perturbed pass, making the model less sensitive to small input changes, thus more robust to both perturbations and under-fitted training data. Experiments on three widely used WMT translation tasks show that our approach can significantly improve over existing perturbation regularization methods. On WMT16 En-De task, our model achieves 1.80 SacreBLEU improvement over vanilla transformer.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル機械翻訳に対する摂動に対する予測差異正則化", "jabstract": "入力摂動を適用する正則化手法は、近年、NMTタスクで注目を集め、頻繁に探求されています。その単純さと効果的さにもかかわらず、これらの手法はトレーニングデータの過少適合によって制限されていると主張します。本論文では、グラウンドトゥルーストークンの予測差を利用してトークンレベルのサンプルの適合性を分析し、過少適合が過剰適合と同様に一般的であることを発見しました。我々は、過剰適合と過少適合の両方を同時に減らすことができる、単純で効果的な予測差正則化（PD-R）を導入します。すべてのトークンレベルのサンプルに対して、PD-Rは、元のパスと入力摂動されたパスの予測差を最小化し、モデルを小さな入力変更に対してより感度が低く、摂動と過少適合のトレーニングデータの両方に対してより堅牢にします。WMT翻訳タスクの3つの広く使用されているタスクでの実験結果は、当社のアプローチが既存の摂動正則化手法よりも大幅に改善できることを示しています。WMT16 En-Deタスクでは、当社のモデルはバニラトランスフォーマーに比べて1.80 SacreBLEUの改善を達成しています。"}
{"title": "Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages", "url": "https://aclanthology.org/2022.acl-long.529/", "abstract": "Cross-lingual transfer learning with large multilingual pre-trained models can be an effective approach for low-resource languages with no labeled training data. Existing evaluations of zero-shot cross-lingual generalisability of large pre-trained models use datasets with English training data, and test data in a selection of target languages. We explore a more extensive transfer learning setup with 65 different source languages and 105 target languages for part-of-speech tagging. Through our analysis, we show that pre-training of both source and target language, as well as matching language families, writing systems, word order systems, and lexical-phonetic distance significantly impact cross-lingual performance. The findings described in this paper can be used as indicators of which factors are important for effective zero-shot cross-lingual transfer to zero- and low-resource languages.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "100以上の言語でのPOSタグ付けによる証拠から、クロスリンガル転送を最大限に活用する\n\nThis paper investigates the effectiveness of cross-lingual transfer learning for part-of-speech (POS) tagging. \n本論文では、品詞タグ付けにおけるクロスリンガル転送学習の効果を調査しています。\n\nWe conduct experiments on a large-scale multilingual dataset with over 100 languages, and show that cross-lingual transfer learning can significantly improve the performance of POS tagging for low-resource languages. \n100以上の言語を含む大規模なマルチリンガルデータセットで実験を行い、クロスリンガル転送学習が低リソース言語の品詞タグ付けの性能を大幅に向上させることを示します。\n\nOur results demonstrate that cross-lingual transfer learning is a promising approach for improving the performance of natural language processing tasks for low-resource languages. \n私たちの結果は、クロスリンガル転送学習が低リソース言語の自然言語処理タスクの性能を向上させる有望な手法であることを示しています。", "jabstract": "大規模な多言語事前学習モデルを用いたクロスリンガル転移学習は、ラベル付きトレーニングデータのない低リソース言語に対して有効なアプローチである。既存の大規模事前学習モデルのゼロショットクロスリンガル汎化性能の評価は、英語のトレーニングデータを使用し、選択されたターゲット言語のテストデータを使用している。本研究では、品詞タグ付けのために65の異なるソース言語と105のターゲット言語を使用したより広範な転移学習セットアップを探究する。分析により、ソース言語とターゲット言語の両方の事前学習、言語ファミリー、書記システム、語順システム、および語彙音韻的距離の一致がクロスリンガルパフォーマンスに重要な影響を与えることを示す。本論文で説明されている知見は、ゼロリソースおよび低リソース言語への効果的なゼロショットクロスリンガル転移のために重要な要因を示す指標として使用できる。"}
{"title": "Should a Chatbot be Sarcastic? Understanding User Preferences Towards Sarcasm Generation", "url": "https://aclanthology.org/2022.acl-long.530/", "abstract": "Previous sarcasm generation research has focused on how to generate text that people perceive as sarcastic to create more human-like interactions. In this paper, we argue that we should first turn our attention to the question of when sarcasm should be generated, finding that humans consider sarcastic responses inappropriate to many input utterances. Next, we use a theory-driven framework for generating sarcastic responses, which allows us to control the linguistic devices included during generation. For each device, we investigate how much humans associate it with sarcasm, finding that pragmatic insincerity and emotional markers are devices crucial for making sarcasm recognisable.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "チャットボットは皮肉を言うべきか？皮肉生成に対するユーザーの好みを理解する", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n従来の皮肉生成研究は、より人間らしい相互作用を作成するために、人々が皮肉として認識するテキストを生成する方法に焦点を当ててきました。本論文では、人間は多くの入力発話に対して皮肉な応答を不適切と考えるため、まず皮肉を生成すべきタイミングに注目すべきだと主張します。次に、理論駆動型の枠組みを使用して皮肉な応答を生成し、生成中に含まれる言語デバイスを制御することができます。各デバイスについて、人間がどの程度それを皮肉と関連付けているかを調査し、実用的な不誠実さと感情的なマーカーが皮肉を認識するために重要なデバイスであることがわかりました。"}
{"title": "How Do Seq2Seq Models Perform on End-to-End Data-to-Text Generation?", "url": "https://aclanthology.org/2022.acl-long.531/", "abstract": "With the rapid development of deep learning, Seq2Seq paradigm has become prevalent for end-to-end data-to-text generation, and the BLEU scores have been increasing in recent years. However, it is widely recognized that there is still a gap between the quality of the texts generated by models and the texts written by human. In order to better understand the ability of Seq2Seq models, evaluate their performance and analyze the results, we choose to use Multidimensional Quality Metric(MQM) to evaluate several representative Seq2Seq models on end-to-end data-to-text generation. We annotate the outputs of five models on four datasets with eight error types and find that 1) copy mechanism is helpful for the improvement in Omission and Inaccuracy Extrinsic errors but it increases other types of errors such as Addition; 2) pre-training techniques are highly effective, and pre-training strategy and model size are very significant; 3) the structure of the dataset also influences the model’s performance greatly; 4) some specific types of errors are generally challenging for seq2seq models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Seq2Seqモデルは、エンドツーエンドのデータからテキスト生成においてどのようにパフォーマンスを発揮するのか？", "jabstract": "深層学習の急速な発展に伴い、Seq2Seqパラダイムはエンドツーエンドのデータからテキスト生成において普及し、BLEUスコアは近年増加しています。しかし、モデルによって生成されたテキストの品質と人間が書いたテキストの品質の間にはまだギャップがあることが広く認識されています。Seq2Seqモデルの能力をよりよく理解し、そのパフォーマンスを評価し、結果を分析するために、我々は多次元品質メトリック（MQM）を使用して、エンドツーエンドのデータからテキスト生成においていくつかの代表的なSeq2Seqモデルを評価することを選択しました。我々は、5つのモデルの出力を4つのデータセットで8つのエラータイプで注釈し、以下のことを発見しました。1）コピー機構は、省略と不正確な外的エラーの改善に役立ちますが、追加などの他のタイプのエラーを増加させます。2）事前トレーニング技術は非常に効果的であり、事前トレーニング戦略とモデルサイズは非常に重要です。3）データセットの構造もモデルのパフォーマンスに大きく影響します。4）特定のタイプのエラーは、一般的にSeq2Seqモデルにとって課題となります。"}
{"title": "Probing for Labeled Dependency Trees", "url": "https://aclanthology.org/2022.acl-long.532/", "abstract": "Probing has become an important tool for analyzing representations in Natural Language Processing (NLP). For graphical NLP tasks such as dependency parsing, linear probes are currently limited to extracting undirected or unlabeled parse trees which do not capture the full task. This work introduces DepProbe, a linear probe which can extract labeled and directed dependency parse trees from embeddings while using fewer parameters and compute than prior methods. Leveraging its full task coverage and lightweight parametrization, we investigate its predictive power for selecting the best transfer language for training a full biaffine attention parser. Across 13 languages, our proposed method identifies the best source treebank 94% of the time, outperforming competitive baselines and prior work. Finally, we analyze the informativeness of task-specific subspaces in contextual embeddings as well as which benefits a full parser’s non-linear parametrization provides.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ラベル付き依存木の探索\n\nWe introduce a new diagnostic tool for natural language understanding models: probing classifiers that learn to predict linguistic annotations from hidden representations of a pre-trained model. \n\n我々は、自然言語理解モデルの新しい診断ツールを紹介する。事前にトレーニングされたモデルの隠れた表現から言語的注釈を予測する学習分類器を探査する。\n\nWe apply this tool to study the linguistic knowledge of pre-trained contextualized representations, which have recently advanced the state of the art in many natural language processing tasks. \n\n我々は、最近多くの自然言語処理タスクで最先端を進めた事前トレーニングされた文脈化表現の言語知識を研究するために、このツールを適用する。\n\nOur probing experiments reveal that these models encode a surprising amount of linguistic information, often in unexpected ways. \n\n我々の探査実験は、これらのモデルが驚くほど多くの言語情報をエンコードしていることを明らかにし、しばしば予期しない方法でエンコードされていることがある。", "jabstract": "プロービングは、自然言語処理（NLP）における表現の分析において重要なツールとなっています。依存解析などのグラフィカルNLPタスクにおいて、線形プローブは現在、直接的またはラベルのない構文木の抽出に限定されており、完全なタスクを捉えることができません。本研究では、より少ないパラメータと計算を使用しながら、埋め込みからラベル付きおよび方向付きの依存構文木を抽出できる線形プローブであるDepProbeを紹介します。完全なタスクカバレッジと軽量なパラメータ化を活用して、フルバイアフィンアテンションパーサーのトレーニングに最適な転移言語を選択するための予測力を調査します。13の言語にわたって、提案手法は競合するベースラインや先行研究を上回り、94％の確率で最適なソースツリーバンクを特定します。最後に、コンテキスト埋め込みのタスク固有のサブスペースの情報量と、フルパーサーの非線形パラメータ化が提供する利点を分析します。"}
{"title": "DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation", "url": "https://aclanthology.org/2022.acl-long.533/", "abstract": "Natural language processing (NLP) algorithms have become very successful, but they still struggle when applied to out-of-distribution examples. In this paper we propose a controllable generation approach in order to deal with this domain adaptation (DA) challenge. Given an input text example, our DoCoGen algorithm generates a domain-counterfactual textual example (D-con) - that is similar to the original in all aspects, including the task label, but its domain is changed to a desired one. Importantly, DoCoGen is trained using only unlabeled examples from multiple domains - no NLP task labels or parallel pairs of textual examples and their domain-counterfactuals are required. We show that DoCoGen can generate coherent counterfactuals consisting of multiple sentences. We use the D-cons generated by DoCoGen to augment a sentiment classifier and a multi-label intent classifier in 20 and 78 DA setups, respectively, where source-domain labeled data is scarce. Our model outperforms strong baselines and improves the accuracy of a state-of-the-art unsupervised DA algorithm.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "DoCoGen：低資源ドメイン適応のためのドメイン反事実生成", "jabstract": "自然言語処理（NLP）アルゴリズムは非常に成功していますが、分布外の例に適用するとまだ苦労しています。本論文では、このドメイン適応（DA）の課題に対処するために、制御可能な生成アプローチを提案します。入力テキスト例が与えられた場合、DoCoGenアルゴリズムはドメイン-反事実的なテキスト例（D-con）を生成します。これは、タスクラベルを含めすべての側面が元のものと似ていますが、ドメインが望ましいものに変更されています。重要なことに、DoCoGenは、NLPタスクラベルやテキスト例とそのドメイン-反事実的な対応ペアは必要とせず、複数のドメインからのラベルのない例のみを使用してトレーニングされます。DoCoGenは、複数の文から構成される一貫した反事実的なものを生成できることを示します。DoCoGenによって生成されたD-conを使用して、ソースドメインのラベル付きデータが不足している20および78のDAセットアップで感情分類器とマルチラベル意図分類器を拡張します。当社のモデルは、強力なベースラインを上回り、最先端の非監視型DAアルゴリズムの精度を向上させます。"}
{"title": "LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding", "url": "https://aclanthology.org/2022.acl-long.534/", "abstract": "Structured document understanding has attracted considerable attention and made significant progress recently, owing to its crucial role in intelligent document processing. However, most existing related models can only deal with the document data of specific language(s) (typically English) included in the pre-training collection, which is extremely limited. To address this issue, we propose a simple yet effective Language-independent Layout Transformer (LiLT) for structured document understanding. LiLT can be pre-trained on the structured documents of a single language and then directly fine-tuned on other languages with the corresponding off-the-shelf monolingual/multilingual pre-trained textual models. Experimental results on eight languages have shown that LiLT can achieve competitive or even superior performance on diverse widely-used downstream benchmarks, which enables language-independent benefit from the pre-training of document layout structure. Code and model are publicly available at https://github.com/jpWang/LiLT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LiLT：構造化ドキュメント理解のためのシンプルで効果的な言語非依存レイアウトトランスフォーマー", "jabstract": "構造化文書理解は、知的文書処理における重要な役割を果たすため、最近注目を集め、重要な進展を遂げています。しかし、既存の関連モデルのほとんどは、事前学習コレクションに含まれる特定の言語（通常は英語）の文書データのみを扱うことができ、非常に限られています。この問題に対処するために、我々は構造化文書理解のための言語非依存レイアウトトランスフォーマー（LiLT）を提案します。LiLTは、単一言語の構造化文書で事前学習され、対応するオフシェルフの単一言語/多言語事前学習テキストモデルで直接ファインチューニングされることができます。8つの言語での実験結果は、LiLTが多様な広く使用されているダウンストリームベンチマークで競争力のある、あるいは優れたパフォーマンスを発揮できることを示しており、文書レイアウト構造の事前学習から言語非依存の利益を得ることができます。コードとモデルはhttps://github.com/jpWang/LiLTで公開されています。"}
{"title": "Dependency-based Mixture Language Models", "url": "https://aclanthology.org/2022.acl-long.535/", "abstract": "Various models have been proposed to incorporate knowledge of syntactic structures into neural language models. However, previous works have relied heavily on elaborate components for a specific language model, usually recurrent neural network (RNN), which makes themselves unwieldy in practice to fit into other neural language models, such as Transformer and GPT-2. In this paper, we introduce the Dependency-based Mixture Language Models. In detail, we first train neural language models with a novel dependency modeling objective to learn the probability distribution of future dependent tokens given context. We then formulate the next-token probability by mixing the previous dependency modeling probability distributions with self-attention. Extensive experiments and human evaluations show that our method can be easily and effectively applied to different neural language models while improving neural text generation on various tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "依存関係ベースの混合言語モデル", "jabstract": "構文構造の知識をニューラル言語モデルに組み込むための様々なモデルが提案されてきた。しかし、これまでの研究では、特定の言語モデル（通常は再帰型ニューラルネットワーク（RNN））に対して緻密なコンポーネントに大きく依存しており、他のニューラル言語モデル（TransformerやGPT-2など）に適用することが実際には困難であった。本論文では、依存ベースの混合言語モデルを紹介する。具体的には、まず、未来の依存トークンの確率分布をコンテキストから学習するための新しい依存モデリング目的でニューラル言語モデルをトレーニングする。次に、前の依存モデリング確率分布を自己注意と混合して、次のトークンの確率を定式化する。広範な実験と人間の評価により、本手法は異なるニューラル言語モデルに簡単かつ効果的に適用でき、様々なタスクでニューラルテキスト生成を改善することが示された。"}
{"title": "Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?", "url": "https://aclanthology.org/2022.acl-long.536/", "abstract": "Identifying argument components from unstructured texts and predicting the relationships expressed among them are two primary steps of argument mining. The intrinsic complexity of these tasks demands powerful learning models. While pretrained Transformer-based Language Models (LM) have been shown to provide state-of-the-art results over different NLP tasks, the scarcity of manually annotated data and the highly domain-dependent nature of argumentation restrict the capabilities of such models. In this work, we propose a novel transfer learning strategy to overcome these challenges. We utilize argumentation-rich social discussions from the ChangeMyView subreddit as a source of unsupervised, argumentative discourse-aware knowledge by finetuning pretrained LMs on a selectively masked language modeling task. Furthermore, we introduce a novel prompt-based strategy for inter-component relation prediction that compliments our proposed finetuning method while leveraging on the discourse context. Exhaustive experiments show the generalization capability of our method on these two tasks over within-domain as well as out-of-domain datasets, outperforming several existing and employed strong baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "社会的な議論からの非監視学習の知識移転は、議論マイニングに役立つか？", "jabstract": "論点マイニングの主要な2つのステップは、非構造化テキストから論点の構成要素を特定し、それらの間に表現される関係を予測することです。これらのタスクの固有の複雑さは、強力な学習モデルを必要とします。事前学習されたTransformerベースの言語モデル（LM）は、さまざまなNLPタスクで最先端の結果を提供することが示されていますが、手動で注釈付けされたデータの不足と論争の高度にドメイン依存性のため、そのようなモデルの能力は制限されています。本研究では、このような課題を克服するための新しい転移学習戦略を提案します。私たちは、ChangeMyView subredditからの論争豊富な社会的議論を、選択的にマスクされた言語モデリングタスクで事前学習されたLMを微調整することにより、教師なしの論争に関する知識源として利用します。さらに、私たちは、提示ベースの戦略を導入し、ディスコースコンテキストを活用しながら、構成要素間の関係予測を補完することができます。徹底的な実験により、提案された微調整方法と戦略の両方によるこれら2つのタスクの汎化能力が、ドメイン内およびドメイン外のデータセットで、いくつかの既存の強力なベースラインを上回ることが示されました。"}
{"title": "Entity-based Neural Local Coherence Modeling", "url": "https://aclanthology.org/2022.acl-long.537/", "abstract": "In this paper, we propose an entity-based neural local coherence model which is linguistically more sound than previously proposed neural coherence models. Recent neural coherence models encode the input document using large-scale pretrained language models. Hence their basis for computing local coherence are words and even sub-words. The analysis of their output shows that these models frequently compute coherence on the basis of connections between (sub-)words which, from a linguistic perspective, should not play a role. Still, these models achieve state-of-the-art performance in several end applications. In contrast to these models, we compute coherence on the basis of entities by constraining the input to noun phrases and proper names. This provides us with an explicit representation of the most important items in sentences leading to the notion of focus. This brings our model linguistically in line with pre-neural models of computing coherence. It also gives us better insight into the behaviour of the model thus leading to better explainability. Our approach is also in accord with a recent study (O’Connor and Andreas, 2021), which shows that most usable information is captured by nouns and verbs in transformer-based language models. We evaluate our model on three downstream tasks showing that it is not only linguistically more sound than previous models but also that it outperforms them in end applications.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nエンティティベースのニューラルローカルコヒーレンスモデリング", "jabstract": "本論文では、従来のニューラル連続性モデルよりも言語学的に優れたエンティティベースのニューラルローカル連続性モデルを提案する。最近のニューラル連続性モデルは、大規模な事前学習言語モデルを使用して入力文書をエンコードする。したがって、彼らのローカル連続性を計算する基盤は単語やサブワードである。彼らの出力の分析から、これらのモデルは、言語学的には役割を果たすべきでない（サブ）単語間の接続に基づいて頻繁に連続性を計算することがわかった。それでも、これらのモデルはいくつかのエンドアプリケーションで最先端のパフォーマンスを達成している。これらのモデルとは対照的に、私たちは名詞句と固有名詞に制限して入力を制限することで、エンティティに基づいて連続性を計算する。これにより、文の中で最も重要なアイテムの明示的な表現が得られ、焦点の概念が生まれる。これにより、私たちのモデルは、連続性を計算するためのニューラル以前のモデルと言語学的に一致する。また、モデルの振る舞いについてより良い説明が得られるため、より良い説明性を提供する。私たちのアプローチは、トランスフォーマーベースの言語モデルにおいて、名詞と動詞が最も有用な情報を捕捉することを示した最近の研究（O'Connor and Andreas、2021）とも一致する。私たちは、エンドアプリケーションにおいて、私たちのモデルが従来のモデルよりも言語学的に優れているだけでなく、それらを上回るパフォーマンスを発揮することを示す3つのダウンストリームタスクで評価する。"}
{"title": "“That Is a Suspicious Reaction!”: Interpreting Logits Variation to Detect NLP Adversarial Attacks", "url": "https://aclanthology.org/2022.acl-long.538/", "abstract": "Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「それは怪しい反応だ！」：ロジットの変動を解釈してNLPの敵対的攻撃を検出する", "jabstract": "敵対的攻撃は、現在の機械学習研究が直面する主要な課題です。これらの目的を持って作られた入力は、最も高度なモデルでも騙すため、安全に関わるアプリケーションの展開を妨げます。コンピュータビジョンにおいては、信頼性の高い防御戦略を開発するための広範な研究が行われています。しかし、自然言語処理においては、同じ問題があまり探求されていません。本研究では、モデルに依存しない敵対的なテキスト例の検出器を提供します。この手法は、入力テキストを摂動させたときに、ターゲット分類器のロジットにパターンを識別します。提案された検出器は、敵対的な入力を認識する現在の最先端の性能を向上させ、異なるNLPモデル、データセット、および単語レベルの攻撃に対して強力な汎化能力を示します。"}
{"title": "Local Languages, Third Spaces, and other High-Resource Scenarios", "url": "https://aclanthology.org/2022.acl-long.539/", "abstract": "How can language technology address the diverse situations of the world’s languages? In one view, languages exist on a resource continuum and the challenge is to scale existing solutions, bringing under-resourced languages into the high-resource world. In another view, presented here, the world’s language ecology includes standardised languages, local languages, and contact languages. These are often subsumed under the label of “under-resourced languages” even though they have distinct functions and prospects. I explore this position and propose some ecologically-aware language technology agendas.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "地域言語、第三の空間、およびその他の高資源シナリオ", "jabstract": "自然言語処理に関する論文の要約の以下の文章を日本語に翻訳してください。\n\n世界の言語の多様な状況に対して、言語技術はどのように対応できるのでしょうか？一つの見方では、言語はリソースの連続体上に存在し、課題は既存の解決策をスケールアップし、リソースが不足している言語を高リソースの世界に取り込むことです。別の見方では、標準化された言語、地方言語、接触言語を含む世界の言語生態系が存在すると考えられます。これらはしばしば「リソースが不足している言語」というラベルの下に包括されますが、それぞれ異なる機能と展望を持っています。私はこの立場を探究し、生態学的に意識した言語技術のアジェンダを提案します。"}
{"title": "That Slepen Al the Nyght with Open Ye! Cross-era Sequence Segmentation with Switch-memory", "url": "https://aclanthology.org/2022.acl-long.540/", "abstract": "The evolution of language follows the rule of gradual change. Grammar, vocabulary, and lexical semantic shifts take place over time, resulting in a diachronic linguistic gap. As such, a considerable amount of texts are written in languages of different eras, which creates obstacles for natural language processing tasks, such as word segmentation and machine translation. Although the Chinese language has a long history, previous Chinese natural language processing research has primarily focused on tasks within a specific era. Therefore, we propose a cross-era learning framework for Chinese word segmentation (CWS), CROSSWISE, which uses the Switch-memory (SM) module to incorporate era-specific linguistic knowledge. Experiments on four corpora from different eras show that the performance of each corpus significantly improves. Further analyses also demonstrate that the SM can effectively integrate the knowledge of the eras into the neural network.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n「夜通し目を開けて眠る！スイッチメモリを用いたクロス時代のシーケンスセグメンテーション」", "jabstract": "言語の進化は、徐々な変化のルールに従います。文法、語彙、および語彙意味の変化が時間の経過とともに起こり、歴史的な言語的ギャップが生じます。そのため、異なる時代の言語で書かれたかなりの量のテキストがあり、単語分割や機械翻訳などの自然言語処理タスクに障害を引き起こします。中国語は長い歴史を持っていますが、以前の中国語自然言語処理研究は主に特定の時代のタスクに焦点を当てていました。したがって、私たちは中国語の単語分割（CWS）のための時代を超えた学習フレームワーク、CROSSWISEを提案します。これは、Switch-memory（SM）モジュールを使用して時代特有の言語知識を組み込みます。異なる時代の4つのコーパスでの実験では、各コーパスのパフォーマンスが大幅に向上することが示されました。さらに、SMが時代の知識をニューラルネットワークに効果的に統合できることも示されました。"}
{"title": "Fair and Argumentative Language Modeling for Computational Argumentation", "url": "https://aclanthology.org/2022.acl-long.541/", "abstract": "Although much work in NLP has focused on measuring and mitigating stereotypical bias in semantic spaces, research addressing bias in computational argumentation is still in its infancy. In this paper, we address this research gap and conduct a thorough investigation of bias in argumentative language models. To this end, we introduce ABBA, a novel resource for bias measurement specifically tailored to argumentation. We employ our resource to assess the effect of argumentative fine-tuning and debiasing on the intrinsic bias found in transformer-based language models using a lightweight adapter-based approach that is more sustainable and parameter-efficient than full fine-tuning. Finally, we analyze the potential impact of language model debiasing on the performance in argument quality prediction, a downstream task of computational argumentation. Our results show that we are able to successfully and sustainably remove bias in general and argumentative language models while preserving (and sometimes improving) model performance in downstream tasks. We make all experimental code and data available at https://github.com/umanlp/FairArgumentativeLM.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "計算論証のための公正かつ議論的な言語モデリングについての論文の要旨です。", "jabstract": "自然言語処理において、セマンティック空間におけるステレオタイプ的なバイアスの測定と軽減に焦点を当てた研究が多く行われてきたが、計算論理学におけるバイアスに対する研究はまだ初期段階にある。本論文では、この研究の空白を埋め、論証言語モデルにおけるバイアスについて徹底的な調査を行う。このために、論証に特化したバイアス測定のための新しいリソースであるABBAを紹介する。我々は、軽量なアダプタベースのアプローチを用いて、トランスフォーマーベースの言語モデルにおける論証の微調整とバイアス除去の効果を評価するために、このリソースを使用する。最後に、計算論理学の下流タスクである論証品質予測の性能に対する言語モデルのバイアス除去の潜在的な影響を分析する。我々の結果は、一般的な言語モデルと論証言語モデルのバイアスを成功裏に持続的に除去することができ、下流タスクにおけるモデルの性能を維持（そして時には改善）することができることを示している。我々は、すべての実験コードとデータをhttps://github.com/umanlp/FairArgumentativeLMで公開している。"}
{"title": "Learning Adaptive Segmentation Policy for End-to-End Simultaneous Translation", "url": "https://aclanthology.org/2022.acl-long.542/", "abstract": "End-to-end simultaneous speech-to-text translation aims to directly perform translation from streaming source speech to target text with high translation quality and low latency. A typical simultaneous translation (ST) system consists of a speech translation model and a policy module, which determines when to wait and when to translate. Thus the policy is crucial to balance translation quality and latency. Conventional methods usually adopt fixed policies, e.g. segmenting the source speech with a fixed length and generating translation. However, this method ignores contextual information and suffers from low translation quality. This paper proposes an adaptive segmentation policy for end-to-end ST. Inspired by human interpreters, the policy learns to segment the source streaming speech into meaningful units by considering both acoustic features and translation history, maintaining consistency between the segmentation and translation. Experimental results on English-German and Chinese-English show that our method achieves a good accuracy-latency trade-off over recently proposed state-of-the-art methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「エンドツーエンド同時翻訳のための適応的セグメンテーションポリシーの学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Learning Adaptive Segmentation Policy for End-to-End Simultaneous Translation\n- エンドツーエンド同時翻訳のための適応的セグメンテーションポリシーの学習", "jabstract": "エンドツーエンド同時音声テキスト翻訳は、高品質で低レイテンシーの翻訳を実現するために、ストリーミングソース音声から直接ターゲットテキストへの翻訳を行うことを目的としています。典型的な同時翻訳（ST）システムは、音声翻訳モデルとポリシーモジュールから構成されており、いつ待機し、いつ翻訳するかを決定するポリシーが重要です。したがって、ポリシーは翻訳品質とレイテンシーのバランスを取るために重要です。従来の方法では、ソース音声を固定長でセグメンテーションし、翻訳を生成するなど、固定ポリシーを採用することが一般的でした。しかし、この方法は文脈情報を無視し、翻訳品質が低いという問題があります。本論文では、エンドツーエンドSTのための適応型セグメンテーションポリシーを提案しています。人間の通訳者から着想を得て、ポリシーは音響特徴と翻訳履歴の両方を考慮して、ソースストリーミング音声を意味のある単位に分割することを学習し、セグメンテーションと翻訳の一貫性を維持します。英独と中英の実験結果から、提案手法は最近提案された最先端の手法に比べて、良好な精度とレイテンシーのトレードオフを実現しています。"}
{"title": "Can Pre-trained Language Models Interpret Similes as Smart as Human?", "url": "https://aclanthology.org/2022.acl-long.543/", "abstract": "Simile interpretation is a crucial task in natural language processing. Nowadays, pre-trained language models (PLMs) have achieved state-of-the-art performance on many tasks. However, it remains under-explored whether PLMs can interpret similes or not. In this paper, we investigate the ability of PLMs in simile interpretation by designing a novel task named Simile Property Probing, i.e., to let the PLMs infer the shared properties of similes. We construct our simile property probing datasets from both general textual corpora and human-designed questions, containing 1,633 examples covering seven main categories. Our empirical study based on the constructed datasets shows that PLMs can infer similes’ shared properties while still underperforming humans. To bridge the gap with human performance, we additionally design a knowledge-enhanced training objective by incorporating the simile knowledge into PLMs via knowledge embedding methods. Our method results in a gain of 8.58% in the probing task and 1.37% in the downstream task of sentiment classification. The datasets and code are publicly available at https://github.com/Abbey4799/PLMs-Interpret-Simile.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済み言語モデルは、人間と同じように比喩を解釈できるか？", "jabstract": "類比解釈は自然言語処理において重要なタスクである。現在、事前学習言語モデル（PLMs）は多くのタスクで最先端の性能を発揮している。しかし、PLMsが類比を解釈できるかどうかはまだ十分に探究されていない。本論文では、PLMsの類比解釈能力を調査するために、新しいタスク「Simile Property Probing」を設計し、つまり、PLMsに類比の共通の特性を推論させることを目的とする。我々は、一般的なテキストコーパスと人間が設計した質問から、7つの主要なカテゴリをカバーする1,633の例を含む類比プロパティプロービングデータセットを構築する。構築されたデータセットに基づく実証研究により、PLMsは類比の共通の特性を推論できることが示されたが、まだ人間の性能には及ばない。人間の性能との差を埋めるために、我々は知識埋め込み法を用いて類比知識をPLMsに組み込むことで、知識強化トレーニング目的を追加的に設計した。この方法により、プロービングタスクで8.58％、感情分類の下流タスクで1.37％の利益が得られた。データセットとコードはhttps://github.com/Abbey4799/PLMs-Interpret-Simileで公開されている。"}
{"title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark", "url": "https://aclanthology.org/2022.acl-long.544/", "abstract": "Artificial Intelligence (AI), along with the recent progress in biomedical language understanding, is gradually offering great promise for medical practice. With the development of biomedical language understanding benchmarks, AI applications are widely used in the medical field. However, most benchmarks are limited to English, which makes it challenging to replicate many of the successes in English for other languages. To facilitate research in this direction, we collect real-world biomedical data and present the first Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark: a collection of natural language understanding tasks including named entity recognition, information extraction, clinical diagnosis normalization, single-sentence/sentence-pair classification, and an associated online platform for model evaluation, comparison, and analysis. To establish evaluation on these tasks, we report empirical results with the current 11 pre-trained Chinese models, and experimental results show that state-of-the-art neural models perform by far worse than the human ceiling.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "CBLUE：中国のバイオメディカル言語理解評価ベンチマーク", "jabstract": "人工知能（AI）は、最近のバイオメディカル言語理解の進歩とともに、医療現場において大きな可能性を持っています。バイオメディカル言語理解のベンチマークの開発により、AIアプリケーションは医療分野で広く使用されています。しかし、ほとんどのベンチマークは英語に限定されているため、他の言語で英語の成功を複製することは困難です。この方向性の研究を促進するために、我々は実世界のバイオメディカルデータを収集し、中国初のバイオメディカル言語理解評価（CBLUE）ベンチマークを提供します。このベンチマークには、固有表現認識、情報抽出、臨床診断の正規化、単文/文ペア分類などの自然言語理解タスクが含まれ、モデルの評価、比較、分析のための関連オンラインプラットフォームも提供されます。これらのタスクの評価を確立するために、現在の11つの事前学習済み中国語モデルについて実証結果を報告し、実験結果は、最先端のニューラルモデルが人間の限界よりもはるかに劣っていることを示しています。"}
{"title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization", "url": "https://aclanthology.org/2022.acl-long.545/", "abstract": "Text summarization aims to generate a short summary for an input text. In this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS) approach, which does not require parallel data for training. Our NAUS first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth. Then, we train an encoder-only non-autoregressive Transformer based on the search result. We also propose a dynamic programming approach for length-control decoding, which is important for the summarization task. Experiments on two datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization, yet largely improving inference efficiency. Further, our algorithm is able to perform explicit length-transfer summary generation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「非自己回帰モデルの学習：教師なし文書要約のための探索から」は、自己回帰モデルに代わる新しいアプローチを提供するために、教師なし文書要約における探索から非自己回帰モデルを学習することを提案しています。この研究では、自己回帰モデルによる文書要約の問題点を指摘し、非自己回帰モデルによる文書要約の有効性を示しています。また、提案手法を用いた実験結果により、非自己回帰モデルが自己回帰モデルよりも優れた性能を発揮することが示されています。", "jabstract": "テキスト要約は、入力テキストの短い要約を生成することを目的としています。本研究では、並列データを必要としない非自己回帰無監督要約（NAUS）アプローチを提案します。NAUSは、まずヒューリスティックに定義されたスコアに向けて編集ベースの検索を実行し、疑似グラウンドトゥルースとして要約を生成します。その後、検索結果に基づいてエンコーダーのみの非自己回帰トランスフォーマーをトレーニングします。また、要約タスクに重要な長さ制御デコーディングのための動的プログラミングアプローチを提案します。2つのデータセットでの実験結果から、NAUSは無監督要約において最先端の性能を発揮し、推論効率を大幅に向上させています。さらに、アルゴリズムは明示的な長さ転送要約生成を実行することができます。"}
{"title": "Learning to Generalize to More: Continuous Semantic Augmentation for Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.546/", "abstract": "The principal task in supervised neural machine translation (NMT) is to learn to generate target sentences conditioned on the source inputs from a set of parallel sentence pairs, and thus produce a model capable of generalizing to unseen instances. However, it is commonly observed that the generalization performance of the model is highly influenced by the amount of parallel data used in training. Although data augmentation is widely used to enrich the training data, conventional methods with discrete manipulations fail to generate diverse and faithful training samples. In this paper, we present a novel data augmentation paradigm termed Continuous Semantic Augmentation (CsaNMT), which augments each training instance with an adjacency semantic region that could cover adequate variants of literal expression under the same meaning. We conduct extensive experiments on both rich-resource and low-resource settings involving various language pairs, including WMT14 English→{German,French}, NIST Chinese→English and multiple low-resource IWSLT translation tasks. The provided empirical evidences show that CsaNMT sets a new level of performance among existing augmentation techniques, improving on the state-of-the-art by a large margin. The core codes are contained in Appendix E.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「より多くの一般化を学ぶための学習：ニューラル機械翻訳のための連続的な意味的拡張」についての論文の要約文です。", "jabstract": "教師ありニューラル機械翻訳（NMT）における主要なタスクは、一連の並列文ペアからソース入力に基づいてターゲット文を生成することを学習し、未知のインスタンスに汎化できるモデルを生成することです。しかし、モデルの汎化性能は、トレーニングに使用される並列データの量に強く影響を受けることが一般的に観察されています。トレーニングデータを豊富にするためにデータ拡張が広く使用されていますが、従来の離散的な操作を用いた方法では、多様で忠実なトレーニングサンプルを生成することができません。本論文では、連続的な意味的拡張（CsaNMT）と呼ばれる新しいデータ拡張パラダイムを提案し、各トレーニングインスタンスに隣接する意味的領域を拡張することで、同じ意味の下で適切なリテラル表現のバリアントをカバーします。WMT14英語→{ドイツ語、フランス語}、NIST中国語→英語、および複数の低リソースIWSLT翻訳タスクを含む、さまざまな言語ペアで豊富なリソースと低リソースの両方の設定で広範な実験を行いました。提供された実証は、CsaNMTが既存の拡張技術の中で新しいパフォーマンスレベルを設定し、最新技術を大幅に改善することを示しています。コアコードは付録Eに含まれています。"}
{"title": "Lexical Knowledge Internalization for Neural Dialog Generation", "url": "https://aclanthology.org/2022.acl-long.547/", "abstract": "We propose knowledge internalization (KI), which aims to complement the lexical knowledge into neural dialog models. Instead of further conditioning the knowledge-grounded dialog (KGD) models on externally retrieved knowledge, we seek to integrate knowledge about each input token internally into the model’s parameters. To tackle the challenge due to the large scale of lexical knowledge, we adopt the contrastive learning approach and create an effective token-level lexical knowledge retriever that requires only weak supervision mined from Wikipedia. We demonstrate the effectiveness and general applicability of our approach on various datasets and diversified model structures.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ニューラル対話生成のための語彙知識内部化」に関する論文の要約文です。\n\nLexical Knowledge Internalization for Neural Dialog Generation", "jabstract": "私たちは、自然言語処理に関する論文の要約文を以下に示します。以下の文を日本語に翻訳してください。\n\n私たちは、知識内部化（KI）を提案し、ニューラル対話モデルに語彙知識を補完することを目的としています。外部から取得した知識に基づく対話（KGD）モデルをさらに条件付けする代わりに、各入力トークンに関する知識をモデルのパラメータに内部的に統合することを目指しています。語彙知識の大規模性による課題に対処するために、対照学習アプローチを採用し、Wikipediaから採掘された弱い監視だけで動作する効果的なトークンレベルの語彙知識リトリーバーを作成します。私たちは、さまざまなデータセットと多様なモデル構造で私たちのアプローチの有効性と一般的な適用性を示します。"}
{"title": "Modeling Syntactic-Semantic Dependency Correlations in Semantic Role Labeling Using Mixture Models", "url": "https://aclanthology.org/2022.acl-long.548/", "abstract": "In this paper, we propose a mixture model-based end-to-end method to model the syntactic-semantic dependency correlation in Semantic Role Labeling (SRL). Semantic dependencies in SRL are modeled as a distribution over semantic dependency labels conditioned on a predicate and an argument word.The semantic label distribution varies depending on Shortest Syntactic Dependency Path (SSDP) hop patterns.We target the variation of semantic label distributions using a mixture model, separately estimating semantic label distributions for different hop patterns and probabilistically clustering hop patterns with similar semantic label distributions.Experiments show that the proposed method successfully learns a cluster assignment reflecting the variation of semantic label distributions.Modeling the variation improves performance in predicting short distance semantic dependencies, in addition to the improvement on long distance semantic dependencies that previous syntax-aware methods have achieved.The proposed method achieves a small but statistically significant improvement over baseline methods in English, German, and Spanish and obtains competitive performance with state-of-the-art methods in English.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「混合モデルを用いた意味役割ラベリングにおける構文意味依存関係相関のモデリング」についての論文の要約です。", "jabstract": "本論文では、シンタックス・セマンティック依存関係の相関をモデル化するために、混合モデルベースのエンドツーエンド手法を提案する。Semantic Role Labeling（SRL）における意味的依存関係は、述語と引数単語に依存する意味的依存関係ラベルの分布としてモデル化される。意味的ラベル分布は、最短シンタックス依存パス（SSDP）ホップパターンに応じて異なる。我々は、混合モデルを用いて意味的ラベル分布の変動をターゲットにし、異なるホップパターンに対して意味的ラベル分布を別々に推定し、類似した意味的ラベル分布を持つホップパターンを確率的にクラスタリングする。実験結果は、提案手法が意味的ラベル分布の変動を反映したクラスタ割り当てを成功裏に学習することを示している。変動をモデル化することで、従来の構文に基づく手法が達成した長距離意味的依存関係の改善に加えて、短距離意味的依存関係の予測性能も向上する。提案手法は、英語、ドイツ語、スペイン語でベースライン手法よりもわずかに統計的に有意な改善を達成し、英語では最先端の手法と競合する性能を発揮する。"}
{"title": "Learning the Beauty in Songs: Neural Singing Voice Beautifier", "url": "https://aclanthology.org/2022.acl-long.549/", "abstract": "We are interested in a novel task, singing voice beautification (SVB). Given the singing voice of an amateur singer, SVB aims to improve the intonation and vocal tone of the voice, while keeping the content and vocal timbre. Current automatic pitch correction techniques are immature, and most of them are restricted to intonation but ignore the overall aesthetic quality. Hence, we introduce Neural Singing Voice Beautifier (NSVB), the first generative model to solve the SVB task, which adopts a conditional variational autoencoder as the backbone and learns the latent representations of vocal tone. In NSVB, we propose a novel time-warping approach for pitch correction: Shape-Aware Dynamic Time Warping (SADTW), which ameliorates the robustness of existing time-warping approaches, to synchronize the amateur recording with the template pitch curve. Furthermore, we propose a latent-mapping algorithm in the latent space to convert the amateur vocal tone to the professional one. To achieve this, we also propose a new dataset containing parallel singing recordings of both amateur and professional versions. Extensive experiments on both Chinese and English songs demonstrate the effectiveness of our methods in terms of both objective and subjective metrics. Audio samples are available at https://neuralsvb.github.io. Codes: https://github.com/MoonInTheRiver/NeuralSVB.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "歌における美しさの学習：ニューラル歌声美化器\n\nAbstract:\nIn this paper, we propose a neural singing voice beautifier that enhances the beauty of singing voices. The proposed model is based on a deep neural network that learns the relationship between the acoustic features of singing voices and their perceived beauty. We train the model on a large dataset of professionally recorded singing voices and evaluate its performance on a set of subjective listening tests. The results show that the proposed model significantly improves the perceived beauty of singing voices, outperforming state-of-the-art methods. Our model can be used as a tool for enhancing the quality of singing voices in various applications, such as music production, karaoke, and vocal training.", "jabstract": "私たちは、新しいタスクである歌声美化（SVB）に興味を持っています。アマチュア歌手の歌声が与えられた場合、SVBは、内容と声質を維持しながら、音程と声のトーンを改善することを目的としています。現在の自動ピッチ補正技術は未熟であり、ほとんどのものが音程に制限され、全体的な美的品質を無視しています。したがって、私たちは、SVBタスクを解決する最初の生成モデルであるニューラル歌声美化器（NSVB）を導入します。NSVBは、条件付き変分オートエンコーダをバックボーンとして採用し、声のトーンの潜在表現を学習します。NSVBでは、ピッチ補正のための新しいタイムワーピングアプローチであるShape-Aware Dynamic Time Warping（SADTW）を提案し、アマチュア録音をテンプレートピッチ曲線に同期させるために既存のタイムワーピングアプローチの堅牢性を改善します。さらに、アマチュアの声のトーンをプロのものに変換するための潜在マッピングアルゴリズムを提案します。これを実現するために、アマチュア版とプロ版の両方の平行な歌唱録音を含む新しいデータセットも提案します。中国語と英語の両方の曲についての広範な実験により、客観的および主観的指標の両方において、私たちの手法の有効性が示されました。オーディオサンプルはhttps://neuralsvb.github.ioで入手できます。コード：https://github.com/MoonInTheRiver/NeuralSVB。"}
{"title": "A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation", "url": "https://aclanthology.org/2022.acl-long.550/", "abstract": "Towards building intelligent dialogue agents, there has been a growing interest in introducing explicit personas in generation models. However, with limited persona-based dialogue data at hand, it may be difficult to train a dialogue generation model well. We point out that the data challenges of this generation task lie in two aspects: first, it is expensive to scale up current persona-based dialogue datasets; second, each data sample in this task is more complex to learn with than conventional dialogue data. To alleviate the above data issues, we propose a data manipulation method, which is model-agnostic to be packed with any persona-based dialogue generation model to improve their performance. The original training samples will first be distilled and thus expected to be fitted more easily. Next, we show various effective ways that can diversify such easier distilled data. A given base model will then be trained via the constructed data curricula, i.e. first on augmented distilled samples and then on original ones. Experiments illustrate the superiority of our method with two strong base dialogue models (Transformer encoder-decoder and GPT2).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ペルソナに基づく対話生成のためのモデルに依存しないデータ操作方法」に関する論文の要約文です。", "jabstract": "知的な対話エージェントを構築するために、生成モデルに明示的なペルソナを導入することに関心が高まっています。しかし、限られたペルソナベースの対話データしか手元にないため、対話生成モデルを十分に訓練することは困難かもしれません。この生成タスクのデータ上の課題は、2つの側面にあることを指摘します。第一に、現在のペルソナベースの対話データセットを拡大するのはコストがかかります。第二に、このタスクの各データサンプルは、従来の対話データよりも複雑で学習が難しいです。上記のデータ問題を緩和するために、我々はデータ操作方法を提案します。この方法は、どのペルソナベースの対話生成モデルにもパックできるモデルに依存しないもので、パフォーマンスを向上させることができます。最初に、元のトレーニングサンプルを蒸留し、より簡単に適合することが期待されます。次に、このような簡単に蒸留されたデータを多様化するためのさまざまな効果的な方法を示します。与えられたベースモデルは、構築されたデータカリキュラムに従ってトレーニングされます。つまり、まず拡張された蒸留サンプルで、次に元のサンプルでトレーニングされます。実験は、2つの強力なベース対話モデル（TransformerエンコーダーデコーダーとGPT2）で我々の方法の優越性を示しています。"}
{"title": "LinkBERT: Pretraining Language Models with Document Links", "url": "https://aclanthology.org/2022.acl-long.551/", "abstract": "Language model (LM) pretraining captures various knowledge from text corpora, helping downstream tasks. However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents. In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks. Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context. We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. We show that LinkBERT outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links). LinkBERT is especially effective for multi-hop reasoning and few-shot QA (+5% absolute improvement on HotpotQA and TriviaQA), and our biomedical LinkBERT sets new states of the art on various BioNLP tasks (+7% on BioASQ and USMLE). We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "LinkBERT: ドキュメントリンクを用いた言語モデルの事前学習", "jabstract": "言語モデル（LM）の事前学習は、テキストコーパスから様々な知識を抽出し、下流タスクを支援する。しかし、BERTなどの既存の方法は単一の文書をモデル化し、文書間の依存関係や知識を捉えることができない。本研究では、文書間のリンク（例えばハイパーリンク）を活用するLM事前学習方法であるLinkBERTを提案する。テキストコーパスを文書のグラフとして捉え、リンクされた文書を同じ文脈に配置してLM入力を作成する。そして、マスクされた言語モデリングと新しい提案である文書関係予測の2つの共同自己教師あり目的でLMを事前学習する。LinkBERTは、一般ドメイン（ハイパーリンクを持つWikipediaで事前学習）とバイオメディカルドメイン（引用リンクを持つPubMedで事前学習）の2つのドメインで、様々な下流タスクでBERTを上回ることを示した。LinkBERTは、マルチホップ推論とフューショットQAに特に効果的であり、HotpotQAとTriviaQAで+5％の絶対改善を達成し、バイオNLPタスクの様々な分野で新しい最高値を記録した（BioASQとUSMLEで+7％）。我々は、事前学習モデルのLinkBERTとBioLinkBERT、コード、データを公開する。"}
{"title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs", "url": "https://aclanthology.org/2022.acl-long.552/", "abstract": "Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "時間的知識グラフに対する質問応答の時間感度の向上", "jabstract": "時間的知識グラフ上の質問応答は、自然言語の質問（例：「オバマの前のアメリカ合衆国大統領は誰でしたか？」）に答えるために、エンティティ関係とそれらが時間において発生する時期を記録する時間的知識グラフに含まれる事実を効率的に利用します。これらの質問には、以前の研究が十分に対処できなかった3つの時間関連の課題がしばしば含まれます：1）質問はしばしば興味のある正確なタイムスタンプを指定しない（例：「2000年」ではなく「オバマ」）；2）時間関係の微妙な語彙的違い（例：「前」vs「後」）；3）以前の研究で構築されたオフシェルフの時間的知識グラフ埋め込みは、タイムスタンプの時間的順序を無視するため、時間的順序に関連する質問に答えるためには重要です。本論文では、これらの問題に対処するために、時間に敏感な質問応答（TSQA）フレームワークを提案します。TSQAには、質問から書かれていないタイムスタンプを推定するタイムスタンプ推定モジュールがあります。また、時間に敏感なKGエンコーダを使用して、TSQAが基づく時間的KG埋め込みに順序情報を注入します。潜在的な回答の検索空間を減らす技術の支援を受けて、TSQAは、時間的KG上の質問応答の新しいベンチマークで以前の最先端を大幅に上回り、特に複数のステップの推論が必要な複雑な質問において32％（絶対）のエラー削減を達成します。"}
{"title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition", "url": "https://aclanthology.org/2022.acl-long.553/", "abstract": "Phonemes are defined by their relationship to words: changing a phoneme changes the word. Learning a phoneme inventory with little supervision has been a longstanding challenge with important applications to under-resourced speech technology. In this paper, we bridge the gap between the linguistic and statistical definition of phonemes and propose a novel neural discrete representation learning model for self-supervised learning of phoneme inventory with raw speech and word labels. Under mild assumptions, we prove that the phoneme inventory learned by our approach converges to the true one with an exponentially low error rate. Moreover, in experiments on TIMIT and Mboshi benchmarks, our approach consistently learns a better phoneme-level representation and achieves a lower error rate in a zero-resource phoneme recognition task than previous state-of-the-art self-supervised representation learning algorithms.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自己教育された意味駆動の音素発見によるゼロリソース音声認識", "jabstract": "音素は単語との関係によって定義されます。音素を変更すると単語が変わります。少ない監視で音声技術のリソース不足に重要な応用がある音素の在庫を学習することは、長年の課題でした。本論文では、言語学的および統計的な音素の定義のギャップを埋め、生の音声と単語ラベルを用いた自己監督学習のための新しいニューラル離散表現学習モデルを提案します。穏やかな仮定の下、我々のアプローチによって学習された音素在庫が真の音素在庫に指数的に低い誤差率で収束することを証明します。さらに、TIMITおよびMboshiベンチマークの実験では、我々のアプローチが一貫してより良い音素レベルの表現を学習し、従来の最先端の自己監督表現学習アルゴリズムよりもゼロリソース音素認識タスクで低い誤差率を達成します。"}
{"title": "Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions", "url": "https://aclanthology.org/2022.acl-long.554/", "abstract": "Neural language models (LMs) such as GPT-2 estimate the probability distribution over the next word by a softmax over the vocabulary. The softmax layer produces the distribution based on the dot products of a single hidden state and the embeddings of words in the vocabulary. However, we discover that this single hidden state cannot produce all probability distributions regardless of the LM size or training data size because the single hidden state embedding cannot be close to the embeddings of all the possible next words simultaneously when there are other interfering word embeddings between them. In this work, we demonstrate the importance of this limitation both theoretically and practically. Our work not only deepens our understanding of softmax bottleneck and mixture of softmax (MoS) but also inspires us to propose multi-facet softmax (MFS) to address the limitations of MoS. Extensive empirical analyses confirm our findings and show that against MoS, the proposed MFS achieves two-fold improvements in the perplexity of GPT-2 and BERT.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ソフトマックスのボトルネックは、言語モデルが多モードの単語分布を表現できなくする。", "jabstract": "ニューラル言語モデル（LM）は、GPT-2などのモデルは、語彙に対する埋め込みと単一の隠れ状態のドット積に基づいて、ソフトマックス層を使用して次の単語の確率分布を推定します。しかし、我々は、他の干渉する単語の埋め込みがある場合、単一の隠れ状態の埋め込みが同時にすべての可能な次の単語の埋め込みに近づくことができないため、この単一の隠れ状態では、LMのサイズやトレーニングデータのサイズに関係なく、すべての確率分布を生成できないことを発見しました。本研究では、この制限の重要性を理論的にも実践的にも示し、ソフトマックスのボトルネックとソフトマックスの混合（MoS）の制限を深めるだけでなく、MoSの制限に対処するためにマルチファセットソフトマックス（MFS）を提案することを示唆しています。広範な実証分析により、提案されたMFSは、GPT-2とBERTのPerplexityにおいてMoSに対して2倍の改善を実現することが示されています。"}
{"title": "Ditch the Gold Standard: Re-evaluating Conversational Question Answering", "url": "https://aclanthology.org/2022.acl-long.555/", "abstract": "Conversational question answering aims to provide natural-language answers to users in information-seeking conversations. Existing conversational QA benchmarks compare models with pre-collected human-human conversations, using ground-truth answers provided in conversational history. It remains unclear whether we can rely on this static evaluation for model development and whether current systems can well generalize to real-world human-machine conversations. In this work, we conduct the first large-scale human evaluation of state-of-the-art conversational QA systems, where human evaluators converse with models and judge the correctness of their answers. We find that the distribution of human machine conversations differs drastically from that of human-human conversations, and there is a disagreement between human and gold-history evaluation in terms of model ranking. We further investigate how to improve automatic evaluations, and propose a question rewriting mechanism based on predicted history, which better correlates with human judgments. Finally, we analyze the impact of various modeling strategies and discuss future directions towards building better conversational question answering systems.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ゴールドスタンダードを捨てよ：会話型質問応答の再評価", "jabstract": "会話型質問応答は、情報検索の会話において自然言語でユーザーに回答を提供することを目的としています。既存の会話型QAベンチマークは、人間-人間の会話を事前に収集し、会話履歴で提供される正解を使用してモデルを比較します。この静的評価をモデル開発に頼ることができるか、また現在のシステムが現実世界の人間-機械の会話にうまく一般化できるかどうかは不明です。本研究では、最新の会話型QAシステムの初の大規模な人間評価を実施し、人間の評価者がモデルと会話し、回答の正確さを判断します。人間とゴールド履歴の評価において、人間-機械の会話の分布が人間-人間の会話と大きく異なり、モデルのランキングに関して意見が分かれていることがわかりました。さらに、自動評価を改善する方法を調査し、予測された履歴に基づく質問書き換えメカニズムを提案し、人間の判断とよりよく相関することを示しました。最後に、さまざまなモデリング戦略の影響を分析し、より良い会話型質問応答システムの構築に向けた将来の方向性について議論します。"}
{"title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity", "url": "https://aclanthology.org/2022.acl-long.556/", "abstract": "When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are “fantastic” and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13% relative improvement for GPT-family models across eleven different established text classification tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ファンタスティックに整理されたプロンプトとその発見場所：フューショット・プロンプト順序感受性の克服」\n\n自然言語処理に関する論文の要約文です。", "jabstract": "ごくわずかなトレーニングサンプルのみでプライムされたGPT-3などの非常に大きな事前学習言語モデルは、完全に監視された、ファインチューニングされた、大規模な事前学習言語モデルと比較して競争力のある結果を示しています。私たちは、提供されるサンプルの順序が、ほぼ最新の状態とランダムな推測のパフォーマンスの違いを生むことを示します。つまり、いくつかの順列は「素晴らしい」ものであり、いくつかはそうではありません。私たちは、この現象を詳しく分析し、次のことを確立しました。それはモデルサイズ全体に存在し（現在の最大のモデルでも）、特定のサンプルのサブセットに関連していないこと、そして1つのモデルにとって良い順列が別のモデルに移植できないことです。開発セットを使用してパフォーマンスの良い順列を決定することができますが、これは追加の注釈付きデータが必要であり、真のフューショット設定から逸脱します。代わりに、言語モデルの生成的性質を利用して人工的な開発セットを構築し、このセット上の候補の順列のエントロピー統計に基づいて、パフォーマンスの良いプロンプトを特定します。私たちの方法は、11種類の確立されたテキスト分類タスク全体でGPTファミリーモデルに対して13％の相対的な改善をもたらします。"}
{"title": "Situated Dialogue Learning through Procedural Environment Generation", "url": "https://aclanthology.org/2022.acl-long.557/", "abstract": "We teach goal-driven agents to interactively act and speak in situated environments by training on generated curriculums. Our agents operate in LIGHT (Urbanek et al. 2019)—a large-scale crowd-sourced fantasy text adventure game wherein an agent perceives and interacts with the world through textual natural language. Goals in this environment take the form of character-based quests, consisting of personas and motivations. We augment LIGHT by learning to procedurally generate additional novel textual worlds and quests to create a curriculum of steadily increasing difficulty for training agents to achieve such goals. In particular, we measure curriculum difficulty in terms of the rarity of the quest in the original training distribution—an easier environment is one that is more likely to have been found in the unaugmented dataset. An ablation study shows that this method of learning from the tail of a distribution results in significantly higher generalization abilities as measured by zero-shot performance on never-before-seen quests.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「手順環境生成を通じた状況対話学習」に関する論文の要約文です。以下、日本語に翻訳してください。\n\n- Situated Dialogue Learning through Procedural Environment Generation\n- 手順環境生成を通じた状況対話学習", "jabstract": "私たちは生成されたカリキュラムでトレーニングすることにより、目的志向エージェントが状況に即して相互作用し、話すことを教えます。私たちのエージェントは、LIGHT（Urbanek et al. 2019）で動作します。これは、テキスト自然言語を介して世界を知覚し、相互作用する大規模なクラウドソーシングファンタジーテキストアドベンチャーゲームです。この環境での目標は、人物と動機から成るキャラクターベースのクエストの形を取ります。私たちは、LIGHTを拡張し、追加の新しいテキストワールドとクエストを手続き的に生成することで、エージェントがそのような目標を達成するための徐々に難易度が上がるカリキュラムを作成します。特に、私たちは、カリキュラムの難易度を、元のトレーニング分布のクエストの希少性で測定します。より簡単な環境は、拡張されていないデータセットでより頻繁に見つかる可能性があるためです。削除研究により、分布のテールから学習するこの方法は、前例のないクエストに対するゼロショットパフォーマンスによって測定される汎化能力が大幅に向上することが示されています。"}
{"title": "UniTE: Unified Translation Evaluation", "url": "https://aclanthology.org/2022.acl-long.558/", "abstract": "Translation quality evaluation plays a crucial role in machine translation. According to the input format, it is mainly separated into three tasks, i.e., reference-only, source-only and source-reference-combined. Recent methods, despite their promising results, are specifically designed and optimized on one of them. This limits the convenience of these methods, and overlooks the commonalities among tasks. In this paper, we propose , which is the first unified framework engaged with abilities to handle all three evaluation tasks. Concretely, we propose monotonic regional attention to control the interaction among input segments, and unified pretraining to better adapt multi-task training. We testify our framework on WMT 2019 Metrics and WMT 2020 Quality Estimation benchmarks. Extensive analyses show that our single model can universally surpass various state-of-the-art or winner methods across tasks.Both source code and associated models are available at https://github.com/NLP2CT/UniTE.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Framework for Natural Language Processing\n\n自然言語処理における統一翻訳評価フレームワークUniTEについての論文の要旨です。", "jabstract": "自然言語処理に関する論文の要約を以下に示す。以下の文章を日本語に翻訳せよ。\n\n機械翻訳において、翻訳品質の評価は重要な役割を果たす。入力形式に応じて、主に参照のみ、ソースのみ、ソースと参照の組み合わせの3つのタスクに分けられる。最近の手法は、有望な結果にもかかわらず、それらのうちの1つに特化して設計および最適化されている。これにより、これらの手法の利便性が制限され、タスク間の共通点が見落とされている。本論文では、これらの3つの評価タスクをすべて処理できる最初の統一フレームワークを提案する。具体的には、入力セグメント間の相互作用を制御するための単調な地域的な注意と、マルチタスクトレーニングに適応するための統一された事前学習を提案する。WMT 2019 MetricsおよびWMT 2020 Quality Estimationベンチマークでフレームワークを検証する。詳細な分析により、単一モデルがタスク全体でさまざまな最先端または優勝手法を普遍的に上回ることが示された。ソースコードと関連するモデルは、https://github.com/NLP2CT/UniTEで入手可能である。"}
{"title": "Program Transfer for Answering Complex Questions over Knowledge Bases", "url": "https://aclanthology.org/2022.acl-long.559/", "abstract": "Program induction for answering complex questions over knowledge bases (KBs) aims to decompose a question into a multi-step program, whose execution against the KB produces the final answer. Learning to induce programs relies on a large number of parallel question-program pairs for the given KB. However, for most KBs, the gold program annotations are usually lacking, making learning difficult. In this paper, we propose the approach of program transfer, which aims to leverage the valuable program annotations on the rich-resourced KBs as external supervision signals to aid program induction for the low-resourced KBs that lack program annotations. For program transfer, we design a novel two-stage parsing framework with an efficient ontology-guided pruning strategy. First, a sketch parser translates the question into a high-level program sketch, which is the composition of functions. Second, given the question and sketch, an argument parser searches the detailed arguments from the KB for functions. During the searching, we incorporate the KB ontology to prune the search space. The experiments on ComplexWebQuestions and WebQuestionSP show that our method outperforms SOTA methods significantly, demonstrating the effectiveness of program transfer and our framework. Our codes and datasets can be obtained from https://github.com/THU-KEG/ProgramTransfer.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "知識ベース上で複雑な質問に答えるためのプログラム転送", "jabstract": "知識ベース（KB）上で複雑な質問に答えるためのプログラム誘導は、質問をマルチステッププログラムに分解し、KBに対する実行によって最終的な答えを生成することを目的としています。プログラム誘導の学習は、与えられたKBの大量の並列質問-プログラムペアに依存します。しかし、ほとんどのKBにおいて、金のプログラム注釈は通常欠落しており、学習が困難になっています。本論文では、プログラム転送アプローチを提案し、豊富なリソースを持つKB上の貴重なプログラム注釈を外部の監視信号として活用し、プログラム注釈が欠落している低リソースKBのプログラム誘導を支援することを目的としています。プログラム転送には、効率的なオントロジーによる剪定戦略を備えた新しい2段階の解析フレームワークを設計しています。最初に、スケッチ解析器が質問を高レベルのプログラムスケッチに変換し、関数の合成になります。次に、質問とスケッチが与えられた場合、引数解析器が関数の詳細な引数をKBから検索します。検索中に、KBオントロジーを組み込んで検索空間を剪定します。ComplexWebQuestionsとWebQuestionSPの実験結果は、プログラム転送とフレームワークの有効性を示し、SOTA方法を大幅に上回ることを示しています。私たちのコードとデータセットは、https://github.com/THU-KEG/ProgramTransferから入手できます。"}
{"title": "EAG: Extract and Generate Multi-way Aligned Corpus for Complete Multi-lingual Neural Machine Translation", "url": "https://aclanthology.org/2022.acl-long.560/", "abstract": "Complete Multi-lingual Neural Machine Translation (C-MNMT) achieves superior performance against the conventional MNMT by constructing multi-way aligned corpus, i.e., aligning bilingual training examples from different language pairs when either their source or target sides are identical. However, since exactly identical sentences from different language pairs are scarce, the power of the multi-way aligned corpus is limited by its scale. To handle this problem, this paper proposes “Extract and Generate” (EAG), a two-step approach to construct large-scale and high-quality multi-way aligned corpus from bilingual data. Specifically, we first extract candidate aligned examples by pairing the bilingual examples from different language pairs with highly similar source or target sentences; and then generate the final aligned examples from the candidates with a well-trained generation model. With this two-step pipeline, EAG can construct a large-scale and multi-way aligned corpus whose diversity is almost identical to the original bilingual corpus. Experiments on two publicly available datasets i.e., WMT-5 and OPUS-100, show that the proposed method achieves significant improvements over strong baselines, with +1.1 and +1.4 BLEU points improvements on the two datasets respectively.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "EAG：完全な多言語ニューラルマシン翻訳のための抽出および生成多方向アラインドコーパス", "jabstract": "完全な多言語ニューラル機械翻訳（C-MNMT）は、異なる言語ペアのバイリンガルトレーニング例を多方向に整列させることにより、従来のMNMTに比べて優れた性能を発揮します。ただし、異なる言語ペアから完全に同一の文が得られることはまれであるため、多方向に整列されたコーパスのパワーはそのスケールに制限されます。この問題を解決するため、本論文では「抽出と生成」（EAG）という2段階のアプローチを提案し、バイリンガルデータから大規模で高品質な多方向に整列されたコーパスを構築します。具体的には、まず、高度に類似したソースまたはターゲット文と異なる言語ペアのバイリンガル例をペアリングして候補の整列例を抽出し、その後、よく訓練された生成モデルで候補から最終的な整列例を生成します。この2段階のパイプラインにより、EAGは、多様性が元のバイリンガルコーパスとほぼ同じである大規模で多方向に整列されたコーパスを構築できます。WMT-5およびOPUS-100という2つの公開データセットでの実験結果は、提案手法が強力なベースラインに比べて有意な改善を達成し、それぞれ2つのデータセットで+1.1および+1.4 BLEUポイントの改善が見られました。"}
{"title": "Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings", "url": "https://aclanthology.org/2022.acl-long.561/", "abstract": "Although contextualized embeddings generated from large-scale pre-trained models perform well in many tasks, traditional static embeddings (e.g., Skip-gram, Word2Vec) still play an important role in low-resource and lightweight settings due to their low computational cost, ease of deployment, and stability. In this paper, we aim to improve word embeddings by 1) incorporating more contextual information from existing pre-trained models into the Skip-gram framework, which we call Context-to-Vec; 2) proposing a post-processing retrofitting method for static embeddings independent of training by employing priori synonym knowledge and weighted vector distribution. Through extrinsic and intrinsic tasks, our methods are well proven to outperform the baselines by a large margin.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文脈からベクトルへのグラフ改修を用いた単語埋め込みの改善について", "jabstract": "大規模な事前学習モデルから生成された文脈埋め込みは多くのタスクで良い性能を発揮するが、低リソースや軽量な環境では、低い計算コスト、展開の容易さ、安定性のために従来の静的埋め込み（例：Skip-gram、Word2Vec）が重要な役割を果たしている。本論文では、1）既存の事前学習モデルからより多くの文脈情報をSkip-gramフレームワークに組み込むことで単語埋め込みを改善する「Context-to-Vec」を提案し、2）事前の同義語知識と重み付けベクトル分布を用いた静的埋め込みの事後処理リトロフィット法を提案する。外的および内的タスクにより、我々の手法は大幅にベースラインを上回ることが証明されている。"}
{"title": "Multimodal Sarcasm Target Identification in Tweets", "url": "https://aclanthology.org/2022.acl-long.562/", "abstract": "Sarcasm is important to sentiment analysis on social media. Sarcasm Target Identification (STI) deserves further study to understand sarcasm in depth. However, text lacking context or missing sarcasm target makes target identification very difficult. In this paper, we introduce multimodality to STI and present Multimodal Sarcasm Target Identification (MSTI) task. We propose a novel multi-scale cross-modality model that can simultaneously perform textual target labeling and visual target detection. In the model, we extract multi-scale visual features to enrich spatial information for different sized visual sarcasm targets. We design a set of convolution networks to unify multi-scale visual features with textual features for cross-modal attention learning, and correspondingly a set of transposed convolution networks to restore multi-scale visual information. The results show that visual clues can improve the performance of TSTI by a large margin, and VSTI achieves good accuracy.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ツイートにおける多様なモーダルの皮肉のターゲットの特定", "jabstract": "社交メディアにおける感情分析において、皮肉は重要である。皮肉の深い理解を得るために、皮肉の対象特定（STI）についてのさらなる研究が必要である。しかし、文脈が欠落したり、皮肉の対象が欠落しているテキストは、対象特定を非常に困難にする。本論文では、STIに多様性を導入し、多様性皮肉の対象特定（MSTI）タスクを提案する。我々は、テキストの対象ラベリングと視覚的対象検出を同時に行うことができる新しいマルチスケールクロスモダリティモデルを提案する。モデルでは、異なるサイズの視覚的皮肉の対象のために空間情報を豊富にするために、マルチスケールの視覚的特徴を抽出する。我々は、クロスモーダルな注意学習のために、マルチスケールの視覚的特徴をテキスト特徴と統合する一連の畳み込みネットワークを設計し、それに対応して、マルチスケールの視覚的情報を復元する一連の転置畳み込みネットワークを設計する。結果は、視覚的手がかりがTSTIの性能を大幅に向上させることができ、VSTIは良好な精度を達成していることを示している。"}
{"title": "Flexible Generation from Fragmentary Linguistic Input", "url": "https://aclanthology.org/2022.acl-long.563/", "abstract": "The dominant paradigm for high-performance models in novel NLP tasks today is direct specialization for the task via training from scratch or fine-tuning large pre-trained models. But does direct specialization capture how humans approach novel language tasks? We hypothesize that human performance is better characterized by flexible inference through composition of basic computational motifs available to the human language user. To test this hypothesis, we formulate a set of novel fragmentary text completion tasks, and compare the behavior of three direct-specialization models against a new model we introduce, GibbsComplete, which composes two basic computational motifs central to contemporary models: masked and autoregressive word prediction. We conduct three types of evaluation: human judgments of completion quality, satisfaction of syntactic constraints imposed by the input fragment, and similarity to human behavior in the structural statistics of the completions. With no task-specific parameter tuning, GibbsComplete performs comparably to direct-specialization models in the first two evaluations, and outperforms all direct-specialization models in the third evaluation. These results support our hypothesis that human behavior in novel language tasks and environments may be better characterized by flexible composition of basic computational motifs rather than by direct specialization.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "断片的な言語入力からの柔軟な生成", "jabstract": "現代の自然言語処理タスクにおいて、高性能モデルの主流は、スクラッチからのトレーニングまたは大規模な事前学習モデルのファインチューニングによる直接のタスク専用モデルです。しかし、直接の専門化は、人間が新しい言語タスクに取り組む方法を捉えているのでしょうか？私たちは、人間のパフォーマンスは、人間の言語ユーザーが利用できる基本的な計算モチーフの柔軟な推論によってよりよく特徴付けられると仮説を立てています。この仮説を検証するために、私たちは新しい断片的なテキスト補完タスクのセットを定式化し、3つの直接専門化モデルの振る舞いを、私たちが紹介する新しいモデルであるGibbsCompleteと比較します。GibbsCompleteは、現代のモデルに中心的な2つの基本的な計算モチーフ、マスクされた単語予測と自己回帰的単語予測を組み合わせます。私たちは、3つの評価を行います。補完品質の人間の判断、入力フラグメントに課せられた構文制約の満足度、および補完の構造統計における人間の行動との類似性。タスク固有のパラメータの調整を行わずに、GibbsCompleteは、最初の2つの評価において直接専門化モデルと同等のパフォーマンスを発揮し、第3の評価においては、すべての直接専門化モデルを上回ります。これらの結果は、人間の新しい言語タスクや環境における行動は、直接専門化ではなく、基本的な計算モチーフの柔軟な組み合わせによってよりよく特徴付けられる可能性があることを支持しています。"}
{"title": "Revisiting Over-Smoothness in Text to Speech", "url": "https://aclanthology.org/2022.acl-long.564/", "abstract": "Non-autoregressive text to speech (NAR-TTS) models have attracted much attention from both academia and industry due to their fast generation speed. One limitation of NAR-TTS models is that they ignore the correlation in time and frequency domains while generating speech mel-spectrograms, and thus cause blurry and over-smoothed results. In this work, we revisit this over-smoothing problem from a novel perspective: the degree of over-smoothness is determined by the gap between the complexity of data distributions and the capability of modeling methods. Both simplifying data distributions and improving modeling methods can alleviate the problem. Accordingly, we first study methods reducing the complexity of data distributions. Then we conduct a comprehensive study on NAR-TTS models that use some advanced modeling methods. Based on these studies, we find that 1) methods that provide additional condition inputs reduce the complexity of data distributions to model, thus alleviating the over-smoothing problem and achieving better voice quality. 2) Among advanced modeling methods, Laplacian mixture loss performs well at modeling multimodal distributions and enjoys its simplicity, while GAN and Glow achieve the best voice quality while suffering from increased training or model complexity. 3) The two categories of methods can be combined to further alleviate the over-smoothness and improve the voice quality. 4) Our experiments on the multi-speaker dataset lead to similar conclusions as above and providing more variance information can reduce the difficulty of modeling the target data distribution and alleviate the requirements for model capacity.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Natural Language Processingに関する論文の要約文を日本語に翻訳してください。\n\nテキストから音声への過度な滑らかさの再検討", "jabstract": "非自己回帰テキスト音声合成（NAR-TTS）モデルは、高速な生成速度により、学術界と産業界の両方から注目を集めています。NAR-TTSモデルの制限の1つは、音声メルスペクトログラムを生成する際に時間と周波数領域の相関を無視するため、ぼやけた結果を引き起こすことです。本研究では、この過度の平滑化問題を新しい観点から再検討します。平滑化の度合いは、データ分布の複雑さとモデリング手法の能力のギャップによって決定されるため、データ分布の簡素化とモデリング手法の改善の両方が問題を緩和できます。したがって、まず、データ分布の複雑さを減らす方法を研究します。次に、いくつかの高度なモデリング手法を使用するNAR-TTSモデルについて包括的な研究を行います。これらの研究に基づいて、以下のことがわかりました。1）追加の条件入力を提供する方法は、データ分布の複雑さをモデル化するために簡素化するため、過度の平滑化問題を緩和し、より良い音声品質を実現できます。2）高度なモデリング手法の中で、ラプラシアン混合損失は多峰性分布をモデル化するのに適しており、その単純さを楽しんでいます。一方、GANとGlowはトレーニングまたはモデルの複雑さの増加に苦しんでいるにもかかわらず、最高の音声品質を実現しています。3）2つの方法のカテゴリを組み合わせることで、過度の平滑化をさらに緩和し、音声品質を改善できます。4）マルチスピーカーデータセットでの実験は、上記と同様の結論を導き、より多様性のある情報を提供することで、ターゲットデータ分布のモデリングの難しさを減らし、モデル容量の要件を緩和できます。"}
{"title": "Coherence boosting: When your pretrained language model is not paying enough attention", "url": "https://aclanthology.org/2022.acl-long.565/", "abstract": "Long-range semantic coherence remains a challenge in automatic language generation and understanding. We demonstrate that large language models have insufficiently learned the effect of distant words on next-token prediction. We present coherence boosting, an inference procedure that increases a LM’s focus on a long context. We show the benefits of coherence boosting with pretrained models by distributional analyses of generated ordinary text and dialog responses. It is also found that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "to coherence, you can boost it by fine-tuning on a coherence task.\n\n自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n文脈の強化：事前学習済みの言語モデルが文脈に十分な注意を払っていない場合、文脈タスクで微調整することで強化することができます。", "jabstract": "長距離の意味的一貫性は、自動言語生成と理解において依然として課題である。我々は、大規模言語モデルが遠い単語が次のトークン予測に与える影響を不十分に学習していることを示す。我々は、長い文脈に焦点を当てるLMの推論手順である「一貫性ブースティング」を提案する。我々は、事前学習済みモデルによる一般的なテキストと対話応答の分布分析による一貫性ブースティングの利点を示す。また、ゼロショットNLPタスクの最先端モデルに対する一貫性ブースティングは、追加のトレーニングなしで性能向上をもたらすことがわかった。"}
{"title": "Uncertainty Estimation of Transformer Predictions for Misclassification Detection", "url": "https://aclanthology.org/2022.acl-long.566/", "abstract": "Uncertainty estimation (UE) of model predictions is a crucial step for a variety of tasks such as active learning, misclassification detection, adversarial attack detection, out-of-distribution detection, etc. Most of the works on modeling the uncertainty of deep neural networks evaluate these methods on image classification tasks. Little attention has been paid to UE in natural language processing. To fill this gap, we perform a vast empirical investigation of state-of-the-art UE methods for Transformer models on misclassification detection in named entity recognition and text classification tasks and propose two computationally efficient modifications, one of which approaches or even outperforms computationally intensive methods.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トランスフォーマー予測の不確実性推定による誤分類検出", "jabstract": "モデルの予測の不確実性推定（UE）は、アクティブラーニング、誤分類検出、敵対的攻撃検出、分布外検出など、さまざまなタスクにおいて重要なステップです。深層ニューラルネットワークの不確実性をモデリングする作業のほとんどは、画像分類タスクで評価されています。自然言語処理におけるUEにはあまり注目されていません。このギャップを埋めるために、私たちは、Transformerモデルに対する最新のUE手法の広範な実証的調査を行い、固有表現認識とテキスト分類タスクにおける誤分類検出において、2つの計算効率の高い修正を提案し、そのうちの1つは計算負荷の高い手法に匹敵またはそれを上回る性能を発揮します。"}
{"title": "VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena", "url": "https://aclanthology.org/2022.acl-long.567/", "abstract": "We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V&L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&L models from a linguistic perspective, complementing the canonical task-centred V&L evaluations.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "VALSE：言語現象を中心にしたビジョンと言語モデルのタスク非依存ベンチマーク", "jabstract": "私たちは、自然言語処理に関する論文の要約文を以下に示します。日本語に翻訳してください。\n\n私たちは、一般的な事前学習済みのビジョンと言語（V＆L）モデルの視覚言語接続能力を特定の言語現象に対してテストするために設計された新しいベンチマークであるVALSE（Vision And Language Structured Evaluation）を提案します。VALSEは、さまざまな言語構造をカバーする6つのテストスイートを提供します。これらを解決するには、モデルが視覚的モダリティで言語現象を接続する必要があり、これまでに比べてより詳細な評価が可能になります。私たちは、有効なフォイルの構築をサポートする方法を使用してVALSEを構築し、5つの広く使用されているV＆Lモデルの評価結果を報告します。私たちの実験は、現在のモデルがほとんどの現象に対処するのが非常に困難であることを示唆しています。したがって、私たちは、VALSEが言語的観点から事前学習済みのV＆Lモデルの将来の進歩を測定するための重要なベンチマークとして役立つことを期待しており、従来のタスク中心のV＆L評価を補完します。"}
{"title": "The Grammar-Learning Trajectories of Neural Language Models", "url": "https://aclanthology.org/2022.acl-long.568/", "abstract": "The learning trajectories of linguistic phenomena in humans provide insight into linguistic representation, beyond what can be gleaned from inspecting the behavior of an adult speaker. To apply a similar approach to analyze neural language models (NLM), it is first necessary to establish that different models are similar enough in the generalizations they make. In this paper, we show that NLMs with different initialization, architecture, and training data acquire linguistic phenomena in a similar order, despite their different end performance. These findings suggest that there is some mutual inductive bias that underlies these models’ learning of linguistic phenomena. Taking inspiration from psycholinguistics, we argue that studying this inductive bias is an opportunity to study the linguistic representation implicit in NLMs.Leveraging these findings, we compare the relative performance on different phenomena at varying learning stages with simpler reference models. Results suggest that NLMs exhibit consistent “developmental” stages. Moreover, we find the learning trajectory to be approximately one-dimensional: given an NLM with a certain overall performance, it is possible to predict what linguistic generalizations it has already acquired.Initial analysis of these stages presents phenomena clusters (notably morphological ones), whose performance progresses in unison, suggesting a potential link between the generalizations behind them.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\nニューラル言語モデルの文法学習の軌跡", "jabstract": "人間の言語現象の学習軌跡は、成人話者の行動を検査することでは得られない言語表現についての洞察を提供する。同様のアプローチを神経言語モデル（NLM）の分析に適用するためには、異なるモデルが行う一般化が十分に類似していることを確立する必要がある。本論文では、異なる初期化、アーキテクチャ、およびトレーニングデータを持つNLMが、異なる最終パフォーマンスにもかかわらず、類似した順序で言語現象を習得することを示す。これらの結果は、これらのモデルの言語現象の学習に基づく相互誘導バイアスがあることを示唆している。心理言語学からのインスピレーションを得て、この相互誘導バイアスを研究することは、NLMに暗黙的に含まれる言語表現を研究する機会であると主張する。これらの発見を活用して、異なる現象における相対的なパフォーマンスを、より単純な参照モデルと比較する。結果は、NLMが一貫した「発達段階」を示すことを示唆している。さらに、学習軌跡はおおよそ一次元であることがわかった。つまり、ある全体的なパフォーマンスを持つNLMが既に習得した言語一般化を予測することができる。これらの段階の初期分析では、形態論的なものを含む現象クラスターが提示され、その背後にある一般化の間に潜在的な関連性があることを示唆している。"}
{"title": "Generating Scientific Definitions with Controllable Complexity", "url": "https://aclanthology.org/2022.acl-long.569/", "abstract": "Unfamiliar terminology and complex language can present barriers to understanding science. Natural language processing stands to help address these issues by automatically defining unfamiliar terms. We introduce a new task and dataset for defining scientific terms and controlling the complexity of generated definitions as a way of adapting to a specific reader’s background knowledge. We test four definition generation methods for this new task, finding that a sequence-to-sequence approach is most successful. We then explore the version of the task in which definitions are generated at a target complexity level. We introduce a novel reranking approach and find in human evaluations that it offers superior fluency while also controlling complexity, compared to several controllable generation baselines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳します。\n\n制御可能な複雑さを持つ科学的定義の生成", "jabstract": "科学の理解には、馴染みのない専門用語や複雑な言語が障壁となることがあります。自然言語処理は、馴染みのない用語を自動的に定義することで、これらの問題に対処することができます。本研究では、読者の背景知識に適応するために、科学用語の定義と生成された定義の複雑さを制御する新しいタスクとデータセットを紹介します。この新しいタスクのために、4つの定義生成方法をテストし、シーケンス・トゥ・シーケンス・アプローチが最も成功したことを発見しました。次に、定義が目標の複雑さレベルで生成されるバージョンのタスクを探索します。我々は新しい再ランキングアプローチを導入し、人間の評価において、いくつかの制御可能な生成ベースラインに比べて、優れた流暢性を提供しながら複雑さを制御することができることを発見しました。"}
{"title": "Label Semantic Aware Pre-training for Few-shot Text Classification", "url": "https://aclanthology.org/2022.acl-long.570/", "abstract": "In text classification tasks, useful information is encoded in the label names. Label semantic aware systems have leveraged this information for improved text classification performance during fine-tuning and prediction. However, use of label-semantics during pre-training has not been extensively explored. We therefore propose Label Semantic Aware Pre-training (LSAP) to improve the generalization and data efficiency of text classification systems. LSAP incorporates label semantics into pre-trained generative models (T5 in our case) by performing secondary pre-training on labeled sentences from a variety of domains. As domain-general pre-training requires large amounts of data, we develop a filtering and labeling pipeline to automatically create sentence-label pairs from unlabeled text. We perform experiments on intent (ATIS, Snips, TOPv2) and topic classification (AG News, Yahoo! Answers). LSAP obtains significant accuracy improvements over state-of-the-art models for few-shot text classification while maintaining performance comparable to state of the art in high-resource settings.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Few-shotテキスト分類のためのラベルセマンティック意識型事前学習", "jabstract": "テキスト分類タスクにおいて、有用な情報はラベル名にエンコードされています。ラベル意味認識システムは、微調整と予測中にこの情報を活用して、テキスト分類のパフォーマンスを改善しています。しかし、事前学習中にラベル意味を使用することは、ほとんど探求されていません。したがって、我々はラベル意味認識事前学習（LSAP）を提案し、テキスト分類システムの汎化とデータ効率を改善します。LSAPは、さまざまなドメインからラベル付き文を二次事前学習することにより、ラベル意味を事前学習された生成モデル（私たちの場合はT5）に組み込みます。ドメイン一般の事前学習には大量のデータが必要なため、我々はフィルタリングとラベリングパイプラインを開発し、ラベルのないテキストから自動的に文-ラベルペアを作成します。我々は意図（ATIS、Snips、TOPv2）とトピック分類（AG News、Yahoo! Answers）の実験を行いました。LSAPは、少数のショットテキスト分類において最新のモデルよりも有意な精度向上を達成し、高リソース設定において最新技術と同等のパフォーマンスを維持します。"}
{"title": "ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation", "url": "https://aclanthology.org/2022.acl-long.571/", "abstract": "Residual networks are an Euler discretization of solutions to Ordinary Differential Equations (ODE). This paper explores a deeper relationship between Transformer and numerical ODE methods. We first show that a residual block of layers in Transformer can be described as a higher-order solution to ODE. Inspired by this, we design a new architecture, ODE Transformer, which is analogous to the Runge-Kutta method that is well motivated in ODE. As a natural extension to Transformer, ODE Transformer is easy to implement and efficient to use. Experimental results on the large-scale machine translation, abstractive summarization, and grammar error correction tasks demonstrate the high genericity of ODE Transformer. It can gain large improvements in model performance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the WMT’14 English-German and English-French benchmarks) at a slight cost in inference efficiency.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ODE Transformer：シーケンス生成のための常微分方程式にインスパイアされたモデル", "jabstract": "残差ネットワークは、常微分方程式（ODE）の解のオイラー離散化です。本論文では、Transformerと数値ODE法のより深い関係を探求します。まず、Transformerの残差ブロックがODEの高階解として記述できることを示します。これに着想を得て、ODE Transformerという新しいアーキテクチャを設計しました。ODE Transformerは、ODEでよく動機づけられるルンゲ・クッタ法に類似しています。Transformerの自然な拡張として、ODE Transformerは実装が容易で効率的です。大規模機械翻訳、要約、文法エラー訂正タスクの実験結果は、ODE Transformerの高い汎用性を示しています。推論効率のわずかなコストで、強力なベースラインに比べて大幅なモデル性能の向上が得られます（例えば、WMT'14英独および英仏ベンチマークで30.77および44.11 BLEUスコア）。"}
{"title": "A Comparison of Strategies for Source-Free Domain Adaptation", "url": "https://aclanthology.org/2022.acl-long.572/", "abstract": "Data sharing restrictions are common in NLP, especially in the clinical domain, but there is limited research on adapting models to new domains without access to the original training data, a setting known as source-free domain adaptation. We take algorithms that traditionally assume access to the source-domain training data—active learning, self-training, and data augmentation—and adapt them for source free domain adaptation. Then we systematically compare these different strategies across multiple tasks and domains. We find that active learning yields consistent gains across all SemEval 2021 Task 10 tasks and domains, but though the shared task saw successful self-trained and data augmented models, our systematic comparison finds these strategies to be unreliable for source-free domain adaptation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自由ソースドメイン適応の戦略の比較", "jabstract": "自然言語処理において、特に臨床領域においてデータ共有制限が一般的であるが、元のトレーニングデータにアクセスできない状況で新しいドメインにモデルを適応させる研究は限られている。このような状況をソースフリードメイン適応と呼ぶ。本研究では、通常ソースドメインのトレーニングデータにアクセスすることを前提とするアルゴリズム、アクティブラーニング、セルフトレーニング、データ拡張をソースフリードメイン適応に適応させ、複数のタスクとドメインでこれらの異なる戦略を系統的に比較した。その結果、アクティブラーニングはすべてのSemEval 2021タスク10タスクとドメインで一貫して利益をもたらすことがわかったが、共有タスクではセルフトレーニングとデータ拡張に成功したモデルがあったものの、系統的な比較ではこれらの戦略はソースフリードメイン適応には信頼性がないことがわかった。"}
{"title": "Ethics Sheets for AI Tasks", "url": "https://aclanthology.org/2022.acl-long.573/", "abstract": "Several high-profile events, such as the mass testing of emotion recognition systems on vulnerable sub-populations and using question answering systems to make moral judgments, have highlighted how technology will often lead to more adverse outcomes for those that are already marginalized. At issue here are not just individual systems and datasets, but also the AI tasks themselves. In this position paper, I make a case for thinking about ethical considerations not just at the level of individual models and datasets, but also at the level of AI tasks. I will present a new form of such an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the assumptions and ethical considerations hidden in how a task is commonly framed and in the choices we make regarding the data, method, and evaluation. I will also present a template for ethics sheets with 50 ethical considerations, using the task of emotion recognition as a running example. Ethics sheets are a mechanism to engage with and document ethical considerations before building datasets and systems. Similar to survey articles, a small number of carefully created ethics sheets can serve numerous researchers and developers.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nAIタスクのための倫理シート", "jabstract": "感情認識システムの大規模な弱者人口へのテストや、道徳的判断を下すために質問応答システムを使用するなど、いくつかの注目すべきイベントが、技術が既にマージナライズされた人々にとってより不利な結果をもたらすことを示しています。問題は、個々のシステムやデータセットだけでなく、AIタスク自体にもあります。このポジションペーパーでは、個々のモデルやデータセットだけでなく、AIタスクのレベルでも倫理的考慮事項を考えることの重要性を主張します。私は、タスクが一般的にどのようにフレーム化され、データ、方法、評価に関する選択に隠れた仮定と倫理的考慮事項を明らかにするために専用の「AIタスクの倫理シート」の新しい形式を提案します。また、感情認識のタスクをランニング例として使用し、50の倫理的考慮事項を含む倫理シートのテンプレートを提示します。倫理シートは、データセットやシステムを構築する前に倫理的考慮事項に取り組み、文書化するためのメカニズムです。調査記事と同様に、少数の注意深く作成された倫理シートは、多数の研究者や開発者に役立ちます。"}
{"title": "Learning Disentangled Representations of Negation and Uncertainty", "url": "https://aclanthology.org/2022.acl-long.574/", "abstract": "Negation and uncertainty modeling are long-standing tasks in natural language processing. Linguistic theory postulates that expressions of negation and uncertainty are semantically independent from each other and the content they modify. However, previous works on representation learning do not explicitly model this independence. We therefore attempt to disentangle the representations of negation, uncertainty, and content using a Variational Autoencoder. We find that simply supervising the latent representations results in good disentanglement, but auxiliary objectives based on adversarial learning and mutual information minimization can provide additional disentanglement gains.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "否定と不確実性の分離表現の学習", "jabstract": "否定と不確実性のモデリングは、自然言語処理における長年の課題です。言語学理論は、否定と不確実性の表現が、それらが修飾する内容と意味的に独立していると仮定しています。しかし、これまでの表現学習に関する研究では、この独立性を明示的にモデル化していませんでした。そこで、Variational Autoencoderを使用して、否定、不確実性、および内容の表現を分離する試みを行いました。潜在表現を単純に監視するだけでも、良好な分離が得られることがわかりましたが、敵対的学習と相互情報最小化に基づく補助的な目的は、追加の分離の利益を提供することができます。"}
{"title": "latent-GLAT: Glancing at Latent Variables for Parallel Text Generation", "url": "https://aclanthology.org/2022.acl-long.575/", "abstract": "Recently, parallel text generation has received widespread attention due to its success in generation efficiency. Although many advanced techniques are proposed to improve its generation quality, they still need the help of an autoregressive model for training to overcome the one-to-many multi-modal phenomenon in the dataset, limiting their applications. In this paper, we propose GLAT, which employs the discrete latent variables to capture word categorical information and invoke an advanced curriculum learning technique, alleviating the multi-modality problem. Experiment results show that our method outperforms strong baselines without the help of an autoregressive model, which further broadens the application scenarios of the parallel decoding paradigm.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「latent-GLAT：潜在変数を一瞥して並列テキスト生成を行う」は、自然言語処理に関する論文の要約です。", "jabstract": "最近、並列テキスト生成は、生成効率の成功により広く注目されています。多くの高度な技術が提案されているにもかかわらず、データセット内の1対多の多様性現象を克服するためにトレーニングに自己回帰モデルの支援が必要であり、その応用範囲が限られています。本論文では、単語のカテゴリ情報を捕捉するために離散的な潜在変数を使用し、高度なカリキュラム学習技術を呼び出すGLATを提案し、多様性問題を緩和します。実験結果は、自己回帰モデルの支援なしで強力なベースラインを上回ることを示し、並列デコーディングパラダイムの応用シナリオをさらに広げることができます。"}
{"title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning", "url": "https://aclanthology.org/2022.acl-long.576/", "abstract": "Prompts for pre-trained language models (PLMs) have shown remarkable performance by bridging the gap between pre-training tasks and various downstream tasks. Among these methods, prompt tuning, which freezes PLMs and only tunes soft prompts, provides an efficient and effective solution for adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to be fully explored. In our pilot experiments, we find that prompt tuning performs comparably with conventional full-model tuning when downstream data are sufficient, whereas it is much worse under few-shot learning settings, which may hinder the application of prompt tuning. We attribute this low performance to the manner of initializing soft prompts. Therefore, in this work, we propose to pre-train prompts by adding soft prompts into the pre-training stage to obtain a better initialization. We name this Pre-trained Prompt Tuning framework “PPT”. To ensure the generalization of PPT, we formulate similar classification tasks into a unified task form and pre-train soft prompts for this unified task. Extensive experiments show that tuning pre-trained prompts for downstream tasks can reach or even outperform full-model fine-tuning under both full-data and few-shot settings. Our approach is effective and efficient for using large-scale PLMs in practice.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nPPT: プリトレーニングされたプロンプトチューニングによるフューショット学習", "jabstract": "事前学習済み言語モデル（PLMs）のプロンプトは、事前学習タスクと様々なダウンストリームタスクのギャップを埋めることで、驚異的なパフォーマンスを発揮しています。その中でも、PLMsを凍結してソフトプロンプトのみを調整するプロンプトチューニングは、大規模なPLMsをダウンストリームタスクに適応させるための効率的かつ効果的な解決策を提供しています。しかし、プロンプトチューニングはまだ完全に探求されていません。私たちのパイロット実験では、ダウンストリームデータが十分な場合、プロンプトチューニングは従来のフルモデルチューニングと同等のパフォーマンスを発揮することがわかりましたが、フューショット学習設定でははるかに劣っており、プロンプトチューニングの応用を妨げる可能性があります。この低いパフォーマンスは、ソフトプロンプトの初期化方法に起因すると考えられます。したがって、本研究では、事前学習段階にソフトプロンプトを追加してプロンプトを事前学習することで、より良い初期化を得ることを提案します。この事前学習済みプロンプトチューニングフレームワークを「PPT」と名付けました。PPTの汎化を確保するために、類似の分類タスクを統一されたタスク形式に形式化し、この統一されたタスクのためにソフトプロンプトを事前学習します。広範な実験により、ダウンストリームタスクのために事前学習されたプロンプトをチューニングすることで、フルデータおよびフューショット設定の両方でフルモデルファインチューニングに達するか、それを上回ることができることが示されました。私たちのアプローチは、実践的に大規模なPLMsを使用するために効果的で効率的です。"}
{"title": "Deduplicating Training Data Makes Language Models Better", "url": "https://aclanthology.org/2022.acl-long.577/", "abstract": "We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings.As a result, over 1% of the unprompted output of language models trained on these datasets is copied verbatim from the training data.We develop two tools that allow us to deduplicate training datasets—for example removing from C4 a single 61 word English sentence that is repeated over 60,000 times.Deduplication allows us to train models that emit memorized text ten times less frequently and require fewer training steps to achieve the same or better accuracy.We can also reduce train-test overlap, which affects over 4% of the validation set of standard datasets, thus allowing for more accurate evaluation.Code for deduplication is released at https://github.com/google-research/deduplicate-text-datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トレーニングデータの重複を削除することで、言語モデルの精度が向上する。", "jabstract": "我々は、既存の言語モデリングデータセットには、多数の近似重複例と長い繰り返し部分文字列が含まれていることを発見しました。その結果、これらのデータセットで訓練された言語モデルの自発的な出力の1％以上が、訓練データから完全にコピーされています。我々は、2つのツールを開発し、訓練データセットを重複排除することができます。たとえば、C4から60,000回以上繰り返される61語の英語の文を1つ削除することができます。重複排除により、記憶されたテキストを10倍以上排出するモデルを訓練し、同じまたはより高い精度を達成するために必要な訓練ステップを減らすことができます。また、標準的なデータセットの検証セットの4％以上に影響を与えるトレイン-テストの重複を減らすこともできます。重複排除のコードは、https://github.com/google-research/deduplicate-text-datasetsで公開されています。"}
{"title": "Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires", "url": "https://aclanthology.org/2022.acl-long.578/", "abstract": "Automated methods have been widely used to identify and analyze mental health conditions (e.g., depression) from various sources of information, including social media. Yet, deployment of such models in real-world healthcare applications faces challenges including poor out-of-domain generalization and lack of trust in black box models. In this work, we propose approaches for depression detection that are constrained to different degrees by the presence of symptoms described in PHQ9, a questionnaire used by clinicians in the depression screening process. In dataset-transfer experiments on three social media datasets, we find that grounding the model in PHQ9’s symptoms substantially improves its ability to generalize to out-of-distribution data compared to a standard BERT-based approach. Furthermore, this approach can still perform competitively on in-domain data. These results and our qualitative analyses suggest that grounding model predictions in clinically-relevant symptoms can improve generalizability while producing a model that is easier to inspect.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "臨床アンケートを活用してうつ病検出の汎用性を向上すること", "jabstract": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n自動化された手法は、ソーシャルメディアを含む様々な情報源から、精神的健康状態（うつ病など）を特定し分析するために広く使用されています。しかし、このようなモデルを現実の医療アプリケーションに展開することには、ドメイン外の一般化の不足やブラックボックスモデルへの信頼の欠如などの課題があります。本研究では、うつ病検査プロセスで臨床医によって使用されるPHQ9に記載された症状の存在によって異なる程度に制約されたうつ病検出のアプローチを提案しています。3つのソーシャルメディアデータセットでのデータセット転送実験において、PHQ9の症状に基づくモデルは、標準的なBERTベースのアプローチに比べて、ドメイン外のデータに対する一般化能力を大幅に向上させることがわかりました。さらに、このアプローチはドメイン内のデータでも競争力のあるパフォーマンスを発揮することができます。これらの結果と質的分析から、臨床的に関連する症状に基づくモデル予測は、一般化能力を向上させ、検査が容易なモデルを生み出すことが示唆されています。"}
{"title": "Internet-Augmented Dialogue Generation", "url": "https://aclanthology.org/2022.acl-long.579/", "abstract": "The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020b).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nインターネット拡張対話生成", "jabstract": "地球上で最も継続的に更新される知識の最大の蓄積は、インターネット検索を通じてアクセスできます。本研究では、この情報を会話エージェントにアクセスさせることを研究しています。大規模言語モデルは、その重み内に印象的な量の知識を保持しているにもかかわらず、ダイアログを生成する際に事実を幻視することが知られています（Shuster et al.、2021）。さらに、それらの事実はモデルトレーニングの時点で凍結されています。それに対して、私たちは、文脈に基づいてインターネット検索クエリを生成する方法を提案し、その後、検索結果に基づいて応答を生成する方法を提案しています。この方法は、最新の関連情報を利用できます。私たちは、知識に基づく議論中にインターネット検索にアクセスできるようになった人間-人間の会話の新しく収集されたデータセットで、このようなモデルをトレーニングおよび評価しました。私たちは、会話中の検索クエリに基づくインターネットへのアクセスが、既存のアプローチ（拡張なしまたはFAISSベースの検索（Lewis et al.、2020b））と比較して優れたパフォーマンスを提供することを発見しました。"}
{"title": "SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities", "url": "https://aclanthology.org/2022.acl-long.580/", "abstract": "Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years. In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks. However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models. SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks. In this paper, we introduce SUPERB-SG, a new benchmark focusing on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB. We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks. It entails freezing pre-trained model parameters, only using simple task-specific trainable heads. The goal is to be inclusive of all researchers, and encourage efficient use of computational resources. We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SUPERB-SG：意味解析と生成能力のための強化音声処理ユニバーサルパフォーマンスベンチマーク", "jabstract": "近年、転移学習は音声および自然言語処理研究の進歩において重要な役割を果たしている。音声においては、自己教師あり学習によって事前学習されたモデルが複数のタスクにおいて驚くほど優れた転移性能を示すことが証明されている。しかし、一貫した評価方法の欠如は、そのようなモデルの効果を包括的に理解することを制限している。SUPERBは、様々な音声タスクにおいて事前学習されたモデルを評価するための共通のベンチマークを導入するための一歩であった。本論文では、SUPERBを上回るタスクの多様性と難易度を持つ、事前学習モデルの意味的および生成的能力を評価するための新しいベンチマークであるSUPERB-SGを紹介する。我々は、事前学習モデルによって学習された表現の堅牢性を、異なるタイプのタスクにおけるデータドメインと品質の変化に対してテストするために、軽量な方法論を使用する。これには、事前学習モデルのパラメータを凍結し、単純なタスク固有のトレーニング可能なヘッドのみを使用する。目標は、すべての研究者を包括し、計算リソースの効率的な使用を促進することである。また、SUPERB-SGのタスクの多様性と限られたタスク監視の組み合わせが、モデル表現の汎化性を評価するための効果的な方法であることを示す。"}
{"title": "Knowledge Neurons in Pretrained Transformers", "url": "https://aclanthology.org/2022.acl-long.581/", "abstract": "Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus. In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons. Specifically, we examine the fill-in-the-blank cloze task for BERT. Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact. We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts. In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning. Our results shed light on understanding the storage of knowledge within pretrained Transformers.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "事前学習済みトランスフォーマーにおける知識ニューロン\n\nWe introduce the concept of knowledge neurons in pretrained transformers, which are individual neurons that are highly activated by specific linguistic features. 我々は、事前学習済みトランスフォーマーにおける知識ニューロンの概念を紹介する。これは、特定の言語的特徴によって高度に活性化される個々のニューロンである。\n\nWe show that knowledge neurons can be used to identify and visualize linguistic patterns in the model, and that they can be used to improve the performance of downstream natural language processing tasks. 我々は、知識ニューロンを使用して、モデル内の言語パターンを特定し、可視化することができることを示し、また、下流の自然言語処理タスクのパフォーマンスを向上させるために使用することができることを示す。\n\nWe also propose a method for identifying and selecting knowledge neurons based on their activation patterns, and we demonstrate the effectiveness of this method on several natural language processing tasks. 我々は、活性化パターンに基づいて知識ニューロンを特定し、選択する方法を提案し、この方法の効果をいくつかの自然言語処理タスクで示す。", "jabstract": "大規模な事前学習言語モデルは、トレーニングコーパスで提示された事実知識を驚くほど正確に記憶することができます。本論文では、知識ニューロンの概念を導入することで、事前学習済みトランスフォーマーにおける事実知識の格納方法についての予備的な研究を行います。具体的には、BERTの穴埋めクローズタスクを調べます。関係性のある事実が与えられた場合、私たちは知識属性方法を提案して、その事実を表現するニューロンを特定します。そのような知識ニューロンの活性化は、それらに対応する事実の表現と正の相関があることがわかりました。私たちの事例研究では、知識ニューロンを活用して、微調整せずに特定の事実知識を編集（更新、削除など）することを試みました。私たちの結果は、事前学習済みトランスフォーマー内での知識の格納方法を理解する上での示唆を与えます。"}
{"title": "Meta-Learning for Fast Cross-Lingual Adaptation in Dependency Parsing", "url": "https://aclanthology.org/2022.acl-long.582/", "abstract": "Meta-learning, or learning to learn, is a technique that can help to overcome resource scarcity in cross-lingual NLP problems, by enabling fast adaptation to new tasks. We apply model-agnostic meta-learning (MAML) to the task of cross-lingual dependency parsing. We train our model on a diverse set of languages to learn a parameter initialization that can adapt quickly to new languages. We find that meta-learning with pre-training can significantly improve upon the performance of language transfer and standard supervised learning baselines for a variety of unseen, typologically diverse, and low-resource languages, in a few-shot learning setup.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "依存構造解析における高速なクロスリンガル適応のためのメタ学習", "jabstract": "メタ学習、すなわち学習することを学ぶことは、新しいタスクに素早く適応することができるため、クロスリンガルNLP問題におけるリソース不足を克服するのに役立つ技術です。我々は、モデルに依存しないメタ学習（MAML）をクロスリンガル依存構造解析のタスクに適用します。我々は、多様な言語でモデルをトレーニングして、新しい言語に素早く適応できるパラメータ初期化を学習します。我々は、事前トレーニングを伴うメタ学習が、多様な未知の、形態論的に異なる、低リソースの言語に対して、少数のショット学習セットアップで、言語転送と標準の教師あり学習のベースラインの性能を大幅に改善することができることを発見しました。"}
{"title": "French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English", "url": "https://aclanthology.org/2022.acl-long.583/", "abstract": "Warning: This paper contains explicit statements of offensive stereotypes which may be upsetting.Much work on biases in natural language processing has addressed biases linked to the social and cultural experience of English speaking individuals in the United States. We seek to widen the scope of bias studies by creating material to measure social bias in language models (LMs) against specific demographic groups in France. We build on the US-centered CrowS-pairs dataset to create a multilingual stereotypes dataset that allows for comparability across languages while also characterizing biases that are specific to each country and language. We introduce 1,679 sentence pairs in French that cover stereotypes in ten types of bias like gender and age. 1,467 sentence pairs are translated from CrowS-pairs and 212 are newly crowdsourced. The sentence pairs contrast stereotypes concerning underadvantaged groups with the same sentence concerning advantaged groups. We find that four widely used language models (three French, one multilingual) favor sentences that express stereotypes in most bias categories. We report on the translation process from English into French, which led to a characterization of stereotypes in CrowS-pairs including the identification of US-centric cultural traits. We offer guidelines to further extend the dataset to other languages and cultural environments.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "フランス語CrowS-Pairs：マスクされた言語モデルの社会的バイアスを測定するためのチャレンジデータセットを英語以外の言語に拡張する。", "jabstract": "警告：この論文には、不快なステレオタイプの明示的な表現が含まれている可能性があります。自然言語処理におけるバイアスに関する多くの研究は、アメリカの英語話者の社会的文化的経験に関連するバイアスに対処してきました。私たちは、フランスの特定の人口グループに対する言語モデル（LM）の社会的バイアスを測定するための材料を作成することによって、バイアス研究の範囲を広げることを目指しています。私たちは、米国中心のCrowS-pairsデータセットを拡張して、言語ごとに特定のバイアスも特徴づける多言語ステレオタイプデータセットを作成します。私たちは、10種類のバイアス（性別や年齢など）に関するステレオタイプをカバーする1,679のフランス語の文のペアを紹介します。1,467の文のペアはCrowS-pairsから翻訳され、212の文のペアは新たにクラウドソーシングされました。文のペアは、不利なグループに関するステレオタイプと有利なグループに関する同じ文を対比させます。私たちは、4つの広く使用されている言語モデル（3つのフランス語、1つの多言語）が、ほとんどのバイアスカテゴリーでステレオタイプを表現する文を好むことを発見しました。私たちは、英語からフランス語への翻訳プロセスについて報告し、CrowS-pairsのステレオタイプの特徴付け、米国中心の文化的特徴の特定を行いました。私たちは、他の言語や文化環境にデータセットをさらに拡張するためのガイドラインを提供します。"}
{"title": "Few-Shot Learning with Siamese Networks and Label Tuning", "url": "https://aclanthology.org/2022.acl-long.584/", "abstract": "We study the problem of building text classifiers with little or no training data, commonly known as zero and few-shot text classification. In recent years, an approach based on neural textual entailment models has been found to give strong results on a diverse range of tasks. In this work, we show that with proper pre-training, Siamese Networks that embed texts and labels offer a competitive alternative. These models allow for a large reduction in inference cost: constant in the number of labels rather than linear. Furthermore, we introduce label tuning, a simple and computationally efficient approach that allows to adapt the models in a few-shot setup by only changing the label embeddings. While giving lower performance than model fine-tuning, this approach has the architectural advantage that a single encoder can be shared by many different tasks.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「シャムネットワークとラベルチューニングを用いたフューショット学習」という論文の要約文を日本語に翻訳します。\n\n- Few-shot learning is a challenging problem in natural language processing.\n- フューショット学習は、自然言語処理における難しい問題です。\n- Siamese networks have shown promising results in few-shot learning tasks.\n- シャムネットワークは、フューショット学習のタスクで有望な結果を示しています。\n- Label tuning is a technique that improves the performance of few-shot learning models.\n- ラベルチューニングは、フューショット学習モデルの性能を向上させる技術です。", "jabstract": "私たちは、少ないまたはほとんどトレーニングデータを使用してテキスト分類器を構築する問題、一般的にゼロおよびフューショットテキスト分類として知られている問題を研究しています。近年、ニューラルテキスト推論モデルに基づくアプローチが、多様なタスクで強力な結果を示すことがわかっています。この研究では、適切な事前トレーニングを行うことで、テキストとラベルを埋め込むシャムネットワークが競争力のある代替手段を提供することを示します。これらのモデルにより、推論コストを大幅に削減できます。ラベルの数に比例するのではなく、定数になります。さらに、ラベルチューニングを導入し、ラベル埋め込みを変更するだけで、モデルをフューショットセットアップに適応させることができる、シンプルで計算効率の良いアプローチを紹介します。モデルのファインチューニングよりも低いパフォーマンスを示しますが、このアプローチには、単一のエンコーダを多くの異なるタスクで共有できるアーキテクチャ上の利点があります。"}
{"title": "Inferring Rewards from Language in Context", "url": "https://aclanthology.org/2022.acl-long.585/", "abstract": "In classic instruction following, language like “I’d like the JetBlue flight” maps to actions (e.g., selecting that flight). However, language also conveys information about a user’s underlying reward function (e.g., a general preference for JetBlue), which can allow a model to carry out desirable actions in new contexts. We present a model that infers rewards from language pragmatically: reasoning about how speakers choose utterances not only to elicit desired actions, but also to reveal information about their preferences. On a new interactive flight–booking task with natural language, our model more accurately infers rewards and predicts optimal actions in unseen environments, in comparison to past work that first maps language to actions (instruction following) and then maps actions to rewards (inverse reinforcement learning).", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "文脈における言語から報酬を推測する", "jabstract": "古典的な指示に従う場合、「JetBlueのフライトが欲しい」という言語は、そのフライトを選択するなどのアクションにマップされます。しかし、言語はまた、ユーザーの基礎となる報酬関数（例えば、JetBlueに対する一般的な好み）についての情報を伝えることができます。これにより、モデルは新しい文脈で望ましいアクションを実行することができます。本論文では、話者が発話を選択する方法について推論することで、言語から報酬を実用的に推論するモデルを提案します。これにより、自分たちの好みに関する情報を明らかにするだけでなく、望ましいアクションを引き出すために発話を選択する話者の推論についても考えます。自然言語を用いた新しい対話型フライト予約タスクにおいて、従来の言語をアクションにマップする（指示に従う）ことから始め、その後アクションを報酬にマップする（逆強化学習）過去の研究と比較して、当モデルは報酬をより正確に推論し、未知の環境で最適なアクションを予測します。"}
{"title": "Generating Biographies on Wikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies", "url": "https://aclanthology.org/2022.acl-long.586/", "abstract": "Generating factual, long-form text such as Wikipedia articles raises three key challenges: how to gather relevant evidence, how to structure information into well-formed text, and how to ensure that the generated text is factually correct. We address these by developing a model for English text that uses a retrieval mechanism to identify relevant supporting information on the web and a cache-based pre-trained encoder-decoder to generate long-form biographies section by section, including citation information. To assess the impact of available web evidence on the output text, we compare the performance of our approach when generating biographies about women (for which less information is available on the web) vs. biographies generally. To this end, we curate a dataset of 1,500 biographies about women. We analyze our generated text to understand how differences in available web evidence data affect generation. We evaluate the factuality, fluency, and quality of the generated texts using automatic metrics and human evaluation. We hope that these techniques can be used as a starting point for human writers, to aid in reducing the complexity inherent in the creation of long-form, factual text.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "ウィキペディアにおける伝記の生成：女性伝記の検索ベース生成におけるジェンダーバイアスの影響", "jabstract": "Wikipediaの記事のような事実に基づく長文テキストを生成することは、関連する証拠を収集する方法、情報を適切な形式のテキストに構造化する方法、生成されたテキストが事実に基づいていることを確認する方法の3つの主要な課題を提起します。私たちは、ウェブ上で関連する支援情報を特定するための検索機構を使用する英語テキストのモデルを開発し、キャッシュベースの事前学習エンコーダ・デコーダを使用して、引用情報を含む長い伝記をセクションごとに生成することでこれらの課題に対処します。利用可能なウェブ証拠が出力テキストに与える影響を評価するために、女性に関する伝記（ウェブ上で利用可能な情報が少ない）と一般的な伝記を生成する場合のアプローチのパフォーマンスを比較します。このために、1,500の女性に関する伝記のデータセットを編成します。生成されたテキストの違いがどのように影響するかを理解するために、生成されたテキストを分析します。自動メトリックと人間の評価を使用して、生成されたテキストの事実性、流暢性、品質を評価します。これらの技術が、長文の事実に基づくテキストの作成に固有の複雑さを軽減するために、人間の作家の出発点として使用されることを望んでいます。"}
{"title": "Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset", "url": "https://aclanthology.org/2022.acl-long.587/", "abstract": "Handing in a paper or exercise and merely receiving “bad” or “incorrect” as feedback is not very helpful when the goal is to improve. Unfortunately, this is currently the kind of feedback given by Automatic Short Answer Grading (ASAG) systems. One of the reasons for this is a lack of content-focused elaborated feedback datasets. To encourage research on explainable and understandable feedback systems, we present the Short Answer Feedback dataset (SAF). Similar to other ASAG datasets, SAF contains learner responses and reference answers to German and English questions. However, instead of only assigning a label or score to the learners’ answers, SAF also contains elaborated feedback explaining the given score. Thus, SAF enables supervised training of models that grade answers and explain where and why mistakes were made. This paper discusses the need for enhanced feedback models in real-world pedagogical scenarios, describes the dataset annotation process, gives a comprehensive analysis of SAF, and provides T5-based baselines for future comparison.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "あなたの回答は正しくありません...なぜか知りたいですか？バイリンガル短い回答フィードバックデータセットの紹介\n\nこの論文は、自然言語処理に関するものです。", "jabstract": "論文や演習を提出し、「悪い」または「間違っている」というフィードバックを受け取るだけでは、改善するためにはあまり役に立ちません。残念ながら、自動短答評価（ASAG）システムが提供するのはこの種のフィードバックです。その理由の1つは、コンテンツに焦点を当てた詳細なフィードバックデータセットが不足していることです。説明可能で理解しやすいフィードバックシステムの研究を促進するために、私たちは短答フィードバックデータセット（SAF）を提供します。SAFは、他のASAGデータセットと同様に、ドイツ語と英語の質問に対する学習者の回答と参照回答を含んでいます。ただし、SAFは、学習者の回答にラベルまたはスコアを割り当てるだけでなく、与えられたスコアを説明する詳細なフィードバックも含んでいます。したがって、SAFは、回答を評価し、どこでどのような間違いがあったかを説明するモデルの監視付きトレーニングを可能にします。本論文では、現実の教育シナリオでの強化されたフィードバックモデルの必要性について説明し、データセットの注釈プロセスを説明し、SAFの包括的な分析を提供し、将来の比較のためのT5ベースラインを提供します。"}
{"title": "Towards Better Characterization of Paraphrases", "url": "https://aclanthology.org/2022.acl-long.588/", "abstract": "To effectively characterize the nature of paraphrase pairs without expert human annotation, we proposes two new metrics: word position deviation (WPD) and lexical deviation (LD). WPD measures the degree of structural alteration, while LD measures the difference in vocabulary used. We apply these metrics to better understand the commonly-used MRPC dataset and study how it differs from PAWS, another paraphrase identification dataset. We also perform a detailed study on MRPC and propose improvements to the dataset, showing that it improves generalizability of models trained on the dataset. Lastly, we apply our metrics to filter the output of a paraphrase generation model and show how it can be used to generate specific forms of paraphrases for data augmentation or robustness testing of NLP models.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「類義語のより良い特徴付けに向けて」", "jabstract": "専門家の人手注釈なしで、言い換えペアの性質を効果的に特徴付けるために、私たちは2つの新しいメトリック、単語位置偏差（WPD）と語彙偏差（LD）を提案します。WPDは構造の変更の程度を測定し、LDは使用される語彙の違いを測定します。これらのメトリックを適用して、一般的に使用されるMRPCデータセットをよりよく理解し、別の言い換え識別データセットであるPAWSとどのように異なるかを研究します。また、MRPCについて詳細な研究を行い、データセットの改善を提案し、データセットで訓練されたモデルの汎用性が向上することを示します。最後に、私たちは言い換え生成モデルの出力をフィルタリングするために私たちのメトリックを適用し、NLPモデルのデータ拡張または堅牢性テストのために特定の形式の言い換えを生成する方法を示します。"}
{"title": "SummScreen: A Dataset for Abstractive Screenplay Summarization", "url": "https://aclanthology.org/2022.acl-long.589/", "abstract": "We introduce SummScreen, a summarization dataset comprised of pairs of TV series transcripts and human written recaps. The dataset provides a challenging testbed for abstractive summarization for several reasons. Plot details are often expressed indirectly in character dialogues and may be scattered across the entirety of the transcript. These details must be found and integrated to form the succinct plot descriptions in the recaps. Also, TV scripts contain content that does not directly pertain to the central plot but rather serves to develop characters or provide comic relief. This information is rarely contained in recaps. Since characters are fundamental to TV series, we also propose two entity-centric evaluation metrics. Empirically, we characterize the dataset by evaluating several methods, including neural models and those based on nearest neighbors. An oracle extractive approach outperforms all benchmarked models according to automatic metrics, showing that the neural models are unable to fully exploit the input transcripts. Human evaluation and qualitative analysis reveal that our non-oracle models are competitive with their oracle counterparts in terms of generating faithful plot events and can benefit from better content selectors. Both oracle and non-oracle models generate unfaithful facts, suggesting future research directions.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "SummScreen：抽象的な脚本要約のためのデータセット", "jabstract": "私たちは、テレビシリーズのトランスクリプトと人間による要約のペアから構成される要約データセットであるSummScreenを紹介します。このデータセットは、いくつかの理由から抽象的な要約に対する厳しいテストベッドを提供します。プロットの詳細は、キャラクターの対話で間接的に表現され、トランスクリプト全体に散らばっている場合があります。これらの詳細を見つけ出し、要約で簡潔なプロットの説明を形成する必要があります。また、テレビの脚本には、中心的なプロットとは直接関係のないキャラクターの発展やコミックリリーフを提供するコンテンツが含まれています。この情報は、要約にはほとんど含まれていません。キャラクターがテレビシリーズの基本であるため、私たちは2つのエンティティ中心の評価メトリックを提案しています。実証的には、ニューラルモデルや最近傍に基づくモデルを含むいくつかの方法を評価することで、データセットを特徴付けます。オラクル抽出アプローチは、自動メトリックによると、すべてのベンチマークモデルを上回り、ニューラルモデルが入力トランスクリプトを十分に活用できないことを示しています。人間の評価と質的分析により、私たちの非オラクルモデルは、忠実なプロットイベントを生成する点でオラクルモデルと競合し、より良いコンテンツセレクターから利益を得ることができることがわかりました。オラクルモデルと非オラクルモデルの両方が不忠実な事実を生成することから、将来の研究方向が示唆されています。"}
{"title": "Sparsifying Transformer Models with Trainable Representation Pooling", "url": "https://aclanthology.org/2022.acl-long.590/", "abstract": "We propose a novel method to sparsify attention in the Transformer model by learning to select the most-informative token representations during the training process, thus focusing on the task-specific parts of an input. A reduction of quadratic time and memory complexity to sublinear was achieved due to a robust trainable top-k operator.Our experiments on a challenging long document summarization task show that even our simple baseline performs comparably to the current SOTA, and with trainable pooling we can retain its top quality, while being 1.8× faster during training, 4.5× faster during inference, and up to 13× more computationally efficient in the decoder.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "トレーニング可能な表現プーリングを用いたTransformerモデルのスパース化", "jabstract": "私たちは、Transformerモデルの注意を疎にするための新しい方法を提案します。トレーニングプロセス中に最も情報量の多いトークン表現を選択することを学習することで、入力のタスク固有の部分に焦点を当てます。堅牢なトレーニング可能なトップk演算子により、二次時間およびメモリの複雑さを亜線形に削減しました。私たちの難しい長文要約タスクにおける実験では、単純なベースラインでも現在のSOTAと同等のパフォーマンスを発揮し、トレーニング中に1.8倍、推論中に4.5倍、デコーダーで最大13倍の計算効率を維持しながら、トレーニング中に1.8倍、推論中に4.5倍、デコーダーで最大13倍の計算効率を維持することができます。"}
{"title": "Uncertainty Determines the Adequacy of the Mode and the Tractability of Decoding in Sequence-to-Sequence Models", "url": "https://aclanthology.org/2022.acl-long.591/", "abstract": "In many natural language processing (NLP) tasks the same input (e.g. source sentence) can have multiple possible outputs (e.g. translations). To analyze how this ambiguity (also known as intrinsic uncertainty) shapes the distribution learned by neural sequence models we measure sentence-level uncertainty by computing the degree of overlap between references in multi-reference test sets from two different NLP tasks: machine translation (MT) and grammatical error correction (GEC). At both the sentence- and the task-level, intrinsic uncertainty has major implications for various aspects of search such as the inductive biases in beam search and the complexity of exact search. In particular, we show that well-known pathologies such as a high number of beam search errors, the inadequacy of the mode, and the drop in system performance with large beam sizes apply to tasks with high level of ambiguity such as MT but not to less uncertain tasks such as GEC. Furthermore, we propose a novel exact n-best search algorithm for neural sequence models, and show that intrinsic uncertainty affects model uncertainty as the model tends to overly spread out the probability mass for uncertain tasks and sentences.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "不確実性は、シーケンス・トゥ・シーケンス・モデルの適切性とデコーディングの扱いやすさを決定する。", "jabstract": "自然言語処理（NLP）の多くのタスクでは、同じ入力（例：ソース文）に対して複数の可能な出力（例：翻訳）が存在する。ニューラルシーケンスモデルが学習する分布にこの曖昧さ（内在的不確実性とも呼ばれる）がどのように影響するかを分析するために、我々は2つの異なるNLPタスク、機械翻訳（MT）と文法エラー訂正（GEC）のマルチリファレンステストセットのリファレンス間の重複度を計算して、文レベルの不確実性を測定する。文レベルとタスクレベルの両方で、内在的不確実性は、ビームサーチの帰納的なバイアスや正確な検索の複雑さなど、検索のさまざまな側面に重大な影響を与える。特に、高い曖昧性を持つMTなどのタスクに適用されるビームサーチエラーの高い数、モードの不適切さ、および大きなビームサイズでのシステム性能の低下などのよく知られた病理学が、より不確実性の低いGECなどのタスクには適用されないことを示す。さらに、我々はニューラルシーケンスモデルのための新しい正確なn-best検索アルゴリズムを提案し、内在的不確実性がモデルの不確実性に影響を与えることを示し、モデルが不確実なタスクや文に対して確率質量を過剰に広げる傾向があることを示す。"}
{"title": "FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning", "url": "https://aclanthology.org/2022.acl-long.592/", "abstract": "Most previous methods for text data augmentation are limited to simple tasks and weak baselines. We explore data augmentation on hard tasks (i.e., few-shot natural language understanding) and strong baselines (i.e., pretrained models with over one billion parameters). Under this setting, we reproduced a large number of previous augmentation methods and found that these methods bring marginal gains at best and sometimes degrade the performance much. To address this challenge, we propose a novel data augmentation method FlipDA that jointly uses a generative model and a classifier to generate label-flipped data. Central to the idea of FlipDA is the discovery that generating label-flipped data is more crucial to the performance than generating label-preserved data. Experiments show that FlipDA achieves a good tradeoff between effectiveness and robustness—it substantially improves many tasks while not negatively affecting the others.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "FlipDA: 効果的かつ堅牢なデータ拡張法によるフューショット学習", "jabstract": "テキストデータ拡張の以前の方法は、単純なタスクと弱いベースラインに限定されていた。我々は、ハードなタスク（つまり、フューショット自然言語理解）と強力なベースライン（つまり、10億以上のパラメータを持つ事前学習モデル）でデータ拡張を探求した。この設定下で、我々は多数の以前の拡張方法を再現し、これらの方法が最大でもわずかな利益をもたらし、時には性能を低下させることがわかった。この課題に対処するために、我々は、生成モデルと分類器を共同して使用してラベル反転データを生成する新しいデータ拡張方法FlipDAを提案する。FlipDAのアイデアの中心は、ラベル反転データを生成することが、ラベル保存データを生成することよりも性能にとってより重要であることを発見したことである。実験結果は、FlipDAが効果と堅牢性の間の良好なトレードオフを実現し、多くのタスクを大幅に改善する一方で、他のタスクに悪影響を与えないことを示している。"}
{"title": "Text-Free Prosody-Aware Generative Spoken Language Modeling", "url": "https://aclanthology.org/2022.acl-long.593/", "abstract": "Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored. Generative Spoken Language Modeling (GSLM) (CITATION) is the only prior work addressing the generative aspect of speech pre-training, which builds a text-free language model using discovered units. Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech. In this work, we present a prosody-aware generative spoken language model (pGSLM). It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms. Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. Audio samples can be found at https://speechbot.github.io/pgslm. Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "テキストフリーの韻律意識を持った生成的な話し言語モデリングに関する論文の要約です。", "jabstract": "音声の事前学習は、主に分類タスクでの有効性が示されてきましたが、GPT-2が連続した段落を生成するように、新しい音声を生成する能力はほとんど探求されていませんでした。Generative Spoken Language Modeling（GSLM）（引用）は、発見されたユニットを使用してテキストフリーの言語モデルを構築することで、音声の生成側面に対処する唯一の先行研究です。残念ながら、GSLMで使用されるユニットは、ほとんどの韻律情報を破棄するため、GSLMは韻律を活用してより良い理解を促進することができず、表現力豊かな音声を生成することができません。本研究では、韻律に注意を払った音声生成言語モデル（pGSLM）を提案します。これは、発見されたユニットと韻律特徴ストリームから構成される音声のマルチストリームトランスフォーマーランゲージモデル（MS-TLM）と、MS-TLMの出力を波形に変換する適応型HiFi-GANモデルから構成されています。実験結果は、pGSLMが韻律を利用して韻律と内容のモデリングを改善し、話し言葉のプロンプトが与えられた場合に自然で意味のある、つながりのある音声を生成できることを示しています。オーディオサンプルはhttps://speechbot.github.io/pgslmで入手できます。コードとモデルはhttps://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslmで入手できます。"}
{"title": "Lite Unified Modeling for Discriminative Reading Comprehension", "url": "https://aclanthology.org/2022.acl-long.594/", "abstract": "As a broad and major category in machine reading comprehension (MRC), the generalized goal of discriminative MRC is answer prediction from the given materials. However, the focuses of various discriminative MRC tasks may be diverse enough: multi-choice MRC requires model to highlight and integrate all potential critical evidence globally; while extractive MRC focuses on higher local boundary preciseness for answer extraction. Among previous works, there lacks a unified design with pertinence for the overall discriminative MRC tasks. To fill in above gap, we propose a lightweight POS-Enhanced Iterative Co-Attention Network (POI-Net) as the first attempt of unified modeling with pertinence, to handle diverse discriminative MRC tasks synchronously. Nearly without introducing more parameters, our lite unified design brings model significant improvement with both encoder and decoder components. The evaluation results on four discriminative MRC benchmarks consistently indicate the general effectiveness and applicability of our model, and the code is available at https://github.com/Yilin1111/poi-net.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\nLite Unified Modeling for Discriminative Reading Comprehension\n\n識別的読解のための軽量統合モデリング", "jabstract": "機械読解（MRC）の広範で主要なカテゴリーである識別的MRCの一般的な目標は、与えられた資料からの回答予測である。しかし、さまざまな識別的MRCタスクの焦点は十分に多様である可能性がある。多肢選択MRCは、モデルがすべての潜在的な重要な証拠をグローバルに強調して統合する必要がある一方、抽出型MRCは回答抽出のためのより高い局所的境界精度に焦点を当てている。以前の研究の中で、全体的な識別的MRCタスクに関連性のある統一された設計が欠けている。このギャップを埋めるために、我々は軽量なPOS-Enhanced Iterative Co-Attention Network（POI-Net）を提案し、多様な識別的MRCタスクを同期的に処理するための最初の試みとして、関連性を持つ統一モデリングを行います。ほとんどパラメータを導入せずに、私たちの軽量な統一設計は、エンコーダーとデコーダーの両方でモデルの重要な改善をもたらします。4つの識別的MRCベンチマークの評価結果は、私たちのモデルの一般的な有効性と適用可能性を一貫して示しており、コードはhttps://github.com/Yilin1111/poi-netで利用可能です。"}
{"title": "Bilingual alignment transfers to multilingual alignment for unsupervised parallel text mining", "url": "https://aclanthology.org/2022.acl-long.595/", "abstract": "This work presents methods for learning cross-lingual sentence representations using paired or unpaired bilingual texts. We hypothesize that the cross-lingual alignment strategy is transferable, and therefore a model trained to align only two languages can encode multilingually more aligned representations. We thus introduce dual-pivot transfer: training on one language pair and evaluating on other pairs. To study this theory, we design unsupervised models trained on unpaired sentences and single-pair supervised models trained on bitexts, both based on the unsupervised language model XLM-R with its parameters frozen. The experiments evaluate the models as universal sentence encoders on the task of unsupervised bitext mining on two datasets, where the unsupervised model reaches the state of the art of unsupervised retrieval, and the alternative single-pair supervised model approaches the performance of multilingually supervised models. The results suggest that bilingual training techniques as proposed can be applied to get sentence representations with multilingual alignment.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "バイリンガルアラインメントは、教師なしの並列テキストマイニングのための多言語アラインメントに転換されます。", "jabstract": "この論文では、対訳または非対訳のバイリンガルテキストを使用して、クロスリンガルな文表現を学習する方法を提案しています。私たちは、クロスリンガルなアラインメント戦略が転移可能であると仮定し、2つの言語のみをアラインメントするためにトレーニングされたモデルは、より多言語的にアラインされた表現をエンコードできると考えています。したがって、私たちはデュアルピボット転送を導入し、1つの言語ペアでトレーニングして他のペアで評価します。この理論を研究するために、非対訳の文に基づく教師なしモデルとバイリンガルテキストに基づく単一ペア教師ありモデルの両方を設計し、そのパラメータを凍結した教師なし言語モデルXLM-Rに基づいています。実験では、2つのデータセットで教師なしビットキストマイニングのタスクでモデルをユニバーサル文エンコーダーとして評価し、教師なしモデルは教師なし検索の最先端に到達し、代替の単一ペア教師ありモデルは多言語教師ありモデルの性能に近づいています。結果は、提案されたバイリンガルトレーニング技術を適用して、多言語アラインメントを持つ文表現を取得できることを示唆しています。"}
{"title": "End-to-End Modeling via Information Tree for One-Shot Natural Language Spatial Video Grounding", "url": "https://aclanthology.org/2022.acl-long.596/", "abstract": "Natural language spatial video grounding aims to detect the relevant objects in video frames with descriptive sentences as the query. In spite of the great advances, most existing methods rely on dense video frame annotations, which require a tremendous amount of human effort. To achieve effective grounding under a limited annotation budget, we investigate one-shot video grounding and learn to ground natural language in all video frames with solely one frame labeled, in an end-to-end manner. One major challenge of end-to-end one-shot video grounding is the existence of videos frames that are either irrelevant to the language query or the labeled frame. Another challenge relates to the limited supervision, which might result in ineffective representation learning. To address these challenges, we designed an end-to-end model via Information Tree for One-Shot video grounding (IT-OS). Its key module, the information tree, can eliminate the interference of irrelevant frames based on branch search and branch cropping techniques. In addition, several self-supervised tasks are proposed based on the information tree to improve the representation learning under insufficient labeling. Experiments on the benchmark dataset demonstrate the effectiveness of our model.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「ワンショット自然言語空間ビデオグラウンディングのための情報ツリーを介したエンドツーエンドモデリング」に関する論文の要約文です。\n\n- End-to-End Modeling: エンドツーエンドモデリング\n- via Information Tree: 情報ツリーを介して\n- for One-Shot Natural Language Spatial Video Grounding: ワンショット自然言語空間ビデオグラウンディングのために", "jabstract": "自然言語空間ビデオグラウンディングは、記述的な文をクエリとして使用し、ビデオフレーム内の関連するオブジェクトを検出することを目的としています。多くの既存の方法は、膨大な人的労力を必要とする密なビデオフレーム注釈に依存しているため、限られた注釈予算の下で効果的なグラウンディングを実現するために、我々はワンショットビデオグラウンディングを調査し、エンドツーエンドの方法で単一のフレームのみをラベル付けし、すべてのビデオフレームで自然言語をグラウンドすることを学びます。エンドツーエンドのワンショットビデオグラウンディングの主な課題は、言語クエリまたはラベル付けされたフレームに関係のないビデオフレームが存在することです。また、限られた監視下では、効果的な表現学習ができない可能性があります。これらの課題に対処するために、情報ツリーを使用したエンドツーエンドのモデルを設計しました。情報ツリーは、枝検索と枝切り技術に基づいて、関係のないフレームの干渉を排除することができます。さらに、情報ツリーに基づくいくつかの自己監督タスクを提案し、不十分なラベリングの下で表現学習を改善します。ベンチマークデータセットでの実験は、当社のモデルの有効性を示しています。"}
{"title": "RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization", "url": "https://aclanthology.org/2022.acl-long.597/", "abstract": "A release note is a technical document that describes the latest changes to a software product and is crucial in open source software development. However, it still remains challenging to generate release notes automatically. In this paper, we present a new dataset called RNSum, which contains approximately 82,000 English release notes and the associated commit messages derived from the online repositories in GitHub. Then, we propose classwise extractive-then-abstractive/abstractive summarization approaches to this task, which can employ a modern transformer-based seq2seq network like BART and can be applied to various repositories without specific constraints. The experimental results on the RNSum dataset show that the proposed methods can generate less noisy release notes at higher coverage than the baselines. We also observe that there is a significant gap in the coverage of essential information when compared to human references. Our dataset and the code are publicly available.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "RNSum：コミットログの要約による自動リリースノート生成のための大規模データセット", "jabstract": "リリースノートは、ソフトウェア製品の最新の変更内容を説明する技術文書であり、オープンソースソフトウェア開発において重要です。しかし、自動的にリリースノートを生成することはまだ困難です。本論文では、GitHubのオンラインリポジトリから派生した約82,000の英語のリリースノートと関連するコミットメッセージを含む新しいデータセットであるRNSumを提案します。そして、特定の制約なしにさまざまなリポジトリに適用できる、BARTのような現代のトランスフォーマーベースのseq2seqネットワークを使用できる、クラスごとの抽出-要約/要約アプローチを提案します。RNSumデータセット上の実験結果は、提案手法がベースラインよりも高いカバレッジでノイズの少ないリリースノートを生成できることを示しています。また、人間のリファレンスと比較した場合、必要な情報のカバレッジには大きなギャップがあることも観察されました。私たちのデータセットとコードは公開されています。"}
{"title": "Improving Machine Reading Comprehension with Contextualized Commonsense Knowledge", "url": "https://aclanthology.org/2022.acl-long.598/", "abstract": "To perform well on a machine reading comprehension (MRC) task, machine readers usually require commonsense knowledge that is not explicitly mentioned in the given documents. This paper aims to extract a new kind of structured knowledge from scripts and use it to improve MRC. We focus on scripts as they contain rich verbal and nonverbal messages, and two relevant messages originally conveyed by different modalities during a short time period may serve as arguments of a piece of commonsense knowledge as they function together in daily communications. To save human efforts to name relations, we propose to represent relations implicitly by situating such an argument pair in a context and call it contextualized knowledge. To use the extracted knowledge to improve MRC, we compare several fine-tuning strategies to use the weakly-labeled MRC data constructed based on contextualized knowledge and further design a teacher-student paradigm with multiple teachers to facilitate the transfer of knowledge in weakly-labeled MRC data. Experimental results show that our paradigm outperforms other methods that use weakly-labeled data and improves a state-of-the-art baseline by 4.3% in accuracy on a Chinese multiple-choice MRC dataset C3, wherein most of the questions require unstated prior knowledge. We also seek to transfer the knowledge to other tasks by simply adapting the resulting student reader, yielding a 2.9% improvement in F1 on a relation extraction dataset DialogRE, demonstrating the potential usefulness of the knowledge for non-MRC tasks that require document comprehension.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「文脈化された常識的知識を用いた機械読解の改善」に関する論文の要旨は以下の通りです。", "jabstract": "機械読解タスクにおいて高い性能を発揮するためには、機械リーダーは通常、与えられた文書に明示的に記載されていない常識的な知識が必要です。本論文では、スクリプトから新しい種類の構造化された知識を抽出し、MRCを改善することを目的としています。スクリプトに焦点を当てる理由は、豊富な言語的および非言語的メッセージを含んでおり、短時間内に異なるモダリティで伝えられた2つの関連メッセージは、日常のコミュニケーションにおいて一緒に機能するため、常識的な知識の引数として機能する可能性があるためです。関係を命名するための人間の労力を節約するために、我々はそのような引数ペアを文脈に配置して暗黙的に関係を表現することを提案し、これを文脈化された知識と呼びます。抽出された知識をMRCの改善に使用するために、文脈化された知識に基づいて構築された弱くラベル付けされたMRCデータを使用するためのいくつかの微調整戦略を比較し、複数の教師を持つ教師-生徒パラダイムを設計して、弱くラベル付けされたMRCデータの知識の転移を促進します。実験結果は、我々のパラダイムが弱くラベル付けされたデータを使用する他の方法よりも優れており、中国語の多肢選択MRCデータセットC3において、事前に述べられていない知識が必要な質問がほとんどである場合に、最新のベースラインを4.3%の精度で改善することを示しています。また、結果として得られた生徒リーダーを単純に適応することで、知識を他のタスクに転移することも試み、関係抽出データセットDialogREにおいてF1を2.9%改善し、文書理解が必要なMRC以外のタスクにおいて知識の潜在的な有用性を示しています。"}
{"title": "Modeling Persuasive Discourse to Adaptively Support Students’ Argumentative Writing", "url": "https://aclanthology.org/2022.acl-long.599/", "abstract": "We introduce an argumentation annotation approach to model the structure of argumentative discourse in student-written business model pitches. Additionally, the annotation scheme captures a series of persuasiveness scores such as the specificity, strength, evidence, and relevance of the pitch and the individual components. Based on this scheme, we annotated a corpus of 200 business model pitches in German. Moreover, we trained predictive models to detect argumentative discourse structures and embedded them in an adaptive writing support system for students that provides them with individual argumentation feedback independent of an instructor, time, and location. We evaluated our tool in a real-world writing exercise and found promising results for the measured self-efficacy and perceived ease-of-use. Finally, we present our freely available corpus of persuasive business model pitches with 3,207 annotated sentences in German language and our annotation guidelines.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "学生の論述的な文章作成を適応的にサポートするための説得的な論述のモデリング", "jabstract": "私たちは、学生が書いたビジネスモデルのピッチにおける議論的な論述の構造をモデル化するための議論注釈アプローチを紹介します。さらに、注釈スキームは、ピッチと個々のコンポーネントの特異性、強度、証拠、関連性などの一連の説得力スコアを捉えます。このスキームに基づいて、私たちは200のドイツ語のビジネスモデルピッチのコーパスを注釈付けしました。さらに、私たちは議論的な論述構造を検出するための予測モデルをトレーニングし、学生に個別の議論フィードバックを提供する適応型ライティングサポートシステムに埋め込みました。このシステムは、教師、時間、場所に依存せずに個別のフィードバックを提供します。私たちは、実際のライティング演習でツールを評価し、測定された自己効力感と知覚された使いやすさについて有望な結果を得ました。最後に、私たちは、3,207のドイツ語の注釈付きの説得力のあるビジネスモデルピッチの自由に利用可能なコーパスと注釈ガイドラインを提供します。"}
{"title": "Active Evaluation: Efficient NLG Evaluation with Few Pairwise Comparisons", "url": "https://aclanthology.org/2022.acl-long.600/", "abstract": "Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment. Given k systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all k \\choose 2 pairs of systems. However, this can be very expensive as the number of human annotations required would grow quadratically with k. In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms. We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80%. To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations. Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain. This reduces the number of human annotations required further by 89%. In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with k. Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently. Our code has been made publicly available at https://github.com/akashkm99/duelnlg", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "アクティブ評価：少数のペアワイズ比較で効率的なNLG評価", "jabstract": "最近の研究では、直接評価に代わってペアワイズ比較を使用してNLGシステムを評価する利点が示されています。 k個のシステムが与えられた場合、トップランクのシステムを特定するための素朴なアプローチは、すべてのk \\choose 2ペアのシステムからペアワイズ比較を均等に取得することです。しかし、これはkの2乗に比例して人間の注釈が必要になるため、非常に高価になる可能性があります。本研究では、デュエリングバンディットアルゴリズムを使用してシステムペアを選択することにより、効率的にトップランクのシステムを特定するActive Evaluationフレームワークを紹介します。5つのタスクをカバーする13のNLG評価データセットで13のデュエリングバンディットアルゴリズムで広範な実験を行い、人間の注釈の数を80％削減できることを示します。さらに、自動評価メトリックと人間の評価を組み合わせたモデルベースのデュエリングバンディットアルゴリズムを提案し、人間の注釈の数を89％削減します。結果として、トップランクのシステムを特定するには、kに比例して線形に増加するわずか数百の人間の注釈が必要であることを示します。最後に、トップランクのシステムを効率的に特定するための実用的な推奨事項とベストプラクティスを提供します。私たちのコードはhttps://github.com/akashkm99/duelnlgで公開されています。"}
{"title": "The Moral Debater: A Study on the Computational Generation of Morally Framed Arguments", "url": "https://aclanthology.org/2022.acl-long.601/", "abstract": "An audience’s prior beliefs and morals are strong indicators of how likely they will be affected by a given argument. Utilizing such knowledge can help focus on shared values to bring disagreeing parties towards agreement. In argumentation technology, however, this is barely exploited so far. This paper studies the feasibility of automatically generating morally framed arguments as well as their effect on different audiences. Following the moral foundation theory, we propose a system that effectively generates arguments focusing on different morals. In an in-depth user study, we ask liberals and conservatives to evaluate the impact of these arguments. Our results suggest that, particularly when prior beliefs are challenged, an audience becomes more affected by morally framed arguments.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "「道徳的な論者：道徳的な枠組みでの議論の計算生成に関する研究」という論文の要約です。", "jabstract": "聴衆の先行信念と道徳は、与えられた議論にどの程度影響を受けるかの強い指標である。このような知識を利用することで、異なる意見を持つ当事者を合意に向けるために共有される価値観に焦点を当てることができる。しかし、議論技術においては、これがほとんど活用されていない。本論文では、道徳的に枠組まれた議論を自動生成することの可能性と、異なる聴衆に与える影響について研究する。道徳的基盤理論に従い、異なる道徳に焦点を当てた議論を効果的に生成するシステムを提案する。詳細なユーザースタディにおいて、リベラル派と保守派にこれらの議論の影響を評価してもらった。その結果、先行信念が挑戦された場合には、道徳的に枠組まれた議論により聴衆がより影響を受けることが示唆された。"}
{"title": "Pyramid-BERT: Reducing Complexity via Successive Core-set based Token Selection", "url": "https://aclanthology.org/2022.acl-long.602/", "abstract": "Transformer-based language models such as BERT (CITATION) have achieved the state-of-the-art performance on various NLP tasks, but are computationally prohibitive. A recent line of works use various heuristics to successively shorten sequence length while transforming tokens through encoders, in tasks such as classification and ranking that require a single token embedding for prediction.We present a novel solution to this problem, called Pyramid-BERT where we replace previously used heuristics with a core-set based token selection method justified by theoretical results. The core-set based token selection technique allows us to avoid expensive pre-training, gives a space-efficient fine tuning, and thus makes it suitable to handle longer sequence lengths. We provide extensive experiments establishing advantages of pyramid BERT over several baselines and existing works on the GLUE benchmarks and Long Range Arena (CITATION) datasets.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "Pyramid-BERT：連続したコアセットベースのトークン選択による複雑さの削減", "jabstract": "Transformerベースの言語モデル、例えばBERTは、様々なNLPタスクで最先端の性能を発揮していますが、計算上の制約があります。最近の研究では、シングルトークンの埋め込みを予測する分類やランキングのタスクで、エンコーダを通してトークンを変換しながらシーケンス長を段階的に短くするための様々なヒューリスティックを使用しています。本論文では、理論的な結果に基づくコアセットベースのトークン選択方法で以前に使用されていたヒューリスティックを置き換えたPyramid-BERTという問題の新しい解決策を提案します。コアセットベースのトークン選択技術により、高価な事前学習を回避し、スペース効率の良いファインチューニングを実現し、より長いシーケンス長を扱うことができます。GLUEベンチマークとLong Range ArenaデータセットにおけるPyramid-BERTの複数のベースラインや既存の研究に対する優位性を確立するための広範な実験を提供します。"}
{"title": "Probing for the Usage of Grammatical Number", "url": "https://aclanthology.org/2022.acl-long.603/", "abstract": "A central quest of probing is to uncover how pre-trained models encode a linguistic property within their representations. An encoding, however, might be spurious—i.e., the model might not rely on it when making predictions. In this paper, we try to find an encoding that the model actually uses, introducing a usage-based probing setup. We first choose a behavioral task which cannot be solved without using the linguistic property. Then, we attempt to remove the property by intervening on the model’s representations. We contend that, if an encoding is used by the model, its removal should harm the performance on the chosen behavioral task. As a case study, we focus on how BERT encodes grammatical number, and on how it uses this encoding to solve the number agreement task. Experimentally, we find that BERT relies on a linear encoding of grammatical number to produce the correct behavioral output. We also find that BERT uses a separate encoding of grammatical number for nouns and verbs. Finally, we identify in which layers information about grammatical number is transferred from a noun to its head verb.", "vol-title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "jtitle": "自然言語処理に関する論文の要約文を日本語に翻訳してください。\n\n文法的数の使用を調査するための探査", "jabstract": "プロービングの中心的な課題は、事前学習されたモデルがその表現内に言語的な特性をエンコードする方法を明らかにすることです。ただし、エンコードは偽物である可能性があります。つまり、モデルが予測を行う際にそれに依存しない可能性があります。本論文では、モデルが実際に使用するエンコードを見つけるために、使用ベースのプロービングセットアップを導入します。まず、言語的特性を使用しないと解決できない行動課題を選択します。次に、モデルの表現に介入して特性を削除しようとします。モデルがエンコードを使用している場合、その削除は選択した行動課題のパフォーマンスに悪影響を与えるはずだと主張します。ケーススタディとして、BERTが文法的数をどのようにエンコードし、このエンコードを使用して数の一致タスクを解決するかに焦点を当てます。実験的に、BERTが文法的数の線形エンコードを使用して正しい行動出力を生成することがわかりました。また、BERTが名詞と動詞の文法的数の別々のエンコードを使用していることもわかりました。最後に、どのレイヤーで名詞からその先頭動詞に文法的数の情報が転送されるかを特定します。"}
